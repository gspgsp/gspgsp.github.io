import{e as E,l as k,w as D,j as R,L as I,I as L,Q as $,_ as N,o as u,c as m,h as M,v as O,b as f,B as b,J as y,F as B,x,i as C,t as v,C as F}from"./app-CHrRue27.js";const U=[{path:"/",title:"",pathLocale:"/",contents:[]},{path:"/comment/",title:"",pathLocale:"/",contents:[]},{path:"/project/",title:"",pathLocale:"/",contents:[]},{path:"/tool/",title:"",pathLocale:"/",contents:[]},{path:"/project/symfony/part1.html",title:"",pathLocale:"/",contents:[{header:"本次课程组要是通过文档(部分通过git动画展示)的形讲解symfony7的使用",slug:"本次课程组要是通过文档-部分通过git动画展示-的形讲解symfony7的使用",content:""},{header:"1.为什么要写这个项目",slug:"_1-为什么要写这个项目",content:`其实之前一直使用的是laravel8(5.8)，自认为laravel项目很方便，很完善，功能也很强大，但是由于目前项目一直使用的是symfony, 于是也习惯使用了这个项目。在使用过程中，我发现了很多问题，和laravel最大的不同就是数据库的操作，
其次是配置，这两个使用起来可能会比较麻烦，当然这个是相对于laravel来讲的，习惯了就好。最后就是目前国内关于symfony7的使用的文档不是很多。`},{header:"2.环境准备",slug:"_2-环境准备",content:`Ubuntu22(本地系统)
Mysql8
PHP8
Symfony7
Docker(运行项目)`}]},{path:"/project/symfony/part2.html",title:"",pathLocale:"/",contents:[{header:"创建项目",slug:"创建项目",content:""},{header:"1.官方网站主要使用Symfony CLI 创建项目，但我还是习惯使用composer创建",slug:"_1-官方网站主要使用symfony-cli-创建项目-但我还是习惯使用composer创建",content:`1.如果需要创建一个传统的web项目，就运行如下命令
composer create-project symfony/skeleton:"7.2.x" my_project_directory
cd my_project_directory
composer require webapp 2。如果只需要创建一个为服务或者API项目，就只用运行如下命令
composer create-project symfony/skeleton:"7.2.x" my_project_directory`},{header:"2.项目结构如下",slug:"_2-项目结构如下",content:`my_project/
├── bin/
├── config/
│ ├── packages/
│ ├── routes/
│ ├── bundles.php
│ ├── preload.php
│ ├── routes.php
│ └── services.yaml
├── migrations/
├── public/
│ └── index.php
├── src/
│ ├── Controller/
│ ├── Entity/
│ ├── Repository/
│ └── Kernel.php
├── var/
│ ├── cache/
│ └── log/
├── vendor/
├── .env
├── .env.dev
├── composer.json
└── symfony.lock`},{header:"3.简单运行一下",slug:"_3-简单运行一下",content:""},{header:"在src/Controller下创建一个控制器LuckyController",slug:"在src-controller下创建一个控制器luckycontroller",content:`class LuckyController
{ #[Route('/lucky/number')] public function number(): Response { $number = random_int(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); }
}`},{header:"然后在浏览器下访问 /lucky/number, 正常情况下，页面上会输出 Lucky number: 52 等随机数",slug:"然后在浏览器下访问-lucky-number-正常情况下-页面上会输出-lucky-number-52-等随机数",content:""}]},{path:"/project/laravel/part1.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:`一、一万个美丽的未来，抵不上一个温暖的现在;每一个真实的现在，都是我们曾经幻想的未来，愿你爱上现在，梦见未来。 二、把体重留给爱的美食，把眼睛留给好风光，把等待留给一直寻觅的真心，把欢喜留给一次次突破障碍的勇敢，把拥抱留给永远不会离开的自己。 三、一件事你犹豫去不去做，那就是该立即动身做的。一个东西你犹豫买不买，那就是该买的。喜欢是非常难得的，尽管去争取你喜欢的，而不是费心找廉价点的替代品。对事物，对人都该如此。
四、对别人要求松一点，就不会总失望；对自己要求严一点，就不会总沮丧。 五、小时候的要求：吃好睡好学习好；长大了的期盼：吃饱睡饱卡里饱；小时候遇见困难，总希望超人出现；长大了遇见困难，却只靠自己摆平。人生坎坷，需坚强面对！ 六、当你珍惜自己的过去，满意自己的现在，乐观自己的未来时，你就站在了生活的最高处；当你明了成功不会造就你，失败不会击垮你，平淡不会淹没你时，你就站在了生命的最高处。
七、20岁那年买得起10岁那年买不起的玩具，又有什么意义呢？人生就是这样，错过了就再也回不来了。有些事，现在不做，以后再也不会做了。 八、人与人之间，多一份理解就会少一些误会；心与心之间，多一份包容就会少一些纷争。有些事，需忍，勿怒；有些人，需让，勿究。嘴上吃些亏又何妨，让他三分又如何。 九、真实的生活是，认真做好每一天你分内的事情。不索取目前与你无关的爱与远景。不纠缠于多余情绪和评断。不妄想，不在其中自我沉醉。不伤害，不与自己和他人为敌。不表演，也不相信他人的表演。
十、没必要让所有人知道真实的你，或者是你没有必要不停地向人说其实我是一个什么样的人。因为这是无效的，人们还是只会愿意看到他们希望看到的。 十一、人生有两条路，一条需要用心走，叫做梦想；一条需要用脚走，叫做现实。心走得太快，脚会迷路；脚走得太快，人会摔倒；心走得太慢，会苍白了现实；脚走得太慢，梦不会高飞。 十二、不要去听别人的忽悠，你人生的每一步都必须靠自己的能力完成。自己肚子里没有料，手上没本事，认识再多人也没用。人脉只会给你机会，但抓住机会还是要靠真本事。所以啊，修炼自己，比到处逢迎别人重要的多。
十三、人生苦短，不要把时间浪费在犹豫不决上，喜欢的东西就去买，喜欢的人就去追，不然你怎么知道你买不起又追不到。 十四、人有两只眼睛，全是平行的，所以应当平等看人；人的两只耳朵是分在两边的，所以不可偏听一面之词；人虽只有一颗心，然而有左右两个心房，所以做事不但要为自己想，也要为别人想。 十五、人人有副好面相，不一定有好心肠，有时眼睛一红，心就黑了，心一横，就把坏事做尽了；眼前得罪人不可怕，不知不觉中得罪人才最要命。所以，看人不能只看表面的微笑，要看背后才知全貌！
十六、无论你活成什么样子，背地里都会有人对你说三道四。不申辩、不计较、一笑了之，其实就是最好的蔑视。 十七、别试图去给年轻人讲经验，讲一万句不如你自己摔一跤，或许，眼泪教你做人，后悔帮你成长，疼痛才是最好的老师，人生该走的弯路，其实一米都少不了。 十八、这个世界没有那么多将心比心。你善良，他便得寸进尺，你软弱，他便狠心欺骗，你正直，他便道德压榨。把深情交付与错误的人，就别责怪这个社会不温暖。因为都是你的愚蠢才收获了伤害，所以你只需要变聪明就好了，而不是痴心妄想改变这个世界。
十九、得意时要看淡，失意时要看开。人生有许多东西是可以放下的。只有放得下，才能拿得起。多一些宽容，多一些大度，挥挥手，笑一笑，一切的不愉快都会成为过去。 二十、总有起风的清晨，总有暖和的午后，总有绚烂的黄昏，总有流星的夜晚。所以，保持顺其自然的心境，把握每一个瞬间，试着去做，去面对每一个昨天，今天和明天。 二一、在这个世界上，没有一劳永逸、完美无缺的选择。你不可能同时拥有春花和秋月，不可能同时拥有硕果和繁花。不可能所有的好处都是你的。你要学会权衡利弊，学会放弃一些什么，然后才可能得到些什么。你要学会接受命的残缺和悲哀，然后，心平气和。因为，这就是人生。`}]},{path:"/project/laravel/part2-1.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:"22222222------1"}]},{path:"/project/laravel/part2-2.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:"22222222------2"}]},{path:"/project/laravel/part3.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:"333333333"}]},{path:"/title/home/backend.html",title:"",pathLocale:"/",contents:[]},{path:"/title/home/frontend.html",title:"",pathLocale:"/",contents:[]},{path:"/title/home/maintenance.html",title:"",pathLocale:"/",contents:[]},{path:"/tool/base64encode/",title:"",pathLocale:"/",contents:[]},{path:"/tool/camesnaketransfer/",title:"",pathLocale:"/",contents:[]},{path:"/tool/caseConvert/",title:"",pathLocale:"/",contents:[]},{path:"/tool/codemirror6/",title:"",pathLocale:"/",contents:[]},{path:"/tool/color/",title:"",pathLocale:"/",contents:[]},{path:"/tool/diffcontent/",title:"",pathLocale:"/",contents:[]},{path:"/tool/diffview/",title:"",pathLocale:"/",contents:[]},{path:"/tool/emoji/",title:"",pathLocale:"/",contents:[]},{path:"/tool/exceldiff/",title:"",pathLocale:"/",contents:[]},{path:"/tool/favicon/",title:"",pathLocale:"/",contents:[]},{path:"/tool/hanzi/",title:"",pathLocale:"/",contents:[]},{path:"/tool/imgtopdf/",title:"",pathLocale:"/",contents:[]},{path:"/tool/jsonformat/",title:"",pathLocale:"/",contents:[]},{path:"/tool/markdown/",title:"",pathLocale:"/",contents:[]},{path:"/tool/md5encode/",title:"",pathLocale:"/",contents:[]},{path:"/tool/mohu/",title:"",pathLocale:"/",contents:[]},{path:"/tool/pdfDecryptor/",title:"",pathLocale:"/",contents:[]},{path:"/tool/pdfEncryptor/",title:"",pathLocale:"/",contents:[]},{path:"/tool/pdfWatermark/",title:"",pathLocale:"/",contents:[]},{path:"/tool/pdfmerge/",title:"",pathLocale:"/",contents:[]},{path:"/tool/qrcode/",title:"",pathLocale:"/",contents:[]},{path:"/tool/qrdecode/",title:"",pathLocale:"/",contents:[]},{path:"/tool/rmbuppercase/",title:"",pathLocale:"/",contents:[]},{path:"/tool/svg/",title:"",pathLocale:"/",contents:[]},{path:"/tool/timeformat/",title:"",pathLocale:"/",contents:[]},{path:"/tool/tokengenerator/",title:"",pathLocale:"/",contents:[]},{path:"/tool/unicodetransfer/",title:"",pathLocale:"/",contents:[]},{path:"/tool/urlencode/",title:"",pathLocale:"/",contents:[]},{path:"/tool/uuidgenerator/",title:"",pathLocale:"/",contents:[]},{path:"/tool/yamlformat/",title:"",pathLocale:"/",contents:[]},{path:"/content/database/mongodb/ubuntu22%E5%AE%89%E8%A3%85mongodb.html",title:"ubuntu22安装mongodb",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22下docker安装mongodb
//安装latest的社区版本
docker pull mongodb/mongodb-community-server // 普通启动
docker run --name mongodb -p 27017:27017 -d mongodb/mongodb-community-server:latest // 加参数，持久化和账号
docker run -d \\ --name mongodb-community \\ -p 27017:27017 \\ -v /usr/local/mongo-data:/data/db \\ -e MONGO_INITDB_ROOT_USERNAME=admin \\ -e MONGO_INITDB_ROOT_PASSWORD=admin123 \\ mongodb/mongodb-community-server:latest // 查看容器启动情况
docker container ls //客户端工具 Robo 3T is now Studio 3T
https://robomongo.org/
https://studio3t.com/download-thank-you/?OS=x64 我是ubuntu22系统，查看linux版本
$ lsb_release -dc
Description:	Ubuntu 22.04.2 LTS
Codename:	jammy 下载好以后(当前在/usr/local/下):
$ mv ~/Downloads/studio-3t-linux-x64.tar.gz ./
$ sudo tar zxvf studio-3t-linux-x64.tar.gz
tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'
studio-3t-linux-x64.sh 这是一个可执行脚本，添加执行权限:
$ sudo chmod +x studio-3t-linux-x64.sh 然后:
$ sudo ./studio-3t-linux-x64.sh
Unpacking JRE ...
Starting Installer ...
直接下一步，安装完成后(可以选择创建icon)，Studio 3T 通常会安装到默认路径（例如 /opt/studio-3t） 打开studio，需要登陆，直接google邮箱登陆了. 到此结束，不用安装官网的mongosh. 使用:
先通过studio链接启动的mongodb(使用这个uri: mongodb://admin:admin123@127.0.0.1:27017/admin)
链接成功之后默认有单个数据库 admin config local 下面是对mongo数据库的分析:`},{header:"MongoDB 默认包含以下三个系统数据库：",slug:"mongodb-默认包含以下三个系统数据库",content:`admin 功能: admin 数据库被认为是 MongoDB 的“全局”数据库，存储系统范围的配置。
如果向 admin 数据库添加用户并授予适当权限，该用户将拥有所有数据库的管理权限。 用途: 存储用户权限和角色信息。
配置系统级别的参数。 常用命令:use admin
db.system.users.find() // 查看用户信息 config 功能: 存储分片集群的信息（仅当启用了分片时有用）。
包含与分片相关的元数据，如分片键和分片分布。 用途: 仅用于分片模式的元数据存储。 注意: 在非分片模式下，这个数据库通常不需要直接访问或修改。 local 功能: 存储本地节点的特定信息。
数据不会在副本集中同步。 用途: 存储 Oplog（操作日志），用于副本集的复制。
本地配置或状态信息。 注意: 通常无需手动修改或删除此数据库中的内容。`},{header:"如何创建自定义数据库",slug:"如何创建自定义数据库",content:`MongoDB 不需要预先创建数据库，插入数据时会自动创建数据库。例如： 切换到新数据库（如 mydatabase）：
use mydatabase 插入一个集合和文档：
db.mycollection.insertOne({ name: "Alice", age: 25 }) 数据库 mydatabase 和集合 mycollection 将被自动创建。`},{header:"查询默认数据库中的内容",slug:"查询默认数据库中的内容",content:`查看默认数据库列表:
show dbs 输出：
admin 0.000GB
config 0.000GB
local 0.000GB 切换到 admin 数据库并查询用户:
use admin
db.system.users.find() 切换到 local 数据库并查看 Oplog（适用于副本集）:
use local
show collections
db.oplog.rs.find().limit(5).pretty()`},{header:"总结",slug:"总结",content:`admin: 系统范围管理和用户权限。
config: 分片集群元数据。
local: 本地节点的配置，不会在集群间复制。 如果你想创建自己的数据库或进行进一步操作，只需切换到你的目标数据库名称并开始插入数据即可！
贴一个node.js链接mongo：
const { MongoClient } = require('mongodb'); const uri = "mongodb://admin:admin123@127.0.0.1:27017/admin"; //这个url也可以作为studio链接mongo的uri const client = new MongoClient(uri); async function run() { try { await client.connect(); console.log("Connected to MongoDB!"); const db = client.db("test"); // 替换为你需要操作的数据库 const collection = db.collection("example"); // 替换为你的集合 const docs = await collection.find().toArray(); console.log(docs); } finally { await client.close(); }
} run().catch(console.error);`}]},{path:"/content/database/postgressql/postgressql%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.html",title:"postgressql的基本使用",pathLocale:"/",contents:[{header:"",slug:"",content:`postgressql的基本使用:
简单的几个使用sql语句：
select id,username from "user"; // 这个 user 表 一定要用 双引号引起来，不然查询报错 select * from "dict" left join "dict_type" on "dict".dict_type_id = "dict_type".id where "dict_type".id = 1; update "dict" set value = 2 where id = 1; // postgres 和mysql 一样 都有 distinct 函数，但是这个函数只能查所有select的字段同时不重复，为此 postgres
// 有一个distinct on 实现单个字段去重,如果加了 order by 那么第一个order by的字段 一定是 on 里面的字段，不然报错
select distinct on(dict_type_id)id, name, dict_type_id from "dict" order by dict_type_id desc, id desc; 关于 distinct on的官方介绍：
用法： DISTINCT ON ( expression [, …] ) keeps only the first row of each set of rows where the given expressions evaluate to equal. […]。 Note that the “first row” of each set is unpredictable unless ORDER BY is used to ensure that the desired row appears first. […]。 The DISTINCT ON expression(s) must match the leftmost ORDER BY expression(s)。 意思是DISTINCT ON ( expression [, …] )把记录根据[, …]的值进行分组，分组之后仅返回每一组的第一行。需要注意的是，如果你不指定ORDER BY子句，返回的第一条的不确定的。如果你使用了ORDER BY 子句，那么[, …]里面的值必须靠近ORDER BY子句的最左边。`}]},{path:"/content/database/mysql/mysql8%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0.html",title:"mysql8窗口函数",pathLocale:"/",contents:[{header:"mysql8窗口函数, 这只是其中两个窗口函数的使用，，我只是觉得比较方便，所以记录一下",slug:"mysql8窗口函数-这只是其中两个窗口函数的使用-我只是觉得比较方便-所以记录一下",content:`1.ROW_NUMBER
使用案例:
select * from (SELECT id, name, age, ROW_NUMBER() OVER (PARTITION BY age ORDER BY name DESC) AS rn
FROM users) as raw_data where rn<3; 主要实现功能:
用户按年龄分组，同时在每个组内按名字排序，只取每个组的前三位，这个和group by 有很大的不同，更方便 ROW_NUMBER 必须配合 OVER 使用 2.RANK
使用案例:
SELECT *
FROM ( SELECT *, RANK() OVER (PARTITION BY event_id ORDER BY price DESC) AS rnk FROM tickets
) AS t
WHERE rnk = 1; 主要实现功能:
按event_id分组，获取每个event_id组内加个最高的数据 二者很相似，但是对于price相同的时候，rank 会为相同排序值的行会获得相同的排名(同时会跳号，使用 DENSE_RANK 不会跳号)， 而ROW_NUMBER会连续编号（1、2、3、4...`}]},{path:"/content/database/mysql/mysql%E4%B8%ADtinytext%E7%AD%89%E5%90%84%E4%B8%AA%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3.html",title:"mysql中tinytext等各个类型详解",pathLocale:"/",contents:[{header:"",slug:"",content:`工作中或者面试中经常会问到mysql个数据类型后的数字的含义，现整理如下:
int smallint等数据类型括号中的数字含义: 类型
大小
范围(有符号)
范围(无符号)
使用场景 TINYINT
1字节
（-128，127）
（0，255）
Mimi小整数值 SMALLINT
2字节
（-32 768,32 767）
（0，65535）
小整数值 MEDIUMINT
3字节
（-8 388 608，8 388 607）
（0，16 777 215）
中整数值 INT
4字节
（）
（0，4 294 967 295）
整数值 BIGINT
8字节
（-9 233 372 036 854 775 808，9 223 372 036 854 775 807）
（0，18 446 744 073 709 551 615）
大整数值 这些类型，是定长的，其容量是不会随着后面的数字而变化的，比如int(6)和int(10)，都是一样的占4字节。tinyint(1)和tinyint(2)也都占用一个字节。 那么后面的6和10，有什么用呢。 数据类型（m）中的m不是表示的数据长度，而是表示数据在显示时显示的最小长度。tinyint(1) 这里的1表示的是 最短显示一个字符。tinyint(2) 这里的2表示的是 最短显示两个字符。 当字符长度（m）超过对应数据类型的最大表示范围时，相当于啥都没发生； 当字符长度（m）小于对应数据类型的表示范围时，就需要指定拿某个字符来填充，比如zerofill（表示用0填充）， 设置tinyint(2) zerofill 你插入1时他会显示01；设置tinyint(4) zerofill 你插入1时他会显示0001。 int smallint中括号中数字表示的是显示宽度。 char和varchar的区别:
CHAR(M)定义的列的长度为固定的，M取值可以为0～255之间，当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。
在存储或检索过程中不进⾏⼤⼩写转换。CHAR存储定长数据很⽅便，CHAR字段上的索引效率级⾼，⽐如定义char(10)，那么不论你存储的数据是否达到了10个字节，
都要占去10个字节的空间,不⾜的⾃动⽤空格填充。 VARCHAR(M)定义的列的长度为可变长字符串，M取值可以为0~65535之间，(VARCHAR的最⼤有效长度由最⼤⾏⼤⼩和使⽤的字符集确定。整体最⼤长度是65,532字节)。
VARCHAR值保存时只保存需要的字符数，另加⼀个字节来记录长度(如果列声明的长度超过255，则使⽤两个字节)。⽐如定义varchar(10)，如果存储的数据没有达到10
个字符数,VARCHAR值保存时不进⾏填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。 varchar存储变长数据，这里的变长其实就是指保存的值不进行填充，而是根据实际大小计算长度；char的固定长度，是因为可能需要填充空格达到定义的长度。
varchar和char括号中数字表示的是字符数。 关于varchar最大可存字符数的判断:
varchar的有效值范围为 0 ~ 65535个字节。为什么不能超过 65535 字节呢？因为MySQL限制了一条记录的最大长度就是 65535 字节。但是根据数据库不同的编码会有不同的结果： 基于报错信息，可以看出，对于utf8mb4字符集，M最大只能设置为16383个字符。对于utf8字符集，M最大只能设置为21845个字符。这两个数值是怎么计算出来的呢？ 在utf8mb4字符集中，最多需要4个字节来表示一个字符，所以 65535 / 4 = 16383 。而在utf8字符集中，最多需要3个字节来表示一个字符，所以 65535 / 3 = 21845。 由此来看，在设置 M 的大小时，起决定作用的并不是 M 的有效值范围（0 ~ 65535），而是 M * 字符集的最大字节数不能超过65535个字节。 当字符个数大于16383或者其它编码的最大值的时候，怎么存数据，可以使用 text和blob来存储:
TINYBLOB TINYTEXT
一个BLOB或TEXT列，最大长度为255(2^8-1)个字符。
BLOB TEXT
一个BLOB或TEXT列，最大长度为65535(2^16-1)个字符。//在utf8-mb4下不准确 MEDIUMBLOB MEDIUMTEXT
一个BLOB或TEXT列，最大长度为16777215(2^24-1)个字符。//在utf8-mb4下不准确
LONGBLOB LONGTEXT
一个BLOB或TEXT列，最大长度为4294967295(2^32-1)个字符。//在utf8-mb4下不准确 虽然上面的数据不准，但是有个规则是，如果定义的text或者blob，大于当前定义的长度，那么数据类型会自动转为下一个类型，比如text--->longtext text和blob的区别
两者的不同之处在于，blob存储的是二进制数据，没有排序规则或字符集，而text类型有字符集和排序规则。
另：mysql对blob和text列进行排序与其他类型是不同的：它只对每个列的最前max_sort_length字节而不是整个字符串做排序。如果只需要排序前面一小部分字符，则可以减小max_sort_length的配置，或者使用order by systring(column,length)。
mysql不能将blob和text全部长度的字符串进行索引，也不能使用这些索引消除排序。`}]},{path:"/content/database/mysql/mysql%E4%B9%8B5-7%E4%B8%8BTIMESTAMP%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC%E4%B8%BAnull%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"mysql之5-7下TIMESTAMP设置默认值为null的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql5.7下，之情迁移文件的时候报错:
1067 Invalid default value for 'created_at' (SQL: alter table d_slides modify column created_at TIMESTAMP DEFAULT NULL) 这个在mysql8下没有问题，但是在mysql5.7下有问题，还来发现需要把 /etc/my.cnf下的 mysqld 添加如下配置:
explicit_defaults_for_timestamp = ON
然后重启:
systemctl restart mysqld
再次执行迁移文件，没有任何问题
关于这个参数:
默认情况下,timestamp 类型字段所在数据行被更新时，该字段会自动更新为当前时间，而参数explicit_defaults_for_timestamp控制这一种行为。
explicit_defaults_for_timestamp=off，数据行更新时，timestamp类型字段更新为当前时间；
explicit_defaults_for_timestamp=on，数据行更新时，timestamp类型字段不更新为当前时间。`}]},{path:"/content/database/mysql/mysql%E4%B9%8B5.7%E5%92%8C8%E5%AF%BC%E6%95%B0%E6%8D%AE%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E7%94%B1%E4%BA%8E%E6%97%B6%E9%97%B4%E6%88%B3%E7%9A%84%E9%BB%98%E8%AE%A4%E6%A0%BC%E5%BC%8F%E4%B8%8D%E5%90%8C%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"mysql之5.7和8导数据的时候，由于时间戳的默认格式不同导致的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之5.7和8导数据的时候，由于时间戳的默认格式不同导致的问题:
MySql 8.0中输入代码： alter table actor add column create_date datetime not null default '0000-00-00 00:00:00'; 报错，提示默认时期格式'0000-00-00 00:00:00'有误。这个在mysql5.7下是没有问题的，查看问题在sql mod配置里: 查看配置:
select @@sql_mode; -- 查看全局sql_mode的值 ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES, NO_ZERO_IN_DATE, NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO, and NO_ENGINE_SUBSTITUTION 其中NO_ZERO_IN_DATE, NO_ZERO_DATE两个选项禁止了0000这样的日期和时间 重新配置sql mod，去掉这两个约束，然后重启mysql即可`}]},{path:"/content/database/mysql/mysql%E4%B9%8BDuplicate-foreign-key%E9%94%99%E8%AF%AF.html",title:"mysql之Duplicate-foreign-key错误",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之Duplicate-foreign-key错误:
有时候导入数据的时候会出现这个错误:Error 1826: Duplicate foreign key constraint 错误，原因如下:
在一个数据库中建了若干张表，其中的外键索引重复了，才导致这个问题：
例如，A表有一个字段 aid，B表有一字段为bid 和 a_id，其中a_id为外键，联系到A表，此时如果再新建一个C表，字段为 cid 和 a_id，其中a_id也为联系A表的外键，默认下生成的index索引名是一样的，故报错！ 记得 foreign key name 也需要改一下，上面改的只是foreign key 对应字段建的index的名称`}]},{path:"/content/database/mysql/mysql%E4%B9%8BXProtocol.html",title:"mysql之XProtocol",pathLocale:"/",contents:[{header:"",slug:"",content:"mysql之XProtocol: 缘起 如下是我的mysql container 端口展示:\n33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp\n我想知道我设置的是3307--->3306, 但是前面的33060是什么意思 解释 您提供的MySQL容器端口映射信息中包含了三个部分： 1. `33060/tcp`: 这是MySQL的X Protocol端口。X Protocol是MySQL 5.7.12及更高版本引入的一个新的协议，用于支持MySQL文档存储等新特性。这个端口默认是暴露的，但没有被映射到主机上。 2. `0.0.0.0:3307->3306/tcp`: 这是您设置的端口映射。它表示容器内的3306端口（MySQL的默认端口）被映射到主机的3307端口上。0.0.0.0意味着它在主机的所有网络接口上都可以访问。 3. `:::3307->3306/tcp`: 这与第二项本质上是相同的，但是针对IPv6。:::是IPv6的简写形式，表示所有IPv6接口。 总结：\n- 33060是MySQL的X Protocol端口，但没有被映射到主机上。\n- 3306是MySQL的主要端口，您将它映射到了主机的3307端口上。\n- 这个映射同时适用于IPv4（0.0.0.0）和IPv6（:::）。"}]},{path:"/content/database/mysql/mysql%E4%B9%8Bbinlog%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A0%BC%E5%BC%8F.html",title:"mysql之binlog的三种格式",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之binlog的三种格式:
MySQL 提供了三种 binlog 格式，通过参数 binlog_format 设置： STATEMENT（默认）：记录 SQL 语句。缺点是某些语句在复制时可能导致不一致（如非确定性函数）。
ROW：记录每一行的更改，数据一致性高，但生成日志量大，适用于高一致性场景。
MIXED：混合模式，MySQL 根据情况自动选择 STATEMENT 或 ROW 格式。 STATEMENT和ROW的区别，主要从 记录内容 和 一致性 两方面来解释:`},{header:"1. STATEMENT 模式",slug:"_1-statement-模式",content:`记录内容：在 STATEMENT 模式下，binlog 日志只记录 SQL 语句本身。例如：
UPDATE users SET last_login = NOW() WHERE id = 1; 这条语句会直接记录到 binlog 中，表示 “将 id 为 1 的用户的 last_login 字段更新为当前时间”。 数据一致性问题：因为 STATEMENT 模式记录的是 SQL 语句，所以在执行时需要依赖运行时环境。如果在不同的数据库环境中执行该 SQL 语句，可能会导致不一致的结果。例如，NOW() 是一个非确定性函数，它在执行时返回的时间依赖于运行时的实际时间。 在主从复制中，假设主库和从库的系统时间不同，那么 NOW() 的值就可能不同，这样在主库和从库中记录的 last_login 就会不一致。
类似的非确定性函数还包括 RAND()、UUID() 等，它们的执行结果每次都可能不同，因此 STATEMENT 模式在使用这些函数时容易导致数据不一致。`},{header:"2. ROW 模式",slug:"_2-row-模式",content:`记录内容：在 ROW 模式下，binlog 不记录 SQL 语句，而是直接记录行级别的数据更改。例如： 假设执行一条 UPDATE 语句 UPDATE users SET last_login = '2024-11-10 12:00:00' WHERE id = 1;
在 ROW 模式下，binlog 会直接记录 id=1 的用户 last_login 字段从旧值到新值的变化（即 '2024-11-10 12:00:00'），而不记录 UPDATE 语句本身。 数据一致性：因为 ROW 模式记录的是行的具体数据变化，所以无论在主库还是从库，直接按照数据变化来同步，不依赖运行时环境。因此即使是使用了非确定性函数，结果也会保持一致。 日志量大：由于 ROW 模式记录的是具体的行变更，因此如果有大批量的更新操作（例如更新数千条数据），binlog 会将这些行的每一个更改记录下来，日志量会非常大。所以在数据更新量较大的场景中，ROW 模式可能会生成大量的日志。`},{header:"举个例子来说明",slug:"举个例子来说明",content:`假设有一条语句：
UPDATE users SET score = score + 10 WHERE region = 'North'; 在 STATEMENT 模式下，binlog 记录的就是这条 SQL 语句。执行时会对 region = 'North' 的所有用户逐个增加 10 分。如果从库的 users 表数据与主库不完全一致，执行结果可能也会不同。 在 ROW 模式下，binlog 不记录这条 SQL，而是直接记录每个符合条件的用户的 score 字段的具体变更。例如：
id=2: score 从 50 变为 60
id=5: score 从 70 变为 80 这样无论在主库还是从库，都只是直接应用这些行变更，不会因为数据库中的其他数据不同而产生不同的结果，保持数据一致性。`},{header:"总结",slug:"总结",content:`STATEMENT 模式日志量小，但对于使用非确定性函数的操作可能导致主从数据不一致。
ROW 模式日志量大，但能保证数据操作的高一致性，非常适合需要数据完全一致的复制场景。`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bcoalesce.html",title:"mysql之coalesce",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之coalesce:
在 MySQL 8 中，COALESCE 函数用于返回表达式列表中第一个非 NULL 的值。如果所有表达式都是 NULL，那么 COALESCE 返回 NULL。它通常用于在查询中处理可能包含 NULL 值的列。
使用:
COALESCE(expression1, expression2, ..., expressionN) expression1, expression2, ..., expressionN 是要检查的表达式。
它会从左到右依次检查，返回第一个非 NULL 的表达式值。
如果所有表达式都是 NULL，则返回 NULL 例子:
SELECT user_id, COALESCE(address1, address2, address3, 'No Address') AS primary_address
FROM users; 有时候可以和IFNULL起到相同的作用. https://dev.mysql.com/doc/refman/8.4/en/comparison-operators.html#function_coalesce mysql之concat-ws:
这个方法默认的doctrine不支持，在symfony框架下使用需要安装: composer require beberlei/doctrineextensions 拓展, 同时需要配置，参考: https://symfony.com/doc/current/doctrine/custom_dql_functions.html https://dev.mysql.com/doc/refman/8.4/en/string-functions.html#function_concat-ws`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bdocker%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E4%B9%8B%E5%90%8E%E5%AF%86%E7%A0%81%E4%B8%8D%E8%83%BD%E4%BF%AE%E6%94%B9%E9%97%AE%E9%A2%98.html",title:"mysql之docker容器启动之后密码不能修改问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之docker容器启动之后密码不能修改问题:
我发现创建完mysql contaienr之后，我需要修改 mysql的密码，修改了docker-compose.yml中对应mysql service部分的账号密码，但是重新 docker compose up -d，发现mysql的密码还是没有改变 原因:
MySQL 的行为：
当 MySQL 容器启动时，如果发现挂载的卷中已经有数据，它会使用这些现有数据而不是初始化新的数据库。 解决办法如下:
1. 由于mysqld的相关数据是被挂载到了宿主机上，所以删除挂载就可以了，docker volume rm docker_volume-mysql-laravel, 这样做的坏处是会丢失mysql现有数据
2. 进入 mysql container ，然后修改密码 mysql -u root -p
ALTER USER 'your_user'@'%' IDENTIFIED BY 'new_password';
FLUSH PRIVILEGES; 然后再把项目中的相关密码改为修改后的密码`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bexplain%E6%9F%A5%E7%9C%8Bsql%E6%89%A7%E8%A1%8C%E4%BF%A1%E6%81%AF.html",title:"mysql之explain查看sql执行信息",pathLocale:"/",contents:[{header:"",slug:"",content:"mysql之explain查看sql执行信息:\n主要是每次做sql优化的时候，总会查看explain参数，所以还是记录一下\n如下sql:\nexplain SELECT `id`,`name`,`cover_image`,`price`,`score`,`remark`,`brand`,`subclass`,`category_one`,`category_two` FROM `products` WHERE (kind = '家居家具' and (name like '%体验%' or detail like '%体验%')) AND (EXISTS(SELECT id FROM product_attributes WHERE `product_attributes`.`product_id` = `products`.`id` AND `product_attributes`.`attribute_value` like '%防滑%')) LIMIT 10; id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra\n1	PRIMARY products ref index_kind index_kind 768 const 1202 20.99 Using where\n2	DEPENDENT SUBQUERY product_attributes ALL 37329 1.11 Using where 我在kind上加了索引 index_kind，现在的type 变为ref，没加之前是ALL，filtered 变为 20.99，所以查询效率还是提高了不少的 相关参数解释：\nid SELECT识别符。这是SELECT的查询序列号 select_type SELECT类型,可以为以下任何一种: SIMPLE:简单SELECT(不使用UNION或子查询) PRIMARY:主查询，即最外面的查询 UNION:UNION中的第二个或后面的查询语句 DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询 UNION RESULT:UNION 的结果 SUBQUERY:子查询中的第一个SELECT DEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询 DERIVED:导出表的SELECT(FROM子句的子查询) table 输出的行所引用的表 type 联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型（由上到下性能逐渐变差）进行排序: system:表仅有一行(=系统表)。这是const联接类型的一个特例。 const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次! eq_ref:类似ref，区别就在使用的索引是唯一索引，对于每个来自于前面的表的行组合,从该表中读取一行，多表连接中使用unique index或者primary key作为关联条件。这可能是最好的联接类型,除了const类型。 ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取(使用非唯一索引扫描或唯一索引的前缀扫描，返回匹配某个单独值的记录行)。 ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。 index_merge:该联接类型表示使用了索引合并优化方法。 unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range:只检索给定范围的行,使用一个索引来选择行，常见于<，<=，>，>=，between等操作符。 index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 ALL:对于每个来自于先前的表的行组合,进行完整的表扫描，全表扫描。 fulltext:全文索引 possible_keys 指出MySQL能使用哪个索引在该表中找到行，表示查询时可能使用的索引。 key 显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。 key_len 显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。 ref 显示使用哪个列或常数与key一起从表中选择行。 rows 显示MySQL认为它执行查询时必须检查的行数。多行之间的数据相乘可以估算要处理的行数。 filtered 显示了通过条件过滤出的行数的百分比估计值。 Extra 该列包含MySQL解决查询的详细信息： Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。 Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。 range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。 Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。 Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。 Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。 Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。 Using sort_union(...), Using union(...), Using intersect(...):这些函数说明如何为index_merge联接类型合并索引扫描。 Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。"}]},{path:"/content/database/mysql/mysql%E4%B9%8Bgroupby%E5%86%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"mysql之groupby再排序的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之groupby再排序的问题:
mysql group by + order by 查询，获取money 最高的uid //简单方法，但是不能准确获取当前那一行数据
SELECT id, uid,MAX(money) as cc, datatime FROM d_rewards GROUP BY uid ORDER BY cc DESC; //下面这个子查询的结果有了，但是 对于 group by 却没有生效
SELECT r.id, r.uid, r.money, r.datatime FROM ( SELECT id, uid, money, datatime FROM d_rewards ORDER BY money DESC) r GROUP BY r.uid ORDER BY r.money DESC; //加上 limit 就可以了，原因待定...，但是 limit 的值是一个问题
SELECT r.id, r.uid, r.money, r.datatime FROM ( SELECT id, uid, money, datatime FROM d_rewards ORDER BY money DESC limit 8) r GROUP BY r.uid ORDER BY r.money DESC;`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bhaving%E5%92%8Cwhere.html",title:"mysql之having和where",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之having和where小区别:
结论：having是从前筛选的字段再筛选，而where是从数据表中的字段直接进行的筛选的 比如我有 select id, usrer_id,name,age from d_users where age > 10;
select id, usrer_id,name,age from d_users having age > 10; 上面两个是等效的，但是如果我把第二个改为 select id, usrer_id,name from d_users having age > 10; 就会报错，原因就是上面说的结论`}]},{path:"/content/database/mysql/mysql%E4%B9%8Binner%E5%92%8Cleft%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"mysql之inner和left的区别",pathLocale:"/",contents:[{header:"mysql之inner和left的区别",slug:"mysql之inner和left的区别",content:`// inner join(这个是inner join)
SELECT *
FROM email_template_action_contents AS etac INNER JOIN email_template_actions AS eta ON etac.template_action_id = eta.id AND eta.template_category_id = 4 AND etac.status_from = 1; // left join 不生效, 和上面的inner join效果一样
SELECT *
FROM email_template_action_contents AS etac
LEFT JOIN email_template_actions AS eta ON etac.template_action_id = eta.id
WHERE etac.status_from = 1 AND eta.template_category_id = 4; // left join 生效
SELECT *
FROM email_template_action_contents AS etac
LEFT JOIN email_template_actions AS eta ON etac.template_action_id = eta.id AND eta.template_category_id = 4
WHERE etac.status_from = 1; 但此时要注意：LEFT JOIN 加 WHERE eta.xxx = yyy 会失效“左连接保留全部”的特性，结果跟 INNER JOIN 一样。
想保留主表全量，条件必须放在 ON 子句中`}]},{path:"/content/database/mysql/mysql%E4%B9%8Blike%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96.html",title:"mysql之like查询优化",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之like查询优化:
最近写项目的时候，有跨表做 like 查询的操作，主表大概有十万条数据 副表大概有 四十万的数据，差不多 1:4的关系，表结构如下：
t_products 字段名
类型
说明 id
int
ID name
string
名称 t_product_attributes 字段名
类型
说明 id
int
ID product_id
int
产品ID attribute
string
属性 我用的laravel框架，
第一次直接 whereHas 通过 like 查询，结果 接口直接超时，报nginx 504，这是标准的 nginx 后端响应超时问题，所以想着不跨表查询，于是在 t_products 表
加了个字段 properties (text类型)，准备把副表中的属性全部用逗号追加起来，然后这样操作以后做like查询，果真要快很多，至少不会报超时问题，但是通过
explain 检查以后发现， type 为 All 查询，也就意味着要全表扫描，这样肯定不行，所以还是想用索引，最后想到用 全文索引(FullText)
通过如下命令给表添加全文索引:
ALTER TABLE t_products ADD FULLTEXT INDEX t_products (properties) with parser ngram;
查询：
①原生
select * from t_products where (match(properties) against('蓝色')) and name like '%手机%';
②对于laravel框架，需要whereRaw操作：
if (isset($params['attribute'])) {
$query = $query->whereRaw("match(properties) against('".$params['attribute']."')");
}
通过explain 检查发现 type 为 fulltext，证明用到了full-text-index，响应时间也更快
关于全文索引(FULLTEXT indexes):
FULLTEXT索引仅支持 InnoDB和 MyISAM表，并且只能包含 CHAR、 VARCHAR和 TEXT列。索引总是发生在整个列上；不支持列前缀索引，如果指定，任何前缀长度都将被忽略。
在MySQL 5.6版本以前,只有MyISAM存储引擎支持全文引擎，
在5.6版本中,InnoDB加入了对全文索引的支持,但是不支持中文全文索引，
在5.7.6版本,MySQL内置了ngram全文解析器,用来支持亚洲语种的分词，并且对MyISAM和InnoDB引擎有效。
在使用前请确认自己的mysql版本, 可以使用 select version() 查看mysql的版本。
在命令行执行：
show VARIABLES like '%innodb_ft_%';
Variable_name Value
innodb_ft_aux_table // 设置调式表 innodb_ft_cache_size 8000000 //定义每个表的全文索引内存大小 innodb_ft_enable_diag_print OFF innodb_ft_enable_stopword ON //是否允许使用停止词 innodb_ft_max_token_size 84 //默认84，表示最大84个字符作为一个关键词，限制该值可减少全文索引的大小 innodb_ft_min_token_size 3 //默认3，表示最小3个字符作为一个关键词，增大该值可减少全文索引的大小 innodb_ft_num_word_optimize 2000 innodb_ft_result_cache_limit	2000000000 innodb_ft_server_stopword_table innodb_ft_sort_pll_degree 2 innodb_ft_total_cache_size 640000000 //定义所有表的全文索引内存大小 innodb_ft_user_stopword_table //定义的停止表，默认为 information_schema.INNODB_FT_DEFAULT_STOPWORD ，可以select * from information_schema.INNODB_FT_DEFAULT_STOPWORD,查看所有的停止词 可以根据实际情况调大 innodb_ft_result_cache_limit 的值
对于innodDb存储引擎，要使用全文索引就必须用到如下格式(需要加 with parser ngram 参数)的命令创建索引：
ALTER TABLE t_products ADD FULLTEXT INDEX t_products (properties) with parser ngram;
关于 ngram：
在全文索引中，n-gram就是一段文字里面连续的n个字的序列，当使用 ngram 分词解析器以后，innodb_ft_min_token_size和innodb_ft_max_token_size 无效
关于全文索引模式：
全文索引主要包括 自然语言模式 IN NATURAL LANGUAGE MODE(默认模式，可以不写) 和布尔模式 IN BOOLEAN MODE
其中boolean模式中,
“+”表示必须包含
“-”表示必须排除
“>”表示出现该单词时增加相关性
“<”表示出现该单词时降低相关性
“*”表示通配符
“~”允许出现该单词，但是出现时相关性为负
“""”表示短语 //该模式下 和 IN NATURAL LANGUAGE MODE 类似
还有一种是：WITH QUERY EXPANSION 这个模式没用过
这种模式的查询分为两个阶段：
第一阶段：根据搜索的单词进行全文索引查询。
第二阶段：根据第一阶段产生的分词再进行一次全文检索的查询
模式使用：
直接在against()参数后空格连接即可
比如上面的查询可以改为：
if (isset($params['attribute'])) {
$query = $query->whereRaw('match(properties) against("'.$params['attribute'].'" IN BOOLEAN MODE)');
}
注意：
在使用过程中发现，如果 against 里只有一个字，那么可能查不到结果，原因是：
默认的 ngram_token_size 大小为2，这个值定义了分词的大小，这个值可以在 mysql的配置文件里，[mysqld]下重新配置,分词的SIZE越小，索引的体积就越大，所以要根据自身情况来设置合适的大小。
通过 show variables like '%ngram%'; 可以查看默认值为2
通过select match against 来计算全文索引相关性：
select id as '数据ID', match(properties) against ('红色') as '全文索引相关性' from t_products where (match(properties) against('红色')) and name like '%手机%';
关于停止词表：
SET GLOBAL innodb_ft_user_stopword_table = "test/my_innodb_ft_stopword"; //test为数据库，my_innodb_ft_stopword 为test库下的表，虽然执行成功但是通过：show VARIABLES like '%innodb_ft_%'; 查看还是没有值
select * from information_schema.innodb_ft_index_table;`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bmyisam%E6%A0%91%E7%B4%A2%E5%BC%95%E6%9F%A5%E6%89%BE.html",title:"mysql之myisam树索引查找",pathLocale:"/",contents:[{header:"myisam树索引查找，但范围查询必须中序遍历所有节点，不能顺序扫描，非常低效，原因是不是不能像b+树那样有链表结构？",slug:"myisam树索引查找-但范围查询必须中序遍历所有节点-不能顺序扫描-非常低效-原因是不是不能像b-树那样有链表结构",content:""},{header:"1. B树（B-Tree）和 B+树（B+Tree）的区别",slug:"_1-b树-b-tree-和-b-树-b-tree-的区别",content:`特点
B树
B+树 数据存储位置
所有节点（包括内部节点和叶子节点）都存储数据
只有叶子节点存储数据，内部节点只存储索引键 叶子节点连接
叶子节点之间没有链表连接
叶子节点通过链表相连，方便范围扫描 查找流程
直接通过树查找，找到目标节点即可
先通过索引找到对应叶子节点，再顺序遍历叶子链表 范围查询
需要在树中中序遍历节点，效率较低
利用叶子节点链表顺序遍历，高效`},{header:"2. 为什么 B树范围查询效率低？",slug:"_2-为什么-b树范围查询效率低",content:`数据散布在所有节点上（包括内部节点），没有统一的顺序链表。
对范围查询，要找到起点后，接下来还得“跳”到其他节点，不能简单地顺序遍历叶子节点。
如果进行中序遍历，要遍历树中所有节点（包括内部节点和叶子节点），访问磁盘多，效率低。
没有叶子节点链表，不能快速顺序扫描。`},{header:"3. B+树范围查询优势",slug:"_3-b-树范围查询优势",content:`所有数据都存储在叶子节点，叶子节点之间通过链表连接。
只要定位到范围起点的叶子节点，就能顺序沿着链表快速扫描范围内所有数据，减少磁盘随机读。
内部节点只做索引导航，不存具体数据，树更高效且结构简单。`},{header:"4. 结论",slug:"_4-结论",content:`B树不能像 B+树一样有叶子节点链表，因此范围查询时必须中序遍历整个树节点，访问效率较低。
B+树的链表结构让范围查询成为顺序扫描，极大提升了性能。`}]},{path:"/content/database/mysql/mysql%E4%B9%8Boptimize%E8%A1%A8.html",title:"mysql之optimize表",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之optimize表:
用法： optimize table '表名' show index from d_japan_products; 索引信息中的列的信息说明：
Table :表的名称。
Non_unique:如果索引不能包括重复词，则为0。如果可以，则为1。
Key_name:索引的名称。
Seq_in_index:索引中的列序列号，从1开始。
Column_name:列名称。
Collation:列以什么方式存储在索引中。在MySQLSHOW INDEX语法中，有值’A’（升序）或NULL（无分类）。
Cardinality:索引中唯一值的数目的估计值。通过运行ANALYZE TABLE或myisamchk -a可以更新。基数根据被存储为整数的统计数据来计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL使用该索引的机会就越大。
Sub_part:如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL。
Packed:指示关键字如何被压缩。如果没有被压缩，则为NULL。
Null:如果列含有NULL，则含有YES。如果没有，则为空。
Index_type：存储索引数据结构方法（BTREE, FULLTEXT, HASH, RTREE） 作用： 当你删除数据时，mysql并不会回收已删除的数据所占据的存储空间(包括数据文件和索引文件)，以及索引位。而是空在那里，而是等待新的数据来弥补这个空缺，这样就有一个缺少，如果一时半会，没有数据来填
补这个空缺，那这样就太浪费资源了。所以对于写比较频繁的表，要定期进行optimize，一个月一次，看实际情况而定了。`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bsql-mode%E8%AE%BE%E7%BD%AE.html",title:"mysql之sql-mode设置",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之sql-mode设置:
mysql8的默认sql_mode:
select @@sql_mode;
ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 这个 ONLY_FULL_GROUP_BY 会在sql的select查询的时候报错，一般需要去掉,原因如下:
Reject queries for which the select list, HAVING condition, or ORDER BY list refer to nonaggregated columns that are neither named in the GROUP BY clause nor are functionally dependent on (uniquely determined by) GROUP BY columns.
对于选择列表、HAVING条件或ORDER BY列表中提到的非分组列的查询都会被拒绝，这些列既没有在GROUP BY子句中命名，也没有在功能上依赖于（由GROUP BY列唯一决定）的查询。 在配置文件 /etc/mysql/my.cnf 中 [mysqld] 下面加上一行
设置: sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION' 对于STRICT_TRANS_TABLES：严格模式 一般也是要禁用的(大部分时候都只是禁用了ONLY_FULL_GROUP_BY)，原因如下:
Strict mode controls how MySQL handles invalid or missing values in data-change statements such as INSERT or UPDATE. A value can be invalid for several reasons. For example, it might have the wrong data type for the column, or it might be out of range. A value is missing when a new row to be inserted does not contain a value for a non-NULL column that has no explicit DEFAULT clause in its definition. (For a NULL column, NULL is inserted if the value is missing.) Strict mode also affects DDL statements such as CREATE TABLE.
严格模式控制MySQL如何处理数据变更语句（如INSERT或UPDATE）中的无效或缺失值。一个值可能因为几个原因而无效。例如，它可能有错误的列的数据类型，或者它可能超出了范围。当要插入的新行不包含一个非NULL列的值时，一个值就会丢失，该列在其定义中没有明确的DEFAULT子句。(对于一个NULL列，如果数值缺失，则插入NULL。) 严格模式也影响到DDL语句，如CREATE TABLE。 生产上可以直接 sql_mode = ''`}]},{path:"/content/database/mysql/mysql%E4%B9%8Bsum%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E5%8F%AA%E8%BF%94%E5%9B%9E%E4%B8%80%E6%9D%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"mysql之sum聚合函数只返回一条数据的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之sum聚合函数只返回一条数据的问题:
最近做sql查询的时候，本来做了分作查询同时对同一组做sum操作，没啥问题，后来突然想到把group by a去掉，就之能查到一条数据，
一时蒙了，后来想到这不就是sum的特性吗，SUM 是一个聚合函数，它将多个行的值相加到一个总和。，如果不分组，就只会有一条。`}]},{path:"/content/database/mysql/mysql%E4%B9%8Btruncate%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E9%97%AE%E9%A2%98.html",title:"mysql之truncate外键约束问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之truncate外键约束问题:
Cannot truncate a table referenced in a foreign key constraint
解决办法，通过命令行操作:
SET foreign_key_checks = 0;
truncate event_series;
SET foreign_key_checks = 1;`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E4%BF%AE%E6%94%B9%E5%AD%97%E6%AE%B5%E4%BF%A1%E6%81%AF.html",title:"mysql之修改字段信息",pathLocale:"/",contents:[{header:"",slug:"",content:`修改字段类型
语法: ALTER TABLE 表名 MODIFY [COLUMN] 字段名 新数据类型 新类型长度 新默认值 新注释; --- COLUMN 关键字可以忽略不屑 例如:
alter table d_slides modify column created_at TIMESTAMP DEFAULT NULL 修改字段名称
语法: ALTER TABLE 表名 CHANGE [COLUMN] 旧字段名 新字段名 新数据类型; 例如:
alter table d_users change nickname nick_name varchar(100) DEFAULT NULL`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E5%90%8C%E4%B8%80%E4%B8%AA%E5%AD%97%E6%AE%B5%E5%81%9A%E4%BA%A4%E9%9B%86%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96.html",title:"mysql之同一个字段做交集查询优化",pathLocale:"/",contents:[{header:"",slug:"",content:"mysql之同一个字段做交集查询优化:\n最近做了一个这样的需求，对同一个字段做条件筛选，开始比较纠结，怎么做效率更高，主要有如下两种方案：\n通过多个 exists对同一个字段(这里正好是等值查询)做交集查询:\nSELECT `id`,`name`,`cover_image`,`price`,`score`,`remark`,`brand`,`subclass`,`category_one`,`category_two`,`detail` FROM `d_products` WHERE (kind = '养老服务' and (name like '%水%' or detail like '%水%')) AND (EXISTS(SELECT id FROM d_product_attributes WHERE `d_product_attributes`.`product_id` = `d_products`.`id` AND `d_product_attributes`.`attribute_value` = '卫浴') and EXISTS(SELECT id FROM d_product_attributes WHERE `d_product_attributes`.`product_id` = `d_products`.`id` AND `d_product_attributes`.`attribute_value` = '介护老人') and EXISTS(SELECT id FROM d_product_attributes WHERE `d_product_attributes`.`product_id` = `d_products`.`id` AND `d_product_attributes`.`attribute_value` = '防滑')) ORDER BY id desc LIMIT 10; explain结果：\nexplain结果：\nid | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra\n1 PRIMARY d_japan_products ref index_kind index_kind 768 const 1276	20.99	Using where\n3 DEPENDENT SUBQUERY	d_japan_product_attributes ref attribute_value-index	attribute_value-index	768 const 669	10 Using where\n2 DEPENDENT SUBQUERY	d_japan_product_attributes ref attribute_value-index	attribute_value-index	768 const 538	10 Using where 通过单个exists 配合 or 范围查询实现:\nSELECT `id`,`name`,`cover_image`,`price`,`score`,`remark`,`brand`,`subclass`,`category_one`,`category_two`,`detail` FROM `d_products` WHERE (kind = '养老服务' and (name like '%水%' or detail like '%水%')) AND (EXISTS(SELECT count(id) as id_count FROM `d_product_attributes` WHERE `d_product_attributes`.`product_id` = `d_products`.`id` AND (`d_product_attributes`.`attribute_value` = '卫浴' or `d_product_attributes`.`attribute_value` = '介护老人') group by `d_product_attributes`.`product_id` HAVING id_count = 2)) ORDER BY id desc LIMIT 10; explain结果：\nid | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra\n1 PRIMARY d_japan_products ref index_kind index_kind 768 const	1276	20.99	Using where\n2 DEPENDENT SUBQUERY	d_japan_product_attributes range	attribute_value-index	attribute_value-index	768 1207	10 Using index condition; Using where; Using temporary; Using filesort 总结：对比可以知道，通过第一种方式查询的更快一些，原因是 第一种 会用到等值查询配合 attribute_value 字段上的索引会非常快，一个 type 是 ref,另一个 type 是 range"}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E7%9A%84%E9%85%8D%E7%BD%AE.html",title:"mysql之数据库外键约束的配置",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之数据库外键约束的配置:
关于数据库外键约束的配置，常见的会给 onDelete 配置一些操作，比如: onDelete: 'CASCADE' CASCADE:
在数据库中，外键（foreign key）是指一个表中的字段，它关联到另一个表中的主键（primary key）。当在一个表中定义了外键，并且设置了 onDelete: 'CASCADE'，这意味着当参考的行（被外键引用的行）被删除时，将会自动删除包含该外键的行，以维持数据的完整性和一致性。 如果不想在删除关联的行时自动删除包含外键的行,可以按下面的配置: RESTRICT:
当被引用的行被删除时，会阻止删除包含外键的行，除非没有任何引用该行的行存在。 NO ACTION: 类似于 RESTRICT，当被引用的行被删除时，不会执行任何操作，除非没有任何引用该行的行存在。 SET NULL: 当被引用的行被删除时，外键列将被设置为 NULL 值。 SET DEFAULT:
当被引用的行被删除时，外键列将被设置为其默认值。 mysql8删除数据，由于外键约束的问题：
Cannot delete or update a parent row: a foreign key constraint fails (sciforum_dev.event_person_affiliations, CONSTRAINT FK_296B1A6AA7EE857A FOREIGN KEY (event_person_id) REFERENCES event_persons (id)) SET FOREIGN_KEY_CHECKS = 0;
DELETE FROM event_persons WHERE session_id IS NULL;
SET FOREIGN_KEY_CHECKS = 1; 可以临时设置不检查外键约束,删除即可`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BBsql%E6%89%A7%E8%A1%8C%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98.html",title:"mysql之数据库迁移sql执行报错问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之数据库迁移sql执行报错问题，有时候需要执行导出的sql文件，但是可能会报下面的错误:
[ERR] 1118 - Row size too large (> 8126). Changing some columns to TEXT or BLOB or using ROW_FORMAT=DYNAMIC or ROW_FORMAT=COMPRESSED may help. 解决办法:
//在mysql的配置文件下添加如下配置，再重启
innodb_file_per_table=1 innodb_file_format=Barracuda innodb_file_format_check = ON innodb_log_file_size = 512M innodb_strict_mode = 0`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%BA%8C%E8%A1%8C%E5%AD%97%E6%AE%B5%E7%9A%84%E5%80%BC%E5%88%B0%E7%AC%AC%E4%B8%80%E8%A1%8C.html",title:"mysql之更新第二行字段的值到第一行",pathLocale:"/",contents:[{header:"",slug:"",content:`目前遇到这样的需求，需要将如下结构的数据进行更行操作： id
user_id
no
no_modify
created_at 1
1
12 2021-08-26 08:23:46 2
1
13 2021-08-26 08:23:50 3
1
14 2021-08-26 08:23:55 更新为： id
user_id
no
no_modify
created_at 1
1
12 2021-08-26 08:23:46 2
1
13
12
2021-08-26 08:23:50 3
1
14
13
2021-08-26 08:23:55 通过存储过程循环指定用户，然后进行更新操作，语句如下:
CREATE DEFINER=\`qinhong\`@\`%\` PROCEDURE \`data_proc\`()
BEGIN #Routine body goes here... declare stop_flag int default 0; declare account_id int default 0; declare account_user_id int default 0; declare num int default 0; declare cur1 cursor for select id, user_id, no from update_test where user_id in (select user_id from update_test) order by created_at asc; declare continue handler for not found set stop_flag=1; start transaction; open cur1; fetch cur1 into account_id,account_user_id,num; while stop_flag<>1 DO update update_test set no_modify = num where user_id = account_user_id and id = (account_id + 1); fetch cur1 into account_id,account_user_id,num; end while; close cur1;
commit; END`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E6%9B%BF%E6%8D%A2%E5%8E%9F%E6%9C%89%E5%AD%97%E6%AE%B5(%E9%87%8D%E5%91%BD%E5%90%8D%E5%AD%97%E6%AE%B5).html",title:"mysql之替换原有字段(重命名字段)",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之替换原有字段(重命名字段)的另一种方式:
ALTER TABLE events ADD singular_session_term VARCHAR(255) DEFAULT NULL, ADD plural_session_term VARCHAR(255) DEFAULT NULL, DROP singular_term, DROP plural_term 这个主要是通过 Alter 多个命令连用的方式，重命名字段
下面是传统方式:
ALTER TABLE table_name CHANGE COLUMN old_column_name new_column_name column_definition;
ex:
ALTER TABLE employees
CHANGE COLUMN phone_number contact_number VARCHAR(20)`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%AE%B5%E5%88%B0%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE.html",title:"mysql之添加字段到指定位置",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql之添加字段到指定位置:
要将新的 title 字段添加到 id 字段之后，您可以使用 MySQL 的 AFTER 子句。以下是修改后的 SQL 语句：
ALTER TABLE books ADD title VARCHAR(255) NOT NULL AFTER id
这条语句会在 id 字段之后添加 title 字段。`}]},{path:"/content/database/mysql/mysql%E4%B9%8B%E7%B4%A2%E5%BC%95%E6%A0%91%E7%BB%93%E6%9E%84%E5%88%86%E7%B1%BB.html",title:"mysql之索引树结构分类",pathLocale:"/",contents:[{header:"mysql之索引树结构分类",slug:"mysql之索引树结构分类",content:"关于树结构中的节点分类：根节点、内部节点、叶子节点，帮你梳理一下它们的关系和特点，尤其结合数据库索引（比如 B+ 树）讲解。"},{header:"1. 节点分类定义",slug:"_1-节点分类定义",content:`节点类型
定义
说明 根节点
树的最顶层节点
唯一一个，没有父节点 内部节点
非根节点且有子节点的节点
介于根节点和叶子节点之间，负责索引导航 叶子节点
没有子节点的节点
树的最底层节点，存储具体数据或指向数据`},{header:"2. 关系示意",slug:"_2-关系示意",content:`[根节点] / \\ [内部节点] [内部节点] | | [叶子节点] [叶子节点] 根节点是树的入口。
内部节点是“中间层”，连接根节点和叶子节点，起导航作用。
叶子节点是最终存放数据的位置。`},{header:"3. 以 B+ 树为例",slug:"_3-以-b-树为例",content:`根节点
存储键值和指向子节点的指针，最顶层索引。
内部节点
也是存键值和子节点指针，但不存具体数据，只是索引层级的导航节点。
叶子节点
存储完整的索引键值以及对应的数据行（聚簇索引）或数据行的主键指针（辅助索引）。`},{header:"4. 特点和作用",slug:"_4-特点和作用",content:`节点类型
作用
存储内容
指针指向 根节点
入口，开始搜索路径
键值+指向子节点的指针
子节点（内部节点或叶子节点） 内部节点
导航，加快查找速度
键值+指向子节点的指针
子节点（内部节点或叶子节点） 叶子节点
存储真正的数据或指向数据的地址
索引键值 + 行数据或主键指针
可能有链表指针指向相邻叶子节点（B+树）`},{header:"5. 说明",slug:"_5-说明",content:`所有节点（根节点和内部节点）都至少有两个子节点，保证树高度平衡。
叶子节点是没有子节点的末端节点，存储数据。
在 B+ 树中，叶子节点之间通常通过链表连接，方便范围扫描。`},{header:"6. 例子：InnoDB 聚簇索引 B+ 树结构",slug:"_6-例子-innodb-聚簇索引-b-树结构",content:`根节点 / \\ 内部节点 内部节点 / \\ / \\
叶子节点 叶子节点 叶子节点 叶子节点（存储完整行数据）`}]},{path:"/content/database/mysql/mysql%E5%9F%BA%E4%BA%8Ek8s%E7%9A%84%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE.html",title:"mysql基于k8s的主从配置",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql基于k8s的主从配置:
使用minikube 搭建mysql8.0的集群，一个主节点两个从节点
1.启动minikube
minikube start 必须要启动，否则后面 kubectl apply 的时候，会报如下错误:
error: error validating "mysql-rep-cluster.yaml": error validating data: failed to download openapi: Get "https://192.168.49.2:8443/openapi/v2?timeout=32s": dial tcp 192.168.49.2:8443: connect: no route to host; if you choose to ignore these errors, turn validation off with --validate=false 2.编写yaml文件，本次文件命名为 mysql-rep-cluster.yaml ， 内容如下:
# mysql-master-config ConfigMap (主节点配置)
apiVersion: v1
kind: ConfigMap
metadata: name: mysql-master-config namespace: default
data: my.cnf: | [mysqld] user=mysql default_authentication_plugin=mysql_native_password bind-address=0.0.0.0 log_bin=mysql-bin server-id=1 binlog-format=ROW expire_logs_days=7 max_binlog_size=100M sql_mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION # 禁用默认的 includedir 指令 loose_mysqlx_port=33060 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/
---
# mysql-slave1-config ConfigMap (从节点1配置)
apiVersion: v1
kind: ConfigMap
metadata: name: mysql-slave1-config namespace: default
data: my.cnf: | [mysqld] user=mysql default_authentication_plugin=mysql_native_password bind-address=0.0.0.0 server-id=2 relay-log=relay-log-bin read-only=1 log_slave_updates=1 max_binlog_size=100M sql_mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION # 禁用默认的 includedir 指令 loose_mysqlx_port=33060 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/
---
# mysql-slave2-config ConfigMap (从节点2配置)
apiVersion: v1
kind: ConfigMap
metadata: name: mysql-slave2-config namespace: default
data: my.cnf: | [mysqld] user=mysql default_authentication_plugin=mysql_native_password bind-address=0.0.0.0 server-id=3 relay-log=relay-log-bin read-only=1 log_slave_updates=1 max_binlog_size=100M sql_mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION # 禁用默认的 includedir 指令 loose_mysqlx_port=33060 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/
---
# StatefulSet 配置
apiVersion: apps/v1
kind: StatefulSet
metadata: name: mysql-cluster namespace: default
spec: serviceName: mysql replicas: 3 selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: initContainers: - name: init-mysql image: busybox:1.36 command: - sh - -c - | # 创建必要的目录结构 mkdir -p /etc/mysql/conf.d mkdir -p /etc/mysql/mysql.conf.d # 根据主机名选择配置 if [ "\${HOSTNAME}" = "mysql-cluster-0" ]; then cp /mnt/master-config/my.cnf /etc/mysql/my.cnf elif [ "\${HOSTNAME}" = "mysql-cluster-1" ]; then cp /mnt/slave1-config/my.cnf /etc/mysql/my.cnf else cp /mnt/slave2-config/my.cnf /etc/mysql/my.cnf fi # 设置正确的权限 chmod -R 755 /etc/mysql chown -R 999:999 /etc/mysql volumeMounts: - name: mysql-master-config mountPath: /mnt/master-config - name: mysql-slave1-config mountPath: /mnt/slave1-config - name: mysql-slave2-config mountPath: /mnt/slave2-config - name: config-dir mountPath: /etc/mysql containers: - name: mysql image: mysql:8.0 env: - name: MYSQL_ROOT_PASSWORD value: "rootpassword" volumeMounts: - name: config-dir mountPath: /etc/mysql - name: mysql-data mountPath: /var/lib/mysql ports: - containerPort: 3306 name: mysql volumes: - name: mysql-master-config configMap: name: mysql-master-config - name: mysql-slave1-config configMap: name: mysql-slave1-config - name: mysql-slave2-config configMap: name: mysql-slave2-config - name: config-dir emptyDir: {} volumeClaimTemplates: - metadata: name: mysql-data spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 1Gi
---
# Headless Service
apiVersion: v1
kind: Service
metadata: name: mysql namespace: default
spec: clusterIP: None ports: - port: 3306 selector: app: mysql
---
# ClusterIP Service
apiVersion: v1
kind: Service
metadata: name: mysql-cluster namespace: default
spec: ports: - port: 3306 targetPort: 3306 selector: app: mysql 这个 yaml 文件我花了两天时间搞定，其中的 ConfigMap 一开始没有分成三个，只是简单的配置了两个，而且在后面使用的时候，还只是配置了 mysql-master-config, 导致最后三个节点的 server-id=1 都是1，然后在后续查看slave节点的状态的时候，报:
Last_IO_Error: Fatal error: The replica I/O thread stops because source and replica have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on replica but this does not always make sense; please check the manual before using it). 这意味着要为所有的节点配置不同的 server-id，我这里有三个节点，那就必须要有三个 ConfigMap，以及在后面 StatefulSet 中分别使用这三个配置。 3.使用yaml文件创建集群
$ kubectl apply -f mysql-rep-cluster.yaml 4.查看pods状态
以下是几种可能出现的情况 1>
$ kubectl get pods //一直找不到任何东西
No resources found in default namespace. 那么就需要取查看错误了
$ kubectl get statefulsets //这个主要是排除yaml文件错误的，因为很复杂，所以很容易出错
NAME READY AGE
mysql-cluster 0/3 9s $ kubectl describe statefulset mysql-cluster // 这个 mysql-cluster 是上面statefulset的名称
Name: mysql-cluster
Namespace: default
CreationTimestamp: Sat, 28 Dec 2024 00:25:12 +0800
Selector: app=mysql
Labels: <none>
Annotations: <none>
Replicas: 3 desired | 0 total
Update Strategy: RollingUpdate Partition: 0
Pods Status: 0 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template: Labels: app=mysql Containers: mysql: Image: mysql:8.0 Port: <none> Host Port: <none> Environment: MYSQL_ROOT_PASSWORD: rootpassword MYSQL_DATABASE: mysql Mounts: /etc/mysql/custom-my.cnf from mysql-config-volume (rw,path="my.cnf") /var/lib/mysql-data from mysql-data (rw) Volumes: <none> Node-Selectors: <none> Tolerations: <none>
Volume Claims: Name: mysql-data StorageClass: Labels: <none> Annotations: <none> Capacity: 1Gi Access Modes: [ReadWriteOnce]
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreate 5s (x12 over 16s) statefulset-controller create Pod mysql-cluster-0 in StatefulSet mysql-cluster failed error: Pod "mysql-cluster-0" is invalid: spec.containers[0].volumeMounts[0].name: Not found: "mysql-config-volume" 这个错误是因为StatefulSet的配置结构不正确。在StatefulSet中，volumes 应该定义在 Pod 模板（spec.template.spec）中，而不是直接在StatefulSet的 spec 下。将 volumes 从 StatefulSet 的 spec 层级移到了 spec.template.spec 下。这个错误其实是我最开始的一个版本里的，我把 volumes 放到了外层。 2>
$ kubectl get pods
NAME READY STATUS RESTARTS AGE
mysql-0 0/1 Init:ImagePullBackOff 0 2m53s // 注意刚开始是这样命名的，这是我之前的一个错误，这里只是贴出来 然后可以执行如下命令查看这个pod的详细情况，一般都会有异常信息
$ kubectl describe pod mysql-0
Name: mysql-0
Namespace: default
Priority: 0
Service Account: default
Node: minikube/192.168.49.2
Start Time: Wed, 25 Dec 2024 23:29:14 +0800
Labels: app=mysql apps.kubernetes.io/pod-index=0 controller-revision-hash=mysql-6759676ccb statefulset.kubernetes.io/pod-name=mysql-0
Annotations: <none>
Status: Pending
IP: 10.244.0.29
IPs: IP: 10.244.0.29
Controlled By: StatefulSet/mysql
Init Containers: init-mysql: Container ID: Image: mysql:8.0 Image ID: Port: <none> Host Port: <none> Command: bash -c set -ex [[ \`hostname\` =~ -([0-9]+)$ ]] || exit 1 ordinal=\${BASH_REMATCH[1]} echo [mysqld] > /mnt/conf.d/server-id.cnf echo server-id=$((ordinal + 1)) >> /mnt/conf.d/server-id.cnf if [[ $ordinal -gt 0 ]]; then cat << EOF >> /mnt/conf.d/repl.cnf [mysqld] gtid_mode=ON enforce-gtid-consistency=ON EOF fi if [[ $ordinal -eq 0 ]]; then cat << EOF >> /mnt/conf.d/master.cnf [mysqld] gtid_mode=ON enforce-gtid-consistency=ON log-bin=mysql-bin binlog_format=ROW EOF fi State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Environment: <none> Mounts: /mnt/conf.d/ from conf (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l2pw2 (ro) clone-mysql: Container ID: Image: busybox Image ID: Port: <none> Host Port: <none> Command: /bin/sh -c if [ ! -d /var/lib/mysql-k8s/mysql ]; then mkdir -p /var/lib/mysql-k8s; fi State: Waiting Reason: PodInitializing Ready: False Restart Count: 0 Environment: <none> Mounts: /var/lib/mysql-k8s from data (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l2pw2 (ro)
Containers: mysql: Container ID: Image: mysql:8.0 Image ID: Port: 3307/TCP Host Port: 0/TCP Args: --datadir=/var/lib/mysql-k8s --default-authentication-plugin=mysql_native_password State: Waiting Reason: PodInitializing Ready: False Restart Count: 0 Environment: MYSQL_ROOT_PASSWORD: password123 Mounts: /docker-entrypoint-initdb.d from config-map (rw) /etc/mysql/conf.d-k8s from conf (rw) /var/lib/mysql-k8s from data (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l2pw2 (ro)
Conditions: Type Status PodReadyToStartContainers True Initialized False Ready False ContainersReady False PodScheduled True Volumes: data: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: data-mysql-0 ReadOnly: false conf: Type: EmptyDir (a temporary directory that shares a pod's lifetime) Medium: SizeLimit: <unset> config-map: Type: ConfigMap (a volume populated by a ConfigMap) Name: mysql-config Optional: false kube-api-access-l2pw2: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true
QoS Class: BestEffort
Node-Selectors: <none>
Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 4m43s default-scheduler 0/1 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling. Normal Scheduled 4m42s default-scheduler Successfully assigned default/mysql-0 to minikube Normal Pulling 2m21s (x4 over 4m40s) kubelet Pulling image "mysql:8.0" Warning Failed 95s (x4 over 4m25s) kubelet Failed to pull image "mysql:8.0": Error response from daemon: Get "https://registry-1.docker.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) Warning Failed 95s (x4 over 4m25s) kubelet Error: ErrImagePull Warning Failed 81s (x6 over 4m24s) kubelet Error: ImagePullBackOff Normal BackOff 68s (x7 over 4m24s) kubelet Back-off pulling image "mysql:8.0" 这里明显的可以看到一个问题，镜像拉不下来，其实这个问题的主要原因是，执行 kubectl apply 的时候，会在 minikube 创建的容器环境下执行，在这个 minikube 的容器环境下还有一套 dcoker 环境，但是这个dockr环境目前还不能直接和宿主机的docker 环境一样访问hub docker 仓库，官方文档说是可以设置代理，然而并没有什么用，所以唯一的方法就是在宿主机上拉取镜像到本地，如下:
$ docker pull mysql:8.0
8.0: Pulling from library/mysql
2c0a233485c3: Pull complete b746eccf8a0b: Pull complete 570d30cf82c5: Pull complete c7d84c48f09d: Pull complete e9ecf1ccdd2a: Pull complete 6331406986f7: Pull complete f93598758d10: Pull complete 6c136cb242f2: Pull complete d255d476cd34: Pull complete dbfe60d9fe24: Pull complete 9cb9659be67b: Pull complete Digest: sha256:d58ac93387f644e4e040c636b8f50494e78e5afc27ca0a87348b2f577da2b7ff
Status: Downloaded newer image for mysql:8.0
docker.io/library/mysql:8.0 minikube image load mysql:8.0 //必须要执行这个，把宿主机上拉取的镜像加载到 minikube的docker环境，包括后面的 busybox 也有相似的问题，我直接限定了 busybox:1.36 版本的镜像，然后以相同的方法处理镜像下载的问题，这里固定版本的好处，方便开版本的一致，最好不要使用latest，因为那样会变化。 3>
$ kubectl get pods
NAME READY STATUS RESTARTS AGE
mysql-cluster-0 1/1 Running 0 18s
mysql-cluster-1 1/1 Running 0 14s
mysql-cluster-2 1/1 Running 0 7s 这个是正常的，说明成功了。 这个:
$ kubectl get statefulsets
NAME READY AGE
mysql-cluster 3/3 115m 也是正常的了. 注意每次处理完错误之后，需要重新apply这个yaml文件，但是需要先执行如下命令:
$ kubectl delete -f mysql-rep-cluster.yaml 如果不删除的话，可能会报如下错误:
statefulset.apps/mysql-cluster configured
The Service "mysql-cluster" is invalid: spec.clusterIPs[0]: Invalid value: "None": may not be set to 'None' for NodePort services 然后再次执行如下命令:
$ kubectl apply -f mysql-rep-cluster.yaml 4.准备配置主从
1>先进入主节点
$ kubectl exec -it mysql-cluster-0 -- mysql -uroot -p //这里把 mysql-cluster-0 当作主节点
Enter password: ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)
command terminated with exit code 1 2>.查看日志
$ kubectl logs mysql-cluster-0
2024-12-27 15:02:30+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.40-1.el9 started.
2024-12-27 15:02:45+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
2024-12-27 15:02:45+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.40-1.el9 started.
2024-12-27T15:02:45.731465Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.40) starting as process 1
2024-12-27T15:02:45.731504Z 0 [ERROR] [MY-010338] [Server] Can't find error-message file '/usr/share/mysql-8.0/errmsg.sys'. Check error-message file location and 'lc-messages-dir' configuration directive.
2024-12-27T15:02:46.140549Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
2024-12-27T15:02:53.781089Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
2024-12-27T15:02:58.264090Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.
2024-12-27T15:02:58.264138Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.
2024-12-27T15:02:58.443162Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '/var/lib/mysql' in the path is accessible to all OS users. Consider choosing a different directory.
2024-12-27T15:02:58.794415Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '::' port: 33060, socket: /var/run/mysqld/mysqlx.sock
2024-12-27T15:02:58.794503Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.40' socket: '/var/lib/mysql/mysql.sock' port: 3306 MySQL Community Server - GPL. 3>.通过/var/lib/mysql/mysql.sock sock文件连接 (默认的是 /var/run/mysqld/mysqld.sock， 但是集群配置的不是这个路径)
$ kubectl exec -it mysql-cluster-0 -- mysql -uroot -p --socket=/var/lib/mysql/mysql.sock
Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.
Your MySQL connection id is 8
Server version: 8.0.40 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners. 4>.创建一个复制用户
CREATE USER 'replicator'@'%' IDENTIFIED BY 'replica_password';
GRANT REPLICATION SLAVE ON *.* TO 'replicator'@'%';
FLUSH PRIVILEGES; mysql> show master status\\G
*************************** 1. row *************************** File: mysql-bin.000002 Position: 2095 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 5>进入第一个从节点
$ kubectl exec -it mysql-cluster-1 -- mysql -uroot -p --socket=/var/lib/mysql/mysql.sock
mysql> SHOW VARIABLES LIKE 'server_id';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| server_id | 2 |
+---------------+-------+
1 row in set (0.02 sec) mysql> SHOW VARIABLES LIKE 'log_bin';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_bin | ON |
+---------------+-------+
1 row in set (0.01 sec) 之前的错误配置导致server_id=1，导致很多问题 然后配置主从同步账号:
mysql> CHANGE MASTER TO -> MASTER_HOST='10.244.0.93', -> MASTER_USER='replica_user', -> MASTER_PASSWORD='replica_password', -> MASTER_LOG_FILE='mysql-bin.000002', -> MASTER_LOG_POS=843;
Query OK, 0 rows affected, 8 warnings (0.81 sec) mysql> START SLAVE;
Query OK, 0 rows affected, 1 warning (0.29 sec) mysql> SHOW SLAVE STATUS\\G
主要看下面两个参数是不是Yes，说明同步配置的没问题，如果不是，就说明有问题
Slave_IO_Running: Yes
Slave_SQL_Running: Yes 下麦年就是有问题的:
最开始我的写法如下
mysql> CHANGE MASTER TO -> MASTER_HOST='mysql-cluster-0.mysql.default.svc.cluster.local', -> MASTER_USER='replica_user', -> MASTER_PASSWORD='replica_password', -> MASTER_LOG_FILE='mysql-bin.000001', # -> MASTER_LOG_POS=4; 然后slave的状态:
mysql> SHOW SLAVE STATUS\\G
*************************** 1. row *************************** Slave_IO_State: Connecting to source Master_Host: mysql-cluster-0.mysql.default.svc.cluster.local Master_User: replica_user Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 4 Relay_Log_File: mysql-cluster-1-relay-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Connecting Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 4 Relay_Log_Space: 157 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULL
Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 2005 Last_IO_Error: Error connecting to source 'replica_user@mysql-cluster-0.mysql.default.svc.cluster.local:3306'. This was attempt 1/86400, with a delay of 60 seconds between attempts. Message: Unknown MySQL server host 'mysql-cluster-0.mysql.default.svc.cluster.local' (-2) Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 0 Master_UUID: Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: 241227 16:53:13 Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set, 1 warning (0.00 sec) 这里有个 Last_IO_Error，就是不能连接master的问题，然后不管我怎么修改MASTER_HOST,都有问题，最后才找到下面的答案:
DNS 解析的主机名问题:
mysql-cluster-0.mysql.default.svc.cluster.local 是通过 ClusterIP 类型的 Service 提供的 DNS 解析。当 Service 类型为 NodePort 时，它不直接支持这种集群内的主机名解析。 跨 Pod 通信的问题:
NodePort 主要用于从集群外部访问服务，而不是集群内部 Pod 的通信。在 StatefulSet 的场景中，主从之间的通信通常依赖于 ClusterIP。 因为我最开始是将service 配置的NodePort类型，所以一直有问题，后来改了还几个版本，使用ClusterIP类型才解决问题 最后我决定直接查看master的ip,将host配置为ip，如下:
$ kubectl describe svc mysql-cluster
Name: mysql-cluster
Namespace: default
Labels: <none>
Annotations: <none>
Selector: app=mysql
Type: ClusterIP
IP Family Policy: SingleStack
IP Families: IPv4
IP: 10.102.80.128
IPs: 10.102.80.128
Port: <unset> 3306/TCP
TargetPort: 3306/TCP
Endpoints: 10.244.0.93:3306,10.244.0.94:3306,10.244.0.95:3306
Session Affinity: None
Internal Traffic Policy: Cluster
Events: <none> 10.244.0.93 就是master的ip，但是这样有个缺点，就是ip可能会变化，所以配置成 mysql-cluster-0.mysql.default.svc.cluster.local 最好，但是好像还是有问题，关于这个问题还需要继续探讨... 当配置为ip之前，执行如下操作:
mysql> stop slave;
Query OK, 0 rows affected, 1 warning (0.19 sec) 然后:
mysql> CHANGE MASTER TO -> MASTER_HOST='10.244.0.93', -> MASTER_USER='replica_user', -> MASTER_PASSWORD='replica_password', -> MASTER_LOG_FILE='mysql-bin.000002', -> MASTER_LOG_POS=843;
Query OK, 0 rows affected, 8 warnings (0.81 sec) mysql> start slave;
Query OK, 0 rows affected, 1 warning (0.19 sec) mysql> show slave status\\G
*************************** 1. row *************************** Slave_IO_State: Waiting for source to send event Master_Host: 10.244.0.93 Master_User: replica_user Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 843 Relay_Log_File: relay-log-bin.000002 Relay_Log_Pos: 326 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 843 Relay_Log_Space: 534 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 16b0a150-c397-11ef-ba7e-c6314bb59e6f Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set, 1 warning (0.00 sec) 现在都是Yes了，基本可以确定主从配置完成，对第二个从节点也是类似的操作 [一天之后]，我重新启动宿主机，发现 show slave status\\G 报如下错误:
Last_IO_Error: Error connecting to source 'replica_user@10.244.0.93:3306'. This was attempt 10/86400, with a delay of 60 seconds between attempts. Message: Can't connect to MySQL server on '10.244.0.93:3306' (113) 果真，重启服务器之后，master 的 ip 发生了变化， slave 无法连接，所以这个 master_host 要配置为名称，经过我的测试，改为如下配置就可以:
mysql> CHANGE MASTER TO -> MASTER_HOST='mysql-cluster-0.mysql', -> MASTER_USER='replica_user', -> MASTER_PASSWORD='replica_password', -> MASTER_LOG_FILE='mysql-bin.000003', -> MASTER_LOG_POS=157; 配置为 mysql-cluster-0.mysql, 而不是 mysql-cluster-0.mysql.default.svc.cluster.local,
再次查看:
mysql> show slave status\\G
*************************** 1. row *************************** Slave_IO_State: Waiting for source to send event Master_Host: mysql-cluster-0.mysql Master_User: replica_user Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000003 Read_Master_Log_Pos: 472 Relay_Log_File: relay-log-bin.000002 Relay_Log_Pos: 326 Relay_Master_Log_File: mysql-bin.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 472 Relay_Log_Space: 534 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 16b0a150-c397-11ef-ba7e-c6314bb59e6f Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set, 1 warning (0.00 sec) 数据验证:
主:
mysql> show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| mysql |
| performance_schema |
| sys |
| testdb |
+--------------------+
5 rows in set (0.00 sec) mysql> mysql> mysql> use testdb;
Database changed
mysql> mysql> show tables;
Empty set (0.00 sec) mysql> mysql> mysql> CREATE TABLE users ( -> id INT PRIMARY KEY AUTO_INCREMENT, -> name VARCHAR(50), -> created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP -> );
Query OK, 0 rows affected (1.13 sec) mysql> mysql> mysql> INSERT INTO users (name) VALUES ('test1'), ('test2');
Query OK, 2 rows affected (0.14 sec)
Records: 2 Duplicates: 0 Warnings: 0 mysql> SELECT * FROM users;
+----+-------+---------------------+
| id | name | created_at |
+----+-------+---------------------+
| 1 | test1 | 2024-12-28 14:13:19 |
| 2 | test2 | 2024-12-28 14:13:19 |
+----+-------+---------------------+
2 rows in set (0.00 sec) 从:
mysql> show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| mysql |
| performance_schema |
| sys |
| testdb |
+--------------------+
5 rows in set (0.00 sec) mysql> mysql> mysql> use testdb;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A Database changed
mysql> mysql> mysql> show tables;
+------------------+
| Tables_in_testdb |
+------------------+
| users |
+------------------+
1 row in set (0.00 sec) mysql> mysql> mysql> select * from users;
+----+-------+---------------------+
| id | name | created_at |
+----+-------+---------------------+
| 1 | test1 | 2024-12-28 14:13:19 |
| 2 | test2 | 2024-12-28 14:13:19 |
+----+-------+---------------------+
2 rows in set (0.00 sec) 从库用户设置:
设置了read_only的slave节点:
mysql> SHOW VARIABLES LIKE 'read_only';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| read_only | ON |
+---------------+-------+
1 row in set (0.00 sec) mysql> SHOW VARIABLES LIKE 'super_read_only';
+-----------------+-------+
| Variable_name | Value |
+-----------------+-------+
| super_read_only | OFF |
+-----------------+-------+
1 row in set (0.00 sec) 发现可以删除数据:
mysql> select * from users;
+----+-------+---------------------+
| id | name | created_at |
+----+-------+---------------------+
| 1 | test1 | 2024-12-28 14:13:19 |
| 3 | test3 | 2024-12-28 14:17:24 |
| 4 | test4 | 2024-12-28 14:17:24 |
+----+-------+---------------------+
3 rows in set (0.00 sec) mysql> delete from users where id =3;
Query OK, 1 row affected (0.09 sec) mysql> mysql> mysql> select * from users;
+----+-------+---------------------+
| id | name | created_at |
+----+-------+---------------------+
| 1 | test1 | 2024-12-28 14:13:19 |
| 4 | test4 | 2024-12-28 14:17:24 |
+----+-------+---------------------+
2 rows in set (0.00 sec) 创建一个普通用户:
CREATE USER 'readonly_user1'@'%' IDENTIFIED BY 'password_read_only';
GRANT SELECT ON *.* TO 'readonly_user1'@'%';
FLUSH PRIVILEGES; SHOW GRANTS FOR 'readonly_user1'@'%'; mysql> CREATE USER 'readonly_user1'@'%' IDENTIFIED BY 'password_read_only';
Query OK, 0 rows affected (0.09 sec) mysql> GRANT SELECT ON *.* TO 'readonly_user1'@'%';
Query OK, 0 rows affected (0.07 sec) mysql> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.02 sec) mysql> SHOW GRANTS FOR 'readonly_user1'@'%';
+---------------------------------------------+
| Grants for readonly_user1@% |
+---------------------------------------------+
| GRANT SELECT ON *.* TO \`readonly_user1\`@\`%\` |
+---------------------------------------------+
1 row in set (0.00 sec) 使用这个普通用户登陆:
$ kubectl exec -it mysql-cluster-2 -- mysql -ureadonly_user1 -p --socket=/var/lib/mysql/mysql.sock mysql> delete from users where id = 4;
ERROR 1290 (HY000): The MySQL server is running with the --read-only option so it cannot execute this statement 现在普通用户不能删除数据，符合需求. 对于普通用户 read_only 设置会生效，如果设置了ON, 那么这个用户只能取数据。但是对于 super user 比如 root 是不生效的，super user 是由 super_read_only 来决定的。 资源查看:
$ kubectl get statefulsets
NAME READY AGE
mysql-cluster 3/3 174m $ kubectl get svc
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 18d
mysql ClusterIP None <none> 3306/TCP 174m
mysql-cluster ClusterIP 10.102.80.128 <none> 3306/TCP 174m $ kubectl get pods
NAME READY STATUS RESTARTS AGE
mysql-cluster-0 1/1 Running 0 175m
mysql-cluster-1 1/1 Running 0 175m
mysql-cluster-2 1/1 Running 0 175m linux命令补充:
vim批量删除操作:
批量部分删除
v 选行，然后 d 批量全部删除
:%d`}]},{path:"/content/database/mysql/mysql%E5%9F%BA%E4%BA%8Ek8s%E7%9A%84%E5%A4%9A%E4%B8%AA%E5%AE%9E%E4%BE%8B%E9%85%8D%E7%BD%AE.html",title:"mysql基于k8s的多个实例配置",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql基于k8s的多个实例配置:
#mysql-cluster.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata: name: mysql-cluster namespace: default
spec: serviceName: "mysql-cluster" replicas: 3 selector: matchLabels: app: mysql-cluster template: metadata: labels: app: mysql-cluster spec: containers: - name: mysql image: mysql:8.0 ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: "rootpassword" - name: MYSQL_DATABASE value: "testdb" volumeMounts: - name: mysql-data mountPath: /var/lib/mysql volumeClaimTemplates: - metadata: name: mysql-data spec: accessModes: ["ReadWriteOnce"] resources: requests: storage: 1Gi
---
apiVersion: v1
kind: Service
metadata: name: mysql-cluster namespace: default
spec: ports: - port: 3306 targetPort: 3306 nodePort: 30036 selector: app: mysql-cluster type: NodePort 这个只是一个具有多实例的mysql集群，通过nodePort访问数据库
$ kubectl apply -f mysql-cluster.yaml
statefulset.apps/mysql-cluster created
service/mysql-cluster created $ kubectl get pods
NAME READY STATUS RESTARTS AGE
mysql-cluster-0 1/1 Running 0 18s
mysql-cluster-1 1/1 Running 0 14s
mysql-cluster-2 1/1 Running 0 7s $ kubectl get svc mysql-cluster
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
mysql-cluster NodePort 10.101.179.247 <none> 3306:30036/TCP 11m 可以从宿主机使用以下命令连接到集群节点：
mysql -h <minikube-ip> -P 30036 -u root -p
其中 <minikube-ip> 可以通过以下命令获取：
$ minikube ip
192.168.49.2 使用: $ mysql -h 192.168.49.2 -P 30036 -u root -p 上面配置service端口解析:
ports: - port: 3306 # Kubernetes 服务的逻辑端口 targetPort: 3306 # Pod 内容器的端口 nodePort: 30036 # 暴露到宿主机的高位端口 port: 3306
表示服务的逻辑端口，客户端通过此端口访问服务。
当客户端发送请求到服务时，它会通过这个端口进行访问。
在 Kubernetes 集群内，其他 Pod 可以通过 mysql-cluster:3306 访问该服务。 targetPort: 3306
表示后端容器的端口，即运行在 Pod 内部容器的实际端口。
服务会将从 port 接收的请求转发到 Pod 中监听 targetPort 的容器。 nodePort: 30036
表示服务暴露在 Kubernetes 节点上的固定端口。
通过 NodePort 类型的服务，外部客户端可以通过 NodeIP:nodePort 访问该服务。
例如，如果 minikube ip 的值是 192.168.49.2，则可以通过 192.168.49.2:30036 从外部访问 MySQL。`}]},{path:"/content/database/mysql/mysql%E5%A4%96%E9%94%AE%E5%85%B3%E8%81%94%E4%BB%A5%E5%8F%8A%E7%BA%A6%E6%9D%9F.html",title:"mysql外键关联以及约束",pathLocale:"/",contents:[{header:"",slug:"",content:`MySQL有两种常用的引擎类型：MyISAM和InnoDB。目前只有InnoDB引擎类型支持外键约束。InnoDB中外键约束定义的语法如下：
ALTER TABLE tbl_name ADD [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name, ...) REFERENCES tbl_name (index_col_name,...) [ON DELETE reference_option] [ON UPDATE reference_option] 添加foreignKey:
ALTER TABLE \`user_resource\` CONSTRAINT \`FKEEAF1E02D82D57F9\` FOREIGN KEY (\`user_Id\`) REFERENCES \`user\` (\`Id\`) 向上面这样没有显式指定reference_option，默认就是 NO ACTION
也可以像下面这样显式指定reference_option：
ALTER TABLE user_resource ADD CONSTRAINT FK_8A4A6B07591CC992 FOREIGN KEY (course_id) REFERENCES user (id) ON DELETE CASCADE 下面是几个reference_option的区别:
CASCADE
在父表上update/delete记录时，同步update/delete掉子表的匹配记录 （硬删除用的比较多） SET NULL
在父表上update/delete记录时，将子表上匹配记录的列设为null (要注意子表的外键列不能为not null) NO ACTION
如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作 RESTRICT
同no action, 都是立即检查外键约束 mysql忽略外键约束:
SET FOREIGN_KEY_CHECKS = 0;
DROP TABLE user_articles;
SET FOREIGN_KEY_CHECKS = 1;`}]},{path:"/content/database/mysql/mysql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0.html",title:"mysql常用函数",pathLocale:"/",contents:[{header:"",slug:"",content:"mysql常用函数:"},{header:"COALESCE",slug:"coalesce",content:`在 MySQL 中，COALESCE 是一个控制流函数，用于返回第一个非 NULL 的值。 COALESCE(value1, value2, ..., valueN)
按顺序检查 value1, value2, ...，返回第一个非 NULL 的值。
如果所有参数都是 NULL，则返回 NULL。 例子:
SELECT COALESCE(NULL, NULL, 'Hello', 'World');
Hello 实际应用:
SELECT COALESCE(updated_at, created_at) AS orderByDate
FROM users; 如果 updated_at 为空，则用 created_at 代替。
确保 orderByDate 总有值，便于排序。`}]},{path:"/content/database/mysql/mysql%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%AD%97%E6%AE%B5%E9%A1%BA%E5%BA%8F.html",title:"mysql手动调整字段顺序",pathLocale:"/",contents:[{header:"mysql手动调整字段顺序",slug:"mysql手动调整字段顺序",content:`ALTER TABLE orders MODIFY COLUMN id int NOT NULL AUTO_INCREMENT AFTER title;//这样是可以的 ALTER TABLE orders MODIFY COLUMN id int NOT NULL AUTO_INCREMENT BEFORE title;//mysql没有before调整，只有after ALTER TABLE orders MODIFY COLUMN id int NOT NULL AUTO_INCREMENT FIRST;//mysql支持放到首尾，直接 first 总结:
MySQL 用于调整字段顺序的语法只有两个关键位置指定方式，这两个是唯一支持的调整顺序的关键字：
FIRST — 把字段放到表的第一个位置
AFTER column_name — 把字段放到指定列的后面`}]},{path:"/content/database/mysql/mysql%E6%8C%87groupby%E5%92%8Corderby.html",title:"mysql指groupby和orderby",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql指groupby和orderby:
mysql关于 group by 和 order by:
1.GROUP BY 会将相同的值分为一组，而 ORDER BY 会根据指定的列对查询结果进行排序。
2.可以在 SELECT 语句中同时使用这两个子句。通常，GROUP BY 在 ORDER BY 之前执行，因为 GROUP BY 会先处理数据并生成分组，然后 ORDER BY 会对分组后的数据进行排序。
3.GROUP BY 用于对列进行分组，不能直接对聚合函数进行分组。ORDER BY 可以对聚合函数的结果进行排序。因此，在实际使用中，通常会先使用 GROUP BY 来对数据进行分组，然后使用 ORDER BY 来排序聚合函数的结果。 例子:
select id, title, event_id, count(*) as num from articles group by event_id order by num desc;`}]},{path:"/content/database/mysql/mysql%E8%A7%A3%E5%86%B3%E5%88%86%E7%BB%84%E6%8A%A5only_full_group_by%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"mysql8解决分组报only_full_group_by的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql8解决分组报only_full_group_by的问题:
mysql8下执行group操作，会报下面的错误，5.7以上都会，只是sql_mode的参数略有不同,具体看下面的注释
Error 1055: Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'age-club-db.d_inner_products.id' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 先执行：
select @@sql_mode; 输出：
ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 删除ONLY_FULL_GROUP_BY：
STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION //注意 mysql8 是没有 NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 参数的，所以只用把 ONLY_FULL_GROUP_BY 去掉，剩下的就可以了，否则重启以后报错 vagrant@homestead:~$ sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 在 [mysqld]最后添加下面的配置，然后重启：
sql_mode="STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION vagrant@homestead:~$ sudo service mysql restart //重启 vagrant@homestead:~$ service mysql status //查看结果`}]},{path:"/content/database/mysql/mysql%E9%80%9A%E8%BF%87%E5%AD%90%E6%9F%A5%E8%AF%A2%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE.html",title:"mysql通过子查询更新数据",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql通过子查询更新数据，下面这个有使用前提就是[主表的待数据为null,需要更新为附表中的值，有个前提是 子查询的数据唯一]:
update video set course_id = (select course_id from course_manage where course_manage.type = 'video' and course_manage.content_id = video.id) where video.course_id is null; 再复杂一点儿就需要使用存储过程的游标循环来做`}]},{path:"/content/database/mysql/symfony7%E4%B9%8B%E4%BD%BF%E7%94%A8mysql8%E7%9A%84CTE%E5%8A%9F%E8%83%BD.html",title:"symfony7之使用mysql8的CTE功能",pathLocale:"/",contents:[{header:"symfony7之使用mysql8的CTE功能",slug:"symfony7之使用mysql8的cte功能",content:`使用CTE查询: public function getEventOrderTickets(Event $event): array { $sql = <<<SQL
WITH reserved AS (
SELECT ticket_id, SUM(quantity) AS reservedAmount
FROM ticket_reservations
GROUP BY ticket_id
)
SELECT
t.id,
t.title,
COALESCE(t.quantity, 0) AS availability,
COALESCE(rs.reservedAmount, 0) as reservedAmount,
s.title AS sectionTitle, COUNT(CASE WHEN o.status_id != :initialStatus THEN 1 ELSE NULL END) AS registeredAmount, COUNT(DISTINCT CASE WHEN o.status_id = :completedStatus THEN JSON_UNQUOTE(JSON_EXTRACT(r.camel_cased_registration_data, '$.email')) ELSE NULL END) AS completedCount, COUNT(DISTINCT CASE WHEN r.checked_in = 1 AND o.status_id = :completedStatus THEN JSON_UNQUOTE(JSON_EXTRACT(r.camel_cased_registration_data, '$.email')) ELSE NULL END) AS checkedInCount FROM tickets t
LEFT JOIN ticket_sections s ON t.section_id = s.id
JOIN events e ON t.event_id = e.id
LEFT JOIN event_registrations r ON r.ticket_id = t.id
LEFT JOIN event_registration_orders o ON r.order_id = o.id
LEFT JOIN reserved rs ON rs.ticket_id = t.id WHERE e.id = :eventId
GROUP BY t.id
ORDER BY t.created_at DESC
SQL;
$params = [
'eventId' => $event->getId(),
'initialStatus' => EventRegistrationOrderStatusEnum::INITIAL->value,
'completedStatus' => EventRegistrationOrderStatusEnum::COMPLETED->value,
]; return $this->getEntityManager()->getConnection() ->executeQuery($sql, $params) ->fetchAllAssociative(); } 使用子查询:
public function getEventOrderTickets(Event $event): array
{
$sql = <<<SQL
SELECT
t.id,
t.title,
COALESCE(t.quantity, 0) AS availability,
COALESCE(rs.reservedAmount, 0) as reservedAmount,
s.title AS sectionTitle,
COUNT(CASE WHEN o.status_id != :initialStatus THEN 1 ELSE NULL END) AS registeredAmount,
COUNT(DISTINCT CASE WHEN o.status_id = :completedStatus THEN JSON_UNQUOTE(JSON_EXTRACT(r.camel_cased_registration_data, '$.email')) ELSE NULL END) AS completedCount,
COUNT(DISTINCT CASE WHEN r.checked_in = 1 AND o.status_id = :completedStatus THEN JSON_UNQUOTE(JSON_EXTRACT(r.camel_cased_registration_data, '$.email')) ELSE NULL END) AS checkedInCount
FROM tickets t
LEFT JOIN ticket_sections s ON t.section_id = s.id
JOIN events e ON t.event_id = e.id
LEFT JOIN event_registrations r ON r.ticket_id = t.id
LEFT JOIN event_registration_orders o ON r.order_id = o.id
LEFT JOIN (
SELECT ticket_id, SUM(quantity) AS reservedAmount
FROM ticket_reservations
GROUP BY ticket_id
) rs ON rs.ticket_id = t.id
WHERE e.id = :eventId
GROUP BY t.id
ORDER BY t.created_at DESC
SQL;
$params = [
'eventId' => $event->getId(),
'initialStatus' => EventRegistrationOrderStatusEnum::INITIAL->value,
'completedStatus' => EventRegistrationOrderStatusEnum::COMPLETED->value,
]; return $this->getEntityManager()->getConnection() ->executeQuery($sql, $params) ->fetchAllAssociative(); }`},{header:"关于CTE",slug:"关于cte",content:`CTE(Common Table Expression)
语法真的非常强大，在复杂查询中几乎是“结构清晰 + 可复用 + 易读”的利器。`},{header:"✅ CTE（WITH 语法）强大的几点",slug:"✅-cte-with-语法-强大的几点",content:""},{header:"1. 让复杂 SQL 拆分更清晰",slug:"_1-让复杂-sql-拆分更清晰",content:`你可以把中间步骤抽出来，不需要嵌套多层子查询，逻辑清楚、语义明确：
WITH active_users AS ( SELECT id, email FROM users WHERE is_active = 1
),
order_totals AS ( SELECT user_id, SUM(total_price) AS total FROM orders GROUP BY user_id
)
SELECT u.email, o.total
FROM active_users u
LEFT JOIN order_totals o ON u.id = o.user_id 相比多层嵌套的子查询，这种结构清晰易维护。`},{header:"2. 可以递归（WITH RECURSIVE）——非常适合处理树形结构",slug:"_2-可以递归-with-recursive-——非常适合处理树形结构",content:`WITH RECURSIVE category_tree AS ( SELECT id, parent_id, name FROM categories WHERE id = 1 UNION ALL SELECT c.id, c.parent_id, c.name FROM categories c INNER JOIN category_tree ct ON c.parent_id = ct.id
)
SELECT * FROM category_tree; 🔍 这对处理无限级分类、组织结构树、评论嵌套等非常强大。`},{header:"3. 可被多次引用，提高复用性和效率",slug:"_3-可被多次引用-提高复用性和效率",content:"比如你聚合一个统计值，在后面多个 JOIN 或 SELECT 中重复使用，CTE 避免重复写 SQL，而不像子查询只能用一次。"},{header:"4. 比子查询更容易调试和优化",slug:"_4-比子查询更容易调试和优化",content:"你可以先调试 CTE 中的部分逻辑，逐步构建主查询。对于优化器来说，有些数据库（如 PostgreSQL）还会将 CTE 内联提升性能（MySQL 目前不一定内联）。"},{header:"🧠 小贴士（MySQL 限制）",slug:"🧠-小贴士-mysql-限制",content:`MySQL 8.0+ 才支持 CTE。
CTE 默认不是 materialized 的（MySQL 会尽量 inline）。 * 如果你希望明确“只执行一次”，你可能需要注意不同数据库（如 PostgreSQL、SQL Server 和 MySQL）对 CTE 的优化策略不同。 --- ##### ✅ 在 Symfony Doctrine 中用法也很友好 如果你是用： * \`->getConnection()->executeQuery($sql)\`：可以直接写 \`WITH\`。
* Doctrine DQL 不支持 CTE，但可以通过原生 SQL 或用 View、SubQuery 实现类似效果。 --- ##### CTE 默认不是 materialized 的（MySQL 会尽量 inline）, 怎么理解?
这个问题非常关键，尤其当你对性能敏感时，**CTE 是否 materialized（物化）** 会直接影响查询的执行效率。 --- ##### 什么是 CTE 的 materialized 与 inline？ 当你写： \`\`\`sql
WITH my_cte AS ( SELECT ... FROM big_table WHERE condition
)
SELECT * FROM my_cte WHERE another_condition; 数据库有两种执行策略： 策略
说明
优缺点 materialized（物化）
数据库先执行 my_cte，将结果缓存（临时表），然后再用于主查询
✅ 结果复用，避免重复计算❌ 对性能有开销（写入临时表） inline（内联）
数据库把 my_cte 看作“纯粹的子查询”，每用一次就重新执行一次
✅ 避免临时表❌ 多次引用会重复计算，影响性能`},{header:"🐬 MySQL 中的行为（重点）",slug:"🐬-mysql-中的行为-重点",content:""},{header:"✅ MySQL 8+ 中，默认是 inline 的",slug:"✅-mysql-8-中-默认是-inline-的",content:`即：CTE 不会被 materialized，而是像“语法糖的子查询”，在查询树中每次展开。
WITH my_cte AS ( SELECT * FROM big_table WHERE col > 100
)
SELECT * FROM my_cte WHERE col < 500; 等价于：
SELECT * FROM ( SELECT * FROM big_table WHERE col > 100
) AS my_cte
WHERE col < 500; 也就是说：MySQL 不会单独执行 my_cte 一次并缓存结果。`},{header:"🧪 举个例子帮助你理解",slug:"🧪-举个例子帮助你理解",content:""},{header:"假设：",slug:"假设",content:`WITH slow_query AS ( SELECT SLEEP(1) AS delay FROM some_table
)
SELECT * FROM slow_query; 如果是 materialized，只会 SLEEP(1) 一次。
如果是 inline，你引用多次，就会 SLEEP(1) 多次。`},{header:"🧩 那能不能控制它是否 materialized 呢？",slug:"🧩-那能不能控制它是否-materialized-呢",content:`✅ 在 MySQL 8.0.23+ 引入了语法控制： WITH my_cte AS MATERIALIZED ( SELECT ...
) 或者：
WITH my_cte AS NOT MATERIALIZED ( SELECT ...
)`},{header:"但注意：",slug:"但注意",content:`默认是 NOT MATERIALIZED（即 inline）
PostgreSQL 默认是 MATERIALIZED，可以手动加 NOT MATERIALIZED 控制（正相反）`},{header:"🔧 小结（MySQL 里的理解）",slug:"🔧-小结-mysql-里的理解",content:`理解点
说明 默认行为
MySQL 默认不物化（inline） 优点
快速、避免不必要的临时表 缺点
多次引用时可能导致重复计算 控制方式（8.0.23+）
可显式写 AS MATERIALIZED`},{header:"🎯 你该怎么做？",slug:"🎯-你该怎么做",content:`一次性引用，inline 足够。
多次引用 or 逻辑复杂 or 数据量大 → 用 AS MATERIALIZED 提高性能（8.0.23+）
对于写业务复杂统计、递归、去重汇总表时，materialized 更安全。
用 EXPLAIN 查看实际执行计划是关键。`}]},{path:"/content/database/mysql/%E5%85%B3%E4%BA%8Emysql%E4%B8%8Bnull%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E7%BB%86%E8%8A%82.html",title:"关于mysql下null的一个小细节",pathLocale:"/",contents:[{header:"关于mysql下null的一个小细节",slug:"关于mysql下null的一个小细节",content:`有如下部分sql语句:ero.statusId IS NULL OR ero.statusId != 0 问题如果 ero.statusId != 0 为什么不能判断 null 分析:
这是 SQL 中关于 NULL 的一个重要特性： NULL 比较的特殊性：
在 SQL 中，NULL 不等于任何值，包括它自己, 因为 NULL 不是一个「值」，而是「没有值」。所以： NULL != 0 的结果是 UNKNOWN（未知），不是 TRUE
NULL = 0 的结果也是 UNKNOWN，不是 FALSE 因此，当 ero.statusId 为 NULL 时： ero.statusId != 0 不会匹配这条记录（因为结果是 UNKNOWN）
这样没有订单的 ticket 就被过滤掉了 解决办法：
必须显式检查 NULL：ero.statusId IS NULL OR ero.statusId != 0 ero.statusId IS NULL → 匹配没有订单的 ticket ✓
ero.statusId != 0 → 匹配有订单但状态不是0的记录 ✓ 这样两种情况都被覆盖了。
简单来说：SQL 中比较 NULL 时，不能用 = 或 !=，必须用 IS NULL 或 IS NOT NULL。`}]},{path:"/content/database/mysql/%E5%85%B3%E4%BA%8Emysql%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E6%80%BB%E7%BB%93.html",title:"关于mysql索引类型总结",pathLocale:"/",contents:[{header:"关于mysql索引类型总结",slug:"关于mysql索引类型总结",content:""},{header:"这里主要拿innob分析，就目前来看，默认都是用innodb, myisam 现在使用很少, 过去总是一直说这个索引，其实呢，按适用类型来分的话，就两种:",slug:"这里主要拿innob分析-就目前来看-默认都是用innodb-myisam-现在使用很少-过去总是一直说这个索引-其实呢-按适用类型来分的话-就两种",content:`主键索引(聚簇索引（Clustered Index）)
辅助索引(辅助索引包含很多: 前缀索引 组合索引 全文索引等)`},{header:"主键索引的结构:",slug:"主键索引的结构",content:`索引数据和表的行数据存放在一起。
主键索引的叶子节点包含了完整的行数据（数据页）。 如下:
[ 50 ] ← 内部节点（索引键）
/ \\
+----------------+ +---------------------+
| [10, 20, 30] | | [50, 70, 90] | ← 叶子节点（含整行数据）
+----------------+ +---------------------+
↓ ↓
+-----------------+ +-----------------+
| PK=10, Row1 | | PK=50, Row4 |
| name: 'A' | | name: 'D' |
| age: 20 | | age: 30 |
+-----------------+ +-----------------+ +-----------------+ +-----------------+ | PK=20, Row2 | | PK=70, Row5 | | name: 'B' | | name: 'E' | | age: 25 | | age: 22 | +-----------------+ +-----------------+ +-----------------+ +-----------------+ | PK=30, Row3 | | PK=90, Row6 | | name: 'C' | | name: 'F' | | age: 28 | | age: 24 | +-----------------+ +-----------------+`},{header:"辅助索引的结构:",slug:"辅助索引的结构",content:`辅助索引的叶子节点 只包含索引列 + 主键列
并不包含整行数据（与聚簇索引不同！）
查询时，如果你要获取其他字段，就必须 “回表” 如下:`},{header:"✅ 场景设定（继续使用原表结构）：",slug:"✅-场景设定-继续使用原表结构",content:`CREATE TABLE users ( id INT PRIMARY KEY, name VARCHAR(50), age INT, INDEX idx_name(name) -- 辅助索引！
); id
name
age 10
Alice
22 20
Bob
25 30
Carol
28 40
Dave
30`},{header:"🎯 图一：辅助索引结构图（idx_name）",slug:"🎯-图一-辅助索引结构图-idx-name",content:"[ Carol ] / \\ +----------------+ +-------------------+ | Alice | Bob | | Carol | Dave | ← 叶子节点 +----------------+ +-------------------+ ↓ ↓ +-------------+ +-------------+ | name=Alice | | name=Carol | | PK=10 | | PK=30 | +-------------+ +-------------+ | name=Bob | | name=Dave | | PK=20 | | PK=40 | +-------------+ +-------------+ ←←←←←←←←←← 双向链表连接 →→→→→→→→→→"},{header:"🔁 图二：辅助索引 → 回表过程",slug:"🔁-图二-辅助索引-→-回表过程",content:`执行 SQL：
SELECT age FROM users WHERE name = 'Carol'; 执行流程图 👇
Step 1: 🔎 辅助索引 idx_name 查 name='Carol' ↓ → 定位到主键值 PK=30 Step 2: 🔁 回到主键 B+树（聚簇索引） ↓ → 从聚簇索引叶子节点中根据 PK=30 取出整行数据（包含 age 字段） Step 3: 🎯 返回结果：age=28 🧠 注意：如果 SELECT 中已经包含 name（即索引字段），那就不用回表。 二者对比, 聚簇索引 vs 辅助索引:
| 特性 | 聚簇索引（主键） | 辅助索引（非主键字段） |
| -------- | -------------- | ------------------- |
| 叶子节点内容 | ✅ 主键值 + 整行数据 | ✅ 索引字段 + 主键值（无其他字段） |
| 是否需要回表 | ❌ 不需要（行数据在叶子中） | ✅ 需要（除非查询字段只包含索引字段） |
| 查找效率 | 高 | 稍慢（需要两次树查找） |
| 索引字段可否重复 | 不可重复（主键） | 可重复（索引允许重复） |`},{header:"✅ 优化建议：",slug:"✅-优化建议",content:`| 场景 | 优化方式 |
| -------------------- | -------------------------- |
| 经常根据 name 查询，并只查 id | ✅ 使用覆盖索引，避免回表 |
| 经常根据 name 查询 + 查 age | 考虑建立**联合索引** (\`name, age\`) |
| 查询字段包含非索引列 | ✅ 回表不可避免，考虑是否值得 |
| name 很长，性能低 | 可用 \`name(10)\` 前缀索引 + hash | 📣 你还可以用 EXPLAIN FORMAT=JSON 看 MySQL 是否进行了回表操作，字段是：
"using_index": true
"using_index_condition": true`},{header:"额外说明：",slug:"额外说明",content:`MyISAM 引擎：主键索引和辅助索引都是普通的B树索引，数据和索引是分开的。
B树索引的含义:
MyISAM 的索引结构是 B树（而不是 B+树），也是一种平衡多路查找树。
索引文件里记录的是索引键值和指向数据文件中对应行的指针（偏移量）。 InnoDB 引擎：主键索引是聚簇索引，辅助索引的叶子节点存的是主键值。`}]},{path:"/content/database/mysql/%E5%85%B3%E4%BA%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91b%E6%A0%91.html",title:"关于二叉树平衡二叉树b树",pathLocale:"/",contents:[{header:"关于二叉树 平衡二叉树 b树",slug:"关于二叉树-平衡二叉树-b树",content:""},{header:"1. 什么是二叉树？",slug:"_1-什么是二叉树",content:`二叉树是一种 每个节点最多有两个子节点（左子节点和右子节点） 的数据结构。
树结构用于存储层级关系，支持快速查找、插入和删除。`},{header:"特点：",slug:"特点",content:`每个节点最多有两个子节点。
没有其他要求。`},{header:"2. 什么是平衡二叉树？",slug:"_2-什么是平衡二叉树",content:`平衡二叉树是一种特殊的二叉树，保证左子树和右子树的高度差不超过1。
这样保证了树的高度尽可能低，避免退化成链表，查找效率高。`},{header:"常见的平衡二叉树：",slug:"常见的平衡二叉树",content:`AVL树
红黑树`},{header:"3. MySQL 中的树结构",slug:"_3-mysql-中的树结构",content:"MySQL 中用到的数据结构主要是："},{header:"B+ 树（B树的变种）",slug:"b-树-b树的变种",content:`MySQL InnoDB 的索引底层实现用的是 B+ 树，而不是简单的二叉树。
B+ 树是一种多路平衡查找树，节点可以有多个子节点。
优点是适合磁盘存储，减少磁盘IO次数。
叶子节点中存储了所有的实际数据（InnoDB聚簇索引），非叶子节点存储索引。`},{header:"为什么不用平衡二叉树？",slug:"为什么不用平衡二叉树",content:`二叉树的高度会比较高，不利于磁盘IO。
B+ 树的多路分支大大减少了树的高度，使得查询更快。
由于数据库存储在磁盘上，B+树的设计更加符合磁盘块存储的特点。`},{header:"4. 区别总结",slug:"_4-区别总结",content:`结构
二叉树
平衡二叉树
B+树（MySQL索引底层） 每个节点子节点数
最多2个
最多2个
多个子节点 是否平衡
不一定
保证平衡（左右子树高度差≤1）
保证平衡 适合场景
内存中简单结构
内存中需快速查找
磁盘存储、数据库索引 叶子节点数据
可以存，也可以不存
可以存，也可以不存
叶子节点存所有数据 查找效率
可能退化到O(n)
O(log n)
O(log n)，更适合磁盘IO`},{header:"5. 简单示意图",slug:"_5-简单示意图",content:""},{header:"二叉树示意",slug:"二叉树示意",content:"10 / \\ 5 20 / \\ 3 7"},{header:"平衡二叉树（AVL）",slug:"平衡二叉树-avl",content:"同样结构，但保证左右子树高度差 ≤ 1"},{header:"B+树（简化示意）",slug:"b-树-简化示意",content:`[10 | 20] / | \\ [1..9] [11..19] [21..30]
叶子节点存储所有数据`},{header:"6. 总结",slug:"_6-总结",content:`MySQL 实际用的是B+树，不是简单的二叉树或平衡二叉树。
平衡二叉树主要用于内存中数据结构（如红黑树在某些缓存或内存索引中）。
二叉树是基础概念，平衡二叉树是它的优化版本。
B+树适合数据库磁盘存储和索引需求。`}]},{path:"/content/database/mysql/%E5%A4%9A%E6%AC%A1leftjoin%E4%BB%A5%E5%8F%8A%E8%81%9A%E5%90%88%E6%9F%A5%E8%AF%A2%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%87%86%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"多次leftjoin以及聚合查询导致数据不准的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`多次leftjoin以及聚合查询导致数据不准的问题
原sql:
SELECT mmr_ID, mmr_projectName, SUM(mmr_hoursWorked.mmr_hoursWorked_hours) AS sumHours
FROM mmr LEFT JOIN mmr_hoursWorked
ON mmr.mmr_ID = mmr_hoursWorked.mmr_hoursWorked_project AND mmr_hoursWorked.mmr_hoursWorked_mm = "P90826"
LEFT JOIN mmr_notes
ON mmr.mmr_ID = mmr_notes.mmr_notes_MMR_ref AND mmr_notes.mmr_notes_author = "P90826"
WHERE mmr_mmAssigned = "P90826" AND mmr_projectStatus != 1 OR mmr_notes.mmr_notes_author = "P90826" AND mmr_projectStatus != 1 GROUP BY mmr_ID 由于JOIN语句返回了结果组合，因此应该分别处理聚合和连接 新sql:
SELECT t.*
FROM
( SELECT mmr_ID, mmr_projectName, SUM(mmr_hoursWorked.mmr_hoursWorked_hours) AS sumHours FROM mmr LEFT JOIN mmr_hoursWorked ON mmr.mmr_ID = mmr_hoursWorked.mmr_hoursWorked_project AND mmr_hoursWorked.mmr_hoursWorked_mm = 'P90826' WHERE mmr_projectStatus != 1 AND mmr_mmAssigned = 'P90826' GROUP BY mmr_ID, mmr_projectName, mmr_mmAssigned
) t
LEFT JOIN mmr_notes
ON t.mmr_ID = mmr_notes.mmr_notes_MMR_ref WHERE mmr_notes.mmr_notes_author = 'P90826';`}]},{path:"/content/database/redis/memecached%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C.html",title:"memecached命令操作",pathLocale:"/",contents:[{header:"",slug:"",content:`memecached命令操作:
1.连接客户端
$ telnet 127.0.0.1 11211 2.查看memcached状态
$ stats 3.查看所有的items
$ stats items 4.查看指定item，通过命令stats cachedump id 0获得key的值。0表示全部列出
$ stats cachedump 7 0 5.获取知道你功夫key对应的值
$ get 15711150681vc //get命令获得key的值 6.删除key
flush_all`}]},{path:"/content/database/redis/redis%E4%B9%8Bstream%E7%B1%BB%E5%9E%8B.html",title:"redis之stream类型",pathLocale:"/",contents:[{header:"",slug:"",content:`php项目用到消息队列，配置了redis，发现数据存储的是stream类型
介绍:
Redis Stream 是 Redis 5.0 版本新增加的数据结构。
Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，
但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。
简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。
而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 命令:
redis> XRANGE messages - + // 获取key messages 下的所有数据`}]},{path:"/content/database/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96%E5%88%86%E6%9E%90.html",title:"redis持久化分析",pathLocale:"/",contents:[{header:"redis持久化分析",slug:"redis持久化分析",content:""},{header:"Redis 提供两种持久化机制：",slug:"redis-提供两种持久化机制",content:""},{header:"1. RDB（Redis Database）",slug:"_1-rdb-redis-database",content:`以 二进制快照 方式保存数据到磁盘。
触发方式： 默认会在一定间隔或达到一定条件（如 N 秒内 M 次修改）时进行 自动快照。
可以执行 SAVE(手动)（阻塞当前进程）或 BGSAVE(手动/自动)（创建子进程异步执行）。 优点： 适合大规模数据恢复（启动时直接加载）。
采用二进制存储，占用空间小，恢复速度快。 缺点： 可能会丢失最近的数据（因为是定期持久化）。
需要 fork 进程，可能消耗 CPU 和内存。`},{header:"2. AOF（Append Only File）",slug:"_2-aof-append-only-file",content:`记录 所有写操作日志，以追加的方式存入文件。
触发方式： appendfsync 配置： always（每次写入都同步，最安全但最慢）。
everysec（每秒同步一次，折中）。
no（依赖 OS，最快但可能丢失数据）。 优点： 数据持久性更强，几乎不会丢失数据。 缺点： AOF 文件比 RDB 大，恢复速度相对慢。
需要定期 AOF rewrite 以控制文件大小。`},{header:"两者组合",slug:"两者组合",content:`Redis 允许 同时开启 RDB 和 AOF，结合两者优点： 先用 RDB 快速加载数据。
再用 AOF 追加最新数据，减少数据丢失。`},{header:"适用场景",slug:"适用场景",content:`机制
适用场景 RDB
适用于 数据丢失影响较小，但需要 快速恢复 的场景，比如缓存 AOF
适用于 数据持久化要求高，但对恢复时间要求不严格的业务 RDB + AOF
需要 快速恢复 和 高持久性 的业务，如重要数据库 如果你的 Redis 需要较强的持久性，一般建议 开启 AOF，并配置 everysec，同时保留 RDB 作为额外的备份手段。`},{header:"redis默认持久化方式",slug:"redis默认持久化方式",content:`Redis 默认使用的是 RDB（Redis Database） 持久化方式。 在默认情况下，Redis 会根据以下配置生成 RDB 快照文件：
save 900 1 # 900秒（15分钟）内，如果至少有1个键被修改，则保存快照
save 300 10 # 300秒（5分钟）内，如果至少有10个键被修改，则保存快照
save 60 10000 # 60秒内，如果至少有10000个键被修改，则保存快照 这个配置意味着 Redis 会在满足一定条件时定期生成快照并保存到磁盘，通常是 dump.rdb 文件。这个文件存放在 Redis 数据目录下，并且是默认的持久化方式。
如果需要启用 AOF（Append-Only File）持久化，可以通过修改 redis.conf 配置文件中的 appendonly 配置项：
appendonly yes
默认情况下，AOF 是关闭的，因此 Redis 启动时只会根据 RDB 快照来加载数据。如果启用了 AOF，Redis 会将每个写操作追加到 AOF 文件中，提供更高的持久性。 如果手动注释掉默认的RDB配置，那么，Redis 将 不再自动进行 RDB 持久化。即数据不会定期保存到磁盘中。如果也不启用 AOF，那么 Redis 只会存储数据在内存中，这意味着数据在 Redis 重启后会丢失。`},{header:"RDB方式的影响",slug:"rdb方式的影响",content:`执行 SAVE 或 BGSAVE(包括自动执行) 后，都会生成新的备份文件（dump.rdb），并且覆盖之前的文件。如果需要保留多个备份，建议手动管理文件名。
例如，可以在执行命令之前，手动将当前的 dump.rdb 重命名为一个带有时间戳或其他标识符的文件：
mv dump.rdb dump-$(date +%Y%m%d%H%M%S).rdb Redis 不会同时保存多个 RDB 文件，只有最新的快照会保存在 dump.rdb 文件中。所以每次执行 SAVE、BGSAVE 或自动触发的持久化时，dump.rdb 都会被新快照替换。`},{header:"最新的RDB文件包括哪些信息",slug:"最新的rdb文件包括哪些信息",content:`当 Redis 执行 SAVE 或 BGSAVE 并覆盖现有的 dump.rdb 文件时，新的 dump.rdb 文件将包含当前 Redis 数据库中的所有数据，即在执行快照时 Redis 内存中的数据状态。 新的 dump.rdb 文件包含的内容：
1>所有数据库的数据：
Redis 默认会有 16 个数据库（编号从 0 到 15），如果你没有修改 redis.conf 中的 databases 配置，新的 dump.rdb 文件会包含所有数据库（及其对应的键值对）的数据。
每个数据库的内容（键和值）都会被保存到新的 dump.rdb 文件中。 2>当前内存中的所有数据：
Redis 在执行快照时，会将 当前内存中的所有键值对（包括字符串、哈希、列表、集合、有序集合等数据结构）保存到磁盘。无论这些数据来自手动写入、自动持久化、还是客户端操作，都会被完整保存。 3>元数据（例如过期键信息）：
dump.rdb 文件还会包含一些与 Redis 数据库相关的元数据，比如键的过期时间（如果有设置过期时间的键）和数据库版本等信息。`},{header:"AOF方式影响",slug:"aof方式影响",content:`默认情况下，Redis 会 只生成一个 AOF 文件，即 appendonly.aof。所有的写命令都会追加到这个文件中。
如果 Redis 重启或持久化操作（例如 AOF 重写）发生，原有的 AOF 文件可能会被重命名为备份文件（如 appendonly.aof.old），并且 Redis 会创建一个新的 AOF 文件。
可以在配置文件中指定多个 AOF 文件，但默认情况下 Redis 只会使用一个 appendonly.aof 文件。 Redis 在使用 AOF 时，也有非阻塞模式（例如，appendfsync always 和 appendfsync everysec）。具体来说：
主进程继续服务客户端请求：Redis 会将每个写操作命令追加到 AOF 文件中。即使 AOF 持久化正在进行，主进程也可以继续处理客户端请求，不会被阻塞。
写操作的影响：在 AOF 持久化过程中，新的写操作会被追加到 AOF 文件中，并且会与现有的 AOF 持久化机制一起进行处理。例如，如果你设置了 appendfsync everysec，Redis 会每秒同步一次 AOF 文件，新的写操作会被定期追加到文件中。`},{header:"AOF 的配置选项",slug:"aof-的配置选项",content:`AOF 的操作和行为可以通过 Redis 配置文件（redis.conf）进行调整，常见的配置选项包括：
appendonly：启用或禁用 AOF，默认为 no。
appendfsync：控制 AOF 的写入同步策略，选项有：
always：每次写入操作都同步到磁盘（最安全，但性能差）。
everysec：每秒同步一次（推荐，平衡了性能和安全性）。
no：不同步（最快，但可能丢失数据）。
auto-aof-rewrite-percentage：触发 AOF 重写的大小增长百分比。
auto-aof-rewrite-min-size：触发 AOF 重写的最小文件大小。`},{header:"AOF 的恢复过程",slug:"aof-的恢复过程",content:"在 Redis 重启时，AOF 文件会被加载到内存中。Redis 会按顺序执行 AOF 文件中的命令，从而恢复数据。恢复过程比 RDB 快照更慢，因为 Redis 需要按顺序重放所有的操作命令，但能够提供更精确的恢复（即恢复到某个时间点）"},{header:"最新的AOF文件会包含哪些信息",slug:"最新的aof文件会包含哪些信息",content:"与 RDB 不同，AOF 会记录 每个执行的写命令（如 SET, HSET, LPUSH 等），并将它们追加到日志文件中。通过重放这些命令，可以恢复数据库的状态。"},{header:"结论：",slug:"结论",content:`RDB 快照：保存的是 Redis 数据库 在某一时刻的完整状态（即所有键值对和其元数据），而不包括实际执行的操作命令。
AOF 持久化：保存的是执行的每个操作命令，可以按顺序重放这些命令恢复数据。`},{header:"AOF 重写",slug:"aof-重写",content:`AOF 重写（AOF Rewrite）是 Redis 提供的一种机制，用于优化 AOF 文件的大小和性能，避免 AOF 文件在长时间运行后变得过于庞大，导致加载和恢复数据时变慢。AOF 重写过程会将当前数据库状态以最小的操作量重新写入新的 AOF 文件，替代原先的 AOF 文件，从而减少冗余和提高性能。 AOF 重写的基本原理：
1>AOF 重写的目的：
随着 Redis 运行，所有写操作会被追加到 appendonly.aof 文件中。随着时间的推移，这个文件可能变得非常大，特别是当你进行大量小的写操作时。由于 AOF 文件会记录每个操作命令，而 Redis 实际的内存状态可能已经发生了很大的变化，许多操作已经不再需要（例如，如果一个键已经被修改或删除，它的历史命令就不再重要）。
AOF 重写就是通过将当前数据库状态（包括所有现有数据）写入一个新的文件，替代现有的 AOF 文件，从而减小文件大小，消除冗余的命令。 2>AOF 重写的工作流程：
异步执行：AOF 重写是异步进行的。Redis 会在后台启动一个新的进程来重写 AOF 文件，这样 Redis 主进程可以继续处理客户端请求，不会阻塞。
新文件生成：在重写过程中，Redis 会通过将数据库的当前状态（从内存中导出的键值对）转换成 AOF 命令的形式，并写入新的 AOF 文件中。这些 AOF 命令会被精简，仅包含最基本的操作（即能够将数据库恢复到当前状态的命令）。
重写完成：当新的 AOF 文件完成后，原有的 AOF 文件会被替换掉。 3>AOF 重写的触发条件： AOF 重写并不是每次都会触发，它有一定的触发条件。Redis 会根据配置选项自动触发 AOF 重写，或者你可以手动触发。常见的触发条件有：
auto-aof-rewrite-percentage：AOF 文件的大小变化百分比。如果当前 AOF 文件的大小比上一次 AOF 重写时大了指定百分比（例如 100%），则触发重写。
auto-aof-rewrite-min-size：AOF 文件的最小大小。如果 AOF 文件的大小超过了这个最小值，并且符合 auto-aof-rewrite-percentage 的要求，AOF 重写将会触发。
手动触发：你也可以通过执行 BGREWRITEAOF 命令来手动触发 AOF 重写操作。`},{header:"Redis持久化有个常见问题，不管是RDB还是 AOF, 如果都不用阻塞的方式持久化，那么在持久化的时候，还有写操作或者更新操作，有影响吗",slug:"redis持久化有个常见问题-不管是rdb还是-aof-如果都不用阻塞的方式持久化-那么在持久化的时候-还有写操作或者更新操作-有影响吗",content:`这个问题涉及到一个 数据一致性问题，对于AOF是没有任何影响的，因为 AOF 是以追加的方式将命令写入文件的，并不涉及创建副本或进行内存快照，所以不存在像 RDB 那样需要担心 COW 问题。但是对于RDB是由影响的，但是有方法加解决,
为了确保数据的一致性，Redis 采用了一种叫做 copy-on-write (COW) 的机制。这是通过操作系统级的内存管理机制来实现的。具体来说，copy-on-write 允许子进程在进行快照时，只读取内存数据的快照，而不影响主进程对数据的修改。`},{header:"COW机制",slug:"cow机制",content:`写时复制（Copy-on-Write, COW），这是操作系统内存管理的一个优化技术。当 Redis 执行 RDB 快照时，创建一个子进程(从父进程fork)用于复制内存中的数据。在这个过程中，父进程继续处理写操作，但不会直接影响子进程的数据。具体来说，这个机制通过操作系统的内存管理实现了“惰性复制”，即只有在修改数据时才会实际复制数据。让我们一步步解析： 写时复制（COW）概念：
写时复制（COW）是一个内存优化策略，主要用于避免不必要的数据复制。在 COW 机制下，当进程创建一个子进程时，子进程并不会直接复制父进程的所有内存数据，而是和父进程共享相同的内存页面（内存的最小单元）。这时，父进程和子进程都可以访问相同的数据。
但是，当父进程或子进程对共享内存做修改时(这个才是重点，cow其实为了处理父进程/子进程对内存内容修改的问题，对如RDB,子进程不会修改数据，所以子进程不会cow,只会在父进程出现)，操作系统才会实际创建内存的副本，并且修改的部分仅会影响其中一个进程。这就避免了不必要的内存复制，提高了效率。 在 Redis 中的应用：
1.子进程创建快照：当 Redis 执行 BGSAVE 命令时，创建一个子进程来进行 RDB 快照生成。子进程会开始读取 Redis 内存中的数据，但是在这时，父进程的数据和子进程的数据是共享的，没有立即复制。父进程和子进程都访问同一块内存区域。 2.父进程修改数据：如果此时父进程有写操作，操作系统会利用 COW 特性延迟复制被修改的内存页面。假设父进程修改了某个内存数据，当父进程试图修改该数据时，操作系统会为父进程“复制”一个新的内存页。父进程继续操作这个新的内存页，而子进程仍然保持对旧内存页的只读访问。 3.子进程的读取操作：子进程在进行快照时，读取的是父进程内存中没有被修改的部分。如果父进程没有修改某些数据，子进程和父进程可以共享这部分数据，避免不必要的复制。 4.写操作的影响：因为修改的内存会被复制到新的内存页，所以写操作不会影响到子进程正在读取的快照数据。也就是说，子进程快照的数据并不会被父进程的写操作改变，它会保持快照开始时的一致性。 5.完成快照：当子进程完成快照时，它会将快照数据写入磁盘。此时，子进程和父进程的数据已经分离，互不干扰。父进程继续进行写操作，子进程已经完成快照。`},{header:"操作系统会为父进程创建一个新的内存副本， 这个新的内存副本包括哪些数据",slug:"操作系统会为父进程创建一个新的内存副本-这个新的内存副本包括哪些数据",content:`在 写时复制（Copy-on-Write, COW） 机制中，当父进程（如 Redis 主进程）修改数据时，操作系统为父进程创建的新的内存副本仅包括 父进程修改的内存页，而不会复制整个内存空间。 具体来说，内存副本的内容包括哪些数据？
1.修改过的数据页（Memory Page）： 操作系统采用的是 按页（page）进行内存管理。内存通常是按 4KB（或更大）为单位划分为多个页。父进程修改内存中的数据时，操作系统并不会直接复制整个数据块，而是只会 复制那些实际被修改的内存页。
这些修改后的内存页是新的副本，只对父进程可见，子进程仍然看到旧的内存页，直到子进程尝试修改这些数据页时才会触发复制。 2.修改的数据内容：
如果父进程修改了某个键的值，操作系统会为该键所在的内存页创建一个新的副本，存储修改后的值。
其他没有被修改的内存页则仍然由父进程和子进程共享，不会被复制。 3.其他内存区域：
对于未被修改的内存区域（例如其他键值对或数据结构），操作系统不会为这些部分创建副本，而是让父进程和子进程共享这些内存页面。这样，内存使用得到有效优化。`},{header:"副本的页数据不需要和原始内存页的数据同步吗",slug:"副本的页数据不需要和原始内存页的数据同步吗",content:`为什么副本和原始数据不需要同步？
在 COW 机制下，内存页在进程修改数据时被复制。具体来说，当一个进程修改共享内存页时，操作系统会将该页复制到该进程的私有地址空间，之后修改会发生在副本上。原始内存页保持不变，直到有另一个进程尝试修改它时，才会再次触发 COW 机制。 为什么不需要同步？
减少开销：COW 机制的主要优势是 延迟内存复制，只有在需要修改数据时才会进行复制。通过这种方式，多个进程可以共享相同的数据，直到某个进程修改数据时才会消耗额外的内存来创建副本。这个过程避免了不必要的复制开销。
独立修改：副本和原始内存页在被复制后是 独立的。修改副本只会影响该进程的数据，而不会影响其他进程。如果副本和原始数据是同步的，那么这将使得数据在多个进程间共享时出现冲突和复杂性。
并发性：不同的进程在不同的时间对数据进行修改，副本机制保证了每个进程都有自己的独立数据副本，这样就避免了多个进程对同一块内存进行并发写入时的竞争问题。`},{header:"对于父进程(主进程)在触发 COW 后，父进程会访问 两个数据页(副本和原始)",slug:"对于父进程-主进程-在触发-cow-后-父进程会访问-两个数据页-副本和原始",content:`COW 机制和内存页访问
共享内存页：
初始时，父进程和子进程共享同一块内存。假设父进程和子进程共享两个数据：key1 = "value1" 和 key2 = "value2"，这两个数据通常会存储在 相同的内存页 中。这个内存页是只读的。 触发 COW：
当父进程修改 key1（例如将其值改为 "new_value"）时，操作系统会创建 key1 的副本（这通常是一个新的内存页），并将修改后的值存储在副本中。此时，原始内存页中的 key1 = "value1" 保持不变，父进程会访问新的副本，修改后的 key1 = "new_value"。 父进程访问内存页：
key1 的副本：父进程访问修改后的 key1 = "new_value" 时，操作系统会将父进程指向新创建的副本内存页。
key2 仍然在原始内存页：对于 key2，因为父进程并没有修改它，所以父进程仍然会访问原始内存页中的 key2 = "value2"，而该内存页没有发生改变。 总结:
在父进程修改 key1 时，操作系统创建了 key1 的副本，但父进程 仍然可以访问 key2，并且会继续访问原始的内存页。父进程通过不同的内存页访问 key1 和 key2，因此 父进程会同时访问两个数据页：一个包含修改后的 key1，另一个包含未修改的 key2。`}]},{path:"/content/database/redis/redis%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%9F%A5%E7%9C%8B.html",title:"redis版本信息查看",pathLocale:"/",contents:[{header:"",slug:"",content:`通过 info server命令即可:
[root@VM-0-12-centos local]# redis-cli
127.0.0.1:6379> info server
# Server
redis_version:7.0.0
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:be628bea27b47068
redis_mode:standalone
os:Linux 3.10.0-1160.62.1.el7.x86_64 x86_64
arch_bits:64
monotonic_clock:POSIX clock_gettime
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:4.8.5
process_id:15227
process_supervised:no
run_id:bd9f26195b882b46fe51054f5fb88da8798d2459
tcp_port:6379
server_time_usec:1661233427282861
uptime_in_seconds:8475918
uptime_in_days:98
hz:10
configured_hz:10
lru_clock:289043
executable:/usr/local/redis-7.0.0/./src/redis-server
config_file:/usr/local/redis-7.0.0/./redis.conf
io_threads_active:0
127.0.0.1:6379>`}]},{path:"/content/database/redis/ubuntu22%E5%AE%89%E8%A3%85memecached.html",title:"ubuntu22安装memecached",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22安装memecached 主要操作步骤如下:
root@k8s:~$ memcached --version
Command 'memcached' not found, but can be installed with:
root@k8s:~$ cd /usr/local/
Cannot write to ‘memcached-1.6.21.tar.gz’ (Permission denied).
root@k8s:/usr/local$ sudo wget -c http://www.memcached.org/files/memcached-1.6.21.tar.gz //官网地址:https://memcached.org/
root@k8s:/usr/local$ sudo tar zxvf memcached-1.6.21.tar.gz
root@k8s:/usr/local$ cd memcached-1.6.21/ 现在安装libevent-dev包，因为它是memcached的依赖项：
root@k8s:/usr/local/memcached-1.6.21$ sudo apt install libevent-dev -y root@k8s:/usr/local$./configure && make && make test && sudo make install 当通过源码安装 Memcached 时，配置文件通常不会自动生成，而是需要手动创建。配置文件的位置可以自行指定，但通常会将其放在 /etc 目录下或 Memcached 的安装目录中
可以手动创建 Memcached 的配置文件。配置文件通常命名为 memcached.conf。你可以选择将其放在 /etc 目录下或 Memcached 的安装目录中。在配置文件中，你可以指定 Memcached 的监听地址、端口、缓存大小以及其他配置选项。
下面是一个示例配置文件的内容：
# Sample Memcached configuration file # Run memcached as a daemon (background process)
-d # Listen on localhost (127.0.0.1) and port 11211
-l 127.0.0.1
-p 11211 # Set the memory cache size to 64 megabytes
-m 64 命令行运行:
/usr/local/memcached-1.6.21/memcached -P /path/to/your/memcached.conf //没有bin 文件，直接就是 memcached 可执行文件
/usr/local/memcached-1.6.21/memcached -d -m 64 -l 127.0.0.1 -p 11211 配置成服务运行:
sudo vim /etc/systemd/system/memcached.service [Unit]
Description=Memcached caching server [Service]
ExecStart=/usr/local/memcached-1.6.21/memcached -u root -p 11211 -m 128 #这里的user 必须配置，配置成这个文件的所有者就可以了，不然启动失败
Restart=always
User=root
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=memcached [Install]
WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl status memcached
sudo systemctl start memcached`}]},{path:"/content/database/redis/%E5%85%B3%E4%BA%8EkeyDB%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"关于keyDB的使用",pathLocale:"/",contents:[{header:"关于keyDB的使用",slug:"关于keydb的使用",content:""},{header:"1.服务配置",slug:"_1-服务配置",content:`docker-compose 文件
vim docker-compose.yml version: "3.9"
services:
keydb-master:
image: eqalpha/keydb:latest
container_name: keydb-master
restart: unless-stopped
ports:
- "6381:6379"
volumes:
- ./master-data:/data
- ./master.conf:/etc/keydb/keydb.conf
command: ["keydb-server", "/etc/keydb/keydb.conf"] keydb-replica:
image: eqalpha/keydb:latest
container_name: keydb-replica
restart: unless-stopped
ports:
- "6382:6379"
volumes:
- ./replica-data:/data
- ./replica.conf:/etc/keydb/keydb.conf
depends_on:
- keydb-master
command: ["keydb-server", "/etc/keydb/keydb.conf"] 创建目录
mkdir -p master-data replica-data 主配置
vim master.conf KeyDB 主节点配置
port 6379
bind 0.0.0.0
requirepass yourpassword
masterauth yourpassword 数据持久化
save 900 1
save 300 10
save 60 10000
dir /data
dbfilename keydb-master.rdb 日志
loglevel notice
logfile "" 其他配置
timeout 0
tcp-keepalive 300
supervised no
pidfile /var/run/keydb_6379.pid
databases 16 从配置
vim replica.conf KeyDB 副本节点配置
port 6379
bind 0.0.0.0
requirepass yourpassword
masterauth yourpassword 主从复制配置
replicaof keydb-master 6379
replica-read-only yes
replica-serve-stale-data yes
replica-priority 100 数据持久化
save 900 1
save 300 10
save 60 10000
dir /data
dbfilename keydb-replica.rdb 日志
loglevel notice
logfile "" 其他配置
timeout 0
tcp-keepalive 300
supervised no
pidfile /var/run/keydb_6379.pid
databases 16`},{header:"启动服务",slug:"启动服务",content:`$ docker-compose up -d
WARN[0000] /home/mdpi/code/code-new/my-keyDB/docker-compose.yml: \`version\` is obsolete
[+] Running 3/3
✔ Network my-keydb_default Created 0.1s
✔ Container keydb-master Started 0.0s
✔ Container keydb-replica Started`},{header:"查看运行状态",slug:"查看运行状态",content:`$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
0e1a6ca9d96e eqalpha/keydb:latest "docker-entrypoint.s…" 8 seconds ago Up 8 seconds 0.0.0.0:6382->6379/tcp, :::6382->6379/tcp keydb-replica
ade18b7c5898 eqalpha/keydb:latest "docker-entrypoint.s…" 8 seconds ago Up 8 seconds 0.0.0.0:6381->6379/tcp, :::6381->6379/tcp keydb-master`},{header:"查看配置是否生效",slug:"查看配置是否生效",content:`$ docker exec -it keydb-master keydb-cli -a yourpassword INFO replication
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
role:master
connected_slaves:1
slave0:ip=172.22.0.3,port=6379,state=online,offset=37,lag=1
master_failover_state:no-failover
master_replid:f214c2411a60042d8e85679c3f3f7648943a245c
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:37
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:37 $ docker exec -it keydb-replica keydb-cli -a yourpassword INFO replication
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
role:slave
master_global_link_status:up
connected_masters:1
master_host:keydb-master
master_port:6379
master_link_status:up
master_last_io_seconds_ago:7
master_sync_in_progress:0
slave_read_repl_offset:51
slave_repl_offset:51
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:f214c2411a60042d8e85679c3f3f7648943a245c
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:51
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:51`},{header:"测试",slug:"测试",content:`$ docker exec -it keydb-master keydb-cli -a yourpassword SET test "hello world"
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
OK $ docker exec -it keydb-replica keydb-cli -a yourpassword GET test
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
"hello world"`},{header:"配置分析",slug:"配置分析",content:`requirepass yourpassword
作用: 设置当前节点的访问密码
用途: 客户端连接到这个节点时需要提供的密码
相当于: "进入这个节点需要密码" masterauth yourpassword
作用: 设置连接主节点时使用的密码
用途: 当前节点作为副本连接主节点时的认证密码
相当于: "连接主节点时用这个密码" 主节点上也配置了: masterauth yourpassword 虽然是主节点，但配置上以防角色切换`},{header:"结论: 顺利启动",slug:"结论-顺利启动",content:""},{header:"简单运行一个laravel12项目，用来测试上面的 keyDB 读写分离",slug:"简单运行一个laravel12项目-用来测试上面的-keydb-读写分离",content:`1.运行comoser 创建命令$ composer create-project laravel/laravel laravel12-project "12.*" Problem 1
- Root composer.json requires laravel/pint ^1.24 -> satisfiable by laravel/pint[v1.24.0, v1.25.0, v1.25.1].
- laravel/pint[v1.24.0, ..., v1.25.1] require ext-xml * -> it is missing from your system. Install or enable PHP's xml extension.
Problem 2
- phpunit/phpunit[11.5.3, ..., 11.5.41] require ext-dom * -> it is missing from your system. Install or enable PHP's dom extension.
- Root composer.json requires phpunit/phpunit ^11.5.3 -> satisfiable by phpunit/phpunit[11.5.3, ..., 11.5.41]. To enable extensions, verify that they are enabled in your .ini files:
- /etc/php/8.4/cli/php.ini
- /etc/php/8.4/cli/conf.d/10-opcache.ini
- /etc/php/8.4/cli/conf.d/10-pdo.ini
- /etc/php/8.4/cli/conf.d/20-calendar.ini
- /etc/php/8.4/cli/conf.d/20-ctype.ini
- /etc/php/8.4/cli/conf.d/20-exif.ini
- /etc/php/8.4/cli/conf.d/20-ffi.ini
- /etc/php/8.4/cli/conf.d/20-fileinfo.ini
- /etc/php/8.4/cli/conf.d/20-ftp.ini 这个报错的意思是 PHP 缺少一些扩展，Laravel 12 的 pint 和 phpunit 需要用到 ext-xml 和 ext-dom。
具体解决方法如下：`},{header:"1. 安装缺失的 PHP 扩展",slug:"_1-安装缺失的-php-扩展",content:`根据你的操作系统不同，安装方式也不一样。你用的是 PHP 8.4（报错里显示 /etc/php/8.4/cli/php.ini），假设是 Ubuntu / Debian 系统：
sudo apt update
sudo apt install php8.4-xml php8.4-xml 会包含 ext-xml 和 ext-dom。
安装后，重启 PHP-FPM / CLI： sudo service php8.4-fpm restart`},{header:"2. 确认扩展已启用",slug:"_2-确认扩展已启用",content:`php -m | grep -E 'xml|dom' 如果输出：
dom
xml 就说明安装成功。`},{header:"3. 重新执行 Composer",slug:"_3-重新执行-composer",content:`composer install 由于使用的是phpredis 客户端，所以还需要 sudo apt install php8.4-redis
还需要：
sudo apt install php8.4-mbstring， 否则报：Call to undefined function Illuminate\\Support\\mb_split()
sudo apt install php8.4-mysql 否则报: could not find driver (Connection: mysql 2.配置redis
'write' => [
'host' => env('REDIS_HOST_1', '127.0.0.1'),
'password' => env('REDIS_PASSWORD', null),
'port' => env('REDIS_PORT_1', 6379), // KeyDB 主节点
'database' => 0,
],
'read' => [
'host' => env('REDIS_HOST_2', '127.0.0.1'),
'password' => env('REDIS_PASSWORD', null),
'port' => env('REDIS_PORT_2', 6380), // KeyDB 从节点
'database' => 0,
], 3.通过php-cli启动服务
php artisan serve (默认8000端口) 也可以手动指定端口
php artisan serve --port=8080 也可以手动指定 IP + 端口（比如想局域网访问）
php artisan serve --host=0.0.0.0 --port=8081 4.测试:
<?php namespace App\\Helpers; use Illuminate\\Support\\Facades\\Redis; class RedisHelper
{ /** * redis 写数据库 * * @return \\Illuminate\\Redis\\Connections\\Connection */ public static function write() { return Redis::connection('write'); } /** * Redis 读数据库 * * @return \\Illuminate\\Redis\\Connections\\Connection */ public static function read() { return Redis::connection('read'); }
} Route::get('/redis-cluster-test', function () { RedisHelper::write()->set('address', 'wuhan'.time()); $value = RedisHelper::read()->get('address'); return response()->json([ 'master_write' => 'success', 'slave_read' => $value ]);
}); http://localhost:8082/redis-cluster-test
{
"master_write": "success",
"slave_read": "wuhan1759033136"
} 5.问题： 还是需要手动控制 读写 连接`}]},{path:"/content/interview/golang/golang%E9%9D%A2%E8%AF%95%E9%A2%982022_10_19.html",title:"golang面试题2022_10_19",pathLocale:"/",contents:[{header:"",slug:"",content:`1.什么是协程泄露(goroutine leak)?
协程泄露是指，在程序运行过程中，有一些协程由于某些原因，无法正常退出。 2.协程泄露的危害?
协程的运行是需要占用内存和 CPU 时间的，一旦这种协程越来越多，会导致内存无端被浪费，CPU 时间片被占用，程序会越来越卡。 3.协程泄露的原因?
goroutine由于channel的读/写端退出而一直阻塞，导致goroutine一直占用资源，而无法退出。
goroutine由于nil channel而阻塞。
goroutine进入死循环中，导致资源一直无法释放。
goroutine同步锁(mutex)操作不当导致
goroutine waitgroup Add的数量和Done的数量不一致，导致一直Wait 以下是几种场景：
package test import ( "fmt" "math/rand" "os" "runtime" "testing" "time"
) /**
泄露场景1-以及解决办法 */
func TestChanLeak(t *testing.T) { randomStream := func(done chan interface{}) <-chan int{ rsc := make(chan int ) go func() { defer fmt.Println("当前协程结束...") defer close(rsc) for { select { case x, ok := <-done: if !ok { fmt.Println("x is:", x) // x is: <nil> } return case rsc <- rand.Int()://send 阻塞 } } }() return rsc } //channel关闭，也可以通过 contextWithCancel 来结束 goroutine done := make(chan interface{}) //调用 rst := randomStream(done) fmt.Println("start...") for i := 1; i <=3; i++ { fmt.Println("rand is:",<-rst) } fmt.Fprintf(os.Stderr, "%d\\n", runtime.NumGoroutine()) // close的特性 // After the last value has been received // from a closed channel c, any receive from c will succeed without // blocking, returning the zero value for the channel element. The form //	x, ok := <-c // will also set ok to false for a closed channel. close(done) //模拟一个耗时操作，10秒的延迟，在这期间 rst 还在阻塞 time.Sleep(10 * time.Second) fmt.Fprintf(os.Stderr, "%d\\n", runtime.NumGoroutine())
} /**
泄露场景2-以及解决办法(这个解决办法就是主协程退出)
*/
func routineTest() { //进入入死循环 for { fmt.Println("开启goroutine") time.Sleep(10 * time.Second) } } func TestChan(t *testing.T) { fmt.Println("开始...") //通过 runtime.NumGoroutine() 获取当前运行的goroutine的数量 fmt.Fprintf(os.Stderr, "%d\\n", runtime.NumGoroutine()) go routineTest() fmt.Fprintf(os.Stderr, "%d\\n", runtime.NumGoroutine()) fmt.Println("结束...")
} /**
泄露场景3-nil channel
*/
func TestNilChan(t *testing.T) { defer func() { time.Sleep(time.Second) fmt.Println("the number of goroutines: ", runtime.NumGoroutine()) }() //ch 就是一个 nil channel, 因为只是声明，但是没有初始化这个ch就直接使用了 var ch chan int go func() { <-ch // receive nil channel // ch<- // send nil channel }() //defer func() { //	time.Sleep(time.Second) //	fmt.Println("the number1 of goroutines: ", runtime.NumGoroutine()) //}() // //done := make(chan struct{}) // //var ch chan int //go func() { //	fmt.Println("the number2 of goroutines: ", runtime.NumGoroutine()) //	defer close(done) //}() // ////fatal error: all goroutines are asleep - deadlock! //select { //case <-ch:// The receive operation might block a goroutine because of the 'nil' channel //case <-done: //	return //}
} /**
泄露场景4-waitGroup
*/
func TestWaitGroup(t *testing.T) { defer func() { time.Sleep(time.Second) fmt.Println("the number1 of goroutines: ", runtime.NumGoroutine()) }() // 无法退出 go handle() time.Sleep(5 * time.Second)
} 4.无缓冲的channel和有缓冲的channel的区别? 之前以为有缓冲与无缓冲的区别是 无缓冲的缓冲为 1 的缓冲式 ，其实不是的，无缓冲 就是缓冲为0， func TestCacheChannel(t *testing.T) { c := make(chan int, 0) // 或者 make(chan int) //不带缓冲的channel可以通过Goroutine给当前channel的发送数据，不会阻塞线程，这个是什么原因还在研究，唯一的解释就是 不带缓冲的channel，的send 和 receive 不能是同一个 goroutine，必须要重新起一个goroutine //go func() { //	c <- 1 //}() //c := make(chan int, 1) //c <- 1 //不带缓冲的channel 这里会阻塞，但是带缓冲就不会阻塞 fmt.Println(<-c)
} 二者区别就是一个会阻塞另一个不会阻塞(或者 同步与非同步的区别) 5.channel 底层数据原理?
通过var声明或者make函数创建的channel变量是一个存储在栈上的指针，占用8个字节，指向堆上的hchan结构体，该结构体在src/runtime/chan.go中 type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex
} //G1 func main(){ ... for _, task := range hellaTasks { ch <- task //sender } ... } //G2 func worker(ch chan Task){ for { //接受任务 task := <- ch //recevier //假设设立会护理很长时间，那么 G1可能会阻塞 process(task) } } 其中G1是发送者，G2是接收，因为ch是长度为3的带缓冲channel，初始的时候hchan结构体的buf为空，sendx和recvx都为0，当G1向ch里发送数据的时候，会首先对buf加锁，然后将要发送的数据copy到buf里，并增加sendx的值，
最后释放buf的锁。然后G2消费的时候首先对buf加锁，然后将buf里的数据copy到task变量对应的内存里，增加recvx，最后释放锁。整个过程，G1和G2没有共享的内存，底层通过hchan结构体的buf，使用copy内存的方式进行通信，
最后达到了共享内存的目的，这完全符合CSP的设计理念。 CSP 是 Communicating Sequential Process 的简称，中文可以叫做通信顺序进程，是一种并发编程模型。
Golang，其实只用到了 CSP 的很小一部分，即理论中的 Process/Channel（对应到语言中的 goroutine/channel） G1和G2的调用涉及到golang的GPM模型 6.GPM模型原理?
了解GPM模型之前，先分析一下线程的三种模型: 用户级线程模型、内核级线程模型和两级线程模型（也称混合型线程模型）
它们之间最大的差异就在于用户线程与内核调度实体（KSE，Kernel Scheduling Entity）之间的对应关系上。而所谓的内核调度实体 KSE 就是指可以被操作系统内核调度器调度的对象实体。简单来说 KSE 就是内核级线程，
是操作系统内核的最小调度单元，也就是我们写代码的时候通俗理解上的线程了。 用户级线程模型:
用户线程与内核线程 KSE 是一对一（1 : 1）的映射模型，也就是每一个用户线程绑定一个实际的内核线程，而线程的调度则完全交付给操作系统内核去做，应用程序对线程的创建、终止以及同步都基于内核提供的系统调用来完
成，大部分编程语言的线程库(比如 Java 的 java.lang.Thread、C++11 的 std::thread 等等)都是对操作系统的线程（内核级线程）的一层封装，创建出来的每个线程与一个独立的 KSE 静态绑定，因此其调度完全由操作
系统内核调度器去做，也就是说，一个进程里创建出来的多个线程每一个都绑定一个 KSE。 内核级线程模型:
用户线程与内核线程 KSE 是多对一（N : 1）的映射模型，多个用户线程的一般从属于单个进程并且多线程的调度是由用户自己的线程库来完成，线程的创建、销毁以及多线程之间的协调等操作都是由用户自己的线程库来负责而
无须借助系统调用来实现。一个进程中所有创建的线程都只和同一个 KSE 在运行时动态绑定，也就是说，操作系统只知道用户进程而对其中的线程是无感知的，内核的所有调度都是基于用户进程。这种实现方式相比内核级线程可
以做的很轻量级，对系统资源的消耗会小很多，因此可以创建的线程数量与上下文切换所花费的代价也会小得多。但该模型有个原罪：并不能做到真正意义上的并发，假设在某个用户进程上的某个用户线程因为一个阻塞调用（比如
I/O 阻塞）而被 CPU 给中断（抢占式调度）了，那么该进程内的所有线程都被阻塞（因为单个用户进程内的线程自调度是没有 CPU 时钟中断的，从而没有轮转调度），整个进程被挂起。即便是多 CPU 的机器，也无济于事，因
为在用户级线程模型下，一个 CPU 关联运行的是整个用户进程，进程内的子线程绑定到 CPU 执行是由用户进程调度的，内部线程对 CPU 是不可见的，此时可以理解为 CPU 的调度单位是用户进程。所以很多的协程库会把自己一
些阻塞的操作重新封装为完全的非阻塞形式，然后在以前要阻塞的点上，主动让出自己，并通过某种方式通知或唤醒其他待执行的用户线程在该 KSE 上运行，从而避免了内核调度器由于 KSE 阻塞而做上下文切换，这样整个进程
也不会被阻塞了。 两级线程模型:
用户线程与内核 KSE 是多对多（N : M）的映射模型：首先，区别于用户级线程模型，两级线程模型中的一个进程可以与多个内核线程 KSE 关联，也就是说一个进程内的多个线程可以分别绑定一个自己的 KSE，这点和内核级线
程模型相似；其次，又区别于内核级线程模型，它的进程里的线程并不与 KSE 唯一绑定，而是可以多个用户线程映射到同一个 KSE，当某个 KSE 因为其绑定的线程的阻塞操作被内核调度出 CPU 时，其关联的进程中其余用户线
程可以重新与其他 KSE 绑定运行。即用户调度器实现用户线程到 KSE 的『调度』，内核调度器实现 KSE 到 CPU 上的『调度』。Go语言中的并发就是使用的这种实现方式，Go为了实现该模型自己实现了一个运行时调度器来负
责Go中的"线程"与KSE的动态关联。 GPM模型:
在 Go 语言中，每一个 goroutine 是一个独立的执行单元，相较于每个 OS 线程固定分配 2M 内存的模式，goroutine 的栈采取了动态扩容方式， 初始时仅为2KB，随着任务执行按需增长，最大可达 1GB（64 位机器最大是 1G，
32 位机器最大是 256M），且完全由 golang 自己的调度器 Go Scheduler 来调度。此外，GC 还会周期性地将不再使用的内存回收，收缩栈空间。 因此，Go 程序可以同时并发成千上万个 goroutine 是得益于它强劲的调度器和
高效的内存模型。 G: 表示 Goroutine，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。 P: Processor，表示逻辑处理器， 对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内
存分配状态(mcache)，任务队列(G)等，P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 >= P 的数量），P 的数量由用户设置的 GOMAXPROCS 决定，但是不论 GOMAXPROCS 设置为多大，P 的数量最大为 256。 M: Machine，OS 线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait
队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础，M 的数量是不定的，由
Go Runtime 调整，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。 每个 P 维护一个 G 的本地队列；
当一个 G 被创建出来，或者变为可执行状态时，就把他放到 P 的本地可执行队列中，如果满了则放入Global；
当一个 G 在 M 里执行结束后，P 会从队列中把该 G 取出；如果此时 P 的队列为空，即没有其他 G 可以执行， M 就随机选择另外一个 P，从其可执行的 G 队列中取走一半。 调度算法如下: 调度过程:
当通过 go 关键字创建一个新的 goroutine 的时候，它会优先被放入 P 的本地队列。为了运行 goroutine，M 需要持有（绑定）一个 P，接着 M 会启动一个 OS 线程，循环从 P 的本地
队列里取出一个 goroutine 并执行。执行调度算法：当 M 执行完了当前 P 的 Local 队列里的所有 G 后，P 也不会就这么在那划水啥都不干，它会先尝试从 Global 队列寻找 G 来执行，
如果 Global 队列为空，它会随机挑选另外一个 P，从它的队列里中拿走一半的 G 到自己的队列中执行。 参考：
https://www.minazuki.cn/post/blog_os/blog_os-1btagnqm2aabq/blog_os-1bti5cvfu5of1/ //理论
https://blog.csdn.net/guoafite/article/details/114833136 //理论 https://www.kuangstudy.com/bbs/1359135859894509570 //理论 https://blog.csdn.net/u010853261/article/details/85887948 //gopark()[用于协程的切换], goready()[主要功能就是唤醒某一个goroutine，该协程转换到runnable的状态，并将其放入P的local queue，等待调度] 7.什么是rune类型?
rune 是 int32的别名，主要用具计算不同字符下字符串的真实长度。(参考另一篇文章：go之rune关键字) 8.struct能不能比较?
回答这个问题之前先看一下golang中哪些数据类型可以比较哪些不可以比较
可比较：Integer，Floating，String，Boolean，Complex(复数型)，Pointer，Channel，Interface，Array
不可比较：Slice，Map，Function func TestCompare(t *testing.T) { //都是可比较成员 type S struct { Name string Age int Address *int } //没有初始化的时候 都是nil //var a S //var b S //=== RUN TestCompare //true //--- PASS: TestCompare (0.00s) //PASS //fmt.Println(a == b) // 分别初始化 var n = 1 var m = 2 a := S{ Name: "aa", Age: 1, Address: &n, } b := S{ Name: "aa", Age: 1, Address: &m, // 若是&n,就返回true, 如是&m,就返回false,因为 指针指向的地址不一样 } //=== RUN TestCompare //true //--- PASS: TestCompare (0.00s) //PASS fmt.Println(a == b) //结论：golang中 Slice，Map，Function 这三种数据类型是不可以直接比较的。我们再看看S结构体，该结构体并没有包含不可比较的成员变量，所以该结构体是可以直接比较的。 //包含不可比较成员 type S2 struct { Name string Age int Address *int Data []int } a2 := S2{ Name: "aa", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } b2 := S2{ Name: "aa", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } //这样 直接编辑器报错，因为 S2包含不可比较类型 //fmt.Println(a2 == b2) //通过 reflect.DeepEqual 反射中的函数进行比较是可以的 //=== RUN TestCompare //true //--- PASS: TestCompare (0.00s) //PASS fmt.Println(reflect.DeepEqual(a2, b2)) //拓展： //DeepEqual函数用来判断两个值是否深度一致。具体比较规则如下： // //不同类型的值永远不会深度相等当两个数组的元素对应深度相等时，两个数组深度相等当两个相同结构体的所有字段对应深度相等的时候，两个结构体深度相等当两个函数都为nil时，两个函数深度相等，其他情况不相等（相同函数也不相等）当两个interface的真实值深度相等时，两个interface深度相等map的比较需要同时满足以下几个 // //两个map都为nil或者都不为nil，并且长度要相等相同的map对象或者所有key要对应相同map对应的value也要深度相等 //指针，满足以下其一即是深度相等 // //两个指针满足go的==操作符两个指针指向的值是深度相等的 //切片，需要同时满足以下几点才是深度相等 // //两个切片都为nil或者都不为nil，并且长度要相等两个切片底层数据指向的第一个位置要相同或者底层的元素要深度相等注意：空的切片跟nil切片是不深度相等的 //其他类型的值（numbers, bools, strings, channels）如果满足go的==操作符，则是深度相等的。要注意不是所有的值都深度相等于自己，例如函数，以及嵌套包含这些值的结构体，数组等 //两个不同的结构体实例,如果S3 S4成员不同，一定也是不能比较的 type S3 struct { Name string Age int Arr [2]bool ptr *int } type S4 struct { Name string Age int Arr [2]bool ptr *int } var k = 1 var j = 2 var a3 = S3{ Name: "aa", Age: 1, Arr: [2]bool{true, false}, ptr: &k, } var b3 = S4{ Name: "aa", Age: 1, Arr: [2]bool{true, false}, ptr: &j,//若是&k,就返回true, 如是&j,就返回false,因为 指针指向的地址不一样 } //由于结构体类型不一样，编辑器报错，不能比较 //fmt.Println(a3 == b3) //类型强转以后，就可以比较了 //=== RUN TestCompare //false //--- PASS: TestCompare (0.00s) //PASS fmt.Println(a3 == S3(b3))
} 根据上面的论证可以知道：结构体能不能比较是要分情况的 9.struct可以作为map的key吗?
func TestMapKey(t *testing.T) { type S1 struct { Name string Age int Arr [2]bool ptr *int slice []int map1 map[string]string } type S2 struct { Name string Age int Arr [2]bool ptr *int } n := make(map[S2]string, 0) // 无报错 //=== RUN TestMapKey //map[]--- PASS: TestMapKey (0.00s) //PASS fmt.Print(n) //m := make(map[S1]string, 0)//Invalid map key type: comparison operators == and != must be fully defined for the key type //fmt.Println(m)
} 根据上面的论证可以知道：struct必须是可比较的，才能作为key，否则编译时报错 10.如何判断map中是否包含某个key? func TestMapKeyExist(t *testing.T){ demo := map[string]string{ "age": "12345", } //判断方法 if v, ok := demo["age"]; ok { fmt.Println(v) }
} 11.map如何顺序读取?
解决方案：通过sort中的排序包进行对map中的key进行排序。然后遍历key
func TestMapOrder(t *testing.T){ var m = map[string]int{ "9": 0, "2": 1, "5": 2, "1": 3, } var keys []string for k := range m { keys = append(keys, k) } sort.Strings(keys) //升序 for _, k := range keys { fmt.Println("Key:", k, "Value:", m[k]) }
} === RUN TestMapOrder
Key: 1 Value: 3
Key: 2 Value: 1
Key: 5 Value: 2
Key: 9 Value: 0
--- PASS: TestMapOrder (0.00s)
PASS 12.关于switch语句，下面说法正确的是？ A. 单个case中，可以出现多个结果的选项； B. 需要使用break来明确退出一个case； C. 只有在case中明确添加fallthrought关键字，才会继续执行紧跟的下一个case； D. 条件表达式必须为常量或者整数。 AC 分析： 支持多条件匹配，使用逗号分隔，例如：case val1,val2,val3 不同的case之间不使用break分隔，默认自带break，只会执行一个case; 如果想要执行多个case，需要使用fallthrought关键字，且不会判断下一个case的表达式是否 为true;也可以使用break终止。 switch语句还可以被用于type-switch来判断某个interface变量中实际存储的变量类型。如：switch i := x.(type){} 13.下面的代码会打印什么?
func TestSwitch(t *testing.T) { switch alwaysFalse() { case true: fmt.Println(true) case false: fmt.Println(false) } // 代码中，switch后面没有跟{，而是另起了一行，在这种情况下，alwaysFalse后自动添加了分号"；"，上述代码等价于： //switch alwaysFalse(); true { //case true: fmt.Println("true") //case false: fmt.Println("false") //} // 所以会返回 true，如果 { 没有换行 就返回 false
} 14.下面的代码会打印什么?
func print() { //这里相当于吧 GPM 中的P 设置为1,所以 // for 循环的时候 会先执行main 里的 for，在执行 go func，就是先主协程再子协程，最后全部输出10 //这实际是一个 协程引用循环变量的问题 // 解决办法是，再声明一个变量 i2 := i，将 i2传给 func；或者 给func 传递参数，将 i 传递 runtime.GOMAXPROCS(1) wg := sync.WaitGroup{} wg.Add(20) for i := 0; i < 10; i++ { go func() { fmt.Println(i) wg.Done() }() } for j := 0; j < 10; j++ { go func() { fmt.Println(j) wg.Done() }() } wg.Wait()
}
func TestWt(t *testing.T) { print()
} === RUN TestWt
2
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
--- PASS: TestWt (0.00s)
PASS 15.下面的代码会打印什么?
func TestDefer(t *testing.T){ //这个简单，defer 肯定最后执行,所以是31 if true { defer fmt.Println("1") }else { defer fmt.Println("2") } fmt.Println("3")
} === RUN TestDefer
3
1
--- PASS: TestDefer (0.00s)
PASS 16.golang中大多数数据类型都可以转化为有效的JSON文本，下面几种类型除外（） A 指针 B channel C complex D 函数 BCD 分析：
golang 中的类型比如：channel（通道）、complex（复数类型）、func（函数）均不能进行 JSON 格式化。
有疑问的地方可能是在A选项指针。
其实 Pointer（指针）也是能被 JSON 格式化的，因为指针会被系统隐式转换为指针所指向的具体对象值，具体的对象值是可以被JSON格式化的。 17.下面的代码会打印什么?
func printEx(x int) (func(), func()) { return func() { println(x) x += 10 }, func() { println(x) }
} func TestCodeExec(t *testing.T) { a, b := printEx(1) a() b()
} //结果如下
//=== RUN TestCodeExec
//1
//11
//--- PASS: TestCodeExec (0.00s)
//PASS 18.下面的代码会打印什么?
func TestCodeExec(t *testing.T) { defer func() { if err := recover(); err != nil { fmt.Println("++++") f := err.(func() string) // err 是一个func类型，打印出一个 0x894040 说明 func是引用类型 fmt.Println(err,"--", f(),"--", reflect.TypeOf(err).Kind().String()) }else { fmt.Println("fatal") } }() //这个defer 会比上面的先执行 defer func() { panic(func() string { return "defer panic" }) }() //这个defer 会比上面的先执行 defer func() { panic(func() string { return "defer panic2" }) }() //最先执行 panic("panic") //=== RUN TestCodeExec //++++ //0x894040 -- defer panic -- func //--- PASS: TestCodeExec (0.00s) //PASS 结论： 如果过有多个panic,那么最终 recover 会拦截最后的那个panic的错误
} 19.golang中的引用类型包括（）
A.数组 B.map C.channel D.interface BCD 解析：go中引用类型有:指针、slice切片、管道channel、接口interface、map、函数等`}]},{path:"/content/front/html/Tailwind%E4%B9%8B%E5%AE%9A%E4%B9%89%E9%A2%9C%E8%89%B2%E7%9A%84%E5%90%8C%E6%97%B6%E5%AE%9A%E4%B9%89%E4%B8%8D%E9%80%8F%E6%98%8E%E5%BA%A6.html",title:"Tailwind之定义颜色的同时定义不透明度",pathLocale:"/",contents:[{header:"",slug:"",content:"Tailwind之定义颜色的同时定义不透明度:"},{header:"如下代码",slug:"如下代码",content:`text-color-error/80 分析:
在 Tailwind CSS 中，text-color-error/80 是一个用于设置文本颜色的类。我们可以分解这个类以了解其含义： text-: 这是一个前缀，表示这是一个文本颜色类。
color-error: 这是具体的颜色名称，通常是在 Tailwind CSS 的配置中定义的颜色。它表示一种错误相关的颜色，通常用于指示错误、警告或负面状态。
/80: 这个部分表示颜色的不透明度（opacity）。在这里，80 表示该颜色的不透明度为 80%（即 20% 的透明度）。在 Tailwind CSS 中，透明度通常以 0 到 100 的百分比表示，值越高表示颜色越不透明。`},{header:"总结",slug:"总结",content:"text-color-error/80 类的作用是将文本颜色设置为错误色，且该颜色具有 80% 的不透明度。使用这种类可以在 UI 中有效地传达错误信息，同时保持一定的透明度，确保与背景色和其他 UI 元素的视觉一致性。"}]},{path:"/content/front/html/Vue-prototype_Vue-component_Vue-use%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"Vue-prototype+Vue-use的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`Vue.prototype和Vue.use的区别:
import Vue from 'vue'
import Element from 'element-ui'
Vue.use(Element)
import echarts from 'echarts'
vue.prototype.$echarts = echarts 这样的代码我们肯定很熟悉， 但是对于Vue.use和Vue.prototype的区别是什么，
可能还不一定完全清楚。Vue为什么要提高两个注册插件的方式？他们各自有什么
优点和联系？ 先说结论，Vue.use和Vue.prototype没有本质区别，Vue.use就
是在Vue.prototype基础上又封装了一层而已，他们实现的原理都是
在Vue.prototype上添加了一个方法，Vue.prototype适合于注册Vue生态
外的插件，Vue.use适合于注册Vue生态内的插件. Vue.prototype的用法:
如果需要设置全局变量，在main.js中，Vue实例化的代码里添加。 这种情况下，你可以通过在 原型 上定义它们使其在每个Vue实例中可用。 vue.prototype.$echarts = echarts Vue.use()的 用法:
1.通过全局方法 Vue.use() 使用插件
2.Vue.use 会自动阻止多次注册相同插件
3.它需要在你调用 new Vue() 启动应用之前完成
4.Vue.use() 方法至少传入一个参数，该参数类型必须是 Object 或 Function，如果是 Object 那么这个 Object 需要定义一个 install 方法，如果是 Function 那么这个函数就被当做 install 方法。在 Vue.use() 执行时 install 会默认执行，当 install 执行时第一个参数就是 Vue，其他参数是 Vue.use() 执行时传入的其他参数。 import Vue from 'vue'
import Element from 'element-ui'
Vue.use(Element) 总结:
Vue.use = function (plugin) { if (plugin.installed) { return; } // additional parameters var args = toArray(arguments, 1); args.unshift(this); if (typeof plugin.install === 'function') { plugin.install.apply(plugin, args); } else { plugin.apply(null, args); } plugin.installed = true; return this;
}; // 准备好 install 方法 给 Vue.use() 使用
const install = function (Vue) { if (install.installed) return; install.installed = true; // 将包装好的 toast 挂到Vue的原型上，作为 Vue 实例上的方法 Vue.prototype.$toast = toast;
} // 默认导出 install
export default { install,
}; 看了源码才知道原来Vue.use主要是执行install方法，而install主要也是执行Vue.prototype方法。所以，其实Vue.use()方法的核心就是Vue.prototype，只不过又封装了一层,更加的灵活，扩展性更好。
不同之处是使用vue.prototype，插件不需要实现install方法，简单粗暴，拿来就用，但是灵活性不如Vue.use(), 而Vue.use()，却要求插件必须实现instal方法或者该插件本身就是函数，在install方法可以完成自己的逻辑， 所以Vue.use()的方式更加的强大，灵活，扩展性更好。`}]},{path:"/content/front/html/bootstrap5%E4%B8%8Bcheckbox%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E5%8F%96%E6%B6%88.html",title:"bootstrap5下checkbox的选择与取消",pathLocale:"/",contents:[{header:"",slug:"",content:`checkbox的全选与反选在后台项目使用的非常多，这里记录一下方便以后使用:
<!DOCTYPE html>
<html lang="en"> <head> <meta charset="UTF-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <meta http-equiv="X-UA-Compatible" content="ie=edge"> <title>table表格的选择功能</title> <!-- 最新版本的 Bootstrap 核心 CSS 文件 --> <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css"> <script src="https://code.jquery.com/jquery-1.11.3.js"><\/script> <!-- 最新的 Bootstrap 核心 JavaScript 文件 --> <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"><\/script> <style> table.table tr th, td { text-align: center; cursor: pointer; } </style>
</head> <body class="container"> <div class=".table-responsive"> <!--<button id="btn" class="btn btn-primary">按钮</button>--> <br> <br> <table id="" class="table table-hover table-bordered"> <thead> <tr> <th> <input type="checkbox" name="" lay-skin="primary" lay-filter="allChoose"> </th> <th>部门名称</th> <th>部门负责人</th> <th>联系电话</th> <th>地址</th> <th>操作列</th> </tr> </thead> <tbody> <tr> <td> <input type="checkbox" name="html" lay-skin="primary" lay-filter="allChoose"> </td> <td>信息部</td> <td>张三</td> <td>1395464646</td> <td>XX市XX区</td> <td>编辑</td> </tr> <tr> <td> <input type="checkbox" name="css" lay-skin="primary" lay-filter="allChoose"> </td> <td>财务部</td> <td>李四</td> <td>1785454646</td> <td>湖北省</td> <td>添加</td> </tr> <tr> <td> <input type="checkbox" name="javascript" lay-skin="primary" lay-filter="allChoose"> </td> <td>业务部</td> <td>王五</td> <td>13246231</td> <td>湖南省</td> <td>删除</td> </tr> </tbody> </table> </div>
</body> </html>
<script> $(function () { checkBox(); function checkBox() { var $thr = $("table thead tr"); //表格头部的tr var $checkAllTh = $("table thead tr").find('input').parent(); //表格头部的的全选按钮 var $tbr = $("table tbody tr"); //表格内容的tr var $checkAll = $thr.find('input'); //表格头部的全选框 //全选 $checkAll.click(function (event) { //根据表格头部（thead）的全选框的是否选中的状态（true或false）来设置表格内容（tbody）的选择框状态 $tbr.find('input').prop('checked', $(this).prop('checked')); if ($(this).prop('checked')) { $tbr.find('input').parent().parent().addClass('danger'); } else { $tbr.find('input').parent().parent().removeClass('danger'); } //防止点击事件向父元素冒泡 必须加阻止事件冒泡，不然会出现单击全选框按钮无作用的情况 event.stopPropagation(); }); //点击表格头部全选框所在的单元格时也触发全选框的点击操作 $checkAllTh.click(function () { $(this).find('input').click(); }); //点击表格内容（tbody）下面的每一行的选择框 $tbr.find('input').click(function (event) { //给选中和未选中，添加和删除样式 $(this).parent().parent().toggleClass('danger'); //判断tbody里面的已经选中的input长度和表格内容本有的input长度是有相等，如果相等，则把theard的选择框置为选中， $checkAll.prop('checked', $tbr.find('input:checked').length == $tbr.find('input').length ? true : false); event.stopPropagation(); //防止点击事件向父元素冒泡 必须加阻止事件冒泡，不然会出现单击每一行内容的选框按钮无作用的情况 }); //点击tbody下面的每一行（非选择框）也能触发选择框的点击操作 $tbr.click(function () { $(this).find('input').click(); }); } })
<\/script>`}]},{path:"/content/front/html/box-shadow%E5%92%8Cdrop-shadow%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"box-shadow和drop-shadow的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`最大的区别是：
drop-shadow才是真正意义上的投影，而box-shadow只是盒阴影而已，下面的例子展示了二者的不同之处
<!DOCTYPE html>
<html>
<head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title></title> <style type="text/css"> .box { margin: 40px; padding: 50px; background-color: #fff; position: relative; font-size: 24px; } .cor { position: absolute; left: -40px; widtd: 0; height: 0; overflow: hidden; border: 20px solid transparent; border-right-color: #fff; } .box-shadow { box-shadow: 5px 5px 10px black; } .drop-shadow { filter: drop-shadow(5px 5px 10px black); } </style>
</head>
<body> <div class="box box-shadow"> <i class="cor"></i> box-shadow
</div>
<div class="box drop-shadow"> <i class="cor"></i> filter: drop-shadow
</div> </body>
</html>`}]},{path:"/content/front/html/css%E4%B9%8B@media%E5%92%8C@supports%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"css之@media和@supports的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`css之@media和@supports的区别:
@media 主要用于在不同的媒体环境下应用不同的 CSS 规则。它通常与媒体查询(media queries)一起使用,根据设备的特征(如屏幕尺寸、分辨率、方向等)来应用不同的样式。这使得网站和应用程序能够有响应式和自适应的布局。
例子:
/* 在屏幕宽度小于 768px 时应用这些样式 */
@media (max-width: 767px) { .container { flex-direction: column; }
} @supports 用于检测浏览器是否支持某个 CSS 属性或者值。如果支持,则应用相应的 CSS 规则;如果不支持,则可以提供一个后备方案或者替代样式。这个特性可以让你在编写 CSS 时利用最新的特性,同时又能确保在旧的浏览器中正常工作。
例子:
@supports (display: grid) { .container { display: grid; grid-template-columns: repeat(3, 1fr); }
} @supports not (display: grid) { .container { display: flex; flex-wrap: wrap; }
} 高级用法:
<button type="button" class="[@media(any-hover:hover){&:hover}]:opacity-100"> <!-- ... -->
</button> 分析：
这段代码使用了 Tailwind CSS 的几个高级特性,让我们来分析一下: [@media(any-hover:hover){&:hover}] 这是一个 Tailwind 的 arbitrary variants(任意变体)语法。它允许你定义一个新的样式变体,并在类名中使用它。
@media(any-hover:hover) 部分指定了这个新变体只在设备支持 hover 交互时才生效。any-hover 是一个媒体查询,用于检测设备是否支持任何形式的 hover 交互,如鼠标悬停或通过键盘导航悬停。
{&:hover} 部分定义了这个新变体的具体样式,即当元素处于 hover 状态时应用的样式。& 代表当前元素。 :opacity-100 这是一个 Tailwind 的实用程序类,用于设置元素的不透明度为 100%,即完全不透明。
综合这两部分,当鼠标悬停在这个按钮上时(或者在支持 hover 的设备上通过键盘导航悬停在按钮上),按钮的不透明度将变为 100%,即完全不透明。
这种写法的好处是: 它利用了 Tailwind 的强大功能,使用简洁的类名就能实现复杂的样式效果。
它实现了渐进增强,只在支持 hover 交互的设备上应用悬停效果,从而提高了可访问性。
它将样式和 HTML 分离,使代码更加模块化和易于维护。 这种利用 Tailwind 的任意变体和媒体查询的写法,体现了 Tailwind 在实用程序优先的 CSS 方法中所提供的灵活性和可定制性。`}]},{path:"/content/front/html/css%E4%B9%8BRegularNormalMediumLight%E5%AF%B9%E5%BA%94%E7%9A%84font-weight%E5%80%BC.html",title:"css之RegularNormalMediumLight对应的font-weight值",pathLocale:"/",contents:[{header:"",slug:"",content:`经常会用到 font-weight: Regular、Normal、Medium、Light，一时想不起来对应的数值，特意记一下
有个特殊的场景：就是 php 在图片上加文字或者水印的时候，会通过字体文件设置字体的属性，一般字体
文件会使用Regular、Normal、Medium、Light 等来命名。
字体粗细：‘font-weight’属性
名称： font-weight
取值： normal | bold | bolder | lighter | 100 | 200 | 300 | 400 | 500 | 600 | 700 | 800 | 900 初始： normal
适用于： 所有元素
继承： 是
百分比： （不适用）
媒介： 视觉
计算值： 详见描述
动画： -
‘font-weight’属性执行字体中字形的重量，这取决于黑度等级或笔划粗细。
其值的意义如下：
100至900
这些有序排列中的每个值，表示至少与其起身拥有相同黑度的重量。其大致符合下列通用重量名称：
100 - Thin
200 - Extra Light (Ultra Light)
300 - Light
400 - Regular (Normal、Book、Roman)
500 - Medium
600 - Semi Bold (Demi Bold)
700 - Bold
800 - Extra Bold (Ultra Bold)
900 - Black (Heavy)
normal、regular与'400'相同。
bold与'700'相同。
bolder指定外观的重量大于继承的值。
lighter 指定外观的重量小于继承的值。`}]},{path:"/content/front/html/css%E4%B9%8Balign-self%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css之align-self的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`css之align-self的使用: 在介绍这个之前，有必要重新回顾及各知识点 cross axis(交叉轴) 和 main axis(主轴) 的关系，如果主轴是x,那么交叉轴就是y; 反过来，如果主轴是y，那么交叉轴就是x,
原文:
The cross axis in flexbox runs perpendicular to the main axis, therefore if your flex-direction is either row or row-reverse then the cross axis runs down the columns. If your main axis is column or column-reverse then the cross axis runs along the rows. 参考: https://developer.mozilla.org/en-US/docs/Glossary/Cross_Axis align-self的作用 align-self CSS属性覆盖grid或flex项目的align-items值。在网格中，它在网格区域内对齐项目。在flexbox中，它在交叉轴上对齐项目。(重点是 覆盖) 原文:
The align-self CSS property overrides a grid or flex item's align-items value. In grid, it aligns the item inside the grid area. In flexbox, it aligns the item on the cross axis. 官方使用案例 1.html
<section> <div>Item #1</div> <div>Item #2</div> <div>Item #3</div>
</section> 2.css
section { display: flex; align-items: center; height: 120px; background: beige;
} div { height: 60px; background: cyan; margin: 5px;
} div:nth-child(3) { align-self: stretch; background: pink;
} 效果就是Item #3 会在section这个box的顶部开始布局，二其它两个则是垂直剧中 常用属性值(还有其它的，但是我认为不常用) align-self: center; /* Put the item around the center */
align-self: start; /* Put the item at the start */
align-self: end; /* Put the item at the end */ 特别注意两个特别属性值 align-self: auto; // Computes to the parent's align-items value.
align-self: normal; //For flex items, the keyword behaves as stretch.`}]},{path:"/content/front/html/css%E4%B9%8Bfill%E5%B1%9E%E6%80%A7.html",title:"css之fill属性",pathLocale:"/",contents:[{header:"",slug:"",content:`css之fill属性:
对于形状元素和文本，fill 属性是外观属性，用来定义给定图形元素内部的颜色。哪一块算是“内部”取决于形状本身以及fill-rule 属性的值。作为一个外观属性，它可以直接用作 CSS 样式表内部的属性。 https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/fill
https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/fill-rule 其中比较重要的:
下列元素可以使用fill属性：
动画元素 形状元素 文本内容元素:包括 https://developer.mozilla.org/zh-CN/docs/Web/SVG/Element#textcontent, 就介绍了svg元素 重要的结论: 可以给 svg元素设置 color,那么就会改变 svg图片内容的颜色，这个也是和svg图片的fill属性相关的.
举个例子:
<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" width="24" height="24" viewBox="0 0 24 24"> <path fill="currentColor" d="M17 23v-4H7q-.825 0-1.412-.587T5 17V7H1V5h4V1h2v16h16v2h-4v4zm0-8V7H9V5h8q.825 0 1.413.588T19 7v8z"></path>
</svg> 样式:
.icon-container:hover :deep(svg) { @apply text-purple-600;
} 在这个 SVG 代码中,<path> 元素的 fill 属性被设置为 currentColor。这意味着它会继承当前元素的 color 值作为填充颜色。因此,当我们将 text-purple-600 应用于 SVG 元素时,它实际上是将 color 值设置为紫色,从而导致 <path> 元素的填充颜色也变为紫色。
所以,虽然 text-purple-600 的命名看起来像是用于设置文本颜色,但它同时也可以应用于 SVG 元素,从而改变 SVG 图形的颜色。这种机制使得我们可以使用相同的 CSS 类来设置文本和 SVG 图形的颜色,提高了代码的一致性和可维护性。 下面是一个官方实例:
<svg viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg" height="100%"> <path fill="red" d="M 10,30 A 20,20 0,0,1 50,30 A 20,20 0,0,1 90,30 Q 90,60 50,80 Q 10,60 10,30 z" />
</svg> https://developer.mozilla.org/zh-CN/docs/Web/SVG/Element/path, 这里我直接通过fill 设置颜色，结果可以生效，证明上面的理论是正确的. 解释： svg中 xmlns="http://www.w3.org/2000/svg"的作用:
xmlns="http://www.w3.org/2000/svg" 这个属性是用来定义 SVG 命名空间的。
命名空间是一种用来避免元素名称冲突的方法。由于 XML 允许组合不同的 XML 文档,因此有可能在同一个 XML 文档中出现相同的元素名称,但具有不同的含义和用途。为了解决这个问题,XML 命名空间就应运而生。
SVG 是基于 XML 的矢量图形语言,因此它也需要使用命名空间来确保元素名称在 XML 文档中的唯一性。xmlns="http://www.w3.org/2000/svg" 这个属性就是用来声明 SVG 元素所属的命名空间。
其中:
xmlns 是 "XML Namespace" 的缩写,表示这是一个 XML 命名空间声明。
http://www.w3.org/2000/svg 是 SVG 命名空间的 URI(Uniform Resource Identifier),这个 URI 是由 W3C(World Wide Web Consortium) 定义的,用于唯一标识 SVG 命名空间。 通过这个命名空间声明,浏览器就可以正确地识别和解析 SVG 元素,避免与其他 XML 语言中的元素发生冲突。`}]},{path:"/content/front/html/css%E4%B9%8Bflex%E5%92%8Cinline-flex%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"css之flex和inline-flex的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`css之flex和inline-flex的区别:
简单来说 就是 flex 会占整行；inline-flex只会占用自己item对应的宽度`}]},{path:"/content/front/html/css%E4%B9%8Bflex%E5%B8%83%E5%B1%80%E8%AE%A9%E5%AD%90%E9%A1%B9%E4%BF%9D%E6%8C%81%E8%87%AA%E8%BA%AB%E9%AB%98%E5%BA%A6.html",title:"css之flex布局让子项保持自身高度",pathLocale:"/",contents:[{header:"",slug:"",content:`css之flex布局让子项保持自身高度:
在用了flex布局会发现，当水平排列后，会发现所有子项的高度都变成一样的了
这是因为flex 布局会默认：把所有子项变成水平排列。默认不自动换行。让子项与其内容等宽，并把所有子项的高度变为最高子项的高度。
这样设置背景色的时候非常不方便，那么直接在父项上，将align-items设为 flex-start,或者align-items属性的其他值都可以,子项就会保持自身的高度了。`}]},{path:"/content/front/html/css%E4%B9%8Bfont-weight%E6%95%B0%E5%80%BC%E5%A4%A7%E5%B0%8F.html",title:"css之font-weight数值大小",pathLocale:"/",contents:[{header:"",slug:"",content:`css之font-weight数值大小命名： Value
Common weight name 100
Thin (Hairline) 200
Extra Light (Ultra Light) 300
Light 400
Normal (Regular) 500
Medium 600
Semi Bold (Demi Bold) 700
Bold 800
Extra Bold (Ultra Bold) 900
Black (Heavy)`}]},{path:"/content/front/html/css%E4%B9%8Binset%E5%B1%9E%E6%80%A7.html",title:"css之inset属性",pathLocale:"/",contents:[{header:"",slug:"",content:`css之inset属性:
inset属性只能应用于设置了position: absolute;或position: fixed;的元素。 对于其他定位方式,如static或relative定位的元素,使用inset属性是没有效果的。这是因为inset属性是专门为了控制绝对定位元素在其包含块中的位置而设计的。
inset属性是top、right、bottom和left属性的缩写。它允许您同时设置所有四个属性的值,或者只设置其中一个或几个属性的值。例如:
/* 设置所有四个边 */
inset: 10px; /* 水平居中 */
inset: 0 auto; /* 各自设置值 */
inset: 10px 20px 30px 40px; /* 设置上下边距,左右居中 */
inset: 10px auto 20px;`}]},{path:"/content/front/html/css%E4%B9%8Blist-style.html",title:"css之list-style",pathLocale:"/",contents:[{header:"",slug:"",content:`css之list-style:
官网链接:
https://developer.mozilla.org/zh-CN/docs/Web/CSS/list-style
https://developer.mozilla.org/zh-CN/docs/Web/CSS/::marker //和list-style配合使用
补充一个 pre 标签 ：
HTML <pre> 元素表示预定义格式文本。在该元素中的文本通常按照原文件中的编排，
以等宽字体的形式展现出来，文本中的空白符（比如空格和换行符）都会显示出来。
(紧跟在 <pre> 开始标签后的换行符也会被省略)`}]},{path:"/content/front/html/css%E4%B9%8Bpx%E8%BD%ACrem.html",title:"css之px转rem",pathLocale:"/",contents:[{header:"",slug:"",content:`在nuxt3中使用scss定于全局的计算属性，转rem
定义一个common.scss
第一个版本： @charset "utf-8";
$defaultSize: 16px !default;
$font-base: 1rem;
@function rem($px){ @return $px / $defaultSize * $font-base;
} 使用:
<style lang="scss" scoped>
@import "assets/scss/common.scss";
...
...
</style > 执行报错：
vite:css] [sass] 40.6875rem/px isn't a valid CSS value 修改后的版本:
@charset "utf-8";
$defaultSize: 16 !default;
$font-base: 1rem;
@function rem($px){ @return calc($px / $defaultSize * $font-base);
} 主要是把这个16px改为16即可`}]},{path:"/content/front/html/css%E4%B9%8Bscope%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css之scope的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`css之:scope的使用:
html中 talbe 中的 scope的使用:
<table> <thead> <tr> <th scope="col">Name</th> <th scope="col">Age</th> </tr> </thead> <tbody> <tr> <th scope="row">Alice</th> <td>25</td> </tr> <tr> <th scope="row">Bob</th> <td>30</td> </tr> </tbody>
</table> 在这个例子中： "Name" 和 "Age" 是列标题，所以使用 scope="col"
"Alice" 和 "Bob" 是行标题，所以使用 scope="row" 虽然在视觉上可能看不出差别，但这种结构化信息对于使用辅助技术的用户非常重要，能够帮助他们更好地理解表格的组织结构。 <td> 标签代表 "table data"（表格数据），是 HTML 表格中最基本和最常用的元素之一。它用于创建表格中的标准单元格，包含表格的实际数据。
<td> 标签代表 "table data"（表格数据），是 HTML 表格中最基本和最常用的元素之一。它用于创建表格中的标准单元格，包含表格的实际数据。
<tr> 标签代表 "table row"（表格行），用于在 HTML 表格中创建一行。它是构建表格结构的关键元素之一。 table相关文档: https://developer.mozilla.org/zh-CN/docs/Web/HTML/Element/table
https://developer.mozilla.org/zh-CN/docs/Web/HTML/Element/tr 其它关于css的 :scope的使用，下面主要是限定样式生效的范围
https://developer.mozilla.org/zh-CN/docs/Web/CSS/:scope
https://liruifengv.com/posts/css-scope/ 和上面的th中的使用是不一样的`}]},{path:"/content/front/html/css%E4%B9%8Bsticky%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"css之sticky的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`css之sticky的问题:
粘性容器 —— 是包装粘性元素的 HTML 元素。 这是粘性元素可以浮动的最大区域。
当你定义一个具有 position:sticky 样式的元素时，具有滚动属性[简单来讲，就是出现滚动条的那个]的最近的父元素会被自动定义为粘性容器！
记住这一点非常重要！ 容器是粘性元素的范围，并且该元素无法离开其所在的粘性容器。 根据官网的解释：
The element is positioned according to the normal flow of the document, and then offset relative to its nearest scrolling ancestor and containing block (nearest block-level ancestor), including table-related elements, based on the values of top, right, bottom, and left. The offset does not affect the position of any other elements. This value always creates a new stacking context. Note that a sticky element "sticks" to its nearest ancestor that has a "scrolling mechanism" (created when overflow is hidden, scroll, auto, or overlay), even if that ancestor isn't the nearest actually scrolling ancestor. 翻译过来就是：
该元素根据文档的正常流程定位，然后根据顶部、右侧、底部和左侧的值，相对于其最近的滚动祖先和包含块（最近的块级祖先）进行偏移，包括与表格相关的元素。偏移不会影响任何其他元素的位置。 该值始终会创建一个新的堆叠上下文。请注意，粘性元素会 "粘附 "到离它最近的、具有 "滚动机制"（在溢出为隐藏、滚动、自动或叠加时创建）的祖先上，即使该祖先不是离它最近的、实际滚动的祖先。 结论就是: 滚动祖先(大于等于三层结构)：overflow必须不能是visible; 但是有一种情况就是 sticky 外的直接父元素的overflow必须要设置为visible,设置成其它值会让sticky失效 补充:overflow 默认值是 visible 为便于理解粘性定位，这里引入四个元素：视口元素，容器元素，粘性约束元素 和 sticky 元素。它们的关系如下：
1.视口元素：显示内容的区域。会设置宽，高。一般会设置 overflow:hidden。
2.容器元素：离 sticky 元素最近的能滚动的祖先元素。
3.粘性约束元素：粘性定位的父元素。有时，也会出现粘性约束元素就是容器元素的情况。
4.sticky 元素：设置了 position: sticky; 的元素。 滚动时，sticky 元素设置的 left, right, top, bottom 的值相对的是容器元素。当粘性约束元素滚出视口时，sticky 元素也会滚出视口。 图解如下: 参考链接：https://www.qinglite.cn/doc/45946476585e34db9 // 这里面的那张图很经典 , 同时这个网站参考`}]},{path:"/content/front/html/css%E4%B9%8Btransform-origin.html",title:"css之transform-origin",pathLocale:"/",contents:[{header:"",slug:"",content:`css之transform-origin,这个主要在图片打开的时候控制显示的位置
x-offset
Is a <length> or a <percentage> describing how far from the left edge of the box the origin of the transform is set. offset-keyword
Is one of the left, right, top, bottom, or center keyword describing the corresponding offset. y-offset
Is a <length> or a <percentage> describing how far from the top edge of the box the origin of the transform is set. x-offset-keyword
Is one of the left, right, or center keyword describing how far from the left edge of the box the origin of the transform is set. y-offset-keyword
Is one of the top, bottom, or center keyword describing how far from the top edge of the box the origin of the transform is set. z-offset
Is a <length> (and never a <percentage> which would make the statement invalid) describing how far from the user eye the z=0 origin is set.`}]},{path:"/content/front/html/css%E4%B9%8Bvm_vh_lvm_lvh%E7%9A%84%E5%B7%AE%E5%88%AB.html",title:"css之vm_vh_lvm_lvh的差别-origin",pathLocale:"/",contents:[{header:"",slug:"",content:`css之vm_vh_lvm_lvh的差别:
大部分前端都知道，在 CSS 世界中，有 vw、vh、vmax、vmin 这几个与视口 Viewport 相关的单位。
正常而言： 1vw 等于1/100的视口宽度 （Viewport Width）
1vh 等于1/100的视口高度 （Viewport Height）
vmin — vmin 的值是当前 vw 和 vh 中较小的值
vmax — vw 和 vh 中较大的值 但是，在移动端，情况就不太一样了。100vh 不总是等于一屏幕的高度。有的时候，100vh 高度会出现滚动条。
根因在于：
很多浏览器，在计算 100vh 的高度的时候，会把地址栏等相关控件的高度计算在内2
同时，很多时候，由于会弹出软键盘等操作，在弹出的过程中，100vh 的计算值并不会实时发生变化！ 新视口相关单位之 lvh、svh、dvh
为了解决上述的问题，规范新推出了三类单位，分别是： The large viewport units（大视口单位）：lvw,lvh, lvi, lvb, lvmin, and lvmax
The small viewport units（小视口单位）：svw, svh, svi, svb, svmin, and svmax
The dynamic viewport units（动态视口单位）：dvw, dvh, dvi, dvb, dvmin, and dvmax
别看看上去很多，其实很好记忆，vw/vw/vmax/vmin 的前缀是 v，而： 大视口单位的前缀是 lv，意为 large viewport
小视口单位的前缀是 sv，意为 small viewport
动态视口单位的前缀是 dv，意为 dynamic viewport
这里我们着重关注 lvh、svh、dvh。它们三者与 vh 有什么异同呢？ 先来看大视口与小视口，规范对它们的定义是：
Large Viewport: The viewport sized assuming any UA interfaces that are dynamically expanded and retracted to be retracted.
Small Viewport: The viewport sized assuming any UA interfaces that are dynamically expanded and retracted to be expanded.
翻译一下： 大视口（Large Viewport）：视口大小假设任何动态扩展和缩回的 UA 界面都没有展开
小视口（Small Viewport）：视口大小假设任何动态扩展和缩回的 UA 界面都展开了 参考链接:https://www.cnblogs.com/coco1s/p/17078218.html`}]},{path:"/content/front/html/css%E4%B9%8BwordBreak.html",title:"css之word-break",pathLocale:"/",contents:[{header:"",slug:"",content:`.css一长串没有空格的字符，让其在容器边界内换行，通过 word-break: break-all;实现如下，如果不这样的话，Author response:就会和后面的内容分别处于不同的行:
<div class="large-8 response-edit-content" style="word-break: break-all;"> <strong>User response:</strong> {{ historyItem.submissionHistoryComments.comment }}
</div> 渲染之后的结果:
User response: sdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd 下面这个是不需要的:
User response: sdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd`}]},{path:"/content/front/html/css%E4%B9%8B%E4%BF%AE%E6%94%B9%E5%BC%95%E7%94%A8blockquote%E5%85%83%E7%B4%A0%E7%9A%84%E5%B1%9E%E6%80%A7.html",title:"css之修改引用blockquote元素的属性",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候会使用富文本编辑器里的 引用 属性，但是展示的时候可能不会展示出来，看不出引用的效果，需要手动设置引用属性blockquote的属性
我的使用： blockquote{ border-left: 2px solid #000;//设置引用的border background: #F8F9FD;//引用内容的背景色
} 还可以有的属性设置:
blockquote { background: #f9f9f9; border-left: 10px solid #ccc; margin: 1.5em 10px; padding: 0.5em 10px; quotes: "\\201C" "\\201D" "\\2018" "\\2019";
} blockquote:before { color: #ccc; content: open-quote; font-size: 4em; line-height: 0.1em; margin-right: 0.25em; vertical-align: -0.4em;
} blockquote p { display: inline;
}`}]},{path:"/content/front/html/css%E4%B9%8B%E6%BB%9A%E5%8A%A8%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"css之滚动的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`css之滚动的问题，在做项目的时候，一直对scroll属性有些疑问，特意记录一下，代码如下:
mounted() { if (process.client){ window.addEventListener('scroll', this.handleScroll, true) } }, methods: {
...
... handleScroll: function (){ console.log('window的滚动距离:', window.scrollY) // 滚动条到顶部的距离 // HTMLElement.offsetParent 是一个只读属性，返回一个指向最近的（指包含层级上的最近）包含该元素的定位元素或者最近的 table, td, th, body 元素。当元素的 style.display 设置为 "none" 时，offsetParent 返回 null。offsetParent 很有用，因为 offsetTop 和 offsetLeft 都是相对于其内边距边界的。 // HTMLElement.offsetTop 为只读属性，它返回当前元素相对于其 offsetParent 元素的顶部内边距的距离。 console.log('元素 articleWrapper offsetTop:', this.$refs.articleWrapper.offsetTop) console.log('元素 articleWrapper scrollHeight:',this.$refs.articleWrapper.scrollHeight) // 整个内容的高度(包括了 滚动框之外的内容) console.log('元素 articleWrapper clientHeight:', this.$refs.articleWrapper.clientHeight) // 客户端看到的高度(就会说滚动框里的内容) console.log('元素 articleWrapper scrollTop:',this.$refs.articleWrapper.scrollTop) // 滚动条到顶部的距离 }, toTop: function (){ this.$refs.articleWrapper.scrollTo({top:0, behavior: "smooth"}) // 常见用法，点击 回到顶部 },
...
...
}`}]},{path:"/content/front/html/css%E4%B9%8B%E7%BB%9D%E5%AF%B9%E5%AE%9A%E4%BD%8D%E4%B8%8B%E7%9A%84%E7%99%BE%E5%88%86%E4%B9%8B%E4%B8%80%E7%99%BE%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css之绝对定位下的百分之一百的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`css之绝对定位下的100%使用:
最近看别人的代码，发现在定位的时候使用到了top:100%，不太明白，和GTP沟通以后，得到了答案，记录一下。代码如下:
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <link rel="stylesheet" href="styles.css"> <title>Relative Positioning Example</title> <style type="text/css"> .container { position: relative; display: inline-block;
} .dropdown-toggle { padding: 10px; background-color: #ccc; border: none; cursor: pointer;
} .dropdown-menu { position: absolute; top: 100%; left: 0; background-color: #f0f0f0; border: 1px solid #aaa; padding: 10px; display: none;
} .container:hover .dropdown-menu { display: block;
} </style>
</head>
<body> <div class="container"> <button class="dropdown-toggle">Open Dropdown</button> <div class="dropdown-menu"> <!-- 下拉菜单内容 --> <li>我的1</li> <li>我的2</li> <li>我的</li> <li>我的</li> <li>我的</li> <li>我的</li> <li>我的</li> </div> </div>
</body>
</html> 现象：下拉菜单会出现在 Open Dropdown 这个button下面，而不会覆盖这个button，
这就是100%的优点，当使用相对定位并设置 top: 100% 时，绝对定位的元素将相对于
其包含块的底部边缘进行定位，但它不会影响到原来的包含块布局。这就是为什么你的
dropdown-toggle 按钮没有被覆盖。
还有另外一个案例，就是 bottom:100%，达到的效果就是元素的底部边缘会紧密贴合其包含块的顶部边缘，从而将元素放置在其包含块的上方。
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <link rel="stylesheet" href="styles.css"> <title>Relative Positioning Example</title> <style type="text/css"> .container { position: relative; /*默认情况下，div 元素的 display 属性值是 block，这意味着它会独占一整行的宽度。如果你希望容器在一行内显示，但又不需要占据整个行的宽度，那么可以将 display 设置为 inline-block。*/ display: inline-block; margin-top: 500px;
} .tooltip-toggle { padding: 10px; background-color: #ccc; border: none; cursor: pointer;
} .tooltip { position: absolute; bottom: 100%; left: 50%; transform: translateX(-50%); background-color: #f0f0f0; border: 1px solid #aaa; padding: 10px; display: none;
} .container:hover .tooltip { display: block;
} </style>
</head>
<body> <div class="container"> <button class="tooltip-toggle">Show Tooltip</button> <div class="tooltip"> <!-- 提示内容 --> <li>我的4</li> <li>我的5</li> <li>我的</li> <li>我的</li> <li>我的</li> <li>我的</li> <li>我的</li> </div> </div>
</body>
</html>`}]},{path:"/content/front/html/css%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89border-bottom%E7%9A%84%E5%AE%BD%E5%BA%A6.html",title:"css之自定义border-bottom的宽度",pathLocale:"/",contents:[{header:"",slug:"",content:`css之自定义border-bottom的宽度，主要通过通过伪元素实现:
.example_div::after { content: ''; width: 50%; height: 1px; display: block; margin: 0 auto; border-bottom: 1px solid rgba(0, 0, 0, 0.09);
}`}]},{path:"/content/front/html/css%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AD%97%E4%BD%93@font-face.html",title:"css之自定义字体@font-face",pathLocale:"/",contents:[{header:"",slug:"",content:`实际开发过程中，可能会使用自己的字体，下面开始介绍@font-face使用方法
1.介绍
@font-face
指定了一种用于显示文本的自定义字体；该字体可以从远程服务器加载，也可以从用户自己的计算机上的本地安装的字体加载。 2.语法
@font-face { font-family: "Trickster"; src: local("Trickster"), url("trickster-COLRv1.otf") format("opentype") tech(color-COLRv1), url("trickster-outline.otf") format("opentype"), url("trickster-outline.woff") format("woff");
} 3.使用
可以新建一个 font.css文件，里面写入如下内容(可以同时定义多个字体文件)
@font-face { font-family: "Trickster"; font-weight:300; src: url("trickster-COLRv1.otf") format("opentype");
}
@font-face { font-family: "Trickster"; font-weight:400; src: src: url("trickster-COLRv1.otf") format("opentype");
}
@font-face { font-family: "Trickster"; font-weight:500; src: src: url("trickster-COLRv1.otf") format("opentype");
} 4.说明
A font-weight value. Accepts two values to specify a range that is supported by a font-face, for example font-weight: 100 400;
翻译过来：font-weight 可以是一个单值，也可以是一个范围值 5.Font MIME Types 字段名
说明 Format
ID Format
MIME type TrueType
font/ttf OpenType
font/otf Web Open Font Format
font/woff Web Open Font Format 2
font/woff2`}]},{path:"/content/front/html/css%E4%B9%8B%E8%AE%BE%E7%BD%AEflex%E5%85%83%E7%BB%84%E7%9A%84%E5%AD%90%E5%85%83%E7%B4%A0%E6%A0%B9%E6%8D%AE%E8%87%AA%E7%94%9F%E5%86%85%E5%AE%B9%E5%8D%A0%E5%AE%BD.html",title:"css之设置flex元组的子元素根据自生内容占宽",pathLocale:"/",contents:[{header:"",slug:"",content:`使用display: flex;属性时，Flex容器的默认行为是让其子元素填充整个可用空间。如果你想要根据内容确定宽度，而不是整行，可以考虑使用以下方法：
使用inline-flex： 将display: flex;更改为display: inline-flex;。这会使Flex容器变成行内元素，根据内容调整宽度。
.flex-container { display: inline-flex;
}`}]},{path:"/content/front/html/css%E4%B9%8B%E8%B4%9F%E8%BE%B9%E8%B7%9D%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css之负边距的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`当子元素被限定在父元素以内，想要突破父元素的约束，可以按照下面的方式解决
<AppSeparator class="-mx-[4.5rem] w-[calc(100%+9rem)]" /> 如果只有w属性是不行的,如:
<AppSeparator class="w-[calc(100%+9rem)]" /> 分析:
只使用 w-[calc(100%+144px)] 而不配合负外边距时会发生的情况。让我们更详细地分析一下这种情况： 1>默认对齐：
HTML 元素默认是左对齐的。当你增加元素的宽度而不改变其位置时，它会向右扩展。 2>宽度计算：
w-[calc(100%+144px)] 使元素宽度等于父元素宽度加上144px。这额外的宽度会全部添加到右侧。 3>视觉效果：
左侧：元素的左边缘与父元素的左边缘完全对齐。
右侧：元素的右边缘会超出父元素右边缘144px。 4>潜在问题：
可能导致水平滚动条出现。
可能干扰页面上其他元素的布局。
右侧内容可能被截断或隐藏，取决于父元素的 overflow 属性设置。 要实现两侧均匀扩展的效果，我们需要配合使用负外边距：
class="w-[calc(100%+144px)] -mx-[72px]" 这个组合做到了：
1>增加总宽度（通过 w-[calc(100%+144px)]）
2>向左移动72px（通过 -mx-[72px] 的左侧负外边距）
3>向右扩展72px（通过宽度增加和右侧负外边距的组合效果） 结果是元素看起来向两侧各扩展了72px，同时保持了中心对齐。 注意:只使用 -ml-[72px] 也可以解决问题，但是为了方便维护代码，还是左右两边都加.与 -ml-[4.5rem] 的对比：
负左外边距会直接影响元素的位置，使其向左移动。
负右外边距通常不会改变元素的位置，除非有特定的布局情况`}]},{path:"/content/front/html/css%E4%BB%A3%E7%A0%81%E5%9D%97.html",title:"css代码块",pathLocale:"/",contents:[{header:"",slug:"",content:`css代码块，之所以起这个名字，是因为有时候在开发过程中会遇到一些写的比较好的代码，就想统一的记在这里:
1> css之flex细节
父级 display: flex, 默认会占用整行，假如子元素只有 120px, 那么如果需要让父元素和子元素占用一样的空间，可以将父级 display: inline-flex // tailwindcss 样式控制
<div class="flex h-[calc(100vh-10rem)] flex-wrap justify-between gap-x-[4.4rem] gap-y-4 overflow-auto px-4 md:h-[calc(100vh-15rem)] md:flex-nowrap"> </div> 2> text-[1.875rem] 设置字体大小为 1.875rem (30px), 设置行高为 2.4375rem (39px), 在 Tailwind 中,斜杠后面的值用来指定行高
<div class="!text-[1.875rem]/[2.4375rem] font-semibold"> </div> 3> 给ul 下的 li 前设置无序列表符号
ul { list-style-type: none; padding-left: 1.25rem; li::before { content: "\\2022"; color: black; font-weight: bold; display: inline-block; width: 1em; // 调整圆点和文本之间的距离 margin-left: -1em; // 这个主要是设置 圆点在1.25rem范围内的位置, 主要是解决圆点想右边挤压文本的问题 } } // tailwindcss写法
.affiliation-box { ul { @apply pl-5; li::before { @apply content-['\\2022'] text-color-default font-semibold inline-block w-4 -ml-4 } }
}
4>html的 details 标签 实现展开收起功能
官方地址: https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/details`}]},{path:"/content/front/html/css%E4%BC%AA%E5%85%83%E7%B4%A0%E5%AE%9E%E7%8E%B0%E7%9F%AD%E7%AB%96%E7%BA%BF.html",title:"css伪元素实现短竖线",pathLocale:"/",contents:[{header:"",slug:"",content:`项目中经常会有短竖线分隔多个元素的设计，下面记录一下实际开发中用的比较多的一种 <div class="test">hello</div> .test width 100px height 50px background #eee position: relative;
.test:after content: '' height: 20px border-right: 2px solid red position: absolute; right: 0; top: 13px; 实际项目中的用法(去掉最后一个为元素的竖线以及margin值):
.st-item{ width: 4.25rem; height: 1.4rem; font-weight: 400; font-size: 0.875rem; line-height: 1.4rem; position: relative; margin-right: 1.25rem; &:after{ content: ''; height: 1.25rem; border-right: 0.0625rem solid #000; position: absolute; right: 0; top: 0.0625rem; } &:last-child{ margin-right: 0; } &:last-child:after{ display: none; } }`}]},{path:"/content/front/html/css%E5%85%B3%E4%BA%8E%E5%9B%BE%E7%89%87%E5%92%8C%E6%96%87%E5%AD%97%E5%9E%82%E7%9B%B4%E5%B1%85%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"css关于图片和文字垂直居中的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`css关于图片和文字垂直居中的问题:
<!DOCTYPE html>
<html>
<head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title></title>
</head>
<style type="text/css"> .parent { width: 1000px; height: 800px; /* 可以不设置*/ display: inline-block; text-align: center; /* 水平居中对齐 */ line-height: 800px; /* 文本子元素与父元素高度相等，用于垂直居中对齐(写在这里其实会被text继承), 也可以直接在 text 上使用 line-height: 800px; 但是在img上是不能使用的；其实设置这个line-height: 800px的原因是，改变text的行内框的高度，以修改基线的位置，修改为400px的位置*/ white-space: nowrap; /* 防止换行 */ } .text { vertical-align: middle; } img{ width: 700px; height: 600px; vertical-align: middle; } </style>
<body>
<div class="parent"> <img src="./cert.jpg" alt="Image"> <span class="text">Some text Some text </span>
</div>
</body>
</html> 理解:
文本的基线与包含它的行内框 分别指的是什么？
文本的基线和包含它的行内框是与文字排列和布局有关的两个重要概念。让我更详细地解释它们： 1>. **文本的基线**：文本的基线是文字字符底部的水平线。它通常用作文本的垂直对齐参考点。不同字体和字符的基线可能会有所不同。文本的基线用于确定文本在垂直方向上的对齐方式。当你应用 \`vertical-align\` 时，它通常是相对于文本的基线进行调整的。 2>. **包含它的行内框**：包含它的行内框是指包含文本的行内块容器或行内框。行内框是文本和内联元素呈现的区域，通常是水平排列的。行内框可以包含一个或多个字符、单词或内联元素。包含元素的行内框的高度取决于其内容。当你在文本中创建段落或包含文本的 \`<div>\` 等元素时，它们通常充当行内块容器，包含一系列行内框。 在上下文中，当你应用 \`vertical-align: middle;\` 时，它将调整元素的垂直位置，以使元素的基线与包含它的行内框的中央对齐。这意味着元素将在行内框内垂直居中对齐，而行内框的高度通常由包含的内容决定。基线与行内框的中央对齐方式有助于文本和内联元素在其上下文中实现垂直对齐。`}]},{path:"/content/front/html/css%E5%8F%98%E9%87%8F%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F.html",title:"css变量工作方式",pathLocale:"/",contents:[{header:"",slug:"",content:`css变量工作方式:
如下样式:
.m-checkbox__control--indeterminate:before { --tw-scale-x: 1 !important; --tw-scale-y: 1 !important; transform: translate(var(--tw-translate-x), var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)) !important;
} 分析:
变量的定义：
--tw-scale-x: 1 和 --tw-scale-y: 1 定义了 scaleX 和 scaleY 的默认缩放值为 1，表示没有缩放效果。
变量的使用：
在 transform 属性中，通过 scaleX(var(--tw-scale-x)) 和 scaleY(var(--tw-scale-y)) 来引用这些变量，并将它们的值应用到 transform 中。
如果需要动态调整缩放比例，可以通过修改这些变量的值（例如通过 JavaScript 或其他 CSS 规则）来实现。
是的，像 --tw-scale-x 这样的 CSS 变量通常是用来为其他样式属性提供值的，它们的作用类似于“占位符”，方便在不同的地方复用这些值或动态设置它们。`},{header:"优点",slug:"优点",content:`复用性：
使用变量可以让样式更容易复用或更新。例如，只需要改动变量值，就可以更新所有使用该变量的样式。 动态性：
CSS 变量支持运行时修改，可以通过 JavaScript 动态改变变量的值。例如：
document.documentElement.style.setProperty('--tw-scale-x', '2'); 响应式设计：
通过配合媒体查询等，可以为变量定义不同的值，从而实现响应式的设计。例如：
@media (max-width: 600px) { --tw-scale-x: 0.8;
}`},{header:"在 Tailwind CSS 中的应用",slug:"在-tailwind-css-中的应用",content:`这是 Tailwind CSS 的内部实现机制之一，许多 Tailwind 的功能（如缩放、平移、旋转等）会依赖于这些变量。
例如，当你使用 scale-150 类时，它实际上是修改了 --tw-scale-x 和 --tw-scale-y 的值：
.scale-150 { --tw-scale-x: 1.5; --tw-scale-y: 1.5;
} 通过这种方式，Tailwind 提供了高度灵活的样式生成能力。`}]},{path:"/content/front/html/css%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%B8%89%E8%A7%92%EF%BC%8C%E5%B8%A6%E8%BE%B9%E6%A1%86.html",title:"css实现的三角，带边框",pathLocale:"/",contents:[{header:"",slug:"",content:`css实现的三角，带边框:
<div id="copy-link"> <div id="copy-button"> <div class="copy-box"> Copy Link <div class="triangle"></div> <div class="triangle-border"></div> </div> </div>
</div> #copy-button{ display: none; color: #000; position: absolute; left: 50%; transform: translateX(-50%); bottom: -70px; border: none; border-radius: 5px; box-shadow: 0 0 10px 6px rgb(0 0 0 / 10%); z-index: 3; background-color: #fff;
}
#copy-link:hover #copy-button{ display: block;
} .copy-box{ box-sizing: border-box; width: 203px; height: 37px; padding: 8px; margin: 10px 14px; font-weight: normal; border: 1px solid #1a8d8d; border-radius: 4px; color: #1a8d8d; font-size: 14px;
}
.triangle { width: 0; height: 0; border-left: 10px solid transparent; border-right: 10px solid transparent; border-bottom: 10px solid #cecece; position: absolute; top: -10px; left: 50%; transform: translateX(-50%);
}
.triangle-border{ position: absolute; top: -16px; left: 50%; transform: translate(-50%,0); border-left: 8px solid transparent; border-right: 8px solid transparent; border-top: 8px solid transparent; border-bottom: 8px solid #fff;
}`}]},{path:"/content/front/html/css%E5%BC%B9%E7%AA%97%E9%A1%B5%E9%9D%A2%E5%9E%82%E7%9B%B4%E6%B0%B4%E5%B9%B3%E5%B1%85%E4%B8%AD.html",title:"css弹窗页面垂直水平居中",pathLocale:"/",contents:[{header:"",slug:"",content:`css弹窗页面垂直水平居中:
&{ width: 100%; .ajaxShowForm{ top: 50% !important; bottom: auto; height: auto; max-height: calc(100vh - 40px); transform: translateY(-50%); margin:0 auto; }
} 代码分析:
&: 表示引用父选择器，这里可能是某个容器元素的选择器。 width: 100%;: 设置该容器元素的宽度为100%。 .ajaxShowForm { ... }: 嵌套的规则，针对具有.ajaxShowForm类的元素。 top: 50% !important;: 设置元素的顶部边缘距离其包含元素顶部的距离为50%，并使用!important确保这个规则的优先级较高。 bottom: auto;: 取消bottom属性的任何值，使其自动计算。 height: auto;: 设置元素的高度为自动，允许其根据内容自动调整高度。 max-height: calc(100vh - 40px);: 设置元素的最大高度为视窗高度（100vh）减去40像素，使用calc()函数执行数学运算。 transform: translateY(-50%);: 使用transform属性对元素进行垂直平移，使其垂直居中。translateY(-50%)表示在垂直方向上向上移动50%的元素高度。 margin: 0 auto;: 设置元素的上下边距为0，左右边距为自动，从而实现水平居中。 这段代码的整体作用是使包含有.ajaxShowForm类的元素垂直和水平居中，同时限制其最大高度为视窗高度减去40像素。父选择器可能是某个包含这个样式的容器元素。`}]},{path:"/content/front/html/css%E6%A0%B7%E5%BC%8F%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css样式变量的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`如下样式:
.m-checkbox__control--indeterminate:before { --tw-scale-x: 1 !important; --tw-scale-y: 1 !important; transform: translate(var(--tw-translate-x), var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)) !important;
} 分析:
变量的定义：
--tw-scale-x: 1 和 --tw-scale-y: 1 定义了 scaleX 和 scaleY 的默认缩放值为 1，表示没有缩放效果。 变量的使用：
在 transform 属性中，通过 scaleX(var(--tw-scale-x)) 和 scaleY(var(--tw-scale-y)) 来引用这些变量，并将它们的值应用到 transform 中。
如果需要动态调整缩放比例，可以通过修改这些变量的值（例如通过 JavaScript 或其他 CSS 规则）来实现。 是的，像 \`--tw-scale-x\` 这样的 CSS 变量通常是用来为其他样式属性提供值的，它们的作用类似于“占位符”，方便在不同的地方复用这些值或动态设置它们。`},{header:"优点",slug:"优点",content:`复用性：
使用变量可以让样式更容易复用或更新。例如，只需要改动变量值，就可以更新所有使用该变量的样式。 动态性：
CSS 变量支持运行时修改，可以通过 JavaScript 动态改变变量的值。例如：
document.documentElement.style.setProperty('--tw-scale-x', '2'); 响应式设计：
通过配合媒体查询等，可以为变量定义不同的值，从而实现响应式的设计。例如：
@media (max-width: 600px) { --tw-scale-x: 0.8;
}`},{header:"在 Tailwind CSS 中的应用",slug:"在-tailwind-css-中的应用",content:`这是 Tailwind CSS 的内部实现机制之一，许多 Tailwind 的功能（如缩放、平移、旋转等）会依赖于这些变量。
例如，当你使用 scale-150 类时，它实际上是修改了 --tw-scale-x 和 --tw-scale-y 的值：
.scale-150 { --tw-scale-x: 1.5; --tw-scale-y: 1.5;
} 通过这种方式，Tailwind 提供了高度灵活的样式生成能力。`}]},{path:"/content/front/html/css%E7%9A%84%E5%87%A0%E4%B8%AA%E6%9C%89%E7%94%A8%E5%B1%9E%E6%80%A7.html",title:"css的几个有用属性",pathLocale:"/",contents:[{header:"",slug:"",content:`css的几个有用属性:
1.css content 属性:
content 属性通常只对伪元素（如 ::before 或 ::after）生效，而不是直接作用于 HTML 元素本身。在您的情况下，您试图直接修改一个 div 元素的内容，这是不会生效的。 错误用法:
:deep(.select-none){ content: 'No results match your search.';
} 正确用法:
:deep(.select-none){ font-size: 0;// 元素的字体大小设置为 0, 实际效果是隐藏了元素的原始文本内容，因为文字大小为 0 就不可见了, 但是，元素本身及其尺寸和其他样式属性仍然保持不变. &:before{ font-size: 1rem; // 这样做是为了确保新的文本内容是可见的，因为父元素的字体大小是 0. content: 'No results match your search.'; // 设置伪元素的内容为指定的文本, 这个文本将会显示在元素中，替代原来的内容. }
} 2.css fit-content使用:
这个属性很有用,如下代码:
<div class="flex w-full flex-col gap-2.5">
<div v-for="(item, index) in selectedItems" :key="index" class="flex items-center rounded border border-color-info bg-brand-subtler hover:border-color-success w-fit"
> <MText class="flex-1"> {{ item.label }} </MText> <MIcon name="close" size="sm" class="cursor-pointer hover:rounded hover:bg-brand-subtle" @click="removeItem(item.value)" />
</div>
</div> 这个实现的是: 父级 100%宽度，但是子元素会根据子级内容的宽度自动伸缩，包括自动换行
https://developer.mozilla.org/zh-CN/docs/Web/CSS/fit-content 下面这个:
<div class="flex w-full flex-col gap-2.5">
<div v-for="(item, index) in selectedItems" :key="index" class="flex items-center justify-between rounded border border-color-info bg-brand-subtler hover:border-color-success"
> <MText class="flex-1"> {{ item.label }} </MText> <MIcon name="close" size="sm" class="cursor-pointer hover:rounded hover:bg-brand-subtle" @click="removeItem(item.value)" />
</div>
</div> 实现的是，父级 100%宽度，但是子元素会占据除去MICon元素，剩余的所有宽度，同时可以自动换行 3.flex-wrap是用于flex容器的,而不是子元素 4.css对子元素设置flex属性:
可以使用一个，两个或三个值来指定 flex 属性 单值语法：值必须是以下之一：
一个 <flex-grow> 的有效值：此时简写会扩展为 flex: <flex-grow> 1 0。
一个 <flex-basis> 的有效值：此时简写会扩展为 flex: 1 1 <flex-basis>。
关键字 none 或者全局关键字之一。 // 注意 flex: none 对应， flex-grow: 0; flex-shrink: 0; flex-basis: auto; 如:
/* 单值，无单位数字：flex-grow
flex-basis 此时等于 0。 */
flex: 2; // 即为: flex: 2 1 0 /* 单值，宽度/高度：flex-basis */
flex: 10em;
flex: 30px; // 即为: flex: 1 1 30px;
flex: min-content; 双值语法：
第一个值必须是一个 flex-grow 的有效值。
第二个值必须是以下之一：
一个 flex-shrink 的有效值：此时简写会扩展为 flex: <flex-grow> <flex-shrink> 0。
一个 flex-basis 的有效值：此时简写会扩展为 flex: <flex-grow> 1 <flex-basis>。 三值语法：值必须按照以下顺序指定：
一个 flex-grow 的有效值。
一个 flex-shrink 的有效值。
一个 flex-basis 的有效值。`}]},{path:"/content/front/html/css%E7%9B%B8%E5%AF%B9%E5%AE%9A%E4%BD%8D%E5%92%8C%E7%BB%9D%E5%BA%A6%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"css相对定位和绝度定位的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`一直以来对相对定位和绝对定位的使用，有一点儿模糊，就是边界问题，今天通过一个例子证明了两个结论：
1.子级的宽高可以比父级的宽高大
2.不管父级设置border-sizing为什么，子级都是相对父级内边框定位的
<!DOCTYPE html>
<html>
<head> <title>相对定位和绝度定位的关系</title> <style type="text/css"> .parent{ width: 200px; height: 300px; display: block; text-align: right; background: #0056B1; /*border: 20px solid #86C671;*/ /*box-sizing: border-box;*/ position: relative; } .child1{ width: 50px; height: 50px; background-color: blue; } .child2{ /*子级的宽高可以比父级的宽高大*/ width: 400px; height: 500px; display: none; text-align: right; background: #CEF6FF; /*border: 20px solid #F67539;*/ /*box-sizing: border-box;*/ position: absolute; /*下面这个证明，不管父级设置border-sizing为什么，子级都是相对父级内边框定位的*/
sss /*top: 0; left: 100%;*/ /*下面这个证明，子级定位的范围可以跑到父级定义的宽高的外面*/ right: 0; top: 300px; /*top: 310px;*/ } </style>
</head>
<body>
<div class="parent"> parent <div class="child1">child1</div> <div class="child2">child2</div>
</div>
</body>
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.3/jquery.js"><\/script>
<script type="text/javascript"> $(function(){ $('.parent').click(function(event){ $('.child2').css('display','none'); event.stopPropagation(); }) $('.child1').click(function(event){ $('.child2').css('display','block'); event.stopPropagation(); }) });
<\/script>
</html>`}]},{path:"/content/front/html/css%E7%BB%99border%E8%AE%BE%E7%BD%AE%E5%8F%AF%E5%8F%98%E9%A2%9C%E8%89%B2.html",title:"css给border设置可变颜色",pathLocale:"/",contents:[{header:"",slug:"",content:`css给border设置可变颜色:
@keyframes borderColorChange { 0% { border-bottom-color: #d0d7de; /* 起始颜色 */ } 16% { border-bottom-color: #ff6347; /* 16%的时间点 */ } 33% { border-bottom-color: #32cd32; /* 33%的时间点 */ } 50% { border-bottom-color: #1e90ff; /* 50%的时间点 */ } 66% { border-bottom-color: #ff1493; /* 66%的时间点 */ } 83% { border-bottom-color: #ffcc00; /* 83%的时间点 */ } 100% { border-bottom-color: #8a2be2; /* 100%的时间点 */ }
} .bordered-element { padding: 20px; font-size: 18px; border-bottom: 1px solid #d0d7de; //主要是设置这个border的颜色 animation: borderColorChange 5s infinite;
} 解释：
0%：动画开始的初始状态。在这里，边框颜色是 #d0d7de（一种淡灰色）。这意味着当动画开始时，元素的 border-bottom 会显示这个颜色。 16%：动画执行了 16% 的时间时，边框颜色变为 #ff6347（番茄色）。动画的进度到达 16% 时，边框颜色会从上一个颜色（#d0d7de）变到番茄色。 33%：动画执行了 33% 的时间时，边框颜色变为 #32cd32（黄绿色）。 50%：动画执行了 50% 的时间时，边框颜色变为 #1e90ff（道奇蓝）。 66%：动画执行了 66% 的时间时，边框颜色变为 #ff1493（深粉色）。 83%：动画执行了 83% 的时间时，边框颜色变为 #ffcc00（金色）。 100%：动画执行了 100% 的时间时，边框颜色变为 #8a2be2（蓝紫色）。这意味着在动画的结束时，边框颜色会变为这个颜色。 animation: borderColorChange 5s infinite
这个语句控制了动画的执行方式： borderColorChange：指定应用的动画名称，对应上面定义的 @keyframes 名称。
5s：指定动画的时长是 5 秒，意思是从动画开始到结束，需要 5 秒的时间，所有的颜色变化都会在 5 秒内完成。
infinite：动画会无限次地循环播放。也就是说，动画从头到尾播放一次后，会立即重新开始。 总结
百分比：表示动画在指定时长（5秒）内的不同时间点，每个时间点定义了元素的样式（在这个例子中是边框的颜色）。
0% 到 100%：分别代表动画的开始和结束，通过这些时间点，你可以精确地控制元素在动画过程中如何变化。
希望这个解释能帮你更好地理解 @keyframes 中的百分比作用以及如何使用 animation 来控制动画的执行。`}]},{path:"/content/front/html/css%E7%BB%99%E6%96%87%E5%AD%97%E8%AE%BE%E7%BD%AE%E5%8F%AF%E5%8F%98%E9%A2%9C%E8%89%B2.html",title:"css给文字设置可变颜色",pathLocale:"/",contents:[{header:"",slug:"",content:`css给文字设置可变颜色:
.text-gradient { background: linear-gradient(90deg, red, blue); -webkit-background-clip: text; -webkit-text-fill-color: transparent;
} 代码分析:
这个代码片段使用了 CSS 的渐变和剪裁属性来创建一个渐变文字效果。每个属性在实现这个效果中都有特定的作用： background: linear-gradient(90deg, red, blue); 这行代码为元素设置了一个线性渐变背景，从红色过渡到蓝色。
90deg 表示渐变的角度，90度表示从左到右（水平）的渐变。
如果你直接应用这个渐变背景在一个普通元素上，会看到元素背景从红色到蓝色的平滑过渡。 -webkit-background-clip: text; background-clip 是一个 CSS 属性，指定背景应该在哪个部分显示。通常可以是 border、padding、content，但这里设置为 text。
当 background-clip 设置为 text 时，背景只会显示在文字本身的区域，而不会出现在文字以外的地方。这样，文字就像是填充了渐变效果。
这个属性前面带有 -webkit- 前缀，因为这是一个实验性的特性，主要在支持 WebKit 引擎（如 Chrome 和 Safari）的浏览器中使用。 -webkit-text-fill-color: transparent; text-fill-color 是一个专门为文字设置颜色的属性，这里也带有 -webkit- 前缀。
将 text-fill-color 设置为 transparent（透明）时，文字本身的颜色变得透明，这样底部的背景渐变才会显现出来。
换句话说，这一行代码的作用是让文字本身没有颜色，以便背景渐变能够“透过”文字的形状显示出来。`},{header:"总结",slug:"总结",content:`通过这三行代码的组合，你的文字看起来像是填充了一个从红色到蓝色的渐变。具体效果如下： 渐变背景通过 background 和 background-clip: text 属性被限制在文字区域内。
透明文字颜色通过 text-fill-color: transparent 让背景渐变得以透过文字。 最终，文字本身看起来就拥有了渐变效果，但实际是因为文字区域内显示了背景的渐变。`}]},{path:"/content/front/html/css%E8%87%AA%E9%80%82%E5%BA%94%E5%B0%8F%E6%8A%80%E5%B7%A7.html",title:"css自适应小技巧",pathLocale:"/",contents:[{header:"",slug:"",content:`css自适应小技巧:
<html> <head></head> <body> <div class="course-box-list"> <!-- 整个box --> <div class="course-box" data-v-cb128327=""> <!-- 封面图 --> <div class="course-avatar" data-v-cb128327=""> <img src="http://academy.pj.test/upload/cover/2023-04-13/dfc1ab1cd137f0745866bc321f01a267.jpg" alt="" data-v-cb128327="" /> <span class="certification-tag" data-v-cb128327="">Certification</span> </div> <!-- 统计信息 --> <div class="course-info" data-v-cb128327=""> <p class="title white-space" data-v-cb128327="">fgdsgdfsgxcvcvx</p> <ul class="statistics" data-v-cb128327=""> <li class="st-item" data-v-cb128327="">1 Videos</li> <li class="st-item" data-v-cb128327="">4 Article</li> <li class="st-item" data-v-cb128327="">6min</li> </ul> <div class="progress-box" data-v-cb128327=""> <p class="percent" data-v-cb128327="">83% completed</p> <div class="bar" data-v-cb128327=""> <div class="progress" data-v-cb128327="" style="width: 83%;"></div> </div> </div> <p class="join" data-v-cb128327="">Joined at 19/04/2023</p> </div> </div> </div> </body>
</html> //关键样式
.course-box-list{ max-width:768px
} .course-box{ width: 100%;//这里设置 100%,会和父级一样宽 height: 100%;//这里设置 100%，那么它的高度就有子元素的高度撑起来 .course-avatar{ height: auto; //这个外层的 box的 高度设置为 auto，很有用，主要就是促使 子元素img 实现，等比缩放 width:100%; position:relative; img{ width: 100%; // 这个设置100%，会和父级的宽度一样 height: 100%; // 这个设置100%，而父级设置的是 auto，那么相当于这里的 height 也为auto，那么就会让这个图片的宽高实现等比例缩放，避免了图像的拉伸或压缩，缩放比例由原图的宽高比决定。实现等比缩放以后，父级高度设置的 auto,那么最后父级的高度就由子元素的高度(这里是img)决定了 max-width: 100%; //这个限制元素的最大宽度不超过其父元素的宽度。当父元素的宽度小于元素的最大宽度时，元素的宽度将会被调整，以适应父元素的宽度。但是这里其实用不到，因为设置了 width:100%，父子宽度一致。如果这里子元素 设置 width:800px,那么当屏幕缩小的时候，比如缩小到 600px，那么页面就会出现滚动条，此时 如果设置了 max-width:100%，就不会有这个问题，因为子元素的宽度会被调整以适应父元素的宽度。 } .certification-tag{ width: auto; //这里没有直接设置宽和高，都设置为100%，以及相应的padding等属性，那么最后这个元素的宽高，就由其内容决定，效果就是，表现出像设计稿一样的效果 height: auto; padding: 0.625rem; border-radius: 0.3125rem; background: rgba(0, 0, 0, 0.7); color: #fff; font-weight: 500; font-size: 0.6875rem; line-height: 2.1875rem; text-align: center; position: absolute; top: 0; right: 0; } } .course-info{ //... }
} //总结
上面代码样式，其实是一个经典的 自适应 布局方式，主用于手机适配，让页面看起来像设计稿的布局，但是也是有问题的，如果尺寸大小不按设计稿来做的话，样式大小其实还是有问题的，只是看起来像。
不过开始让我做的话，我可能会先设置这个 course-box 的宽高，当然了是rem单位。所以上面这种方式 适用于自由发挥的情况，没有设计稿约束，只是让最后的页面看起来像，而不关心尺寸大小。`}]},{path:"/content/front/html/css%E8%A3%81%E5%89%AA%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"css裁剪的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`关于css裁剪的使用:
1>clip-path 介绍
clip-path 是一种 CSS 属性，用于定义一个裁剪区域，只显示该区域内的内容，其余部分被裁剪掉，不会显示。 作用原理：
它为元素定义了一个裁剪区域（例如矩形、圆形、多边形等）。
只有在这个裁剪区域内部的内容会被渲染。
剩余的部分被隐藏，但仍然存在于 DOM 中。 语法:
clip-path: shape; 2>举例子
<div class="example"></div> .example { width: 200px; height: 100px; background: linear-gradient(90deg, red, blue); clip-path: polygon(20% 43%, 80% 43%, 80% 57%, 20% 57%); transition: clip-path 0.3s ease;
} 原理解析：
polygon() 定义了一个多边形，顶点的顺序是关键，按顺时针或逆时针连接点定义形状。
坐标值的格式是 x y，分别表示水平（x）和垂直（y）的偏移。
每个坐标点之间用逗号分隔，20% 43% 表示从元素左上角出发，水平偏移 20%，垂直偏移 43%。
这个多边形的定义细节：
第一点 (20% 43%): 多边形从左侧 20%，高度 43% 的点开始。
第二点 (80% 43%): 延伸到右侧 80%，高度仍为 43%。
第三点 (80% 57%): 向下延伸到高度 57%。
第四点 (20% 57%): 左移回到左侧 20%，高度仍为 57%。
这四个点连接起来，就形成了一个宽为 60%（80%-20%），高为 14%（57%-43%）的水平矩形。 裁剪后的视觉效果:
元素只显示 clip-path 定义的矩形区域内的部分。
矩形外部的内容会被裁剪掉，像是被一个“模板”遮住。 裁剪后的元素大小:
即使元素被 clip-path 裁剪，它的实际布局区域（包括宽度和高度）仍然保留不变。元素的布局大小由 CSS 的 width 和 height（或其内容）决定，与裁剪后的形状无关。裁剪仅改变渲染效果，不会改变元素在文档流中的尺寸或占位。 3>使用这个创建svg图片
<svg width="200" height="100"> <defs> <clipPath id="clip"> <polygon points="100,0 200,50 100,100 0,50" /> </clipPath> </defs> <rect width="200" height="100" fill="red" clip-path="url(#clip)" /> </svg> 这里：
<rect> 标签：
定义了一个宽为 200px、高为 100px 的矩形。
fill="red" 指定矩形的填充颜色为红色。 这个其实是定义了裁剪的外部区域，而不是以svg的width 和 height定义的，也可以设置 <rect width="100" height="50" fill="red" clip-path="url(#clip)" />，就会发现另一种效果. 但是一般会和svg设置相同的width和height。`}]},{path:"/content/front/html/css%E9%80%9A%E8%BF%87filter%E6%94%B9%E5%8F%98icon%E7%9A%84%E9%A2%9C%E8%89%B2.html",title:"css通过filter改变icon的颜色",pathLocale:"/",contents:[{header:"",slug:"",content:`css通过filter改变icon的颜色，实际应用有个场景，就是点击课程播放列表的时候，要给当前选中的课时加上高亮(选中状态)，默认的icon是黑色，高亮的时候没有切图,所以就需要自己根据当前默认的icon生成一个高亮的icon，于是css的filter的drop-shadow属性正好可以解决这个问题.
1.概念
filter: drop-shadow(x-offset y-offset blur color)
2.属性
drop-shadow()方法的参数有4个，每一个参数说明如下:
（1）x-offset：定义水平阴影的偏移距离，可以使用负值。由于CSS3采用的是W3C坐标系，因此x-offset取值为正时，向右偏移；取值为负时，向左偏移。
（2）y-offset：定义垂直阴影的偏移距离，可以使用负值。由于CSS3采用的是W3C坐标系，因此y-offset取值为正时，向下偏移；取值为负时，向上偏移。
（3）blur：定义阴影的模糊半径，只能为正值。
（4）color：定义阴影的颜色。
3.实际使用代码
<div class="lesson-list"> <ul> <li v-for="(item, index) in courseManageList" :key="index" :style="{'background-color': item.id === learnId ? backlogColor : defaultBacklogColor}"> <a @click="learnTheCourse(item.id, item.type)"> <div class="active-img" v-if="item.id === learnId"> <img src="~/assets/img/play_circle.svg" alt="" v-if="item.type === 'video'"> <img src="~/assets/img/article_circle.svg" alt="" v-else-if="item.type === 'article'"> <img src="~/assets/img/quiz_circle.svg" alt="" v-else> </div> <div v-else> <img src="~/assets/img/play_circle.svg" alt="" v-if="item.type === 'video'"> <img src="~/assets/img/article_circle.svg" alt="" v-else-if="item.type === 'article'"> <img src="~/assets/img/quiz_circle.svg" alt="" v-else> </div> <span class="title three-white-space" :style="{'color': item.id === learnId ? color : defaultColor}">{{item.title}}</span> </a> <span class="times" :style="{'color': item.id === learnId ? color : defaultColor}">{{ item.length }}</span> </li> </ul> </div> 样式 .lesson-list { border: 0.0625rem solid #000; ul { li { display: flex; align-items: center; justify-content: space-between; height: 3.9375rem; margin: 0.53125rem 1.25rem; box-sizing: border-box; a { display: flex; align-items: center; color: #000; cursor: pointer; img { display: block; width: 1.5rem; height: 1.5rem; margin-right: 0.75rem; } .title{ max-width: 17.1875rem; font-size: 0.875rem; line-height: 150%; } @media (max-width: 768px) { .title { max-width: 12rem; } } } .times { margin-left: auto; font-size: 0.875rem; line-height: 1.3125rem; } } } } #重点是这里
.active-img{ overflow: hidden; img { filter: drop-shadow(1.5rem 0 0 #007BE5); transform: translateX(-1.5rem); }
}`}]},{path:"/content/front/html/css%E9%9A%90%E8%97%8F%E9%BB%98%E8%AE%A4%E5%B1%9E%E6%80%A7.html",title:"css隐藏默认属性",pathLocale:"/",contents:[{header:"",slug:"",content:`关于css隐藏默认属性:
通过 appearance: none; 实现 appearance: none 的作用 移除默认样式:
通过 -webkit-appearance, -moz-appearance, 和标准的 appearance 属性，可以移除 HTML 元素的默认样式。
对于 checkbox 和 radio 这样的表单控件，移除后它们将失去默认的外观（例如复选框的方框和勾选符号）。 保持元素的功能性:
使用 appearance: none 后，元素仍然是可见的，并且能够响应用户的交互（点击、焦点等），无需额外的 JS 脚本。 支持伪元素定制:
移除默认样式后，可以通过伪元素（::before 和 ::after）自由定义外观，例如形状、颜色和动画。`}]},{path:"/content/front/html/css%E9%BC%A0%E6%A0%87%E6%82%AC%E6%B5%AE%E6%8E%A7%E5%88%B6%E5%85%83%E7%B4%A0%E9%9A%90%E8%97%8F%E4%B8%8E%E6%98%BE%E7%A4%BA.html",title:"css鼠标悬浮控制元素隐藏与显示",pathLocale:"/",contents:[{header:"",slug:"",content:`css鼠标悬浮控制元素隐藏与显示,这个主要基于hover事件，以及元素的相对定位和绝对定位实现，代码如下：
<div class="float-right"> <div class="user-head-box" v-if="isLogin" @mouseenter="isShowNav = true" @mouseleave="isShowNav = false"> <div class="after-login"> <NuxtLink to="/my/profile"> <img :src="resourceUrl+'/'+userInfo.avatar || resourceUrl+'/'+defaultUserImage" alt=""> </NuxtLink> </div> <div class="user-nav-box" v-if="isShowNav"> <div class="user-img-box" @click="isShowNav = false"> <NuxtLink to="/my/profile"> <img :src="resourceUrl+'/'+userInfo.avatar || resourceUrl+'/'+defaultUserImage" alt=""> </NuxtLink> </div> <div class="user-operate-box" @click="isShowNav = false"> <ul> <li> <NuxtLink to="/my/course"> My course </NuxtLink> </li> <li> <NuxtLink to="/my/certification"> My certification </NuxtLink> </li> <li> <NuxtLink to="/my/favorite"> My favorite </NuxtLink> </li> <li v-if="userInfo.isAdmin"> <a :href="resourceUrl+'/admin'"> Backend </a> </li> <li> <a :href="resourceUrl+'/logout'" class="log-out"> Log out </a> </li> </ul> </div> </div> </div> <div class="before-login" v-else> <Button @click="loginAction" rounded="none" customColor="#fff" customBgColor="transparent" :active=false variant="quaternary" class="btn-login-style btn">Login </Button> </div> </div> scss文件：
.user-head-box{ position: relative; //父级 height: 4.375rem; margin-right: 1.25rem;
} .user-nav-box{ width: 18.125rem; position: absolute; //子级 top: 4.375rem; right: 0; background-color: #F8F9FD; filter: drop-shadow(0px 3.99831px 11.9949px rgba(53, 60, 85, 0.2)); z-index: 99; .user-img-box{ width: 100%; height: 6.25rem; padding: 0.875rem 1.25rem; img{ display: block; width: 4.5rem; height: 4.5rem; border-radius: 50%; } } .user-operate-box{ li{ height: 3.125rem; padding: 0 1.25rem; line-height: 3.125rem; font-weight: 400; cursor: pointer; a{ display: inline-block; width: 100%; font-size: 0.75rem; line-height: 3.125rem; } .log-out{ font-size: 0.875rem; line-height: 1.3125rem; } } }
}`}]},{path:"/content/front/html/flex%E5%AD%90%E5%85%83%E7%B4%A0%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E8%AE%BE%E7%BD%AEz-index.html",title:"flex子元素可以直接设置z-index",pathLocale:"/",contents:[{header:"",slug:"",content:`flex子元素可以直接设置z-index:
Flex items paint exactly the same as inline blocks [CSS2], except that order-modified document order is used in place of raw document order, and z-index values other than auto create a stacking context even if position is static (behaving exactly as if position were relative). https://drafts.csswg.org/css-flexbox-1/#painting
https://www.sitepoint.com/quick-tip-how-z-index-and-auto-margins-work-in-flexbox/ //解析`}]},{path:"/content/front/html/flex%E5%B8%83%E5%B1%80%E6%9C%80%E5%90%8E%E4%B8%80%E8%A1%8C%E5%88%97%E8%A1%A8%E5%B7%A6%E5%AF%B9%E9%BD%90.html",title:"flex布局最后一行列表左对齐",pathLocale:"/",contents:[{header:"",slug:"",content:`在实际开发过程中，经常会使用到流式布局，需要有间隔同时排列整齐，我这里用到: justify-content: space-between;布局
但是这样有问题，就是 最后一行不能左对齐，解决办法如下：
.parent{ display: flex; justify-content: space-between; flex-wrap: wrap; &::after { content: ''; flex: auto; }
} 但是其实上面的思路还是有问题，flex: auto;以后，最后一行的间隙会被这个auto占完，导致最后一行的排列都黏在一起(使最后一行的边距失效)
由于我这里刚刚好是3个(只有这一种场景可以用)，所以将上面的代码改了一下，正好解决问题(核心就是把最后一个通过伪元素占了)，如下:
user-list-wrapper{ display: flex; flex-wrap: wrap; justify-content: space-between; margin-top: 2.8125rem; &:after { content: ''; flex: 0 1 24.0625rem; } .user-box{ width: 24.0625rem; height: 19.9375rem; margin-bottom: 2.84375rem; cursor: pointer; }
}`}]},{path:"/content/front/html/flex%E7%9A%84%E4%B8%89%E4%B8%AA%E5%B1%9E%E6%80%A7%E4%BD%BF%E7%94%A8.html",title:"flex的三个属性使用",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目遇到个需求：水平方向有四个元素，间距大小不一样，需要做自适应，开始通过设置之间的padding
后来发现屏幕大小变化以后，会出现滚动条，不能自适应，之前用过flex:1，没有仔细研究这个属性，今天特意
研究一下：
flex: param1 param2 param3 ,主要是：控制 Flex 子元素在主轴上的比例，这个写法其实是：
flex-grow: 这个 flex 子元素得到（伸张）多少 positive free space? //解决除去自身的宽度，如果还有剩余空间，如何分配的问题
flex-shrink: 从这个 flex 子元素要消除（收缩）多少 negative free space? // 解决父级空间小于子元素的宽度时候，子元素如何收缩的问题，一般直接设为1，表示支持缩放
flex-basis: 在 flex 子元素未伸张和收缩之前，它的大小是多少？ // 子元素默认大小
的缩写。
比如我这里有三个元素：
A B C
16---A----20----B----50-----C-----60
那么可以分别加样式(加入 A B C的宽度分别为：10 20 30 )：
A:
flex: 20 1 10px
margin-left:16px
B:
flex: 50 1 20px
C:
flex: 60 1 20px
即可实现自适应`}]},{path:"/content/front/html/html%E4%B9%8Bdom%E4%BA%8B%E4%BB%B6.html",title:"html之dom事件",pathLocale:"/",contents:[{header:"",slug:"",content:`dom操作的几个事件 事件冒泡
从实际操作的元素（事件）向上级父元素一级一级执行下去，直到达到document 在JavaScript中，并非所有的事件都可以冒泡，像：blur、unload、load等事件就不能冒泡
有些时候父元素和子元素都定义了click事件，但是不希望点击子元素的时候执行父元素的click事件（例如dialog弹窗的遮罩层如果是父元素，而dialog弹窗内容层是子元素，同时可以通过点击遮罩层来关闭弹窗，但是点击内容层不关闭弹窗），可以通过stopPropagation()在子元素上阻止冒泡。vue使用.stop 事件捕获（不常用）
当鼠标点击或者触发dom事件时（被触发dom事件的这个元素被叫作事件源），浏览器会从根节点 =>事件源（由外到内）进行事件传播。 事件委托
又称事件代理：将原本作用在子元素的事件写在父元素，而子元素通过事件冒泡的原理，会触发绑定在父元素上的事件，这就是事件委托。 作用：
可以节省内存，不需要给所有子元素绑定事件
新增的子元素依旧会拥有事件`}]},{path:"/content/front/html/html%E9%A1%B5%E9%9D%A2%E6%BB%9A%E5%8A%A8%E9%A1%B6%E9%83%A8%E5%AF%BC%E8%88%AA%E6%A0%8F%E5%9B%BA%E5%AE%9A%E4%B8%8E%E9%9A%90%E8%97%8F.html",title:"html页面滚动顶部导航栏固定与隐藏",pathLocale:"/",contents:[{header:"",slug:"",content:`下面的案例实现的是一个非常常见的需求:
顶部导航栏默认隐藏， 在内容向下滚动一定距离，比如200px 以后，导航栏展示出来
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <title>Scrolling Navbar Example</title> <style type="text/css"> body { margin: 0; padding: 0; } .navbar { background-color: #333; color: white; position: fixed; top: 0; left: 0; width: 100%; transition: top 0.3s; display: none;/* 初始状态隐藏 */ } .content { padding: 20px; } ul{ display: flex; justify-content: center; align-items: center; } ul>li{ display: inline-block; } </style>
</head>
<body> <header class="navbar" id="navbar"> <nav> <!-- 导航链接 --> <ul> <li>测试1</li> <li>测试2</li> <li>测试3</li> <li>测试4</li> <li>测试5</li> </ul> </nav> </header> <div class="content"> <!-- 页面内容 --> 鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。
鹅掌风是手癣的俗称，是指由皮肤癣菌引起的手部皮肤浅表真菌感染。手癣经过积极治疗可治愈，但患者需坚持用药，若不规范用药，疾病容易反复发作。 1、外用药物治疗：患者应根据不同临床类型选择不同的处理方法，如水疱型手癣存在手掌水疱等，应遵医嘱选择刺激性小的霜剂或水剂，例如复方酮康唑乳膏、硝酸益康唑溶液等。 浸渍糜烂型手癣患者存在指间皮肤发白、糜烂、浸渍，医生可给予3%硼酸溶液、0.1%依沙吖啶等湿敷，待渗出减少时再给予氧化锌粉、咪康唑粉等，皮损干燥后再外用霜剂、软膏，不宜选用刺激性大、剥脱性强的药物。 鳞屑角化型手癣患者以脱屑为主，有少数癣疱，可在医生指导下应用剥脱作用较强的制剂，例如复方苯甲酸软膏等，必要时可采用封包疗法。 2、系统药物治疗：外用药物治疗疗效不佳、反复发作、受累面积大、不愿意接受外用药物，或伴有某些系统性疾病，例如糖尿病、艾滋病等，导致免疫功能低下的患者，可遵照医嘱服用盐酸特比萘芬分散片、伊曲康唑分散片等药物进行治疗。 手癣容易复发，因此患者应遵医嘱正确足疗程用药，同时应注意个人卫生、积极治疗其他部位的癣病，切断传染源头，防止再次感染。 </div> <script> const navbar = document.getElementById('navbar'); let prevScrollPos = window.pageYOffset; console.log('prevScrollPos init is:', prevScrollPos); window.onscroll = function() { const currentScrollPos = window.pageYOffset; console.log('currentScrollPos is:', currentScrollPos); if (prevScrollPos > currentScrollPos) { // 向上滚动 console.log('1111111'); navbar.style.display = "none"; //再次隐藏 } else { // 向下滚动 if (currentScrollPos > 200) { // 当滚动距离达到200px时 navbar.style.display = 'block'; } else { navbar.style.display = 'none' // 继续隐藏 } } prevScrollPos = currentScrollPos; console.log('prevScrollPos current is:', prevScrollPos);
}; <\/script>
</body>
</html>`}]},{path:"/content/front/html/img%E6%A0%87%E7%AD%BE%E5%8F%AA%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%E4%B8%AD%E9%97%B4%E5%8C%BA%E5%9F%9F.html",title:"img标签只显示图片中间区域",pathLocale:"/",contents:[{header:"",slug:"",content:`img标签只显示图片中间区域:
通过设置object-fit属性实现(适用于可替换元素，像img video iframe这些)
cover:图片填充满父节点，超出部分隐藏，仅显示中间。
contain:图片根据父节点宽高等比例缩放。
①背景图
<!-- 背景图实现图片居中 -->
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <title>背景图的做法</title> <style> .images{ background-image: url("背景图的链接"); background-repeat: no-repeat; background-position:center center; background-size: cover; width: 80px; height: 80px; } </style>
</head>
<body> <h3>背景图的做法</h3> <img class="images" />
</body>
</html> ②img标签
<!-- img标签src实现图片居中 -->
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <title>img标签src的做法</title> <style> .images{ width: 80px; height: 80px; object-fit: cover; } </style>
</head>
<body> <h3>img标签src的做法</h3> <img class="images" />
</body>
</html>`}]},{path:"/content/front/html/img%E6%A0%87%E7%AD%BE%E5%B1%85%E4%B8%AD%E4%B9%8Btext-align.html",title:"img标签居中之text-align",pathLocale:"/",contents:[{header:"",slug:"",content:`img标签居中之text-align:
\`\`\`text\`
重要的一点，需要将img的样式设置:display: inline-block;或者 display: inline;不能设置为display: block;
text-align只对文字，行内元素（inline），行内块元素（inline-block）起作用，对块元素（block）不起作用。
官方文档:https://developer.mozilla.org/en-US/docs/Web/CSS/text-align
The text-align CSS property sets the horizontal alignment of the inline-level content inside a block element or table-cell box. This means it works like vertical-align but in the horizontal direction.
补充:关于img标签 是一个可替换元素。它的 display 属性的默认值是 inline，但是它的默认分辨率是由被嵌入的图片的原始宽高来确定的，使得它就像 inline-block 一样。你可以为 设置 border/border-radius、padding/margin、width、height 等 CSS 属性。
补充:vertical-align
https://www.cnblogs.com/fsg6/p/12711341.html // 这个里面有代码代码可实现 图+文字垂直居中(图片底部空白，可以通过设置父级的font-size：0;解决:https://www.cnblogs.com/goloving/p/8526095.html): 图片文字居中的案例:
\`\`\`html
<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <title>Document</title> <style> .a{ width: 600px; height: 600px; background-color: #bfa; <-----这里可以设置line-height:600px;使整个页面的内容垂直居中 -----> } img{ vertical-align: middle;//是图片设置vertical-align属性，而不是文字 width: 20%; height: 20%; } </style>
</head>
<body> <div class="a"> <img src="https://image.helixlife.cn/edu-cn/package/202003/qyuJO6dp2L9gWZwXwVaV1G4698Y73Ua1ptnm3bi4.png" alt=""> <span>nioifhiughi</span> </div>
</body>
</html> 在线运行css+html平台: https://developer.mozilla.org/en-US/play`}]},{path:"/content/front/html/input%E8%BE%93%E5%85%A5%E6%A1%86%E5%8E%BB%E9%99%A4%E8%AE%B0%E5%BF%86%E5%8A%9F%E8%83%BD.html",title:"input输入框去除记忆功能",pathLocale:"/",contents:[{header:"",slug:"",content:`浏览器input输入框含有记忆功能，当用户在input输入框开始输入时，浏览器会显示出之前输入的选项。
当然很多时候我们会不想显示历史记录，首先是样式太丑，其次是避免隐私泄露。那么怎么清除呢？
autocomplete 属性
autocomplete 属性规定输入字段是否应该启用自动完成功能。 属性值
值	描述
on	默认。规定启用自动完成功能。
off	规定禁用自动完成功能。 autocomplete 属性适用于 <form>，以及下面的 <input> 类型：
text, search, url, telephone, email, password, datepickers, range 以及 color <!-- 在form中使用 此方法将取消form表单中所有input的记忆功能-->
<form method="post" action="submit.asp" autocomplete="off"></form > <input autocomplete="off"/>`}]},{path:"/content/front/html/package%E4%B9%8Bjson%E6%96%87%E4%BB%B6%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AE.html",title:"package之json文件安全配置",pathLocale:"/",contents:[{header:"",slug:"",content:`package之json文件安全配置:
"private": true,
"engines": { "node": ">=20", "pnpm": ">=9.9.0", "npm": ">=10"
}, 分析:
在 package.json 中，以下字段有各自的含义： "private": true: 这表示该项目是私有的，不能被发布到公共的 npm 注册表（如 npmjs.com）。当 "private": true 被设置时，尝试使用 npm publish 发布这个项目会失败。
这通常用于确保内部项目或应用程序不会意外发布到公共的包管理系统中。 "engines": "engines" 字段用来指定项目对 Node.js 版本以及其他包管理工具（如 pnpm 或 npm）的要求。
"node": ">=20"：表示这个项目需要 Node.js 版本 20 或更高。这确保了在 Node.js 版本过低时会抛出警告或错误，以防项目在不支持的环境中运行。
"pnpm": ">=9.9.0"：表示项目需要 pnpm 包管理工具的版本 9.9.0 或更高。pnpm 是一个替代 npm 和 yarn 的包管理工具，特别注重性能和磁盘空间的使用。
"npm": ">=10"：表示项目需要 npm 版本 10 或更高。即便项目主要使用 pnpm 作为包管理工具，依旧可以使用 npm，而此处规定了 npm 的最低版本要求。 这些字段的设置有助于在项目的不同环境中保证一致性和稳定性。`}]},{path:"/content/front/html/position-fixed%E7%9A%84%E5%A6%99%E7%94%A8.html",title:"position-fixed的妙用",pathLocale:"/",contents:[{header:"",slug:"",content:`position-fixed的妙用:
<div class="wrap-container" style=" position: fixed; height: calc(100vh - 100px); width: 100%; max-width: 1410px;
"> <div class="course-container" style="position: absolute;right: 0;top: 5.9375rem; z-index: 5;"> <CourseLesson ref="courseLesson"></CourseLesson> </div> </div> 很重要的结论:
虽然position:fixed是对于浏览器窗口定位的，但是只要不设置fixed元素的top，bottom，left，right，
此时该元素就是相对于父元素进行定位的。如果要移动元素的位置，可以通过margin/padding来实现(就像一个
处理一个普通的div元素一样，之前一直以为position:fixed之后只能相对窗口调整位置，其实不是的)。`}]},{path:"/content/front/html/rem%E5%92%8Cem%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"rem和em的区别",pathLocale:"/",contents:[{header:"rem和em的区别",slug:"rem和em的区别",content:`rem 和 em 都是 CSS 中的相对单位，但它们的参考点不同：
rem（Root EM）
参考 根元素 <html> 的 font-size。
1rem = html { font-size } 的值，默认是 16px（如果没有修改）。
适用于全局统一的缩放，比如排版时确保不同组件的大小一致。 例子:
html { font-size: 16px;
} p { font-size: 2rem; /* 2 × 16px = 32px */
} em（Element EM）
参考 当前元素的 font-size。
适用于相对于父元素的字体大小、边距、内边距等，适合局部调整。
em 会 继承 父元素的 font-size，可能导致 嵌套放大（累积效应）。 例子:
div { font-size: 16px;
} p { font-size: 1.5em; /* 1.5 × 16px = 24px */
} strong { font-size: 1.2em; /* 1.2 × p 的 24px = 28.8px, 可能会越来越大 */
}`}]},{path:"/content/front/html/scss%E4%B9%8B%E5%93%8D%E5%BA%94%E5%BC%8F%E5%AA%92%E4%BD%93%E6%9F%A5%E8%AF%A2.html",title:"scss之自适应媒体查询",pathLocale:"/",contents:[{header:"",slug:"",content:`scss之自适应媒体查询:
//feature.scss
div { text-align: right; margin: 0 0 10px 0; @include bp-small { padding-left: 20px; padding-right: 20px; } @include bp-medium { padding-left: 50px; padding-right: 50px; } @include bp-large { padding-left: 50px; padding-right: 50px; }
} //common.scss:
@mixin bp-small { @media only screen and (max-width: 40em) { @content; }
} @mixin bp-medium { @media only screen and (min-width: 40.063em) { @content; }
} @mixin bp-large { @media only screen and (min-width: 60em) { @content; }
} //上面两个scss文件在同级目录下 代码分析:
这段样式和 SCSS 代码使用了响应式设计的思想，根据不同屏幕宽度应用不同的样式。这里使用了 mixin 来定义媒体查询，然后在 div 元素的样式中调用这些 mixin。下面是对代码的分析： div { ... }: 这是一个选择器，应用于所有 div 元素。 text-align: right;: 设置文本在 div 中右对齐。 margin: 0 0 10px 0;: 设置 div 的上、右、下、左边距为0、0、10px、0。 嵌套了三个媒体查询 mixin，分别是 bp-small、bp-medium、bp-large。 @include bp-small { ... }: 当屏幕宽度小于等于40em时，应用以下样式。 padding-left: 20px;: 在小屏幕上设置左内边距为20px。
padding-right: 20px;: 在小屏幕上设置右内边距为20px。
@include bp-medium { ... }: 当屏幕宽度大于40.063em时，应用以下样式。 padding-left: 50px;: 在中等屏幕上设置左内边距为50px。
padding-right: 50px;: 在中等屏幕上设置右内边距为50px。
@include bp-large { ... }: 当屏幕宽度大于60em时，应用以下样式。 padding-left: 50px;: 在大屏幕上设置左内边距为50px。
padding-right: 50px;: 在大屏幕上设置右内边距为50px。
这样的设计使得在不同屏幕尺寸上都能有合适的内边距，提升页面在不同设备上的可读性和用户体验。 mixin 中定义的媒体查询允许在多个地方重用相同的屏幕宽度条件，提高了代码的可维护性。`}]},{path:"/content/front/html/tailwindcss%E4%B9%8Barbitrary-variants%E4%BD%BF%E7%94%A8.html",title:"tailwindcss之arbitrary-variants使用",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之arbitrary-variants(任意变体)使用:
class="[&_.m-modal\\_\\_panel]:!overflow-visible" 分析:
&_ 中的下划线并不是必须的，只有在修改子元素的时候才需要加，如果本来修改的就是父元素，那么直接 & 就可以了. 原理是:
https://tailwindcss.com/docs/hover-focus-and-other-states#using-arbitrary-variants`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E4%BD%BF%E7%94%A8%E4%BC%AA%E5%85%83%E7%B4%A0%E6%B7%BB%E5%8A%A0%E5%86%85%E5%AE%B9%E7%9A%84%E5%9D%91.html",title:"tailwindcss之使用伪元素添加内容的坑",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之使用伪元素添加内容的坑:
:deep(.select-none) { @apply text-[0px]; &::before { @apply text-base @apply content-['No results match your search.']; } } 报: The content-["No class does not exist. If content-["No is a custom class, make sure it is defined within a @layer directive :deep(.select-none) { @apply text-[0px]; &::before { @apply text-base; @apply content-['No_results_match_your_search.']; } } 原因: Since whitespace denotes the end of a class in HTML, replace any spaces in an arbitrary value with an underscore. 原文: https://tailwindcss.com/docs/content#setting-a-pseudo-elements-content`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E5%B1%8F%E5%B9%95%E7%B1%BB%E7%9A%84%E5%9D%91.html",title:"tailwindcss之动态添加屏幕类的坑",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之动态添加屏幕类的坑:
1>本来想动态修改 lg 条件下，div的宽度, 如下，但是不生效
withDefaults( defineProps<{ isNotificationVisible?: boolean; content?: string; maxWidth?: string; }>(), { isNotificationVisible: false, content: "", maxWidth: "25rem", }
); <div class="w-full" :class="\`lg:max-w-[\${maxWidth}]\`" > 2>通过style可以加载这个动态宽度，但是没法使用 lg 条件
<div class="w-full" :style="{ maxWidth: maxWidth }" >
也可以直接这样:
<div class="w-full" :style="{ maxWidth }" > 3>解决 lg 问题
// 使用媒体查询，也不生效
<div class="w-full" :style="{ '@media (min-width: 1024px)': { maxWidth: maxWidth } }" > //下面的方法是可行的
定义:
@layer utilities { .lg-dynamic-max-w { @apply lg:max-w-[var(--max-width)]; }
} 使用:
<div class="w-full lg-dynamic-max-w" :style="{ '--max-width': maxWidth }" >
原理:
①
@layer utilities 告诉 Tailwind 这是一个自定义工具类。
@apply 指令允许您在自定义类中使用 Tailwind 的原子类。
lg:max-w-[var(--max-width)] 是一个响应式类，它在大屏幕（lg）断点上应用最大宽度。
var(--max-width) 是一个 CSS 变量，它的值可以动态设置。 ②
class="w-full lg-dynamic-max-w" 应用了我们自定义的响应式类。
:style="{ '--max-width': maxWidth }" 动态设置 CSS 变量的值。 ③
当屏幕宽度达到 lg 断点时，Tailwind 的响应式系统激活 lg: 前缀的样式。
此时，max-w-[var(--max-width)] 开始生效。
var(--max-width) 的值是通过 Vue 的 :style 绑定动态设置的。
结果是，在大屏幕上，元素获得了一个动态的最大宽度。 ④
它利用了 Tailwind 的 JIT（即时编译）模式，允许使用任意值。
它结合了 Tailwind 的响应式设计和 CSS 变量的动态性。
通过 @apply，我们创建了一个可重用的类，它既包含 Tailwind 的功能，又允许动态值。 ⑤
保持了 Tailwind 的响应式特性。
允许动态设置最大宽度。
将响应式逻辑保留在 CSS 中，而不是 JavaScript。
可以在多个组件中重用自定义类。 总结: 这种方法之所以有效，是因为它巧妙地在 Tailwind 的静态类系统和 CSS 变量的动态特性之间架起了一座桥梁。它允许您在保持 Tailwind 工作流程的同时，引入动态值的灵活性。`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E5%A4%9A%E6%A0%B7%E5%BC%8F%E8%BF%9E%E7%94%A8.html",title:"tailwindcss之多样式连用",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之多样式连用:
class="hover:drop-shadow-md hover:z-10"
上面的两个样式都是在 hover 的时候才会生效`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E5%AE%9A%E4%B9%89%E6%96%87%E6%9C%AC%E9%A2%9C%E8%89%B2.html",title:"tailwindcss之定义文本颜色",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之定义文本颜色:
text-blue-600/75
在Tailwind CSS中，text-blue-600/50这个class的含义如下： text-blue-600: 设置文本颜色为蓝色，色值为600（在Tailwind的蓝色色阶中是一个中等深度的蓝色）
/50: 设置这个颜色的不透明度为50% (相当于设置了rgba的第四个参数) 这个色值需要在tailwind.config.js下定义,比如:
module.exports = { theme: { extend: { colors: { blue: { 50: '#eff6ff', 100: '#dbeafe', 200: '#bfdbfe', 300: '#93c5fd', 400: '#60a5fa', 500: '#3b82f6', 600: '#2563eb', 700: '#1d4ed8', 800: '#1e40af', 900: '#1e3a8a', } } } }
} 所以，text-blue-600/50会将文本设置为一个中等深度的蓝色，但是只有50%的不透明`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E6%A0%B7%E5%BC%8F%E8%87%AA%E5%AE%9A%E4%B9%89.html",title:"tailwindcss之样式自定义",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之样式自定义:
@tailwind base;
@tailwind components;
@tailwind utilities; 主要两种方法:
①在css下定义 ②在plugins下定义(tailwind.config.js里) 以上三层的使用场景详细文档:
https://tailwindcss.com/docs/adding-custom-styles#using-css-and-layer
https://tailwindcss.com/docs/functions-and-directives 补充一个，关于tailwindcss的事件触发效果: https://tailwindcss.com/docs/hover-focus-and-other-states`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E9%A2%9C%E8%89%B2%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8AOpacity%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"tailwindcss之颜色定义以及Opacity的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之颜色定义以及Opacity的使用:
自定义颜色
:root{ --color-white: 255, 255, 255;
} 使用颜色变量:
const withOpacity = (variableName) => \`rgba(var(\${variableName}), <alpha-value>)\`; white: withOpacity("--color-white"), 说明： the special <alpha-value> placeholder that Tailwind will use to inject the alpha value when using an opacity modifier，实际上就是看这个 white 用在哪里，如果是bg的话，那么 alpha-value 的值就是 bg-opacity-100 (默认是100,也就是1)， 如果是text的话，就是 text-opacity-100，这些在 v2 版本下看的比较清楚. v3 下，默认没有展示这些属性，但是就是这么用的. 参考: https://tailwindcss.com/docs/customizing-colors#using-css-variables`}]},{path:"/content/front/html/tailwindcss%E4%B9%8B%E9%BB%98%E8%AE%A4font-weight%E7%9A%84%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E6%AF%8D%E5%85%B3%E7%B3%BB.html",title:"tailwindcss之默认font-weight的数字和字母关系",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之默认font-weight的数字和字母关系: class name
property font-thin
font-weight: 100 font-extralight
font-weight: 200 font-light
font-weight: 300 font-normal
font-weight: 400 font-medium
font-weight: 500 font-semibold
font-weight: 600 font-bold
font-weight: 700 font-extrabold
font-weight: 800 font-black
font-weight: 900 参考: https://tailwindcss.com/docs/font-weight
补充: 关于border-width， 为啥没有 border-height,因为 这个其实定义的是border的视觉宽度，从左往右看，就好理解了，虽然会有 border-top-width, 但是都是一样的效果
参考: https://tailwindcss.com/docs/border-width`}]},{path:"/content/front/html/tailwindcss%E4%BD%BF%E7%94%A8important%E8%A6%86%E7%9B%96.html",title:"tailwindcss使用important覆盖",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss使用important覆盖:
.alert { @apply bg-red-500 #{!important};
} 参考：https://tailwindcss.com/docs/using-with-preprocessors#sass`}]},{path:"/content/front/html/tailwindcss%E8%87%AA%E5%AE%9A%E4%B9%89css%E6%A0%B7%E5%BC%8F%E8%A6%86%E7%9B%96.html",title:"tailwindcss自定义css样式覆盖",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss自定义css样式覆盖:
有如下自定义样式:
addUtilities({ ".all-initial": { all: "initial" }, ".all-inherit": { all: "inherit" }, ".all-revert": { all: "revert" }, ".all-unset": { all: "unset" }, }); 这段代码定义了 4 个新的 CSS 工具类，每个类都对应 CSS all 属性的不同值。
all 属性可以同时作用于所有 CSS 规则（如 color、margin、padding、display 等），避免单独重置多个属性。 类名 等效 CSS 说明
.all-initial all: initial; 将所有继承和非继承属性重置为默认值（与浏览器的初始样式一致）。
.all-inherit all: inherit; 让所有属性继承父元素的样式（包括默认不会继承的属性，如 margin）。
.all-revert all: revert; 让样式回退到浏览器的用户代理样式表或父级的样式规则。
.all-unset ll: unset; 对 继承属性（如 color）应用 inherit，对 非继承属性（如 display）应用 initial。 什么是用户代理（UA）样式表？
用户代理（User Agent）样式表 就是浏览器默认提供的 CSS 规则，比如：
<h1> 默认是 加粗 且 比普通文本大。
<button> 默认有 边框、背景颜色 和 内边距。
<ul> 默认带有 列表项圆点（bullet points）。 👉 这些默认样式就是浏览器的 UA 样式表 提供的。 举例:
<ul> <li>默认样式</li>
</ul> <ul class="no-style"> <li>自定义无样式</li>
</ul> <ul class="no-style revert"> <li>恢复默认样式</li>
</ul> .no-style { list-style: none; padding: 0; margin: 0;
} .revert { all: revert;
} 结果:
默认样式 → 带 • 圆点
自定义无样式 → 没有 • 圆点
恢复默认样式 → 重新带回 • 圆点 什么时候用 revert？
撤销项目里写的 CSS，让元素回归浏览器默认的行为。
想要去掉框架样式（比如 Bootstrap、Tailwind 可能会覆盖默认样式）。
想保留继承关系，但又不想用 unset 影响非继承属性`}]},{path:"/content/front/html/vue3%E4%B8%8Bvideo%E6%A0%87%E7%AD%BE%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%94%A8%E6%B3%95.html",title:"vue3下video标签的两种用法",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下video标签的两种用法:
<div class="video-box"> <video class="video-player" controls="controls" ref="videoCon" :src="resourceUrl+'/'+video.playUrl">
<!-- <source :src="resourceUrl+'/'+video.playUrl" type="video/mp4">--> </video> </div> 我的问题是，后后台接口请求完成，source 下对的src 有数据，但是视频没有播放；改为直接 video 下src的方式，就可以播放了`}]},{path:"/content/front/html/vue3%E4%B9%8Bslot%E8%B0%83%E7%94%A8.html",title:"vue3之slot调用",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之slot调用:
v-slot 有对应的简写为#号，因此 <template v-slot:header> 可以简写为 <template #header>。其意思就是“将这部分模板片段传入子组件的 header 插槽中”。`}]},{path:"/content/front/html/vue3%E5%85%B3%E4%BA%8Echeckbox%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"vue3关于checkbox的使用",pathLocale:"/",contents:[{header:"",slug:"",content:"wait ...."}]},{path:"/content/front/html/vue3%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9class%E5%B0%8F%E6%8A%80%E5%B7%A7.html",title:"vue3动态修改class小技巧",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3动态修改class小技巧:
//有下面一段vue的代码，其中通过 class 动态赋值，但是这个 bgColor 并没有在 data 中定义，而是直接在 style 中定义的
//但是却可以使用，这个属性还是挺好的 <div class="mission-box"> <p class="title" :class="{bgColor: true}">Mission and Values</p>
</div> <style scoped>
.bgColor{ background-color: #01F0E0;
}
</style>`}]},{path:"/content/front/html/vue%E4%B8%ADasync%E5%92%8Cawait%E4%BD%BF%E7%94%A8%E5%AF%BC%E8%87%B4%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%E4%B8%8D%E4%B8%80%E6%A0%B7.html",title:"vue中async和await使用导致函数执行顺序不一样",pathLocale:"/",contents:[{header:"",slug:"",content:`async/await场景:
这是一个用同步的思维来解决异步问题的方案，当前端接口调用需要等到接口返回值以后渲染页面时。
async
async的用法，它作为一个关键字放到函数前面，用于表示函数是一个异步函数，因为async就是异步的意思， 异步函数也就意味着该函数的执行不会阻塞后面代码的执行，async 函数返回的是一个promise 对象，可以使用then方法添加回调函数。当函数执行的时候，一旦遇到await就会先返回，等到异步操作完成，再接着执行函数体内后面的语句。
await
await的含义为等待。意思就是代码需要等待await后面的函数运行完并且有了返回结果之后，才继续执行下面的代码。这正是同步的效果。
data() { return { topicList: [] }
},
created() { this.getTopicList() console.log(this.topicList)
},
methods: { async getTopicList() { let resp = await axios.get(\`/topic\`) if (resp.data.status === 1) { this.topicList = resp.data.data.data } }
} 可以看到打印出来的是空数组。因为这时候调用接口返回的数据还没有被赋值。 修改如下，添加await：
data() { return { topicList: [] }
},
async created() { await this.getTopicList() console.log(this.topicList)
},
methods: { async getTopicList() { let resp = await axios.get(\`/topic\`) if (resp.data.status === 1) { this.topicList = resp.data.data.data } }
} 刷新页面，可以看到打印出来的是已经被赋值的数组。 但是这种写法，不适合Nuxt3，在nuxt3下 是不能在created 前使用async的，会报错，提示nuxt实例不存在，但是可以在methods 方法前使用，比如： <template> <button @click="getTopicList">获取</button> </template> methods: { getTopicList() { await this.getData(); // 前面一定要加 await 否则下面的this.status 获取不到想要的数据 //等待 this.status 有结果再执行其它操作 if(this.status == 1){ } }, async getData(){ let resp = await axios.get(\`/topic\`) if (resp.data.code === 0) { this.status = resp.data.data.status } }
}`}]},{path:"/content/front/html/vue%E4%B9%8Bthis._nextTick%E8%AF%A6%E8%A7%A3.html",title:"vue之this.$nextTick详解",pathLocale:"/",contents:[{header:"",slug:"",content:`vue之this.$nextTick详解:
先看如下demo:
<template> <section> <h1 ref="testTick">{{ value }}</h1> <br/> <button @click="get">点击测试</button> </section>
</template> <script>
export default { name:'verify', data() { return { value: '更新前' }; }, methods: { get() { this.value = '更新后'; console.log(this.$refs.testTick.innerText); // 更新前 this.$nextTick(() => { console.log(this.$refs.testTick.innerText); // 更新后 }); } }
}
<\/script> 解析如下:
第一次 console.log 的时候，获取的到的是旧值，这是因为 value 数据发生变化的时候，Vue 没有立刻去更新 DOM ，而是将修改数据的操作放在了一个异步操作队列中，如果一直修改相同数据，异步操作队列还会进行去重，等待同一事件循环中的所有数据变化完成之后，会将队列中的事件拿来进行处理，进行 DOM 的更新 第二次的 console.log 是放到 this.$nextTick 回调函数中的，此时获取到的是新值，是因为 nextTick 的回调函数是在 DOM 更新之后触发的 vue异步更新原理:
vue 里面用到了观察者模式，默认组件渲染的时候，会创建一个 watcher，并且渲染视图
当渲染视图的时候，会取 data 中的数据，触发属性的 get 方法，就让这个属性的 dep 记录watcher（注意：每一个data属性都对应一个dep）
同时让 watcher 也记住 dep ，dep 和 watcher 是多对多的关系，因为一个属性可能对应多个视图，一个视图对应多个数据
如果数据发生变化，也就是在 set 的时候，会触发 dep.notify() ，通知 dep 中存放的 watcher 去更新
每次更新数据都会同步调用 watcher 中 update 方法，此时就可以将更新的逻辑缓存起来，等会同步更新数据的逻辑执行完毕后，依次调用 (去重的逻辑)`}]},{path:"/content/front/html/vue%E5%AE%9E%E7%8E%B0%E7%80%91%E5%B8%83%E6%B5%81%E5%B8%83%E5%B1%80.html",title:"vue实现瀑布流布局",pathLocale:"/",contents:[{header:"",slug:"",content:`vue实现瀑布流布局:
可以使用 yeger/vue-masonry-wall 包实现, 其中比较重要的一点，往列表添加数据的时候要用:this.items = [...this.items, item]
不要用push，这样不会有效果。参考这个issue：https://github.com/DerYeger/yeger/issues/15`}]},{path:"/content/front/html/%E4%BF%AE%E6%94%B9%E6%BB%9A%E5%8A%A8%E6%9D%A1%E6%A0%B7%E5%BC%8F.html",title:"修改滚动条样式",pathLocale:"/",contents:[{header:"",slug:"",content:"修改滚动条样式: .topic-list-wrapper { padding: 0 1.875rem 0 1.25rem; margin-bottom: 6.25rem; border: 0.0625rem solid #000; max-height: 40.75rem; overflow-y: auto; &::-webkit-scrollbar{ width:.25rem; height:6.25rem; } &::-webkit-scrollbar-track{ background: rgb(239, 239, 239); border-radius:.125rem; } &::-webkit-scrollbar-thumb{ background: #000; border-radius:.625rem; //设置圆角更好看 } //还可以设置 hover 属性 }"}]},{path:"/content/front/html/%E5%85%B3%E4%BA%8Ecss%E8%A3%81%E5%89%AA%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"关于css裁剪的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`关于css裁剪的使用:
1>clip-path 介绍
clip-path 是一种 CSS 属性，用于定义一个裁剪区域，只显示该区域内的内容，其余部分被裁剪掉，不会显示。 作用原理：
它为元素定义了一个裁剪区域（例如矩形、圆形、多边形等）。
只有在这个裁剪区域内部的内容会被渲染。
剩余的部分被隐藏，但仍然存在于 DOM 中。 语法:
clip-path: shape; 2>举例子
<div class="example"></div> .example { width: 200px; height: 100px; background: linear-gradient(90deg, red, blue); clip-path: polygon(20% 43%, 80% 43%, 80% 57%, 20% 57%); transition: clip-path 0.3s ease;
} 原理解析：
polygon() 定义了一个多边形，顶点的顺序是关键，按顺时针或逆时针连接点定义形状。
坐标值的格式是 x y，分别表示水平（x）和垂直（y）的偏移。
每个坐标点之间用逗号分隔，20% 43% 表示从元素左上角出发，水平偏移 20%，垂直偏移 43%。
这个多边形的定义细节：
第一点 (20% 43%): 多边形从左侧 20%，高度 43% 的点开始。
第二点 (80% 43%): 延伸到右侧 80%，高度仍为 43%。
第三点 (80% 57%): 向下延伸到高度 57%。
第四点 (20% 57%): 左移回到左侧 20%，高度仍为 57%。
这四个点连接起来，就形成了一个宽为 60%（80%-20%），高为 14%（57%-43%）的水平矩形。 裁剪后的视觉效果:
元素只显示 clip-path 定义的矩形区域内的部分。
矩形外部的内容会被裁剪掉，像是被一个“模板”遮住。 裁剪后的元素大小:
即使元素被 clip-path 裁剪，它的实际布局区域（包括宽度和高度）仍然保留不变。元素的布局大小由 CSS 的 width 和 height（或其内容）决定，与裁剪后的形状无关。裁剪仅改变渲染效果，不会改变元素在文档流中的尺寸或占位。 3>使用这个创建svg图片
<svg width="200" height="100"> <defs> <clipPath id="clip"> <polygon points="100,0 200,50 100,100 0,50" /> </clipPath> </defs> <rect width="200" height="100" fill="red" clip-path="url(#clip)" /> </svg> 这里：
<rect> 标签：
定义了一个宽为 200px、高为 100px 的矩形。
fill="red" 指定矩形的填充颜色为红色。 这个其实是定义了裁剪的外部区域，而不是以svg的width 和 height定义的，也可以设置 <rect width="100" height="50" fill="red" clip-path="url(#clip)" />，就会发现另一种效果. 但是一般会和svg设置相同的width和height。`}]},{path:"/content/front/html/%E5%85%B3%E4%BA%8Ecss%E9%9A%90%E8%97%8F%E9%BB%98%E8%AE%A4%E5%B1%9E%E6%80%A7.html",title:"关于css隐藏默认属性",pathLocale:"/",contents:[{header:"",slug:"",content:`关于css隐藏默认属性:
通过 appearance: none; 实现 appearance: none 的作用 移除默认样式:
通过 -webkit-appearance, -moz-appearance, 和标准的 appearance 属性，可以移除 HTML 元素的默认样式。
对于 checkbox 和 radio 这样的表单控件，移除后它们将失去默认的外观（例如复选框的方框和勾选符号）。 保持元素的功能性:
使用 appearance: none 后，元素仍然是可见的，并且能够响应用户的交互（点击、焦点等），无需额外的 JS 脚本。 支持伪元素定制:
移除默认样式后，可以通过伪元素（::before 和 ::after）自由定义外观，例如形状、颜色和动画。`}]},{path:"/content/front/html/%E5%85%B8%E5%9E%8B%E7%9A%84tailwindcss%E8%AE%A9%E5%86%85%E5%AE%B9%E5%B1%85%E4%B8%AD%E7%9A%84%E5%86%99%E6%B3%95.html",title:"典型的tailwindcss让内容居中的写法",pathLocale:"/",contents:[{header:"",slug:"",content:`典型的tailwindcss让内容居中的写法:
<div class="relative"> <div v-if="isLoading" class="absolute inset-0 z-10 flex bg-black bg-opacity-50" > <div class="m-auto"> some content... </div> </div>
</div> //分析，这里 使用了 m-auto, 就不用再使用align-self: center了`}]},{path:"/content/front/html/%E8%87%AA%E5%AE%9A%E4%B9%89tinymce%E5%AF%8C%E6%96%87%E6%9C%AC%E7%9A%84%E6%BB%9A%E5%8A%A8%E6%9D%A1%E6%A0%B7%E5%BC%8F.html",title:"自定义tinymce富文本的滚动条样式",pathLocale:"/",contents:[{header:"",slug:"",content:`自定义tinymce富文本的滚动条样式:
https://juejin.cn/post/7244407068097265701
http://tinymce.ax-z.cn/configure/content-appearance.php //中文文档`}]},{path:"/content/front/html/%E8%8E%B7%E5%8F%96window%E7%9A%84%E5%AE%BD%E5%BA%A6%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95.html",title:"获取window的宽度的两种方法",pathLocale:"/",contents:[{header:"",slug:"",content:`获取window的宽度的两种方法:
正常情况下两个的值是一样的，但是在做h5屏幕和pc屏幕切换的时候，innerWidth会和实际相等，而screenWidth会小于屏幕大小
let screenWidth = doc.documentElement.clientWidth const { innerWidth, innerHeight } = window 我这里在width 为768的时候做了屏幕切换，实际处处结果如下:
ex:
screenWidth: 750 innerWidth: 765 适配时的大小指的是分辨率点数 分辨率点数和分辨率像素，浏览器调试的时候看的是分辨率点数`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8BShouldBindJSON%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AFEOF.html",title:"gin框架下ShouldBindJSON返回错误EOF",pathLocale:"/",contents:[{header:"",slug:"",content:`这里做个记录吧，由于需要对前端参数进行验证，用到了 ShouldBindJSON ,比如我这里的注册接口：
func (r *RegisterParam) VerifyJson(c *gin.Context) string { if err := c.ShouldBindJSON(r); err != nil { return validator2.FirstMessage(err) } return ""
} 发现 err 一直返回 EOF，后来想起来，如果用到了 ShouldBindJSON，那么前端数据必须是json格式，而我这里是通过 form-data传递的，所以会报这个问题`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E5%90%8C%E6%97%B6%E8%BF%94%E5%9B%9E%E6%80%BB%E6%95%B0.html",title:"gin框架下分页查询同时返回总数",pathLocale:"/",contents:[{header:"",slug:"",content:`我感觉这个操作很nice，直接分页同时返回总数：
common.Db.Preload("Attributes").Where("kind = ? and name like ?", res.Kind.Kind, "%"+keywords+"%").Scopes(common.Paginate(page, 10)).Find(&Products).Offset(-1).Limit(-1).Count(&count) //重点是这个 Offset(-1).Limit(-1).Count(&count) 操作`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%A4%9A%E8%A1%A8%E5%85%B3%E8%81%94%E6%93%8D%E4%BD%9C%E4%B9%8BPreload.html",title:"gin框架下多表关联操作之Preload",pathLocale:"/",contents:[{header:"",slug:"",content:'数据库结构如下:\ntype Product struct { ID uint `gorm:"primarykey"` Name string `gorm:"type:varchar(15);default:NULL;comment:名称"` CoverImage string `gorm:"type:varchar(255);default:NULL;comment:封面图"` Description string `gorm:"type:varchar(255);default:NULL;comment:描述"` Detail string `gorm:"type:text;default:NULL;comment:详情"` Price string `gorm:"type:decimal(10, 2);default:NULL;comment:价格"` Sales uint `gorm:"type:bigint;default:NULL;comment:销量"` Remark uint `gorm:"type:bigint;default:NULL;comment:评价"` Kind string `gorm:"type:varchar(255);default:NULL;comment:品类"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:更新时间"` //一对一，注意：references 为主表的外键，foreignKey：为附表的主键，可以大写为struct 字段名，也可以直接小写为数据库对应字段 //Category Kind `gorm:"foreignKey:ID;references:KindId;"` //一对多，注意：references 为主表的主键，foreignKey：为附表的外键 //Attributes []ProductAttribute `gorm:"foreignKey:ProductId;references:ID"` Attributes []ProductAttribute `gorm:"foreignKey:product_id;references:id"`\n} type Kind struct { ID uint `gorm:"primarykey"` Name string `gorm:"type:varchar(15);default:NULL;comment:名称"`\n} type ProductAttribute struct { ID uint `gorm:"primarykey;column:id;"` ProductId string `gorm:"type:int;default:NULL;comment:产品ID"` Attribute string `gorm:"type:varchar(255);default:NULL;comment:属性"` AttributeValue string `gorm:"type:varchar(255);default:NULL;comment:属性值"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:更新时间"`\n} ①一对一\n//common.Db.Model(&model.InnerProduct{}).Preload("Category").Find(&products)\n//common.Db.Model(&model.InnerProduct{}).Joins("Category").Find(&products) 这里Preload和Joins 都可以实现关联查询\n②一对多\ncommon.Db.Preload("Attributes").Where("kind = ? and name like ?", res.Kind.Kind, "%"+keywords+"%").Find(&products)\n这里只能用Preload 关联，因为 Attributes 是一个slice'}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%AE%9E%E7%8E%B0whereHas%E5%8A%9F%E8%83%BD.html",title:"gin框架下实现whereHas功能",pathLocale:"/",contents:[{header:"",slug:"",content:'gorm里没有这个函数，但是本质上也就是一个 exist 查询操作:\n核心代码如下：\ncommon.Db.Model(&model.Product{}).Where("EXISTS(SELECT * FROM product_attributes WHERE `product_attributes`.`product_id` = `products`.`id` AND `product_attributes`.`attribute_value` like ?)", attribute)'}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%AF%B9%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E8%BF%9B%E8%A1%8C%E5%B0%81%E8%A3%85.html",title:"gin框架下对分页查询进行封装",pathLocale:"/",contents:[{header:"",slug:"",content:`gin框架下对分页查询进行封装：
func Paginate(page int,pageSize int) func(db *gorm.DB) *gorm.DB { return func (db *gorm.DB) *gorm.DB { if page == 0 { page = 1 } switch { case pageSize > 100: pageSize = 100 case pageSize <= 0: pageSize = 10 } offset := (page - 1) * pageSize return db.Offset(offset).Limit(pageSize) }
} 使用：
在gorm查询里，通过Scopes闭包查询
common.Db.Scopes(common.Paginate(page,10)).Find(&)`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%B0%86%E5%BE%AE%E4%BF%A1%E9%A2%84%E6%94%AF%E4%BB%98%E9%93%BE%E6%8E%A5%E8%BD%ACbase64%E5%9B%BE%E7%89%87%E6%B5%81.html",title:"gin框架下将微信预支付链接转base64图片流",pathLocale:"/",contents:[{header:"",slug:"",content:`gin框架下将微信预支付链接转base64图片流：
1.安装需要的拓展包
go get github.com/skip2/go-qrcode
2.具体实现代码
func ReturnValue(c *gin.Context) { qrCode, err := qrcode.Encode("weixin://wxpay/bizpayurl?pr=6094umbzz", qrcode.Medium, 256) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{"resp": err}) } base64Data := base64.StdEncoding.EncodeToString(qrCode) c.JSON(http.StatusOK,gin.H{ "code":http.StatusOK, "message":"成功", "data":"data:image/png;base64,"+base64Data, })
} 小技巧：
1.如果不想返回json数据可以直接调用 c.Data 返回指定格式的数据 c.JSON(http.StatusOK,gin.H{ "code":http.StatusOK, "message":"成功", "data":"data:image/png;base64,"+base64Data, }) c.Data(200,"Content-Type/image/png",qrCode)// qrCode为[]byte 类型, 直接输出图片到客户端 2.通过 fmt.Fprint 返回指定格式的数据，这个在支付宝支付的时候会用到 const ( AckSuccess = \`<xml><return_code><![CDATA[SUCCESS]]></return_code></xml>\` AckFail = \`<xml><return_code><![CDATA[FAIL]]></return_code></xml>\`
) fmt.Fprint(c.Writer, AckSuccess)//直接调用这个就会返回数据给客户端，因为writer会写数据`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E8%AE%BE%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E7%BA%A7%E5%88%AB.html",title:"gin框架下设置mysql数据日志打印级别",pathLocale:"/",contents:[{header:"",slug:"",content:`gin框架下设置mysql数据日志打印级别：
func init() { dsn := viper.GetString("mysql.db_user_name") + ":" + viper.GetString("mysql.db_password") + "@tcp(" + viper.GetString("mysql.db_host") + ":" + viper.GetString("mysql.db_port") + ")/" + viper.GetString("mysql.db_database") + "?charset=utf8mb4&parseTime=true&loc=Local" db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{ NamingStrategy: schema.NamingStrategy{ TablePrefix: viper.GetString("mysql.db_prefix"), }, Logger: logger.Default.LogMode(logger.Info),//这里设置mysql的sql语句打印级别 }) if err == nil && db != nil { Db = db } else { Log.Println("mysql 连接错误") }
}`}]},{path:"/content/go/gin/gin%E6%A1%86%E6%9E%B6%E4%B8%8B%E9%80%9A%E8%BF%87Scopes%E5%AE%9E%E7%8E%B0%E9%97%AD%E5%8C%85%E6%9F%A5%E8%AF%A2%E5%8A%9F%E8%83%BD.html",title:"gin框架下通过Scopes实现闭包查询功能",pathLocale:"/",contents:[{header:"",slug:"",content:`①多个查询共用一个 tx *DB，查询句柄
比如 公共部分如下：
db := common.Db.Model(&model.Product{}).Select("id, kind, count(*) as total") 后面可以根据 不同条件进行操作:
db.Where(...) ②通过Scopes实现闭包查询功能 下面这个操作主要实现的是，where and or 功能，可以直接在where里面通过()将两个条件括起来，就像原生sql查询一样，其实这也是gorm的一个优势，直接可以在orm里写原生sql
//listTx := common.Db.Preload("Attributes").Where("kind = ? and (name like ? or properties like ?)", res.Kind.Kind, "%"+keywords+"%", "%"+keywords+"%") //通过Scopes来实现闭包where查询，就像 laravel 一样，
listTx := common.Db.Preload("Attributes").Scopes(func(db *gorm.DB) *gorm.DB { return db.Where("name like ? or properties like ?", "%"+keywords+"%", "%"+keywords+"%")
})`}]},{path:"/content/go/base/go-module%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%B9%E7%9B%AE%E5%88%B0%E8%BF%9C%E7%A8%8B.html",title:"go-module初始化项目到远程",pathLocale:"/",contents:[{header:"",slug:"",content:`实现go module的初始化：
1.生成包
在正式了解Golang Modules之前，我们先速览一下其使用方式。
在$GOPATH之外的任意地方，创建一个文件夹：
$ mkdir -p /tmp/hello
$ cd /tmp/hello 然后初始化一个新的Module：
$ go mod init github.com/gspgsp/el-api 输出：
go: creating new go.mod: module github.com/gspgsp/el-api go.mod内容为：
module github.com/gspgsp/el-api //代表项目的根目录，这里是一个远程地址，而不是之前的本地地址，这样可以让别的项目调用，如果是gitlab的话，就可以私有化了 go 1.17 然后git init 生成git文件，再提交到远程地址即可 2.调用github.com/gspgsp/el-api
在其它项目中先 import ,然后 go mod tidy 即可 3.如果是私有仓库或者是提交了但是国内仓库代理没有及时拉取你的仓库到镜像，那么可以直接配置：
export GOPRIVATE=gitlab.com/xxx 或者github.com/xxx即可 4.由于配置了私有仓库，那么在 go mod tidy 或者 go get 的时候 需要登录 输入用户名和密码，这个在自动发布项目就会有问题，解决办法就是在 ~/.netrc 文件里记录私
有仓库的登录信息，如下就是记录了 gitee下的账号信息，如果执行 git pull 就不用再输入账号密码信息；go mod tidy 或者 go get 实际上也是调用 git 命令拉取相关的
依赖，也就不用再输入账号密码信息了，这个在做 k8s 的项目自动发布的时候很有用，后面得分项目我会用大
[root@k8smaster ~]# vim ~/.netrc
machine gitee.com
login xxxxx@qq.com
password xxxyyyx=zzz 如果有多个 server 就重复上面的三行， 分别输入对应的服务器、 用户名和密码即可. 也可以把这三行写在同一行：machine gitee.com login xxxxx@qq.com password xxxyyyx=zzz`}]},{path:"/content/go/base/goalng%E4%B9%8Binit%E9%A1%BA%E5%BA%8F.html",title:"golang之init顺序",pathLocale:"/",contents:[{header:"",slug:"",content:`实现go module的初始化：
goalng之 init 顺序: 1、在同一个 package 中，可以多个文件中定义 init 方法
2、在同一个 go 文件中，可以重复定义 init 方法
3、在同一个 package 中，不同文件中的 init 方法的执行按照文件名先后执行各个文件中的 init 方法 // 这个使用的还是很多的，尤其是在加载带有配置文件的init项目里
4、在同一个文件中的多个 init 方法，按照在代码中编写的顺序依次执行不同的 init 方法
5、对于不同的 package，如果不相互依赖的话，按照 main 包中 import 的顺序调用其包中的 init() 函数
6、如果 package 存在依赖，调用顺序为最后被依赖的最先被初始化，例如：导入顺序 main –> A –> B –> C，则初始化顺序为 C –> B –> A –> main，一次执行对应的 init 方法。 所有 init 函数都在同⼀个 goroutine 内执⾏。
所有 init 函数结束后才会执⾏ main.main 函数。`}]},{path:"/content/go/base/golang%E4%B8%AD%E7%9A%84%E6%B3%9B%E5%9E%8B%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8.html",title:"golang中的泛型概念以及使用",pathLocale:"/",contents:[{header:"",slug:"",content:`golang中的泛型概念以及使用:
由于go语言是强类型语言，所以在1.18版本以前，无法像使用PHP一样，随意对不同类型数据进行操作；为了解决这个问题在1.18版本以后就有了泛型的使用
所谓泛型就是：定义一类通用的模板变量，可以传入不同类型的变量，使得逻辑更加通用，代码更加精简。
注意：使用1.18版本，必须要对编辑(GOLAND)进行升级(现在GOLAND和go语言版本不知道是不是做了绑定，要使用高版本的go，必须升级GOLAND，然后面临收费问题)，我用的是2021.1.3，最好2022版本，但是由于无法破解，所以一直用的2021版本，意味着无法使用泛型操作，但是可以在这个网站 https://gotipplay.golang.org 在线操作，建议在谷歌浏览器下执行，其它浏览器可能没有反应
我们可以这样定义一个泛型变量，比如，我们定义一个泛型切片，切片里的值类型，既可以是int，也可以是float64，也可以是string：
type ScoreSlice [T int|float64|string] []T
这个怎么理解呢：
①T表示我们提炼出来的通用类型参数(Type parameter)，是我们就用来表示不同类型的模板，T只是取的一个通用的名字，你可以取名任意其他名字都行。
②后面的int|float64|string 叫类型约束（Type constraint），也就是约束了T的取值范围，只能从(int、float64、string）中取值。中间的|表示的是或的关系，等于语法"||"，所以你可以根据你类型的使用场景定义更多的类型约束。
③[]里面的这一串T int|float64|string，叫类型参数列表(type parameter list)，表示的是我们定义了几个泛型的参数。我们例子当中只有1个，下面的例子中，我们会创建多个。
④最后面的[]T这个我们就很熟悉了，就是申请一个切片类型，比如常见的：[]int, []string 等等，只不过我们这里的类型是T，也就是参数列表里面定义的变量值。
这个 ScoreSlice 类型的切片相当于定义了三种类型的切片: []int []float64 []string
//来个官方的demo:
package main import ( "fmt"
) // This playground uses a development build of Go:
// devel go1.20-7c3284401f Thu Sep 15 06:23:50 2022 +0000 func Print[T any](s ...T) { for _, v := range s { fmt.Print(v) }
} func main() { Print("Hello, ", "playground\\n")
} //定义泛型的Map，然后实例化对象
package main import "fmt" type MapA[K string, V any] map[K]V func main() { m1 := MapA[string, int]{"zhangsan": 16} m1["zhangsan"] += 2 //修改val m2 := MapA[string, string]{"lisi": "湖北省武汉市"} fmt.Println(m1, m2)
} 注意如果写成下面的格式就会报错
package main import "fmt" type MapA[K string, V any] map[K]V func main() { m1 := MapA{"zhangsan": 16} //必须为 MapA[string, int] m1["zhangsan"] += 2 //修改val m2 := MapA{"lisi": "湖北省武汉市"} //MapA[string, int] fmt.Println(m1, m2)
} ./prog.go:8:8: cannot use generic type MapA[K string, V any] without instantiation(实例化)
./prog.go:11:8: cannot use generic type MapA[K string, V any] without instantiation实例化) //定义泛型的Channel，然后实例化对象
package main import "fmt" type C[T int|float64] chan T func main() { cha := make(C[int], 1) cha <- 1 fmt.Println(<-cha) chb := make(C[float64], 1) chb <- 23.56 fmt.Println(<-chb)
} //定义泛型的Slice，然后实例化对象，最后调用泛型函数打印输出
package main import "fmt" type SliceT[T any] []T func testSlice[T any](s []T) { //[T any]表示支持任何类型的参数 （s []T表示形参s是一个T类型的切片） for _, v := range s { fmt.Println("val is:", v) }
}
func main() { s1 := SliceT[int]{1,3,5,7} testSlice(s1) s2 := SliceT[string]{"zhangsan","lisi","wangwu"} testSlice(s2)
} //使用interface中规定的类型 约束泛型函数的参数
package main import "fmt" type NumStr interface { int | int32 | string //这个在高版本的golang下才会生效，如果换成自定义的 struct，好像不太能操作
} func add[T NumStr](a, b T) T { return a + b
} func main() { fmt.Println(add(-3,-4))
fmt.Println(add(10.34,23.78))// 会报错：./prog.go:15:16: float64 does not implement NumStr (float64 missing in int | int32 | string)
fmt.Println(add("hello","world"))
} //其实最想验证的是 泛型的 struct，不知道可不可以
package main import "fmt" type A struct { name string
} func GetVal[T A]() T { return T{ // 这里如果写 A 会报：./prog.go:11:9: cannot use A{…} (value of type A) as type T in return statement name: "zhangsan", }
} func main() { fmt.Println(GetVal()) }`}]},{path:"/content/go/base/golang%E4%B9%8Batomic%E4%BD%BF%E7%94%A8.html",title:"golang之atomic使用",pathLocale:"/",contents:[{header:"",slug:"",content:`golang的另一种锁竞争解决方案,基于atomic
/**
atomic 原子操作，只针对go中的一些基本数据类型使用：int32、int64、uint32、uint64、uintptr(uintptr 是 Go 内置类型，表示无符号整数，可存储一个完整的地址) */
var ( x int64 wg sync.WaitGroup
) func AmAdd() { //通过 atomic 原子操作，保证数据操作的原子性，结果一定是500 atomic.AddInt64(&x, 1) //直接x++，非原子操作，数据结果不准确，得到的结果可能是400多 //x++ //还可以通过sync.Mutex同步锁实现，加锁性能开销大 wg.Done()
} func TestAtomic(t *testing.T) { start := time.Now() for i := 0; i < 500; i++ { wg.Add(1) go AmAdd() // 原子操作版Add函数，是并发安全的，性能优于加锁版 } end := time.Now() wg.Wait() fmt.Println(x) fmt.Println(end.Sub(start).Seconds())
} atomic和mutex的区别 1.atomic的包处于sync/atomic，mutex则是sync下的包 2.atomic是对cpu底层进行原子操作，不能通过程序干预。而mutex则是在语言层面的，操作自由度较高。 3.atomic省去了lock和unlock的操作，代码比较简洁 4.atomic因为其在底层就已封装好的特性，所以它在goroutine下的运行表现是连续不间断的；而mutex则在goroutine运行间由于锁的等待或持有等情况，断断续续地执行 5.atomic总体运行较快，但是如果存储数据的非常巨大，它的性能会大打折扣。因为每次更新atomic的数据，都会进行一次数据复制，数据越大效率下降越大`}]},{path:"/content/go/base/golang%E4%B9%8Bbcript%E5%8A%A0%E5%AF%86%E5%92%8C%E9%AA%8C%E8%AF%81.html",title:"golang之bcript加密和验证",pathLocale:"/",contents:[{header:"",slug:"",content:`通过 bcrypt 对数据加密，这个和Laravel里的 bcrypt() 方法原理是一样的
package main import ( "fmt" "golang.org/x/crypto/bcrypt"
) func HashPassword(password string) (string, error) { bytes, err := bcrypt.GenerateFromPassword([]byte(password), 14) return string(bytes), err
} func CheckPasswordHash(hash, password string) bool { err := bcrypt.CompareHashAndPassword([]byte(hash), []byte(password)) return err == nil //直接比较，返回bool
} func main() { password := "123456" hash, _ := HashPassword(password)// 先生成password的hash码，这个码存到数据库，也就是password字段 res := CheckPasswordHash(hash,password) // 将hash后的password和hash前的password作比较 fmt.Println("比较结果为:", res)
}`}]},{path:"/content/go/base/golang%E4%B9%8Bclose()%E7%94%9F%E6%95%88%E6%97%B6%E9%97%B4%E7%82%B9.html",title:"golang之close()生效时间点",pathLocale:"/",contents:[{header:"",slug:"",content:`func TestCodeRes(t *testing.T) { require := make(chan int, 5) for i := 0; i < 5; i++ { require <- i } //关闭 require close(require) //设置定时器控制读取速率 ti := time.Tick(time.Duration(1) * time.Second) //直接range只会读取值，缓冲区无数据会读取默认零值，chan关闭，则退出range for i := range require { <-ti fmt.Printf("i: %d time: %v\\n", i, time.Now()) } //	=== RUN TestCodeRes // i: 0 time: 2022-10-23 20:06:52.6746003 +0800 CST m=+1.026004901 // i: 1 time: 2022-10-23 20:06:53.6702704 +0800 CST m=+2.021675001 // i: 2 time: 2022-10-23 20:06:54.6643626 +0800 CST m=+3.015767201 // i: 3 time: 2022-10-23 20:06:55.6645058 +0800 CST m=+4.015910401 // i: 4 time: 2022-10-23 20:06:56.6647772 +0800 CST m=+5.016181801 //	--- PASS: TestCodeRes (5.01s) //	PASS 结论：close()，会在最后一个send的值被receive了以后执行，这里就是 for range 循环完以后执行。通过官方文档的介绍也是可以知道的 // The close built-in function closes a channel, which must be either // bidirectional or send-only. It should be executed only by the sender, // never the receiver, and has the effect of shutting down the channel after // the last sent value is received. After the last value has been received // from a closed channel c, any receive from c will succeed without // blocking, returning the zero value for the channel element. The form //	x, ok := <-c // will also set ok to false for a closed channel. func close(c chan<- Type)
}`}]},{path:"/content/go/base/golang%E4%B9%8Bgo-get%E5%92%8Cgo-install%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"golang之go-get和go-install的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之go get和go install的区别:
go get 和 go install 是 Go 语言中的两个常用命令，它们用于获取和安装依赖包或将代码编译为可执行文件。它们的区别如下： 1、go get： go get 用于获取、更新和安装远程依赖包。它会自动从远程代码库（如 GitHub、GitLab）下载依赖包，并将其安装到 GOPATH 的pkg目录中。 当您执行 go get 命令时，它会下载指定的包及其依赖项，并将其放置在正确的目录结构中，以供项目引用。 通常，go get 会自动安装依赖项，无需手动执行 go install。 2、go install： go install 用于编译并安装 Go 语言的可执行程序。它将 Go 代码编译成二进制文件，并将其安装到 GOPATH 的bin目录中，以供后续执行。 当您执行 go install 命令时，它会在当前包的目录中执行编译过程，并将生成的可执行文件放置在 bin 目录中。 通过 go install 安装的可执行文件可以通过命令行直接运行，无需指定文件路径。 总结： go get 主要用于获取和更新依赖包，将其下载并安装到正确的目录结构中。 go install 主要用于将 Go 代码编译为可执行文件，并将其安装到 bin 目录中，以便执行。 需要注意的是，在 Go 1.16 版本之后，模块模式（go mod）成为默认的包管理方式，取代了旧的 GOPATH 方式。因此，在使用 Go 1.16 及更高版本时，go get 和 go install 命令会根据项目的模块文件（go.mod）来确定包的下载和安装位置。`}]},{path:"/content/go/base/golang%E4%B9%8Bgoroutine%E7%9A%84%E9%80%80%E5%87%BA%E5%9C%BA%E6%99%AF.html",title:"goroutine的退出场景",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之goroutine退出时间点：
原先自以为在自定义函数里面开辟一个新的协程，函数退出，开辟的协程也会强制退出，直到跟公司项目，看大佬写的调度才发现只有一种情况正在运行的goroutine会因为其他goroutine的结束被终止，就是main函数的退出或程序停止执行。 goroutine的调度是由 Golang 运行时进行管理的。同一个程序中的所有 goroutine 共享同一个地址空间。goroutine设计的退出机制是由goroutine自己退出，不能在外部强制结束一个正在执行的goroutine(只有一种情况正在运行的goroutine会因为其他goroutine的结束被终止，就是main函数退出或程序停止执行)。 ①进程/main函数退出 ②通过channel退出 ③通过context退出 ④通过Panic退出 ⑤等待自己退出`}]},{path:"/content/go/base/golang%E4%B9%8Bomitempty%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%89%B9%E6%AE%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF.html",title:"golang之omitempty关键字的两种特殊使用场景",pathLocale:"/",contents:[{header:"",slug:"",content:'golang之omitempty关键字的两种特殊使用场景: 问题\ngolang在处理json转换时，对于标签omitempty定义的field，如果给它赋得值恰好\n等于空值（比如：false、0、""、nil指针、nil接口、长度为0的数组、切片、映射），\n则在转为json之后不会输出这个field。那么，针对结构体中嵌套结构体，如果嵌套结构\n体为空，是否也会忽略？如果要忽略空结构体输出，怎么处理？ 实际使用过程中，针对结构体中嵌套结构体，如果嵌套结构体为空，默认不会忽略，会输出一个空的对象 情况一：匿名结构体：使用omitempty修饰该匿名结构体中的字段，那么当为空时不会输出 type Book struct{ Name string `json:"name"` Price float32 `json:"price"` Desc string `json:"desc,omitempty"` Author //匿名结构体\n}\ntype Author struct { Gender int `json:"gender,omitempty"` Age int `json:"age,omitempty"`\n} func main() { var book Book book.Name = "testBook" bookByte,_:=json.Marshal(book) fmt.Printf("%s\\n", string(bookByte))\n} 输出：\n{"name":"testBook","price":0} 情况二：非匿名结构体 type Book struct{ Name string `json:"name"` Price float32 `json:"price"` Desc string `json:"desc,omitempty"` Author Author `json:"author,omitempty"`\n}\ntype Author struct { Gender int `json:"gender,omitempty"` Age int `json:"age,omitempty"`\n} func main() { var book Book book.Name = "testBook" bookByte,_:=json.Marshal(book) fmt.Printf("%s\\n", string(bookByte))\n} 输出：\n{"name":"testBook","price":0,"author":{}} 可以发现，没有给嵌套结构体赋值时，会打印该嵌套结构体的空结构体。这是因为该空结构体不属于omitempty能识别的空值（false、0、""、nil指针、nil接口、长度为0的数组、切片、映射）。但若期望该嵌套结构体的空结构体也不会输出，可以通过指针实现。 type Book struct{ Name string `json:"name"` Price float32 `json:"price"` Desc string `json:"desc,omitempty"` Author *Author `json:"author,omitempty"` //这里加上指针类型，但是后面给这个这个指针元素赋值的时候需要(*Author).Age = xxx\n}\ntype Author struct { Gender int `json:"gender"` Age int `json:"age"`\n} func main() { var book Book book.Name = "testBook" bookByte,_:=json.Marshal(book) fmt.Printf("%s\\n", string(bookByte))\n} 输出：\n{"name":"testBook","price":0} 实际开发过程中，我使用的是第二种场景，因为给前端API返回的数据，经常会有嵌套的情况，但是这个 Author 需要先初始化，不然会报错 nil pointer'}]},{path:"/content/go/base/golang%E4%B9%8Brune%E7%B1%BB%E5%9E%8B.html",title:"golang之rune类型",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之rune类型:
字符串中的每一个元素叫做“字符”，在遍历或者单个获取字符串元素时可以获得字符 Go语言的字符有以下两种：
一种是byte 类型，代表了 ASCII 码的一个字符。byte等价于uint8类型
另一种是 rune 类型，代表一个Unicode字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。rune 类型等价于 int32 类型 // byte is an alias for uint8 and is equivalent to uint8 in all ways. It is
// used, by convention, to distinguish byte values from 8-bit unsigned
// integer values.
type byte = uint8 // rune is an alias for int32 and is equivalent to int32 in all ways. It is
// used, by convention, to distinguish character values from integer values.
type rune = int32 关于rune的几个点:https://juejin.cn/post/7068726981159829541
rune的使用场景:https://learnku.com/articles/23411/the-difference-between-rune-and-byte-of-go int的各个单位大小:https://clickhouse.com/docs/en/sql-reference/data-types/int-uint unicode和ascii的区别主要体现在:
1.编码范围不同
ASCII的编码范围是0-127，主要用于表示英语字母；而Unicode的编码范围广阔得多，可以表示几乎所有的语言字符。 2.存储空间不同
ASCII编码通常使用1个字节来存储一个字符，而Unicode编码可能使用2个或更多的字节来存储一个字符。 3.兼容性不同
ASCII编码是Unicode编码的一部分，也就是说，所有的ASCII字符在Unicode编码中都有对应的编码。这也意味着ASCII编码的文本可以直接转换为Unicode编码，而不会丢失任何信息。`}]},{path:"/content/go/base/golang%E4%B9%8Bswitch%E7%94%A8%E6%B3%95.html",title:"golang之switch用法",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之switch用法：
//switch 带表达式，switch n 要和case 值相等 才会执行，case 里可以跟多个值，比如 case 1,2,3: func main() { n := 2 switch n { case 1: fmt.Println("n = ",n) case 2: fmt.Println("n = ",n) case 3: fmt.Println("n = ",n) default: fmt.Println("default case") } } //switch 带表达式，通过switch做类型判断 func main() { var t interface{} switch t.(type) { case int: fmt.Println("int") case string: fmt.Println("string") case bool: fmt.Println("bool") case float64: fmt.Println("float64") default: fmt.Println("default interface") } } //switch通过 fallthrough 穿透，下面的 n := 2 ，会输出： 1,2 3,4 5,6 只要遇到 fallthrough 就会继续向下执行,而不管条件成不成立 func main(){ n := 2 switch n { case 1, 2: fmt.Println("1,2") fallthrough case 3, 4: fmt.Println("3,4") fallthrough case 5, 6: fmt.Println("5,6") fallthrough default: fmt.Println("default case") } } //switch 不带表达式，这种用法相当于 switch true，case 后表达式也要为 true 才会执行 func main() { n := 1 switch { case n == 1: fmt.Println("n = ",n) case n == 2: fmt.Println("n = ",n) case n == 3: fmt.Println("n = ",n) default: fmt.Println("default case") } }`}]},{path:"/content/go/base/golang%E4%B9%8B%E5%86%8D%E7%9C%8Bomitempty%E5%85%B3%E9%94%AE%E5%AD%97.html",title:"golang之再看omitempty关键字",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之再看omitempty关键字:
在Go语言中，omitempty是结构体标签中的一个选项，用于在将结构体转换为JSON或其他格式时，忽略具有零值的字段，从而减少生成的数据量。omitempty可以应用于各种类型的字段，但需要注意它只能在字段的值为其类型的零值时才会生效。以下是一些常见的类型和它们的零值，可以被omitempty忽略： 数值类型（int、float等）：0、0.0
布尔类型：false
字符串类型：空字符串 ""
切片：nil 或者长度为0的切片
映射（map）：nil 或者长度为0的映射
指针：nil
接口：nil
通道（channel）：nil
函数：nil
结构体：所有字段都为零值的结构体 通过上面的说明可以知道，在Go语言中，只有某些特定的类型可以被赋值为nil，这通常包括： 指针（Pointers）
接口（Interfaces）
切片（Slices）
映射（Maps）
通道（Channels）
函数（Functions）
这些类型的变量可以被赋值为nil，表示它们没有指向实际数据或对象。其他类型（如基本数据类型，如int、float，以及字符串、布尔等）不能被赋值为nil，因为它们是值类型，而不是引用类型。`}]},{path:"/content/go/base/golang%E4%B9%8B%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E9%80%9A%E8%BF%87viper%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"golang之单元测试通过viper读取配置报错的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之单元测试通过viper读取配置报错的问题
①在项目的任意目录下创建 xxx_test.go文件，我这里是 gorm_test.go文件
内容如下：
package product import ( "common" "model" "testing"
) func TestGormOperation(t *testing.T) { //create product :=model.Product{} product.Name = "超级大的滑雪场冬季必备" product.Kind = "旅游" common.Db.Create(product)
} 一运行报错了，原来是common下通过viper读取配置文件，路劲错了，主要是因为在 test下，viper读取的配置文件的相对路径不是项目的根目录，而是当前目录，所系需要根据实际情况通过 ../../ 访问配置文件
我这里： //configPathW = "./config/" configPathW = "../../config/"`}]},{path:"/content/go/base/golang%E4%B9%8B%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E%E8%A2%AB%E9%81%AE%E8%94%BD%E7%8E%B0%E8%B1%A1.html",title:"golang之变量声明被遮蔽现象",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之变量声明被遮蔽现象:
在Go语言中，"shadows declaration"（变量声明被遮蔽）是指在同一作用域内使用了相同名称的变量，导致内部变量（在更小的作用域中声明的变量）"遮蔽"了
外部变量（在更大的作用域中声明的变量）。这意味着在内部作用域中，访问该变量时将只能看到内部变量，而无法访问外部变量。 当编译器检测到变量被遮蔽时，它会发出"shadows declaration"警告或提示。这个警告的目的是为了提醒开发者可能存在的问题，以免在代码中引入不必要的混淆和错误。 例如，考虑以下代码示例：
package main import "fmt" func main() { x := 10 fmt.Println(x) // 输出: 10 if x := 20; x > 0 { fmt.Println(x) // 输出: 20 } fmt.Println(x) // 输出: 10
}`}]},{path:"/content/go/base/golang%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html",title:"golang之数据类型",pathLocale:"/",contents:[{header:"",slug:"",content:`1.基本数据类型
整数型：int, uint, int8, uint8(byte), int16, uint16, int32(rune), uint32, int64, uint64
浮点类型：float32, float64
复数类型：complex64, complex128 (就是高中学习的: y = 3+5i 这样的复数类型 )
布尔类型：bool
字符串：string 2.复合数据类型
array、struct、function 3.引用类型
slice、map、channel`}]},{path:"/content/go/base/golang%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%B9%E5%BA%94%E7%9A%84%E9%9B%B6%E5%80%BC.html",title:"golang之数据类型对应的零值",pathLocale:"/",contents:[{header:"",slug:"",content:`类型
零值 数值类型(int、float等)
0 bool
false string
""(空字符串) struct
内部字段的零值 slice
nil map
nil 指针
nil 函数
nil chan
nil interface
nil 这个有什么用，主要用处就是 初始化变量的时候夫默认值：
如下：
// 这个会报错：Cannot assign nil without the explicit type
var a = nil
// 这个没问题
var a interface{} = nil
// 这个会报错：Cannot use 'nil' as the type string
var a string = nil
// 这个没问题
var a error = nil
fmt.Println("a is:", a)`}]},{path:"/content/go/base/golang%E4%B9%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html",title:"golang之设计模式",pathLocale:"/",contents:[{header:"",slug:"",content:`创建型模式，共五种：简单工厂模式、工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。
结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。
行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代器模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。
1.简单工厂模式，一般是以NewXXX 返回 interface(接口)，然后根据这个 返回的接口对象，调用对象实现接口的方法，就可以了
2.工厂方法模式：使用子类的方式延迟生成对象到子类中实现
package test import ( "fmt" "testing"
) type ParseInterface interface { parseConfigFile()
} type parser struct { name string
} func (y *parser) parseConfigFile() { fmt.Println("config name is:", y.name)
} type jsonParser struct { parser
} func newJsonParser() ParseInterface { return &jsonParser{ parser{ name: "json", }, }
} type yamlParser struct { parser
} func newYamlParser() ParseInterface { return &yamlParser{ parser{ name: "yaml", }, }
} func sFactory(t int) ParseInterface { var obj ParseInterface switch t { case 1: obj = newJsonParser() case 2: obj = newYamlParser() default: fmt.Println("类型错误") } return obj
} func TestFactory(t *testing.T) { ft := sFactory(1) ft.parseConfigFile() //=== RUN TestFactory //config name is: json //--- PASS: TestFactory (0.00s) //PASS // //Process finished with the exit code 0
} 3.单例模式
package test import ( "fmt" "sync" "testing"
) type user struct { Name string
} var once sync.Once //通过这个实现单次加载
var userInstance *user func NewUser() *user { once.Do(func() { userInstance = new(user) }) return userInstance
} func TestSingle(t *testing.T) { //user1 := NewUser() //user1.Name = "测试11111111111" //fmt.Printf("user1 p is:%p\\n", user1) // //user2 := NewUser() //user2.Name = "测试22222222222222" //fmt.Printf("user2 p is:%p\\n", user2) //打印结果，user1和user2的地址相同 //=== RUN TestSingle //user1 p is:0xc00070a1f0 //user2 p is:0xc00070a1f0 //--- PASS: TestSingle (0.00s) //PASS // //Process finished with the exit code 0 onceFunc := func() { fmt.Println("func is coming") } for i := 0; i < 5; i++ { once.Do(onceFunc) } // 打印结果 只会输出一次；还加了 debug 调试 //=== RUN TestSingle //func is coming //--- PASS: TestSingle (31.72s) //PASS // //Debugger finished with the exit code 0
}`}]},{path:"/content/go/base/golang%E4%B9%8B%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86.html",title:"golang之迁移文件管理",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之迁移文件管理:
下载:https://github.com/golang-migrate/migrate //主要包括cli[单独下载releases下的文件] 模式 和 引入包[go get github.com/golang-migrate/migrate/v4] 模式 安装:https://github.com/golang-migrate/migrate/releases 执行迁移[sslmode=enable 这个参数不要随便加，不然会报错]:
duo@k8s:/usr/local/go-project/src/duoxiaozhan-api$ migrate create -ext sql -dir ./migrations -seq create_users_table
duo@k8s:/usr/local/go-project/src/duoxiaozhan-api$ migrate create -ext sql -dir ./migrations -seq add_role_id_users
duo@k8s:/usr/local/go-project/src/duoxiaozhan-api$ migrate -database 'mysql://root:123456@tcp(127.0.0.1:3306)/duo?charset=utf8mb4&parseTime=true&loc=Local' -path ./migrations up [N]
1/u create_users_table (15.020662ms)
duo@k8s:/usr/local/go-project/src/duoxiaozhan-api$ migrate -database 'mysql://root:123456@tcp(127.0.0.1:3306)/duo?charset=utf8mb4&parseTime=true&loc=Local' -path ./migrations down [N]
2/d add_role_id_to_users (32.834926ms) N: 是指定到的版本号,不指定就是全部 duo@k8s:/usr/local$ sudo dpkg -i ./migrate.linux-amd64.deb duo@k8s:/usr/local$ migrate --help
Usage: migrate OPTIONS COMMAND [arg...] migrate [ -version | -help ] Options: -source Location of the migrations (driver://url) -path Shorthand for -source=file://path -database Run migrations against this database (driver://url) -prefetch N Number of migrations to load in advance before executing (default 10) -lock-timeout N Allow N seconds to acquire database lock (default 15) -verbose Print verbose logging -version Print version -help Print usage
...
...`}]},{path:"/content/go/base/golang%E4%B9%8B%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE.html",title:"golang之运行环境的环境变量配置",pathLocale:"/",contents:[{header:"",slug:"",content:`golang之运行环境的环境变量配置
主要是在通过 go enc -w 配置golang运行的环境变量的时候，会有下面的问题
[root@k8smaster ~]# go env -w GO111MODULE=on
[root@k8smaster ~]# go env -w GOPROXY=https://goproxy.cn,direct
warning: go env -w GOPROXY=... does not override conflicting OS environment variable 解决办法:
[root@k8smaster ~]# unset GOPROXY
[root@k8smaster ~]# go env -w GOPROXY=https://goproxy.cn,direct`}]},{path:"/content/go/base/golang%E5%88%A0%E9%99%A4%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%9C%80%E5%B7%A6%E6%88%96%E6%9C%80%E5%8F%B3%E7%9A%84%E5%AD%97%E7%AC%A6.html",title:"golang删除字符串最左或最右的字符",pathLocale:"/",contents:[{header:"",slug:"",content:`golang删除字符串最左或最右的字符:
这个在字符串拼接的时候特别有用 //去除最右边字符 strings.TrimLeft(data, ",") //去除最左边字符 strings.TrimRight(data, ",")`}]},{path:"/content/go/base/golang%E5%A3%B0%E6%98%8E%E4%B8%80%E4%B8%AA%E7%A9%BA%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%87%E7%89%87.html",title:"golang声明一个空的字符串切片",pathLocale:"/",contents:[{header:"",slug:"",content:`golang声明一个空的字符串切片:
有时候需要遍历一个slice，处理完以后 存到一个新的slice里面，那么需要初始化一个空的字符串切片，而不是nil字符串切片，空和nil有很大的区别:
var list = []string{""} // 至少有一个元素，一般设为""，相当于有一个空的slice，最后通过 list[1:] 排除这个 "" 元素 如果声明为如下格式：
var list = []string{} // 其实这和 var list []string 没有区别，是一个nil的slice，所以直接适用会报下面的错误: out of range ...
通过 recover 可以捕获如下错误：
defer func() { if r := recover(); r != nil { common.Log.Println("错误:", r) } }() [api_request]2022/09/16 15:38:00 duplicateString.go:79: 错误: runtime error: index out of range [0] with length 0`}]},{path:"/content/go/base/golang%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%87%E7%89%87%E5%8E%BB%E9%87%8D.html",title:"golang字符串切片去重",pathLocale:"/",contents:[{header:"",slug:"",content:`golang字符串切片去重:
有时候需要去除字符串切片里的重复数据，可以通过下面的方法实现，其中 sort.Strings 很有用，这样可以很精确的对数据进行处理 func removeDuplicateString(data string) []string { dataS := strings.Split(data, ",") sort.Strings(dataS) i := 0 var list = []string{""} for j := 0; j < len(dataS); j++ { if strings.Compare(list[i], dataS[j]) == -1 { list = append(list, dataS[j]) i++ } } return list
}`}]},{path:"/content/go/base/golang%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BAtime.html",title:"golang格式化输出time",pathLocale:"/",contents:[{header:"",slug:"",content:'在实际项目中，我们经常需要输出时间，由于一般在Model类里会定义如下的字段：\nCreatedAt time.Time gorm:"type:timestamp;default:NULL;comment:创建时间"\nUpdatedAt time.Time gorm:"type:timestamp;default:NULL;comment:更新时间"\n这在输出以后基本上都是如下格式：\n"created_at": "2022-09-08T09:29:42+08:00"\n那么怎么解决这个问题，就需要通过自定义类型解决，代码如下： //自定义时间类型\ntype JsonTime time.Time func (j JsonTime) MarshalJSON() ([]byte, error) { var stamp = fmt.Sprintf(`"%s"`, time.Time(j).Format("2006-01-02 15:04:05")) return []byte(stamp), nil\n} //\ntype i struct { Id uint `json:"id"` Name string `json:"name"` CreatedAt response.JsonTime `json:"created_at"`\n} type val struct { ID uint `gorm:"primarykey;column:id;"` Name string `gorm:"type:varchar(15);default:NULL;comment:名称"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;comment:更新时间"`\n} i.CreatedAt = response.JsonTime(val.CreatedAt) //这里需要类型强转 //再通过json返回数据 i 的时候，就会格式化为 "2006-01-02 15:04:05" 格式'}]},{path:"/content/go/base/golang%E7%B1%BB%E5%9E%8B%E5%88%AB%E5%90%8D%E4%B8%8E%E7%B1%BB%E5%9E%8B%E5%AE%9A%E4%B9%89%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"golang类型别名与类型定义的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`golang类型别名与类型定义的区别:
类型别名 是 Go 1.9 版本添加的新功能。至于为什么要添加这个功能，官方文档：https://go.dev/talks/2016/refactor.article 有说明，简单来说就是：为了在代码库重构期间实现逐步的代码修复，必须能够为常量、函数、变量或类型创建替代名称。 类型别名的语法：
type OldAPI = NewPackage.API 类型定义的语法:
type OldAPI NewPackage.API 这俩的最大区别是，类型别名和源类型是相同的，可以直接使用，以及源类型自有的属性和方法，不允许自定义源类型没有的属性和方法；而类型定义 会生成一个新的类型和从语法上是不相等的，不能用于赋值 比较等操作
比如下面，主要是为了实现对time的格式化输出： type JsonTime = time.Time func (j JsonTime) MarshalJSON() ([]byte, error) { //这里就会报: Cannot define new methods on the non-local type 'time.Time' var stamp = fmt.Sprintf(\`"%s"\`, time.Time(j).Format("2006-01-02 15:04:05")) return []byte(stamp), nil
} 所以就需要通过类型定义来实现这个功能:
type JsonTime time.Time // 把 = 号去掉 func (j JsonTime) MarshalJSON() ([]byte, error) { var stamp = fmt.Sprintf(\`"%s"\`, time.Time(j).Format("2006-01-02 15:04:05")) return []byte(stamp), nil
}`}]},{path:"/content/go/base/golang%E9%80%9A%E8%BF%87%E5%8F%8D%E5%B0%84%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%B9%B6%E4%B8%94%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%AF%B9%E8%B1%A1.html",title:"golang通过反射获取数据类型并且实例化对象",pathLocale:"/",contents:[{header:"",slug:"",content:`golang通过反射获取数据类型并且实例化对象:
主要是有时候需要判断 interface{}类型数据，对应的源数据类型，可以通过下面的方法实现
// DuplicateString d 是 []Type 类型的数据
func DuplicateString(d interface{}) interface{} { t := reflect.TypeOf(d) if t.Kind() == reflect.Slice { t = t.Elem()//元素的类型 } newStruct := reflect.New(t)// 调用反射创建对象 newStruct.Elem().FieldByName("Suits").SetString("机车") //设置值 return newStruct
}`}]},{path:"/content/go/base/gorm%E4%B8%8B%E5%AF%B9json%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86.html",title:"gorm下对json数据的处理",pathLocale:"/",contents:[{header:"",slug:"",content:`gorm下对json数据的处理:
实际开发过程中，如果数据库有json类型的数据，那么在取数据的时候或者存储数据的时候可能会有问题，需要如下的包:
https://github.com/go-gorm/datatypes`}]},{path:"/content/go/base/gorm%E4%B9%8Bsql%E8%B0%83%E8%AF%95%E6%A8%A1%E5%BC%8F.html",title:"gorm之sql调试模式",pathLocale:"/",contents:[{header:"",slug:"",content:`gorm之sql调试模式:
//通过 Db 的 Debug() 调用，将 mysql 的日志级别降为 logger.Info (Debug a single operation, change current operation’s log level to logger.Info)，方便调试
//也可以直接将 mysql 初始化的时候，在 config 里配置：Logger: logger.Default.LogMode(logger.Info),//这里设置mysql的sql语句打印级别
var pList []model.Product
common.Db.Debug().Raw("select * from t_products where id < 30").Scan(&pList)`}]},{path:"/content/go/base/gorm%E5%8F%AF%E4%BB%A5%E8%AE%BE%E7%BD%AE%E7%9A%84%E5%85%B3%E8%81%94%E5%85%B3%E7%B3%BBtag%E5%A6%82%E4%B8%8B.html",title:"gorm可以设置的关联关系tag如下",pathLocale:"/",contents:[{header:"",slug:"",content:`gorm可以设置的关联关系tag如下: many2many 指定连接表
foreignkey 设置外键 //这个用的比较多,其实是给被关联表设置外键 或者 通过这个外键进行关联查询，默认是 主表模型_id。比如：user表 user_profile表，就需要将user表的id和user_profile表的user_id关联
references 指定引用的表中的字段 //这个用的也比较多，其实是给主表设置和被关联表外键相关的一个字段，默认是id
association_foreignKey 设置当前表中关联的外键字段//
polymorphic 指定多态类型
polymorphic_value 指定多态值
jointable_foreignkey 指定连接表的外键
association_jointable_foreignkey 指定连接表的关联外键
save_associations 是否自动完成 save 的相关操作
association_autoupdate 是否自动完成 update 的相关操作
association_autocreate 是否自动完成 create 的相关操作
association_save_reference 是否自动完成引用的 save 的相关操作 Tag	Description
foreignKey	Specifies column name of the current model that is used as a foreign key to the join table
references	Specifies column name of the reference’s table that is mapped to the foreign key of the join table
polymorphic	Specifies polymorphic type such as model name
polymorphicValue	Specifies polymorphic value, default table name
many2many	Specifies join table name
joinForeignKey	Specifies foreign key column name of join table that maps to the current table
joinReferences	Specifies foreign key column name of join table that maps to the reference’s table
constraint	Relations constraint, e.g: OnUpdate,OnDelete`}]},{path:"/content/go/base/gorm%E5%AF%B9%E5%A4%9A%E4%B8%AAor%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2%E5%B0%81%E8%A3%85.html",title:"gorm对多个or条件查询封装",pathLocale:"/",contents:[{header:"",slug:"",content:'gorm对多个or条件查询封装: // w 的key 为要查询的字段 []string为查询内容\nfunc Where(w map[string][]string) func(db *gorm.DB) *gorm.DB { var likeWhere string for k, val := range w { for _, v := range val { likeWhere += k + ` like "%` + v + `%" or ` } } // 去除尾部or likeWhere = likeWhere[:len(likeWhere)-3] return func(db *gorm.DB) *gorm.DB { return db.Where(likeWhere) }\n}'}]},{path:"/content/go/base/gorm%E5%AF%B9%E5%A4%9A%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F.html",title:"gorm对多个字段排序",pathLocale:"/",contents:[{header:"",slug:"",content:`gorm对多个字段排序: // 多字段排序,一个Order
common.Db.Order("age desc, name").Find(&users)
// SELECT * FROM users ORDER BY age desc, name; // 多字段排序,多个order
common.Db.Order("age desc").Order("name").Find(&users)
// SELECT * FROM users ORDER BY age desc, name; // 覆盖排序
common.Db.Order("age desc").Find(&users1).Order("age", true).Find(&users2)
// SELECT * FROM users ORDER BY age desc; (users1)
// SELECT * FROM users ORDER BY age; (users2) //对Order进行封装
//TODO`}]},{path:"/content/go/base/gorm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E4%B8%8A.html",title:"gorm数据库操作上",pathLocale:"/",contents:[{header:"",slug:"",content:`gorm数据库操作上:
package product import ( "testing"
) func TestGormOperation(t *testing.T) { //以下都是一对多操作 //新增，无关联 //Product :=model.Product{} //Product.Name = "超级大的滑雪场冬季必备" //Product.Kind = "文娱旅游" // //common.Db.Set("gorm:save_associations", false).Create(&Product) //新僧，有关联 //Product := model.Product{} //Product.Name = "避暑的好地方" //Product.Kind = "文娱旅游" //Product.Attributes = []model.ProductAttribute{ //	{Attribute: "地点", AttributeValue: "武汉"}, //	{Attribute: "地点", AttributeValue: "成都"}, //} // //common.Db.Create(&Product) //批量创建 //products := []model.Product{{Name: "宝马", Kind: "游戏", Attributes: []model.ProductAttribute{ //	{Attribute: "大灯", AttributeValue: "LED"}, //	{Attribute: "方向盘", AttributeValue: "真皮"}, //}}, {Name: "奔驰", Kind: "游戏", Attributes: []model.ProductAttribute{ //	{Attribute: "大灯", AttributeValue: "LED"}, //	{Attribute: "方向盘", AttributeValue: "真皮"}, //}}} // //common.Db.Create(&products) //通过 CreateInBatches 限制批量插入的数量 //common.Db.CreateInBatches(&products, 50) //products := []model.Product{{Name: "本田", Kind: "游戏", Attributes: []model.ProductAttribute{ //	{Attribute: "大灯", AttributeValue: "LED"}, //	{Attribute: "方向盘", AttributeValue: "真皮"}, //}}, {Name: "大众", Kind: "游戏", Attributes: []model.ProductAttribute{ //	{Attribute: "大灯", AttributeValue: "LED"}, //	{Attribute: "方向盘", AttributeValue: "真皮"}, //}}} ////Omit 忽略 某些字段(关联)，这里直接 clause.Associations，忽略所有的关联 //common.Db.Omit(clause.Associations).Create(products) //update with callbacks，这个更新操作将执行模型的BeforeUpdate, AfterUpdate方法，更新其UpdatedAt时间戳 //common.Db.Model(model.Product{}).Set("gorm:save_associations", false).Where("id = ?", 8).Updates(map[string]interface{}{"name":"避暑旅游打卡的好地方"}) //update，这个更新操作不会执行 callbacks相关的方法 //common.Db.Model(model.Product{}).Set("gorm:save_associations", false).Where("id = ?", 8).UpdateColumns(map[string]interface{}{"name": "避暑旅游打卡带娃野炊的好地方", "kind": "医疗健康"}) //update，这个更新操作不会执行 callbacks相关的方法，通过 Omit 忽略某些字段，不做更新 //common.Db.Model(model.Product{}).Set("gorm:save_associations", false).Where("id = ?", 8).Omit("name").UpdateColumns(map[string]interface{}{"name": "避暑旅游打卡带娃野炊的好地方", "kind": "医疗健康"}) //update，同时更新相关的关联模型,如果待更新内容不包含 关联模型字段，那么直接更新成功 //common.Db.Model(model.Product{}).Where("id = ?", 8).UpdateColumns(map[string]interface{}{"name": "避暑旅游团建的好地方", "kind": "健身运动"}) //关于更新有几个细节问题：①如果使用map的话可以更新任意结果，但是如果使用struct的话，如果待更新值为 "" 0 false，都不会被更新，下面的name值不会变 //common.Db.Model(model.Product{}).Where("id = ?", 8).UpdateColumns(model.Product{Name: "", Kind: "中医理疗"}) //name的值变为空 //common.Db.Model(model.Product{}).Where("id = ?", 8).UpdateColumns(map[string]interface{}{"name": "", "kind": "中医理疗"}) //带关联模型的 更新，我还没找到怎么更新关联关系...，下面这个肯定是不行的，因为没有关联关系数据的id //product := model.Product{Name: "避暑旅游团建打卡的好地方", Kind: "健身运动", Attributes: []model.ProductAttribute{ //	{Attribute: "大灯", AttributeValue: "LED"}, //	{Attribute: "方向盘", AttributeValue: "真皮"}, //}} //common.Db.Model(model.Product{}).Where("id = ?", 8).Save(product) //删除操作,当数据库定义了 deleted_at，那么就会出发软删除操作(给deleted_at赋值) //common.Db.Where("id = ?", 1).Delete(&model.Order{}) //Unscoped的用法，①可以用来硬删除数据 ②可以用来查询软删除的数据 //order := model.Order{} //common.Db.Where("id = ?", 1).Unscoped().First(&order) //fmt.Printf("order is:%+v\\n", order) //common.Db.Where("id = ?", 1).Unscoped().Delete(&model.Order{}) //验证 多对多 操作 //TODO::明天更新 }`}]},{path:"/content/go/base/gorm%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB%E4%B8%8A.html",title:"gorm数据库迁移上",pathLocale:"/",contents:[{header:"",slug:"",content:'gorm数据库迁移上: //简单数据库迁移,这个是比较简单的迁移操作(单表迁移) type Order struct { Id uint `gorm:"primarykey;not null;auto_increment;column:id;comment:ID"` No string `gorm:"type:varchar(255);default:NULL;column:no;comment:订单编号"` OutTradeNo string `gorm:"type:varchar(255);default:NULL;column:out_trade_no;comment:订单流水号"` PayOrderNo string `gorm:"type:varchar(255);default:NULL;column:pay_order_no;comment:支付平台订单号"` Title string `gorm:"type:varchar(255);default:NULL;column:title;comment:订单标题"` Amount float64 `gorm:"type:decimal(10,2);default:0.0;column:amount;comment:订单金额"` Status int8 `gorm:"type:tinyint(1);default:0;column:status;comment:订单状态[0:未支付,1:已完成,-1:已过期]"` PayAmount float64 `gorm:"type:decimal(10,2);default:0.0;column:pay_amount;comment:支付金额"` PayStatus int8 `gorm:"type:tinyint(1);default:0;column:pay_status;comment:支付状态[0:未支付,1:已支付,-1:支付失败]"` PayExpiredAt time.Time `gorm:"type:timestamp;default:NULL;column:pay_expired_at;comment:支付过期时间"` PayAt time.Time `gorm:"type:timestamp;default:NULL;column:pay_at;comment:支付过期时间"` UserId int `gorm:"type:int;default:NULL;column:user_id;comment:用户ID"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;column:created_at;comment:创建时间"` DeletedAt time.Time `gorm:"type:timestamp;default:NULL;column:deleted_at;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;column:updated_at;comment:更新时间"` CreatedAdminId int `gorm:"type:int;default:NULL;column:created_admin_id;comment:创建人ID"` UpdatedAdminId int `gorm:"type:int;default:NULL;column:updated_admin_id;comment:更新人ID"` } //err := common.Db.AutoMigrate(&model.Order{}) //if err != nil { //	fmt.Println("迁移错误:", err) //} // //fmt.Println("迁移完成") //手动通过 Migrator 对象实现相关的操作 //m := common.Db.Migrator() //err := m.CreateTable(&model.Order{}) //if err != nil { //	fmt.Println("迁移错误:", err) //} // //fmt.Println("迁移完成")'}]},{path:"/content/go/base/gorm%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB%E4%B8%8B.html",title:"gorm数据库迁移下",pathLocale:"/",contents:[{header:"",slug:"",content:'gorm数据库迁移下 type Room struct { Id uint `gorm:"primarykey;not null;auto_increment;column:id;"` Name string `gorm:"type:varchar(15);default:NULL;column:name;comment:名称"` Students []Student `gorm:"foreignKey:room_id;references:id;constraint:OnUpdate:RESTRICT,OnDelete:CASCADE;"`// foreignKey 和 references 配合，用于主表 CreatedAt time.Time `gorm:"type:timestamp;default:NULL;column:created_at;comment:创建时间"` DeletedAt time.Time `gorm:"type:timestamp;default:NULL;column:deleted_at;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;column:updated_at;comment:更新时间"` CreatedAdminId int `gorm:"type:int;default:NULL;column:created_admin_id;comment:创建人ID"` UpdatedAdminId int `gorm:"type:int;default:NULL;column:updated_admin_id;comment:更新人ID"`\n} type Student struct { Id uint `gorm:"primarykey;not null;auto_increment;column:id;"` Name string `gorm:"type:varchar(15);default:NULL;column:name;comment:名称"` RoomId int `gorm:"type:int;default:NULL;column:room_id;comment:房间ID"` //room_id 要在Student 表被声明为外键的话，必须要在 room 申明 `gorm:"foreignKey:room_id;references:id;constraint:OnUpdate:RESTRICT,OnDelete:CASCADE;"` 在执行了迁移文件以后才会将room_id声明为Student表的外键 //RoomInfo Room `gorm:"foreignKey:room_id,references:id"` //这一行在迁移文件应该注释掉(否则会报错，就是互相引用的问题，导致room表和student表的创建失败)，这个只是在业务逻辑操作的时候，才会有的，比如 我想查某个学生信息，同时又想知道这个学生的room RoomInfo Room `gorm:"foreignKey:room_id"` //试验证明 这里只能定义 foreignKey，不能 定义 references ，否则通过Preload 查询 报错，至于 Association 更是不行。目前还没调通 Association 的使用 CreatedAt time.Time `gorm:"type:timestamp;default:NULL;column:created_at;comment:创建时间"` DeletedAt time.Time `gorm:"type:timestamp;default:NULL;column:deleted_at;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;column:updated_at;comment:更新时间"` CreatedAdminId int `gorm:"type:int;default:NULL;column:created_admin_id;comment:创建人ID"` UpdatedAdminId int `gorm:"type:int;default:NULL;column:updated_admin_id;comment:更新人ID"`\n} //一对一迁移数据库，一对多迁移数据库，注意会有相互引用的问题，所以我建议：单独建一个 migration文件，包括所有的数据表迁移信息，而不是直接用 model来控制迁移文件 err := common.Db.AutoMigrate(&model.Room{}, &model.Student{}) if err != nil { fmt.Println("迁移错误:", err) } fmt.Println("迁移完成") //通过主表查询 var rooms []model.Room common.Db.Preload("Students").Find(&rooms) fmt.Printf("rooms are:%+v/n", rooms) //通过附表查询 var students []model.Student common.Db.Preload("RoomInfo").Find(&students) fmt.Printf("students is:%+v\\n", students) //下面两种使用 Association 的方法都调不通，都会报错 foreign key 定义错误的问题，还不知道 Association 刀子应该怎么使用，目前还是只能通过 Preload调用成功 //common.Db.Model(model.Student{}).Association("RoomInfo").Find(&room) //fmt.Printf("students are:%+v\\n", students) //common.Db.Model(model.Room{}).Association("Students").Find(&students) //fmt.Printf("students are:%+v\\n", students) //总结：foreignKey 和 references 放到主表和附表，它们的意义是不一样的，放到主表：foreignKey 其实是定义在附表的外键字段,references 为主表的id字段；放到附表：foreignKey 指的就是当前附表的外键，references 为主表的id(默认)[这是v2版本官网的定义,https://gorm.io/docs/belongs_to.html] //还有就是：gorm的Related和Association 区别： Relate是v1版本才有的方法，Association是v2(1.2.+就是v2版本)才有的方法，没有了，网上的答案 真的是让人伤不起。'}]},{path:"/content/go/base/gorm%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB%E4%B8%AD.html",title:"gorm数据库迁移中",pathLocale:"/",contents:[{header:"",slug:"",content:'gorm数据库迁移中: //多对多数据库迁移 type Article struct { Id uint `gorm:"primarykey;not null;auto_increment;column:id;"` Title string `gorm:"type:varchar(15);default:NULL;column:title;comment:标题"` Detail string `gorm:"type:varchar(15);default:NULL;column:detail;comment:详情"` Categories []Category `gorm:"many2many:article_has_categories;"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;column:created_at;comment:创建时间"` DeletedAt time.Time `gorm:"type:timestamp;default:NULL;column:deleted_at;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;column:updated_at;comment:更新时间"` CreatedAdminId int `gorm:"type:int;default:NULL;column:created_admin_id;comment:创建人ID"` UpdatedAdminId int `gorm:"type:int;default:NULL;column:updated_admin_id;comment:更新人ID"` } type Category struct { Id uint `gorm:"primarykey;not null;auto_increment;column:id;"` Name string `gorm:"type:varchar(15);default:NULL;comment:名称"` Articles []Article `gorm:"many2many:article_has_categories;"` CreatedAt time.Time `gorm:"type:timestamp;default:NULL;column:created_at;comment:创建时间"` DeletedAt time.Time `gorm:"type:timestamp;default:NULL;column:deleted_at;comment:创建时间"` UpdatedAt time.Time `gorm:"type:timestamp;default:NULL;column:updated_at;comment:更新时间"` CreatedAdminId int `gorm:"type:int;default:NULL;column:created_admin_id;comment:创建人ID"` UpdatedAdminId int `gorm:"type:int;default:NULL;column:updated_admin_id;comment:更新人ID"` } //①通过 AutoMigrate 实现的数据库迁移，可以实现表之间的关系，比如我这里的 Category 里定义了 many2many tag,通过 AutoMigrate 可以自动创建三张表: //categories表 article_has_categories表 articles表 //②不能通过手动迁移数据库创建这样的表 //err := common.Db.AutoMigrate(&model.Category{}) //if err != nil { //	fmt.Println("迁移错误:", err) //} // //fmt.Println("迁移完成") //多对多查询，我发现只能通过Preload查询，Association不生效 //var categories []model.Category //err := common.Db.Preload("Articles").Find(&categories).Error //if err != nil { //	fmt.Println("err is:", err) //} // //fmt.Printf("categories are:%+v\\n", categories) //多对多更新 //common.Db.Model(model.Category{}).Where("id = ?", 1).Update("name", "分类111") //多对多删除，这个得先删除中间表的数据，再删除主表的数据(最然主表数据定义了deleted_at 字段，但是会被硬删除，而不会软删除，这点和laravel还是有区别的) //这个过程需要事务操作：① 自动事务(和laravel很像，很方便) ② 手动事务 err := common.Db.Transaction(func(tx *gorm.DB) error { //tx.Exec(""),本来想对中间表执行原生sql删除的，不想定义中间表的model，实际上也不需要，但是我还是定义了 if err := tx.Where("category_id = ?", 2).Delete(&model.ArticleHasCategory{}).Error; err != nil { return err } if err := tx.Where("id = ?", 2).Delete(&model.Category{}).Error; err != nil { return err } return nil }) if err != nil { fmt.Println("数据删除失败", err) } fmt.Println("数据删除成功")'}]},{path:"/content/go/base/go%E4%B9%8Bchan%E7%9A%84send%E4%B8%8Ereceive.html",title:"go之chan的send与receive",pathLocale:"/",contents:[{header:"",slug:"",content:`一直以来，对于chan的两个方向有一些定义上的模糊，有说写/读，但是官网上一直定义的是 send-only type/receive-only type，那么就来解释一下这两个的由来 send-only type:
比如：chan<- int 我这里声明一个chan
rsc := make(chan<- int ) 那么就只能 rsc <- rand.Int() // 这个send相对于 rand.Int() 来讲就是send receive-only type:
比如：<-chan int 我这里声明一个chan
rsc := make(<-chan int ) 那么就只能 intVal := <-rsc // 这个receive相对于 intVal 来讲就是receive`}]},{path:"/content/go/base/go%E4%B9%8Brune%E5%85%B3%E9%94%AE%E5%AD%97.html",title:"go之rune关键字",pathLocale:"/",contents:[{header:"",slug:"",content:`今天在看go的一个源码的时候，看到了rune，所以就想看看它的使用场景。
官网说 rune 是 int32的别名
下面通过一个案例说明问题:
package test import ( "fmt" "testing" "unicode/utf8"
) func TestRune(t *testing.T) { var str = "hello 中国" //golang中string底层是通过byte数组实现的。中文字符在unicode下占2个字节，在utf-8编码下占3个字节，而golang默认编码正好是utf-8。 fmt.Println("len(str):", len(str))//输出 12 //如果我们预期想得到一个字符串的长度，而不是字符串底层占得字节长度，那就可以通过rune实现 //通过utf8的RuneCountInString方法处理 fmt.Println("RuneCountInString:", utf8.RuneCountInString(str))//输出8 //通过rune类型处理 fmt.Println("rune:", len([]rune(str)))//输出8 //for-range循环，输出结果如下 //k1= 0 v1= h //k1= 1 v1= e //k1= 2 v1= l //k1= 3 v1= l //k1= 4 v1= o //k1= 5 v1= //k1= 6 v1= 中 //k1= 9 v1= 国 //这里索引自动 +3 //k2= 0 v2= h //k2= 1 v2= e //k2= 2 v2= l //k2= 3 v2= l //k2= 4 v2= o //k2= 5 v2= //k2= 6 v2= 中 //k2= 7 v2= 国 //索引递增 //--- PASS: TestRune (0.00s) //PASS s1 := "hello 中国" for k, v := range s1 { fmt.Println("k1=", k, "v1=", string(v)) } fmt.Println("") for k, v := range []rune(s1) { fmt.Println("k2=", k, "v2=", string(v)) } //rune 等同于int32,常用来处理unicode或utf-8字符
}`}]},{path:"/content/go/base/go%E4%B9%8Bsync_Map%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"go之sync_Map的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`普通map在并发写的场景下是不安全的，所以golang有了sync.Map数据类型，这个可以解决这个问题，当然还有读写锁
使用案例如下: func main(){ //声明 scene，类型为 sync.Map，注意，sync.Map 不能使用 make 创建。 var scene sync.Map // 将键值对保存到sync.Map scene.Store("zhangsan", 23) scene.Store("lisi", 28) scene.Store("wangwu", "湖北武汉") scene.Store("zhaoliu", "上海浦东") // 从sync.Map中根据键取值 fmt.Println(scene.Load("lisi")) // 根据键删除对应的键值对 scene.Delete("zhangsan") // 遍历所有sync.Map中的键值对 i := 0 scene.Range(func(k, v interface{}) bool { fmt.Println("遍历syn_map====>:", k, v) //统计map的大小 i++ return true }) fmt.Println("syn_map大小为:", i)
}`}]},{path:"/content/go/base/go%E4%B9%8B%E7%A9%BAmap%E5%92%8Cnilmap%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"go之空map和nilmap的区别",pathLocale:"/",contents:[{header:"",slug:"",content:'这两个概念经常会出现，下面就以实际运行结果，比较二者的不同吧: //nil map var m1 map[string]string //可以取值，但是结果为空 fmt.Println("m1的元素为:", m1["1"]) fmt.Println("m1为:", m1) fmt.Println("m1大小为:", len(m1)) //空map m2 := make(map[int]interface{}) fmt.Println("m2为:", m2) fmt.Println("m2大小为:", len(m2)) if m1 == nil { fmt.Println("m1 is nil") } if m2 == nil { fmt.Println("m2 is nil") }'}]},{path:"/content/go/base/go%E5%85%B3%E4%BA%8Edefer-func.html",title:"go关于defer-func",pathLocale:"/",contents:[{header:"",slug:"",content:`defer概述:
defer用来声明一个延迟函数，把这个函数放入到一个栈上，当外部的包含方法return之前，返回参数到调用方法之前调用，
也可以说是运行到最外层方法体时调用，我们经常用他来做一些资源的释放，比如关闭io操作。 defer特性:
1.defer定义的延迟函数参数在defer语句定义时就已经确定下来了
2.defer定义顺序与实际执行顺序相反，即先进后出 return特性:
return不是原子操作，执行过程是：保存返回值(若有)-->执行defer（若有）-->执行ret跳转，具体过程如下：
关键字return不是一个原子操作，实际上return只代理汇编指令ret，即将跳转程序执行。return i，实际上分两步进行，
即将i值存入栈中作为返回值，然后执行跳转，而defer的执行时机正是跳转前，所以说defer执行时还是有机会操作返回值的。 defer使用：
在申请资源后调用defer关闭资源
返回前通过defer写日志或者发送通知 关于defer的细节:
defer return 返回值 三者的执行顺序: 1.return 赋值 最先执行，即先将结果写入返回值中；
2.接着defer开始执行一些收尾工作；
3.最后函数携带当前返回值退出（即返回值）。 所以结论是：第一步先return赋值，第二步再执行defer，第三步执行空的return。但是在有名与无名的函数返回值的情况下会有些区别：
如果函数的返回值是无名的（不带命名返回值）如上例中的f2()，则go语言会在执行return指令时,创建一个临时变量保存返回值，最后返回,如下返回 1:
// 这里返回值是无名
func f2() int { // 第一步:return赋值；创建了一个临时变量保存返回值 n := 1 // 后续defer对n操作，这里的n并不是返回值变量 defer func() { n++ }() // 空的return,这一步是将第一步中的临时变量保存的值返回 return } 有名返回值的函数,由于返回值变量已经提前定义，所以运行过程中并不会再创建临时变量，后续defer操作的变量都是返回值变量,如下返回 2:
// 定义了返回值变量
func f1() (n int) { // 直接操作返回值 n = 1 defer func() { // 这里操作的也是返回值 n++ }() return n
} 参考链接: http://liuqh.icu/2023/05/18/go/bottom/6-defer/`}]},{path:"/content/go/base/go%E5%B8%B8%E7%94%A8%E9%94%81.html",title:"go常用锁",pathLocale:"/",contents:[{header:"",slug:"",content:`golang当中提供了两种常用的锁。 一种是 sync.Mutex （互斥锁） 另外一种是 sync.RWMutex （读写锁） Mutex，它就是最简单最基础的同步锁，当一个goroutine持有锁的时候，其他的goroutine只能等待到锁释放之后才可以尝试持有。 RWMutex 是读写锁的意思，它支持一写多读，也就是说允许支持多个goroutine同时持有读锁，而只允许一个goroutine持有写锁。当有goroutine持有读锁的时候，会阻止写操作。当有goroutine持有写锁的时候，无论读写都会被堵塞。 假设我们当前有多个goroutine，但是我们只希望持有锁的goroutine执行，我们可以这么写：
var lock sync.Mutex for i := 0; i < 10; i++ { go func() { lock.Lock() defer lock.Unlock() // do something }()
} RWMutex分为读写锁，所以我们一共会有4个api，分别是Lock, Unlock, RLock, RUnlock。Lock和Unlock是写锁的加锁以及解锁，而RLock和RUnlock就是读锁的加锁和解锁了。`}]},{path:"/content/go/base/go%E6%9B%B4%E6%96%B0%E9%A1%B9%E7%9B%AE%E4%BE%9D%E8%B5%96%E7%89%88%E6%9C%AC.html",title:"go更新项目依赖版本",pathLocale:"/",contents:[{header:"",slug:"",content:`go更新项目依赖版本:
go mod 管理依赖，但是更新某个依赖的话 需要用到 go get 命令 1:go get更新特定版本
go get package@[@version]
version可以是vx.y.z这种形式或者直接使用commit的checksum，也可以是master或者latest 2：go get -u
package会更新所有依赖该包的版本 3：go get package
package会更新当前包版本和所有依赖该包的版本 4.通过这个包实现交互式更新操作
在当前项目下执行:
$ go get -u github.com/oligot/go-mod-upgrade $ go-mod-upgrade`}]},{path:"/content/go/base/grpc%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html",title:"grpc环境搭建",pathLocale:"/",contents:[{header:"",slug:"",content:`grpc环境搭建:
1.prococ安装
①到 https://github.com/protocolbuffers/protobuf/releases 分别下载Windows和Linux环境的执行器
②选择最新版本的protoc下载
③将下载的文件解压，将解压后的bin目录加入到环境变量的path下
④查看安装是否成功
命令：protoc --version
输出:libprotoc 3.20.2
2.protobuf下go、grpc 插件的安装
protoc-gen-go： go专用的protoc的编译器插件，安装后会在GOPATH的bin目录下生成一个protoc-gen-go.exe
protoc-gen-go-grp：go调用grpc的插件，安装后会在GOPATH的bin目录下生成一个protoc-gen-go-grpc.exe
go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.26
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.1
至此使用Protobuf的准备工作就做完了
3.创建go项目，同时编写 proto文件
①先新建一个 proto 文件夹，再在里面编写 hello.proto
syntax = "proto3";
package hello;
option go_package = "./grpc/service"; // 这个参数主要是定义生成的 pb.go 以及 grpc.pb.go 存到哪里 可以直接设为 "./" 就在当前目录下
service Greeter {
rpc SayHello (HelloRequest) returns (HelloReply) {}
}
message HelloRequest {
string name = 1;
}
message HelloReply {
string message = 1;
}
②进入存放.proto路径下
③运行如下命令，生成 pb.go 以及 grpc.pb.go 代码
D:\\go-registry\\src\\k8s-hello\\proto>protoc --go_out=. --go-grpc_out=. *.proto
可以在 D:\\go-registry\\src\\k8s-hello\\proto\\grpc\\service 看到生成的 pb.go 以及 grpc.pb.go 文件，到这里准备工作算是完成了`}]},{path:"/content/go/base/ubuntu22%E8%AE%BE%E7%BD%AEgolang%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F.html",title:"ubuntu22设置golang环境变量",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22设置golang环境变量:
#PATH
export GOROOT=/usr/local/go
export GOPATH=/usr/local/go-project
export PATH=$PATH:$GOROOT/bin:$GOPATH/bin 运行 sudo go mod init xxx ,报:sudo: go: command not found 我们使用 sudo 时，使用的配置文件是 /etc/sudoers。
配置 /etc/sudoers 文件中的 Defaults secure_path 这一项。将 $GOROOT/bin 目录加入进去
Defaults secure_path 这一行：
Defaults secure_path="/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"`}]},{path:"/content/go/base/%E6%89%A7%E8%A1%8Cgo-mod-tidy%E6%8A%A5%E9%94%99.html",title:"执行go-mod-tidy报错",pathLocale:"/",contents:[{header:"",slug:"",content:`执行go-mod-tidy报错:
duo@k8s:/usr/local/go-project/src/duoxiaozhan-api$ go mod tidy
go: finding module for package github.com/gin-gonic/gin
go: downloading github.com/gin-gonic/gin v1.9.1
gitee.com/qinhong_design/duoxiaozhan-api/main imports github.com/gin-gonic/gin: github.com/gin-gonic/gin@v1.9.1: verifying module: github.com/gin-gonic/gin@v1.9.1: open /usr/local/go-project/pkg/sumdb/sum.golang.org/latest: no such file or directory 如果go get时啥的出问题, 一定记得关闭GOSUMDB, 命令为. go env -w GOSUMDB=off 几乎所有和go mod有关的疑难杂症,都是没执行这个命令!`}]},{path:"/content/java/spring/SpringBoot%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E9%A1%B9%E7%9B%AE.html",title:"",pathLocale:"/",contents:[]},{path:"/content/java/spring/SpringBoot%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90.html",title:"SpringBoot项目结构分析",pathLocale:"/",contents:[{header:"",slug:"",content:`SpringBoot项目结构分析:
通过 IntelliJ IDEA 新建了一个名叫 spring-demo 的项目,以下是几个重要的目录文件说明: .idea：IntelliJ IDEA 生成，用于配置应用信息的文件目录。内部包含了类库，应用字符编码，模块，工作区等信息。
.mvn：Spring Boot 生成，用于一键通过 Maven 构建、编译、打包和部署的文件目录。内部结构如下： ├── .mvn
│ └── wrapper
│ ├── maven-wrapper.jar
│ └── maven-wrapper.properties
├── mvnw
└── mvnw.cmd 可以看到，该文件目录包含了 maven-wrapper.jar、maven-wrapper.properties 两个个文件。另外和 .mvn 同层级的 mvnw 和 mvnw.cmd 两个文件，是执行 maven-wrapper.jar 的入口，mvnw 用于 Linux 或 macOS，mvnw.cmd 用于 Windows。 wrapper 和 原生的 maven 的区别:
和传统 maven 的使用方式相比， maven-wrapper 每次更换版本要少操作一步(图中标红箭头)，只需要更新配置文件(maven-wrapper.properties )中的 distributionUrl 为目标版本即可。不过也有代价，就是首次下载 maven 包的时候，要单独下载 wrapper(图中蓝色区块)，但这是一劳永逸的事情。 src：Spring Boot 生成，存放应用源代码的文件目录。 二级目录 main存放程序实际执行相关代码， test 存放程序测试相关代码。
三级目录 java 存放后缀为 .java 的代码文件，resources 存放静态文件，模板文件，应用配置文件等资源或配置类文件。java 目录里边就是一个个代码包和代码文件，CourseApplication 是整个应用程序的启动入口。 target：应用构建时生成，主要存放了源代码编译后的 class 文件，相关的配置文件以及打好的包文件等用于实际执行的文件。 .gitignore：Spring Boot 生成，版本控制系统 Git 的配置文件，表示忽略提交。该文件中，只要遵循相应的语法，每一行可以指定一个忽略规则。 spring-demo.iml：IntelliJ IDEA 生成，IntelliJ IDEA 的工程配置文件。包含了当前工程的一些配置信息，比如模块信息，Java 组件，Maven 组件等等以及一些模块的路径信息和依赖信息。 HELP.md：Spring Boot 生成，帮助文档，提供了 Spring Boot相关文档和教程。 pom.xml：Spring Boot 生成的项目对象模型文档，主要描述了项目的 Maven 坐标和依赖关系等信息，是项目级别的配置文件。`}]},{path:"/content/linux/command/centos7%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E6%9C%8D%E5%8A%A1%E5%90%8D%E7%A7%B0.html",title:"centos7查看所有服务名称",pathLocale:"/",contents:[{header:"",slug:"",content:`centos7查看所有服务名称:
有时候我们会忘记一些服务的名称，导致查看服务状态，没法敲命令，可以通过下面的命令列出所有的服务:
[root@k8smaster ~]# systemctl list-unit-files //列出所有服务 [root@k8smaster ~]# systemctl list-unit-files | grep 'php*' //列出php相关的服务`}]},{path:"/content/linux/command/centos7%E9%85%8D%E7%BD%AEclash%E4%BB%A3%E7%90%86.html",title:"centos7配置clash代理",pathLocale:"/",contents:[{header:"",slug:"",content:`最近在网站开发过程中，线上服务器可能需要使用chat-gpt服务，主要是问答功能，因此需要vpn服务，现将使用步骤记录如下:
1.下载当前操作系统与 CPU 架构对应的包文件，我这儿是 X86_64 平台下 CentOS7 所以对应的使用clash-linux-amd64-v1.14.0.gz
#执行命令，加上 --no-check-certificate 避免github链接失败
cd /usr/local
wget https://github.com/Dreamacro/clash/releases/download/v1.14.0/clash-linux-amd64-v1.14.0.gz --no-check-certificate 2.解压缩文件
gunzip clash-linux-amd64-v1.14.0.gz #执行完后可以在当前路径下看到解压缩后的文件：clash-linux-amd64-v1.14.0 同时原gz文件会被自动删除 3.创建配置文件目录，并下载 MMDB 文件，这个文件应该是一个内存级别数据库
mkdir /etc/clash
wget -O /etc/clash/Country.mmdb https://www.sub-speeder.com/client-download/Country.mmdb #注意 www.sub-speeder.com 这个链接大概率是访问不到的，可以单独下载然后重命名为Country.mmdb, 通过ftp上传到 /etc/clash/Country.mmdb 4.创建 systemd 脚本，脚本文件路径为 /etc/systemd/system/clash.service，内容如下：
[Unit]
Description=clash daemon [Service]
Type=simple
User=root
ExecStart=/usr/local/clash-linux-amd64-v1.14.0 -d /etc/clash/
Restart=on-failure [Install]
WantedBy=multi-user.target 5.重载 systemctl daemon
systemctl daemon-reload 6.配置代理网络信息
wget -O /etc/clash/config.yaml [自己的订阅链接] #注意 自己的订阅链接 大概率也是打不开的，所以直接浏览器打开链接，会自动下载一个yaml文件，把这个yaml文件重命名为config.yaml，然后ftp上传到 /etc/clash/config.yaml 7.设置系统代理，添加配置文件 /etc/profile.d/proxy.sh 并在其中写入如下内容：
export http_proxy="127.0.0.1:7890"
export https_proxy="127.0.0.1:7890"
export no_proxy="localhost, 127.0.0.1" 8.重载 /etc/profile 配置
source /etc/profile 9.启动 clash 服务，并设置为开机自动启
systemctl start clash
systemctl enable clash 10.查看7890端口情况
[root@worker1 clash]# lsof -i:7890
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
clash-lin 15539 root 7u IPv6 1115515191 0t0 TCP *:7890 (LISTEN) #说明服务没啥问题 11.测试google是否能够访问
[root@worker1 clash]# curl google.com
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>301 Moved</TITLE></HEAD><BODY>
<H1>301 Moved</H1>
The document has moved
<A HREF="http://www.google.com/">here</A>.
</BODY></HTML> #说明是ok的 12.至此整个服务器代理配置完成，当然还可以配置一个Clash客户端，这里就不弄了
13.如果想停止使用代理，执行如下命令即可:
[root@worker1 clash]# unset https_proxy
[root@worker1 clash]# unset http_proxy #不用管/etc/profile.d/proxy.sh 文件，然后就可以不使用代理访问站点；最好再把clash服务也停了 systemctl stop clash 14.如果想再次使用代理，执行如下命令即可:
source /etc/profile
systemctl start clash`}]},{path:"/content/linux/command/curl%E5%91%BD%E4%BB%A4%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%A3%E6%9E%90.html",title:"curl命令自定义解析",pathLocale:"/",contents:[{header:"",slug:"",content:`curl命令自定义解析:
root@tvm:~$ curl --header "Host: academy.web.test" 127.0.0.1 //本地将不同域名解析到同一个ip上的测试访问，格式： curl --header "Host: www.mydomain.com" SERVER_IP_HERE 这种方法在 HTTPS 的世界里会出现各种问题,解决办法是添加 --resolve 参数： 语法:
curl http[https]://www.mydomain.com --resolve www.mydomain.com[* 解析所有域名]:80[443]:<EXTERNAL-IP> 使用:
curl http://example.com/version --resolve example.com:80:127.0.0.1`}]},{path:"/content/linux/command/linux%E4%B8%8Bbase64%E8%A7%A3%E5%AF%86.html",title:"linux下base64解密",pathLocale:"/",contents:[{header:"",slug:"",content:`linux下base64解密:
echo "SGVsbG8sIFdvcmxkIQ==" | base64 --decode`}]},{path:"/content/linux/command/linux%E4%B8%8B%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E9%95%BF%E5%BA%A6%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2.html",title:"linux下生成随机长度的字符串",pathLocale:"/",contents:[{header:"",slug:"",content:"linux下生成随机长度的字符串,这里以生成16位或32位为例:\n[root@k8smaster ~]# echo `openssl rand -base64 50 | tr -dc A-Z-a-z-0-9 | head -c${1:-32}`\nPHiN0WRxghm5APvgDGpdlRVKdwhj4tcG\n[root@k8smaster ~]# echo `openssl rand -base64 50 | tr -dc A-Z-a-z-0-9 | head -c${1:-16}`\nPnIYarw1K18AfKiy"}]},{path:"/content/linux/command/linux%E4%B9%8Bgetent%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"linux之getent命令的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`linux之getent命令的使用:
root@ca4989b3147e:/var/www# getent passwd www-data
www-data:x:1000:33:www-data:/var/www/:/bin/bash 分析:
www-data：用户名
x：密码字段（现代系统一般用 x 表示密码已加密存储）
33：用户 ID (UID)
33：组 ID (GID)
www-data：用户描述信息
/var/www：用户的家目录
/usr/sbin/nologin：用户登录时的 Shell（通常表示该用户不能直接登录） root@ca4989b3147e:/var/www# root@ca4989b3147e:/var/www# getent group www-data
www-data:x:33: 分析:
www-data：组名
x：密码字段（组的密码，一般为空）
33：组 ID (GID)
空字段表示没有附加的成员信息 root@ca4989b3147e:/var/www# root@ca4989b3147e:/var/www# getent services http
http 80/tcp www 分析：
使用 getent services 查询指定服务的端口和协议 root@ca4989b3147e:/var/www# root@ca4989b3147e:/var/www# getent protocols tcp
tcp 6 TCP 分析:
使用 getent protocols 查询协议的相关信息`}]},{path:"/content/linux/command/linux%E4%B9%8Bll%E8%AF%A6%E8%A7%A3.html",title:"linux之ll详解",pathLocale:"/",contents:[{header:"",slug:"",content:`linux之ll详解:
ll--->ls -l
也可以加上-a: ls -al 用于列出目录中的所有文件和目录，包括隐藏文件和目录`}]},{path:"/content/linux/command/linux%E5%91%BD%E4%BB%A4shell%E4%B9%8Bsource%E5%91%BD%E4%BB%A4.html",title:"linux命令shell之source命令",pathLocale:"/",contents:[{header:"",slug:"",content:`linux命令shell之source命令:
语法：
Syntax . filename [arguments] source filename [arguments]
使用:
. ~/script.sh
解析:
这时候，点号"."表示"source"命令，它的作用是将指定文件中的命令都当作是当前shell的命令来执行，而不是新开一个子shell来执行。换句话说，使用"."可以让你在当前shell环境中执行脚本，从而让脚本中的变量和函数等在执行完脚本后仍然保留在当前shell中。 需要注意的是，使用"."命令执行脚本时，脚本文件必须具有可执行权限，否则会提示“Permission denied”错误。`}]},{path:"/content/linux/command/realpath%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"realpath命令的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`realpath命令的使用:用于获取指定目录或文件的绝对路径。
使用场景:编写 Shell 脚本中，通常会使用相对路径来指明文件，但有时候，我们需要用到绝对路径，此时可以使用 realpath 来获取。`}]},{path:"/content/linux/command/ubuntu22%E4%BD%BF%E7%94%A8netstat%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E4%BF%A1%E6%81%AF.html",title:"ubuntu22使用netstat查看进程信息",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22使用 netstat 查看进程信息:
$ netstat -tnulp
(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 21/nginx: worker pr tcp 0 0 127.0.0.11:34989 0.0.0.0:* LISTEN - tcp6 0 0 :::22 :::* LISTEN -
udp 0 0 127.0.0.11:51413 0.0.0.0:*`}]},{path:"/content/linux/command/ubuntu22%E5%B0%86%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E6%B7%BB%E5%8A%A0%E8%B6%85%E7%BA%A7%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E5%85%8D%E5%AF%86.html",title:"ubuntu22将普通用户添加超级管理员权限免密",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22将普通用户添加超级管理员权限免密:
官方推荐使用 sudo visudo /etc/sudoers， 然后修改 ctrl +o 回车 ctrl+x 即可 # User privilege specification
root ALL=(ALL:ALL) ALL # Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL # Allow members of group sudo to execute any command
%sudo ALL=(ALL:ALL) ALL
qinhong ALL=(ALL:ALL) NOPASSWD: ALL //可以使用 sudo 不用输密码，但是还是要sudo操作 使用:
tee /etc/sudoers.d/qinhong <<< 'qinhong ALL=(ALL) NOPASSWD: ALL' //另一种方式`}]},{path:"/content/linux/command/ubuntu22%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E4%B8%8B%E5%AD%90%E6%96%87%E4%BB%B6%E5%A4%B9%E7%9A%84%E6%95%B0%E9%87%8F.html",title:"ubuntu22查看文件下子文件夹的数量",pathLocale:"/",contents:[{header:"ubuntu22查看文件下子文件夹的数量",slug:"ubuntu22查看文件下子文件夹的数量",content:"在 Ubuntu 22.04（或其它 Linux 发行版）里，可以通过几种方式查看某个目录下子文件夹的数量。下面给你几种常见方法："},{header:"1. ls + grep + wc",slug:"_1-ls-grep-wc",content:`ls -l /path/to/dir | grep ^d | wc -l ls -l 显示目录详情
grep ^d 筛选出以 d 开头（表示目录）的行
wc -l 统计行数，即子目录数量 ⚠️ 这种方式只统计一级子目录。`},{header:"2. 使用 find（推荐）",slug:"_2-使用-find-推荐",content:`find /path/to/dir -mindepth 1 -maxdepth 1 -type d | wc -l -mindepth 1 表示不包括当前目录本身
-maxdepth 1 限制只看一层
-type d 表示目录
wc -l 统计数量 这个方法最准确，而且不会受 ls 输出格式影响。`},{header:"3. tree",slug:"_3-tree",content:`如果安装了 tree 工具：
tree -d -L 1 /path/to/dir | tail -n 1 -d 只显示目录
-L 1 限制层级为一层
最后一行会显示“X directories”，即子目录数量 如果没装，可以先安装：
sudo apt install tree`}]},{path:"/content/linux/command/ubuntu22%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E5%AD%97%E7%AC%A6%E4%B8%B2.html",title:"ubuntu22生成随机字符串",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22生成随机字符串:
$ openssl rand -base64 32 //这将生成一个包含32个字符的随机字符串，并以Base64编码输出
envqJ4DI/PRaZMozDQUyvc+sBwYjlgHiiexo2G1OkIQ=`}]},{path:"/content/linux/command/ubuntu%E4%B8%8BGnuTLS%E9%97%AE%E9%A2%98.html",title:"ubuntu下GnuTLS问题",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下GnuTLS问题：
ubuntu下使用git报：
GnuTLS recv error (-110): The TLS connection was non-properly terminated 解决办法:
apt-get install gnutls-bin
git config --global http.sslVerify false
git config --global http.postBuffer 1048576000`}]},{path:"/content/linux/command/ubuntu%E4%B8%8Bapt-get%E4%B8%8Edpkg%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"ubuntu下apt-get与dpkg的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下apt-get与dpkg的区别：
apt 与 dpkg 均为 ubuntu 下面的包管理工具。
dpkg 侧重于本地软件的管理。
apt 基于dpkg，侧重于远程包的下载和依赖管理，相当于 dpkg 的前端。 主要区别:
dpkg 仅用于安装本地的软件包，安装时不会安装依赖包，不解决依赖问题。
sudo dpkg -i <package_name>.deb
apt 默认会从远程仓库搜索包的名字，下载并安装，安装时会自动安装依赖包，并解决依赖问题
sudo apt install <package_name> 如果需要使用apt 从本地安装，需要在包名前指定路径，否则只从远程仓库查找。 sudo apt install <path>/<package_name>.deb`}]},{path:"/content/linux/command/ubuntu%E4%B8%8Bdeb%E6%96%87%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85.html",title:"ubuntu下deb文件的安装",pathLocale:"/",contents:[{header:"",slug:"",content:`记录一下.deb文件的安装以及卸载命令:
ubuntu下deb文件的安装:
sudo dpkg -i 软件包名.deb
卸载.deb文件：
先执行 dpkg --list 查看安装后的包名称
sudo dpkg -r 软件包名 [比如卸载 有到云笔记 ，sudo dpkg -r ynote-desktop]`}]},{path:"/content/linux/command/ubuntu%E4%B8%8Bnetstat%E5%91%BD%E4%BB%A4%E6%89%BE%E4%B8%8D%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"ubuntu下netstat命令找不到的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下netstat命令找不到的问题：
vagrant@homestead:~$ netstat -a
-bash: netstat: command not found 解决办法:
使用netstat需要安装net-tools包
vagrant@homestead:~$ sudo apt install net-tools
然后就可以用了`}]},{path:"/content/linux/command/ubuntu%E4%B8%8Bunzip%E5%91%BD%E4%BB%A4%E8%A7%A3%E5%8E%8B%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98.html",title:"ubuntu下unzip命令解压中文乱码问题",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下unzip命令解压中文乱码问题：
来在windows上的zip文件, 在CentOS上使用unzip直接解压会显示乱码,
因为windows简体中文版的操作系统一般上用的是GBK编码, 所以会导致这个问题,
可以使用-O参数来解决, 即: unzip -O GBK ./测试文件.zip`}]},{path:"/content/linux/command/ubuntu%E4%B8%8Bvim%E6%96%B9%E5%90%91%E9%94%AE%E5%8F%98ABCD%E9%97%AE%E9%A2%98.html",title:"ubuntu下vim方向键变ABCD问题",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下vim方向键变ABCD问题：
只要依次执行以下两个命令即可解决： 第一步： sudo apt-get remove vim-common 第二步： sudo apt-get install vim`}]},{path:"/content/linux/command/ubuntu%E4%B8%8B%E5%A4%9A%E7%89%88%E6%9C%ACPHP%E5%88%87%E6%8D%A2.html",title:"ubuntu下多版本PHP切换",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下多版本PHP切换：
root@k8s-server:$ update-alternatives --config php There are 2 choices for the alternative php (providing /usr/bin/php). Selection Path Priority Status
------------------------------------------------------------ 0 /usr/bin/php8.1 81 auto mode
* 1 /usr/bin/php7.4 74 manual mode 2 /usr/bin/php8.1 81 manual mode Press <enter> to keep the current choice[*], or type selection number: 1
update-alternatives: using /usr/bin/php7.4 to provide /usr/bin/php (php) in manual mode 然后查看/usr/bin/php，其对应的软连接为 /etc/alternatives/php，说明是可选择的
/usr/bin/php---->/etc/alternatives/php 查看/etc/alternatives/php，发现又会指向真正设置的版本:
$ ls -l /etc/alternatives/php
lrwxrwxrwx 1 root root 15 12月 12 09:39 /etc/alternatives/php -> /usr/bin/php7.4 或者通过 readlink 命令查看:
$ readlink -f /etc/alternatives/php
/usr/bin/php7.4 不同版本php状态查看:
$ systemctl status php8.1-fpm
$ systemctl status php7.4-fpm`}]},{path:"/content/linux/command/ubuntu%E4%B8%8B%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E7%89%88%E6%9C%AC.html",title:"ubuntu下查看系统版本",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下查看系统版本：
root@user-1:~/Downloads$ lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 22.04.1 LTS
Release:	22.04
Codename:	jammy`}]},{path:"/content/linux/command/ubuntu%E4%B9%8B%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E6%9C%8D%E5%8A%A1.html",title:"ubuntu之查看所有服务",pathLocale:"/",contents:[{header:"ubuntu之查看所有服务:",slug:"ubuntu之查看所有服务",content:`$ systemctl list-unit-files -t service UNIT FILE STATE VENDOR PRESET
accounts-daemon.service enabled enabled acpid.service disabled enabled alsa-restore.service static - alsa-state.service static - alsa-utils.service masked enabled anacron.service enabled enabled apparmor.service enabled enabled apport-autoreport.service static - apport-forward@.service static - apport.service generated - apt-daily-upgrade.service static - apt-daily.service static - apt-news.service static - autovt@.service alias - avahi-daemon.service enabled enabled bluetooth.service enabled enabled bolt.service static - brltty-udev.service static - brltty.service disabled enabled colord.service static - ...
...`},{header:"ubuntu之查指定服务运行状态",slug:"ubuntu之查指定服务运行状态",content:`$ ps aux | grep nginx
root 1155 0.0 0.0 84836 2760 ? Ss 13:35 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on;
root+ 1156 0.0 0.0 85500 6472 ? S 13:35 0:00 nginx: worker process
root+ 1157 0.0 0.0 85500 6472 ? S 13:35 0:00 nginx: worker process
root+ 1158 0.0 0.0 85500 6472 ? S 13:35 0:00 nginx: worker process
root+ 1159 0.0 0.0 85500 6600 ? S 13:35 0:00 nginx: worker process
root+ 1160 0.0 0.0 85500 6344 ? S 13:35 0:00 nginx: worker process
root+ 1161 0.0 0.0 85500 6344 ? S 13:35 0:00 nginx: worker process
root+ 1162 0.0 0.0 85500 6344 ? S 13:35 0:00 nginx: worker process
...
... // 参数解析
a → 显示所有终端下的进程，包括其他用户的。
u → 以用户为中心的格式显示，包含用户、CPU/内存占用等。
x → 显示没有控制终端的进程（例如守护进程）。`},{header:"ubuntu之查所有服务运行状态",slug:"ubuntu之查所有服务运行状态",content:`$ ps aux
USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
root 1 0.0 0.0 167468 11956 ? Ss 13:35 0:05 /sbin/init splash
root 2 0.0 0.0 0 0 ? S 13:35 0:00 [kthreadd]
root 3 0.0 0.0 0 0 ? S 13:35 0:00 [pool_workqueue_release]
root 4 0.0 0.0 0 0 ? I< 13:35 0:00 [kworker/R-rcu_g]
root 5 0.0 0.0 0 0 ? I< 13:35 0:00 [kworker/R-rcu_p]
...
... //参数解析
USER → 进程所属用户
PID → 进程 ID
%CPU → 占用 CPU 百分比
%MEM → 占用物理内存百分比
VSZ → 占用的虚拟内存大小（KB）
RSS → 实际常驻内存大小（KB）
TTY → 进程的控制终端（? 表示无终端）
STAT → 进程状态（例如 S=睡眠，R=运行，Z=僵尸，T=停止）
START → 进程启动时间
TIME → 占用 CPU 的累计时间
COMMAND → 启动进程的命令`},{header:"ubuntu之查指定端口",slug:"ubuntu之查指定端口",content:`$ netstat -tnlp | grep 80
(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)
tcp 0 0 0.0.0.0:8083 0.0.0.0:* LISTEN 1156/nginx: worker tcp 0 0 0.0.0.0:9080 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp6 0 0 :::9080 :::* LISTEN - tcp6 0 0 :::80 :::* LISTEN - ...
... // 参数解析
-t → TCP
-n → 显示数字地址（不做域名反查）
-l → 只显示监听状态的端口
-p → 显示对应的进程 PID/程序名`},{header:"ubuntu之查所有端口",slug:"ubuntu之查所有端口",content:`$ netstat -tnlp
(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:43817 0.0.0.0:* LISTEN 8127/clash-linux tcp 0 0 127.0.0.1:11211 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:8081 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:8083 0.0.0.0:* LISTEN 1156/nginx: worker tcp 0 0 0.0.0.0:8109 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:8108 0.0.0.0:* LISTEN - ...
... // 参数解析
Proto → 协议类型 tcp → IPv4 TCP tcp6 → IPv6 TCP
Recv-Q → 接收队列中未被应用程序取走的数据（一般为 0，如果不是 0，可能表示应用处理不过来）
Send-Q → 发送队列中未被对方确认的数据（一般为 0，如果不是 0，可能表示网络拥塞或应用未读取）
Local Address → 本地监听的地址和端口 0.0.0.0:22 → 监听所有 IPv4 地址的 22 端口 :::80 → 监听所有 IPv6 地址的 80 端口
Foreign Address → 对端地址（监听状态下一般是 *，表示未建立连接）
State → 当前连接状态 常见值：LISTEN、ESTABLISHED、TIME_WAIT、CLOSE_WAIT
PID/Program name → 占用端口的进程 PID 和程序名 1234/sshd 表示 PID=1234 的 sshd 占用 常见情况解释 0.0.0.0:80
→ 监听所有网卡的 IPv4 地址 80 端口（外部可访问）。 127.0.0.1:3306
→ 仅监听本机回环地址（外部不能访问，只能本机连接）。 :::443
→ 监听所有 IPv6 地址的 443 端口`}]},{path:"/content/linux/command/ubuntu%E4%B9%8B%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E7%A8%8B%E5%BA%8F%E8%BF%9B%E7%A8%8B%E4%BB%A5%E5%8F%8A%E5%85%B3%E9%97%AD%E6%8C%87%E5%AE%9A%E7%A8%8B%E5%BA%8F%E8%BF%9B%E7%A8%8B.html",title:"ubuntu之查看所有程序进程以及关闭指定程序进程",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu之查看所有程序进程以及关闭指定程序进程，通过如下命令可以打开一个GUI窗口:
root@k8s:~$ gnome-system-monitor`}]},{path:"/content/linux/command/ubuntu%E5%AE%89%E8%A3%85clash.html",title:"ubuntu安装clash",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu安装clash:
1.进入：https://github.com/Dreamacro/clash，选择合适的版本下载，我这里选择： clash-linux-amd64-v1.16.0.gz 版本 2.解压缩：gzip -d clash-linux-amd64-v1.16.0.gz 3.添加可执行权限： chmod +x clash-linux-amd64-v1.16.0 4.移动到bin目录下： sudo mv clash-linux-amd64-v1.16.0 /usr/local/bin/clash 5.查看版本：clash -v 6.执行命令: clash，可能回去要一个mmb文件，默认会自动下载 7.添加配置文件到yaml： wget -O config.yaml https://v3.45678.xyz/link/pyokPnvoerX5aDW8?clash=1 //代理链接 8.当上面配置好了，再次运行clash即可，如下：
guoshipeng@tianyi510s:~$ clash INFO[0000] Start initial compatible provider AsianTV INFO[0000] Start initial compatible provider GlobalTV INFO[0000] Start initial compatible provider Others INFO[0000] Start initial compatible provider Proxy INFO[0000] Start initial compatible provider Domestic INFO[0000] RESTful API listening at: [::]:9090 9.会发现这个官方版本，没有clash的客户端，使用了网上的各种客户端，都不哈用，最后还是看国人版的:https://github.com/Fndroid/clash_for_windows_pkg/releases
使用步骤如下:
进入到local目录: cd /usr/local
下载最新版本:https://github.com/Fndroid/clash_for_windows_pkg/releases/download/0.20.24/Clash.for.Windows-0.20.24-x64-linux.tar.gz
解压缩:sudo tar zxvf Clash.for.Windows-0.20.24-x64-linux.tar.gz
将这个长文件移动到clash, sudo mv 'Clash for Windows-0.20.24-x64-linux' clash
cd ./clash
执行: ./cfw 即可弹出可视化框，在Profiles的输入Download from a URL链接，然后下载，即可加载所有代理的配置文件`}]},{path:"/content/linux/command/ubuntu%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6.html",title:"ubuntu安装软件",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu安装与删除软件：
sudo dpkg -i sogoupinyin_4.0.0.1605_amd64.deb sudo dpkg -r virtualbox-6.1 sudo dpkg -l //显示所有已安装的Deb包，同时显示版本号以及简短说明`}]},{path:"/content/linux/command/ubuntu%E6%9F%A5%E7%9C%8Bcup%E4%BB%A5%E5%8F%8A%E5%86%85%E5%AD%98%E4%BF%A1%E6%81%AF.html",title:"ubuntu查看cup以及内存信息",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu查看cup以及内存信息:
shipengguo@dev_env:~$ cat /proc/cpuinfo processor	: 0
vendor_id	: GenuineIntel
cpu family	: 6
model : 85
model name	: Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz
stepping	: 7
microcode	: 0x5003604
cpu MHz : 2400.000
cache size	: 14080 KB
physical id	: 0
siblings	: 20
core id : 0
cpu cores	: 10
apicid : 0
initial apicid	: 0
fpu : yes
fpu_exception	: yes
cpuid level	: 22
wp : yes
...
... shipengguo@dev_env:~$ cat /proc/meminfo
MemTotal: 247272116 kB
MemFree: 32688360 kB
MemAvailable: 113584576 kB
Buffers: 38315172 kB
Cached: 30518784 kB
SwapCached: 0 kB
...
...`}]},{path:"/content/linux/command/ubuntu%E8%AE%BE%E7%BD%AE%E7%82%B9%E5%87%BB%E5%9B%BE%E6%A0%87%E6%9C%80%E5%B0%8F%E5%8C%96.html",title:"ubuntu设置点击图标最小化",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu设置点击图标最小化:
guoshipeng@tianyi510s:/usr/local$ gsettings range org.gnome.shell.extensions.dash-to-dock click-action
enum
'skip'
'minimize'
'launch'
'cycle-windows'
'minimize-or-overview'
'previews'
'minimize-or-previews'
'focus-or-previews'
'focus-minimize-or-previews'
'quit' 设置为minimize:
guoshipeng@tianyi510s:/usr/local$ gsettings set org.gnome.shell.extensions.dash-to-dock click-action 'minimize'`}]},{path:"/content/linux/command/vagrant%E6%96%B0%E5%A2%9Eroot%E7%94%A8%E6%88%B7.html",title:"vagrant新增root用户",pathLocale:"/",contents:[{header:"",slug:"",content:"搭配好vagrant系统后，默认都是使用vagrant用户登录的，如果想改用root用户登录的话，可以使用下面的几条命令 根据提示输入两次新密码 sudo passwd root 切换到root用户 su root //根据自己输入的密码，登录root用户"}]},{path:"/content/linux/command/vim%E5%88%A0%E9%99%A4%E8%A1%8C%E6%95%B0%E6%8D%AE.html",title:"vim删除行数据",pathLocale:"/",contents:[{header:"",slug:"",content:"vim删除行数据: 删除当前行后面所有的行： ,$d 删除第一行到当前行： 1,.d"}]},{path:"/content/linux/command/vim%E5%A4%9A%E8%A1%8C%E6%B3%A8%E9%87%8A_%E5%8F%96%E6%B6%88%E5%A4%9A%E8%A1%8C%E6%B3%A8%E9%87%8A_%E5%A4%9A%E8%A1%8C%E5%A4%8D%E5%88%B6_%E5%A4%9A%E8%A1%8C%E5%88%A0%E9%99%A4.html",title:"vim多行注释_取消多行注释_多行复制_多行删除",pathLocale:"/",contents:[{header:"",slug:"",content:`vim多行注释，取消多行注释，多行复制，多行删除:
多行注释
进入命令行模式，按ctrl + v进入 visual block模式（可视快模式），然后按j, 或者k选中多行，把需要注释的行标记起来 按大写字母i，再插入注释符，例如# 按esc键就会全部注释了 取消多行注释：
进入命令行模式，按ctrl + v进入 visual block模式（可视快模式），按小写字母L横向选中列的个数，例如 // 需要选中2列 按字母j，或者k选中注释符号 按d键或x键就可全部取消注释 多行复制
如果知道需要复制几行
将光标移至需要复制的内容的第一行，计算需要复制多少行，比如需要复制5行 按下5yy，将光标移至需要复制的地方，按下p粘贴 如果不知道需要复制几行
有时候不想费劲看多少行或复制大量行时，可以使用标签来替代
1. 光标移到起始行，输入ma
2. 光标移到结束行，输入mb
3. 光标移到粘贴行，输入mc
4. 然后 :’a,’b co ‘c 把 co 改成 m 就成剪切了 多行删除
跟多行复制的情况差不多，第一种方法里5yy改成5dd就行，第二种方法里，或者用:5, 9 de。`}]},{path:"/content/linux/nginx/NGINX%E5%92%8CHAProxy%E5%AF%B9%E6%AF%94.html",title:"NGINX和HAProxy对比",pathLocale:"/",contents:[{header:"NGINX和HAProxy对比",slug:"nginx和haproxy对比",content:"从使用场景、作用侧重点、以及实际应用举例来对比 NGINX 和 HAProxy，详细对比："},{header:"1. NGINX",slug:"_1-nginx",content:`类型：Web 服务器 + 反向代理 + 负载均衡器
核心功能： 静态文件服务（如 HTML、CSS、JS、图片）
动态请求反向代理（PHP、Python、Node.js 等后端服务）
简单的负载均衡（轮询、权重、IP 哈希）
SSL/TLS 终端（HTTPS）
缓存功能（静态资源缓存、代理缓存） 典型使用场景： 网站前端服务器 直接服务静态文件，减轻后端压力
代理动态请求到后端应用服务器
示例：Nginx + PHP-FPM 架构 反向代理和负载均衡 将请求分发到多个后端应用服务器
示例：前端 NGINX 反向代理到多个 Node.js 服务 SSL/TLS 终端 NGINX 支持 HTTPS 卸载，后端服务可以只处理 HTTP
示例：提供 HTTPS 网站访问，同时内部通信保持 HTTP 缓存和压缩 静态资源缓存、gzip 压缩、HTTP/2 支持
示例：CDN 边缘缓存 + NGINX 提供加速服务 总结：NGINX 更偏向“Web 层面”，处理 HTTP/HTTPS 流量和静态文件，同时提供简单的负载均衡和代理功能。`},{header:"2. HAProxy",slug:"_2-haproxy",content:`类型：高性能 TCP/HTTP 负载均衡器
核心功能： 高性能 TCP/HTTP/HTTPS 负载均衡
支持健康检查（health check）
高级路由（基于 URL、Cookie、Header 等）
会话保持（sticky session）
支持大规模集群和高并发 典型使用场景： 高并发应用负载均衡 面向大量请求，快速转发 TCP 或 HTTP 流量
示例：大型电商网站，前端 HAProxy 分发请求到多台 Web 服务 数据库或 TCP 服务负载均衡 处理非 HTTP 协议流量
示例：MySQL 主从读写分离，HAProxy 做读写分流 健康检查和故障转移 自动检测后端服务健康状态，剔除不可用节点
示例：集群服务宕机时自动切换请求到可用节点 高可用架构 支持 active/passive、active/active HA 配置
示例：配合 Keepalived 做虚拟 IP 漂移，实现无缝切换 总结：HAProxy 更偏向“负载均衡和高可用层”，适合 TCP/HTTP 流量的大规模分发、故障转移和高性能要求场景。`},{header:"3. 对比总结表",slug:"_3-对比总结表",content:`特性
NGINX
HAProxy 主要功能
Web 服务器、HTTP 反向代理、简单负载均衡
高性能 TCP/HTTP 负载均衡 支持协议
HTTP/HTTPS、少量 TCP
TCP、HTTP/HTTPS、SSL 适合场景
静态文件服务、Web 前端反向代理、SSL 卸载
高并发请求分发、数据库/TCP 负载均衡、健康检查 性能
高性能，但处理纯 TCP 负载一般不如 HAProxy
极高性能，专注负载均衡和健康检查 配置复杂度
简单到中等
中等到高（特别是复杂路由和 HA 场景） 高可用支持
基本依赖第三方（Keepalived 等）
内置健康检查 + HA 配合 Keepalived 可高可用`},{header:"4. 实际组合场景",slug:"_4-实际组合场景",content:`在大型互联网项目中，NGINX + HAProxy 的组合也很常见： HAProxy 作为第一层负载均衡器，处理 TCP/HTTP 高并发请求，并做健康检查。
NGINX 作为第二层反向代理，处理 HTTPS、静态资源、缓存和路由到具体的后端应用。
后端应用（如 Node.js、PHP-FPM）实际处理业务逻辑。 优点：HAProxy 保证高性能负载均衡，NGINX 负责 HTTP 层优化和静态资源加速。`}]},{path:"/content/linux/nginx/nginx403%E9%97%AE%E9%A2%98.html",title:"nginx403问题",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx403问题：
查看日志：
$ vim /var/log/nginx/error.log
$ vim /var/log/nginx/access.log 主要问题：
①file not found，还是user:group的问题
root@k8s-server:/etc/php/8.1/fpm$ ll
total 96
drwxr-xr-x 4 root root 4096 11月 3 17:20 ./
drwxr-xr-x 5 root root 4096 11月 3 10:05 ../
drwxr-xr-x 2 root root 4096 11月 3 12:16 conf.d/
-rw-r--r-- 1 root root 5457 11月 3 17:16 php-fpm.conf
-rw-r--r-- 1 root root 72928 9月 15 19:30 php.ini
drwxr-xr-x 2 root root 4096 11月 3 17:21 pool.d/ //php-fpm.conf 里不能直接配置 user:group ,需要在 pool.d 里的www.conf 里配置和项目一样的user:group
root@k8s-server:/etc/php/8.1/fpm$ pwd
/etc/php/8.1/fpm ② 502 bad gatwway
root@k8s-server:/run/php$ ll
total 4
drwxr-xr-x 2 www-data www-data 100 11月 3 17:21 ./
drwxr-xr-x 37 root root 1000 11月 3 17:02 ../
-rw-r--r-- 1 root root 5 11月 3 17:21 php8.1-fpm.pid
srw-rw---- 1 mdpi mdpi 0 11月 3 17:21 php8.1-fpm.sock= // 这个的用户名和用户组不对，统一改为项目的user:group,nginx.conf 里面也要改
lrwxrwxrwx 1 root root 30 11月 3 10:05 php-fpm.sock -> /etc/alternatives/php-fpm.sock=`}]},{path:"/content/linux/nginx/nginx%E4%B8%8A%E4%BC%A0%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E9%97%AE%E9%A2%98.html",title:"nginx上传报错问题问题",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx上传报错问题问题：
nginx 上传图片报：
open() "/var/lib/nginx/tmp/client_body/0000001950" failed (13: Permission denied), client:...... 这肯定是目录权限的问题，排查发现 .../tmp 的目录权限和nginx.conf里user配置的相同，但是 .../nginx 的目录权限和nginx.conf里user配置不同,
所以通过命令: cd /var/lib/nginx && chown -R jenkins ./ 修改 .../nginx的user为jenkins即可`}]},{path:"/content/linux/nginx/nginx%E4%B9%8Blocation%E9%85%8D%E7%BD%AE%E6%A0%BC%E5%BC%8F.html",title:"nginx之location配置格式",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx之location配置格式:
location 语法
Location 块通过指定模式来与客户端请求的URI相匹配。
Location基本语法： 1.匹配 URI 类型，有四种参数可选，当然也可以不带参数。
location [ = | ~ | ~* | ^~ ] /URI { … } 2.命名location，用@来标识，类似于定义goto语句块。
location @/name/ { … } 参数解释: location 后参数类型
解释 空
location 后没有参数直接跟着 标准 URI，表示前缀匹配，代表跟请求中的 URI 从头开始匹配。 =
用于标准 URI 前，要求请求字符串与其精准匹配，成功则立即处理，nginx停止搜索其他匹配。 ^~
用于标准 URI 前，并要求一旦匹配到就会立即处理，不再去匹配其他的那些个正则 URI，一般用来匹配目录 ~
用于正则 URI 前，表示 URI 包含正则表达式， 区分大小写 ~*
用于正则 URI 前， 表示 URI 包含正则表达式， 不区分大小写 @
@ 定义一个命名的 location，@ 定义的locaiton名字一般用在内部定向，这个在请求静态资源(图片 pdf文件等)用的比较多 匹配顺序: location = # 精准匹配
location ^~ # 带参前缀匹配
location ~ # 正则匹配（区分大小写）
location ~* # 正则匹配（不区分大小写）
location /a # 普通前缀匹配，优先级低于带参数前缀匹配。
location / # 任何没有匹配成功的，都会匹配这里处理`}]},{path:"/content/linux/nginx/nginx%E5%87%BA%E7%8E%B0413.html",title:"nginx出现413",pathLocale:"/",contents:[{header:"",slug:"",content:`在做上传的时候，尤其会出现413 Request Entity Too Large的问题，解决办法如下:
打开nginx主配置文件nginx.conf，一般在/usr/local/nginx/conf/nginx.conf这个位置，找到http{}段，修改或者添加:
client_max_body_size 30m;`}]},{path:"/content/linux/nginx/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE.html",title:"nginx反向代理配置",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx反向代理配置:
#pass requests to port 4444 which is used by the Dockerized version of the Web App v2
server{ listen 80; server_name qinhong-v2.test; location / { proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_pass http://127.0.0.1:4448; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; }
}`}]},{path:"/content/linux/nginx/nginx%E5%A4%9A%E4%B8%AA80%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E9%97%AE%E9%A2%98.html",title:"nginx多个80端口占用问题",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx多个80端口占用问题： 如下server 配置：
server { listen 80 default_server; #这里有个default_server标识 listen [::]:80 default_server; #这里有个default_server标识 root /home/www/blog/public; #网站根目录，既index.php入口文件所在目录，结尾不加 / index index.php index.html; server_name www.front.test; # 域名或者ip地址 location / { try_files $uri $uri/ /index.php?$query_string; #larvel优雅连接。请根据实际配置 } location ~ \\.php$ { # 支持php include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.0-fpm.sock; # 这里对应着上面安装的php7.0 } } 如果还有其它server 需要使用 80 端口，那么需要把 default_server 去掉 即可，否则就会报错`}]},{path:"/content/linux/nginx/nginx%E7%9A%84latest%E5%92%8Calpine%E5%8C%BA%E5%88%AB.html",title:"nginx的latest和alpine区别",pathLocale:"/",contents:[{header:"",slug:"",content:"nginx 相关的 docker 镜像标签：latest 和 alpine 区别和特点:\n1. nginx:latest - 这是 Nginx 的官方 Docker 镜像的默认版本。 - 通常基于 Debian 操作系统构建。 - 包含完整的 Nginx 安装，以及常用的库和工具。 - 镜像尺寸较大，通常在 100-150MB 左右。 - 适合需要完整功能和工具集的场景。 2. nginx:alpine - 这是基于 Alpine Linux 构建的 Nginx 镜像。 - Alpine 是一个轻量级的 Linux 发行版，以其小体积和安全性著称。 - 镜像尺寸显著小于 `latest` 版本，通常只有 20-30MB 左右。 - 包含最小化的 Nginx 安装，仅包含运行所需的基本组件。 - 适合对镜像大小敏感的场景，如微服务架构或资源受限的环境。 主要区别： 1. 镜像大小：Alpine 版本明显更小，有利于快速部署和节省存储空间。\n2. 基础系统：`latest` 基于 Debian，而 `alpine` 基于 Alpine Linux。\n3. 包含的工具：`latest` 版本包含更多的工具和库，而 `alpine` 版本更加精简。\n4. 安全更新：Alpine 版本可能在某些情况下获得更快的安全更新。\n5. 兼容性：某些依赖特定 Linux 发行版的应用可能在 Alpine 版本上遇到兼容性问题。 选择建议：\n- 如果您需要最小化的镜像体积和快速部署，选择 `alpine` 版本。\n- 如果您需要更多的工具和库，或者担心兼容性问题，选择 `latest` 版本。 需要注意的是，使用 `latest` 标签可能会导致不可预测的更新，因为它总是指向最新版本。在生产环境中，建议使用特定的版本标签以确保一致性和可重复性。"}]},{path:"/content/linux/nginx/nginx%E7%AE%80%E5%8D%95%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6.html",title:"nginx简单访问控制",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx简单访问控制的两种实现方式:
1、auth_basic 本机认证
2、ngx_http_auth_request_module 第三方认证
第一种实现方式:
server { listen 80; server_name local.server.com; auth_basic "User Authentication"; auth_basic_user_file /usr/local/nginx-1.10.2/conf/pass.db; //需要维护 pass.db 文件 location / { root /data/www; index index.html; }
} 第二种实现方式: 编译 Nginx 时需要添加该模块 --with-http_auth_request_module
该模块可以将客户端输入的用户名、密码 username:password 通过 Base64 编码后写入 Request Headers 中
例如：zhang:123456 -> Authorization:Basic d2FuZzp3YW5n=
然后通过第三方程序解码后跟数据库中用户名、密码进行比较，Nginx 服务器通过 header 的返回状态判断是否认证通过。 使用:
server { listen 80; server_name local.server.com; auth_request /auth; location / { root html; index index.html; } location /auth { proxy_pass http://auth.gsplovedss.xyz/AuthRequestServer.php; proxy_pass_request_body off; proxy_set_header Content-Length ""; proxy_set_header X-Original-URI $request_uri; }
} AuthRequestServer.php的代码如下:
<?php if(isset($_SERVER['PHP_AUTH_USER'], $_SERVER['PHP_AUTH_PW'])){ $username = $_SERVER['PHP_AUTH_USER']; $password = $_SERVER['PHP_AUTH_PW']; if ($username == 'zhang' && $password == '123456'){ return true; }
} header('WWW-Authenticate: Basic realm="Auth Server"');
header('HTTP/1.0 401 Unauthorized');`}]},{path:"/content/linux/nginx/nginx%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%E9%85%8D%E7%BD%AE.html",title:"nginx跨域问题配置",pathLocale:"/",contents:[{header:"",slug:"",content:"nginx跨域问题配置: # Virtual Host Configs ## add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;"}]},{path:"/content/linux/nginx/nginx%E9%85%8D%E7%BD%AEserver.html",title:"nginx配置server",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx配置server：
问题：现在执行vagrant up 在/etc/nginx/sites-available 下不会生成配置文件，连default也没有，很奇怪，所以需要手动配置: server { listen 80 default_server; listen [::]:80 default_server; root /home/www/blog/public; #网站根目录，既index.php入口文件所在目录，结尾不加 / index index.php index.html; server_name www.front.test; # 域名或者ip地址 location / { try_files $uri $uri/ /index.php?$query_string; #larvel优雅连接。请根据实际配置 } location ~ \\.php$ { # 支持php include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.0-fpm.sock; # 这里对应着上面安装的php7.0 } } 更改sites-available以后在 /etc/nginx/sites-enabled 目录下建立一个软链接: ln -s /etc/nginx/sites-available/www.front.test.conf /etc/nginx/sites-enabled/www.front.test.conf`}]},{path:"/content/front/js/HttP%E4%B9%8BPATCH%E8%AF%B7%E6%B1%82.html",title:"HttP之PATCH请求",pathLocale:"/",contents:[{header:"",slug:"",content:`HttP之PATCH请求，这个平时用的不是很多，所以这里记录一下
1.PUT 和 PATCH 根据约定( Convention )，PUT 方法用于更新数据，PATCH 方法也用于更新数据，为什么 PUT 方法是幂等的而 PATCH 方法不是幂等的呢？我们继续研究文档（第54页） The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI. PUT 方法将请求所包含的实体存储在所提供的 Request-URI 下。如果该 URI 指代一个已经存在的资源，那么请求中的实体应该被视为保存在原服务器上的实体的修改版本。如果 Request-URI 没有指向一个现有资源，
并且该 URI 可以被发送请求的用户代理定义为新资源，则原服务器可以使用该 URI 来创建资源。 The PATCH method requests that a set of changes described in the request entity be applied to the resource identified by the Request-URI. The set of changes is represented in a format called a “patch document” identified by a media type. If the Request-URI does not point to an existing resource, the server MAY create a new resource, depending on the patch document type (whether it can logically modify a null resource) and permissions, etc. PATCH 方法请求将一组描述在请求实体里的更改应用到 Request-URI 标志的资源。这组更改以称为 “补丁文档” 的格式（该格式由媒体类型标志）表示，如果 Request-URI 未指向现有资源，服务器可能根据
补丁文档的类型（是否可以在逻辑上修改空资源）和权限等来创建一个新资源。 幂等性：用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。
除了 POST和 PATCH ，其它的请求方法(GET PUT DELETE TRACE OPTIONS 等) 都是幂等的.
各个方法的详细说明:
GET
特点：安全、幂等。
说明：从服务器端获取数据，请求body在地址栏上。
作用：获取资源。 HEAD
特点：安全、幂等。
说明：与get方法类似，但不返回message body内容，仅仅是获得获取资源的部分信息（content-type、content-length）。
作用：restful框架中较少使用。 POST
特点：非安全、非幂等。
说明：向服务器端提交数据，请求数据在报文body里；
发送一个修改数据的请求，需求数据要重新新创建。
作用：用于创建子资源。创建、更新、删除、查询资源均可使用。 PUT
特点：非安全、幂等。
说明：向服务器端提交数据，请求数据在报文body里；
发送一个修改数据的请求，需求数据更新（全部更新）。
作用：用于创建、更新资源。 DELETE
特点：非安全、幂等。
说明：向服务器端提交数据，请求数据在报文body里；
发送一个删除数据的请求。
作用：删除资源。 OPTIONS
特点：安全、幂等。
作用：用于url验证，验证接口服务是否正常。 TRACE
特点：安全、幂等。
说明：维基百科“回显服务器收到的请求，这样客户端可以看到（如果有）哪一些改变或者添加已经被中间服务器实现。”
作用：restful框架中较少使用。 PATCH
特点：非安全、幂等。
说明：向服务器端提交数据，请求数据在报文body里；
与PUT类似，发送一个修改数据的请求，区别在于PATCH代表部分更新；
后来提出的接口方法，使用时可能去要验证客户端和服务端是否支持；
作用：用于创建、更新资源。局部更新，比如：user对象，只更改了name属性，那么他的其他属性值是不会变的，如果用post，那么其他属性值会被设置为null（全局更新）`}]},{path:"/content/front/js/JavaScript%E4%B9%8B%E5%AF%B9%E8%B1%A1%E8%A7%A3%E6%9E%84%E5%92%8C%E9%87%8D%E5%91%BD%E5%90%8D%E7%9A%84%E8%AF%AD%E6%B3%95.html",title:"JavaScript之对象解构和重命名的语法",pathLocale:"/",contents:[{header:"",slug:"",content:`JavaScript之对象解构和重命名的语法: 对象解构： 对象解构允许你从对象中提取属性并赋值给变量。基本语法如下：
const { property1, property2 } = object; 这等同于：
const property1 = object.property1;
const property2 = object.property2; 重命名语法： 在解构过程中，你可以给解构出来的属性指定一个新的名字。语法如下：
const { originalName: newName } = object; 这等同于：
const newName = object.originalName; 组合使用： 你可以在一个解构语句中同时使用普通解构和重命名：
const { property1, originalName: newName, property2 } = object; 在您的代码中的应用： const { shouldShowLoader: isLoading, heading, sidebarLinks } = storeToRefs(eventDashboardStore); 这行代码做了以下事情： 从 storeToRefs(eventDashboardStore) 返回的对象中提取 shouldShowLoader 属性，并将其重命名为 isLoading
同时提取 heading 和 sidebarLinks 属性，保持原名 这种语法的主要优点是： 代码更简洁
允许你在使用时给属性一个更有意义或更符合当前上下文的名字
可以避免命名冲突`}]},{path:"/content/front/js/Nuxt3%E4%B8%8B%E4%BD%BF%E7%94%A8sidebase_nuxt_auth%E7%AE%A1%E7%90%86%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E4%BF%A1%E6%81%AF%E6%93%8D%E4%BD%9C.html",title:"Nuxt3下使用@sidebase_nuxt-auth管理用户登录信息操作",pathLocale:"/",contents:[{header:"",slug:"",content:`Nuxt3下使用@sidebase_nuxt-auth管理用户登录信息操作: auth: { baseURL: "/api/auth", // https://sidebase.io/nuxt-auth/configuration/nuxt-config -> local provider provider: { type: "refresh", //这里把 local 改为 refresh 即可有 无状态刷新 token 的功能 endpoints: { signIn: { path: "/login", method: "post" }, getSession: { path: "/user", method: "get" }, // signOut: { path: "/logout", method: "get" }, refresh: { path: "/refresh", method: "post" }, // 这个需要打开，如果使用 local 的话，这个可以注释掉, 对应的下面的也要注释掉 }, pages: { login: "/auth/login", }, token: { signInResponseTokenPointer: "/token/accessToken", sameSiteAttribute: "lax", }, // refresh 下这个也需要打开 refreshToken: { signInResponseRefreshTokenPointer: "/token/refreshToken", }, // 这个就是 data 数据， 可以通过 getSession() 重新获取最新的用户数据 sessionDataType: { id: "string", email: "string", first_name: "string", last_name: "string", }, }, }, server/api/refresh.post.ts文件: export default defineEventHandler(async (event) => { const config = useRuntimeConfig(); const body = await readBody(event); const unauthenticatedResponse = { token: { accessToken: "", refreshToken: "", }, }; if (!body.refreshToken) { return unauthenticatedResponse; } try { const data = await $fetch<{ token: string; refresh_token: string }>( "/api/token/refresh", { method: "POST", headers: { "X-API-TOKEN": config.duoxiaozhan.apiToken }, body: { refresh_token: body.refreshToken, }, baseURL: config.duoxiaozhan.baseUrl, } ); return { token: { accessToken: data.token, refreshToken: data.refresh_token, }, }; } catch (error: any) { return unauthenticatedResponse; }
}); 参考: https://sidebase.io/nuxt-auth/getting-started/quick-start`}]},{path:"/content/front/js/PC%E7%AB%AF%E7%BD%91%E7%AB%99%E9%A1%B5%E9%9D%A2%E5%92%8C%E7%A7%BB%E5%8A%A8%E7%AB%AF%E4%BA%92%E7%9B%B8%E5%88%87%E6%8D%A2.html",title:"PC端网站页面和移动端互相切换",pathLocale:"/",contents:[{header:"",slug:"",content:`1.基于tailwind(配合nuxt3框架使用)
个人总结一下，目前感觉如果没有设计稿约束的话，可以直接用响应式布局的框架，如tailwind
但是如果严格按照设计稿来做的话，tailwind的样式可能不够用，所以要自定义很样式，这个可能是tailwind的一大弊端吧
tailwind弊端:
Tailwind CSS虽然好用，但是它有一个非常大的缺点，就是它自身提供的类名是非常有限的，并且它的默认单位是rem，这就导致如果一个项目要严格按照设计稿的尺寸来编写，它需要你手动添加大量的样式，也就是如果一个盒子的宽是375px，虽然你可以使用蓝湖这一类的工具将设计稿转换为rem为单位，375px如果按照16px的基准来转换就是23.4375rem。如果你需要严格参照设计稿，那么你就必须手动在tailwind.config.js文件中添加93.75: "23.4375rem"这一类的参数，如果你每次都要这么进行计算的话，那会是一个非常麻烦的事情，这个时候你会想：直接在tailwind.config.js文件中将1px~2000px全部添加进去不就好了嘛！ 事实上是不行，tailwind.config.js文件中，你预设的样式越多，你项目启动的速度就会越慢，因为它会通过postcss进行大量的计算，我尝试过将1px~2000px全部填入配置文件中，每次启动项目的时间大概是在2~3分钟左右。 我在项目中直接没有使用tailwind的样式类库，只用了基本的几个，如:container 其他的都直接写到vue页面的 scope 范围内。基于scss语法 rem 单位。 2.普通网站处理
if((navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i))) { window.location.href = ""; //手机 m站 } else { window.location.href = ""; //电脑 www站 } 3.如何在Nuxt3中检测用户设备并加载相应的用户界面？
上面说了，如果严格按照设计稿来做的话，就需要www 和 m 站各处一套设计稿，对应的样式可能就有两套，页面也有两套，就需要根据用户当前设备来加载相应的界面了
这里使用：mobile-detect 这个js包
安装(基于:https://github.com/hgoebl/mobile-detect.js):
npm i mobile-detect / yarn add mobile-detect 使用:
plugins/device.ts 中import 报错：
can only be default-imported using the 'esModuleInterop' flag
import {defineNuxtPlugin, useRequestHeaders} from '#app';
import * as MobileDetect from 'mobile-detect'; // 这样import就不会有问题了 export default defineNuxtPlugin(() => { let headers = useRequestHeaders() const md = process.server ? new MobileDetect(headers['user-agent']) : new MobileDetect(navigator.userAgent) const isMobile = md.phone() !== null || md.mobile() === 'UnknownMobile' const isTablet = md.tablet() !== null || md.mobile() === 'UnknownTablet' const isDesktop = !isMobile && !isTablet return { provide: { isMobile: () => isMobile, isTablet: () => isTablet, isDesktop: () => isDesktop }, };
}) 但是上面的代码运行以后会报：vite_ssr_import_1 is not a constructor
所以还是改为 plugins/device.js 格式：
import {defineNuxtPlugin, useRequestHeaders} from '#app';
import MobileDetect from 'mobile-detect'; export default defineNuxtPlugin(() => { let headers = useRequestHeaders() const md = process.server ? new MobileDetect(headers['user-agent']) : new MobileDetect(navigator.userAgent) const isMobile = md.phone() !== null || md.mobile() === 'UnknownMobile' const isTablet = md.tablet() !== null || md.mobile() === 'UnknownTablet' const isDesktop = !isMobile && !isTablet return { provide: { isMobile: () => isMobile, isTablet: () => isTablet, isDesktop: () => isDesktop }, };
}) 4.项目中使用(判断了$isMobile，就可以加载不同的页面了)
<template> <div v-if="$isMobile()" > show on mobile </div> <div v-else > show on pc </div>
</template>`}]},{path:"/content/front/js/Pina%E4%B9%8BstoreToRefs%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"Pina之storeToRefs的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`Pina之storeToRefs的使用:
storeToRefs 是 Pinia 提供的一个非常有用的函数，它的主要作用就是保持store中的状态的响应性，确保在store中的值更新时，组件会自动重新渲染。
以下是关于 storeToRefs 的一些重要点：
1.响应式：
storeToRefs 返回的是响应式引用（refs）。这意味着当store中的值改变时，使用这些引用的组件会自动更新。
2.只针对状态：
storeToRefs 只会为 store 中的状态（state）创建引用，不会为 actions 或非响应式属性创建引用。
3.性能优化：
使用 storeToRefs 可以避免不必要的组件重新渲染。它只会在被使用的属性发生变化时触发更新。
4.用法示例：
<script setup>
import { storeToRefs } from 'pinia'
import { useEventDashboardStore } from './stores/eventDashboard' const store = useEventDashboardStore() // 使用 storeToRefs 解构，保持响应性
const { shouldShowLoader, heading, sidebarLinks } = storeToRefs(store) // 直接从 store 中获取 action
const { fetchEventDashboardItems } = store // 不需要显式地返回任何东西，<script setup> 会自动暴露声明的变量和函数给模板
<\/script> <template> <!-- 现在你可以直接在模板中使用这些响应式引用和 action 例如： <div v-if="shouldShowLoader">Loading...</div> <h1>{{ heading }}</h1> <ul> <li v-for="link in sidebarLinks" :key="link.id">{{ link.text }}</li> </ul> <button @click="fetchEventDashboardItems">Fetch Items</button> -->
</template> 5.实时更新：
当 store 中的 shouldShowLoader、heading 或 sidebarLinks 发生变化时，使用这些变量的组件会自动更新，无需手动触发。
6.与普通解构的区别：
如果你直接解构 store 而不使用 storeToRefs，你会失去响应性：
// 错误用法，会失去响应性
const { shouldShowLoader, heading, sidebarLinks } = store 总的来说，storeToRefs 确实能保持实时更新，这是它的主要用途之一。它使得在组件中使用 Pinia store 的状态变得既方便又高效。`}]},{path:"/content/front/js/Pina%E9%85%8D%E7%BD%AEHMR%E7%83%AD%E6%9B%B4%E6%96%B0.html",title:"Pina配置HMR热更新",pathLocale:"/",contents:[{header:"",slug:"",content:"Pina配置HMR热更新:\nif (import.meta.hot) { import.meta.hot.accept( acceptHMRUpdate(useEventDashboardStore, import.meta.hot) );\n}\n这段代码是与热模块替换（Hot Module Replacement, HMR）相关的，通常用在 Vite 或类似的现代开发环境中。让我们逐部分分析： 1. `import.meta.hot`: - 这是一个特殊的对象，在支持 HMR 的环境中可用。 - 它提供了与 HMR API 交互的方法。 2. `if (import.meta.hot)`: - 这个检查确保代码只在支持 HMR 的环境中执行。 - 在生产环境中，`import.meta.hot` 通常是 undefined，所以这个 if 块不会执行。 3. `acceptHMRUpdate`: - 这是 Pinia 提供的一个函数，用于使 store 支持热模块替换。 - 它允许在不刷新整个页面的情况下更新 store 的定义。 4. `useEventDashboardStore`: - 这是您的 Pinia store 函数。 5. `import.meta.hot.accept(...)`: - 这个方法告诉 HMR 系统如何处理这个模块的更新。 - 它接受一个函数作为参数，这个函数在模块更新时被调用。 6. 整体功能: - 当 `useEventDashboardStore` 的定义发生变化时（例如，您修改了 store 文件并保存）， - HMR 系统会调用 `acceptHMRUpdate`， - 这会更新 store 的定义，而不需要刷新整个页面， - 从而保持应用的当前状态，提高开发效率。 这段代码的主要作用是:\n1. 在开发环境中启用 Pinia store 的热模块替换。\n2. 允许您修改 store 的代码并立即看到效果，无需手动刷新页面。\n3. 提高开发效率，使得状态管理的调试和开发更加流畅。 关于HMR:\nHMR（热模块替换）配置与 Vite 密切相关，但不完全限于 Vite。让我们更详细地探讨一下： 1. Vite 特性： - Vite 确实默认支持并大力推广这种 HMR 配置。 - `import.meta.hot` 是 Vite 原生支持的一个特性。 2. 其他构建工具： - 类似的 HMR 配置也可以在其他现代构建工具中找到，如 Webpack（通过 `module.hot`）。 - 但具体语法和实现可能略有不同。 3. Pinia 的适配： - Pinia 设计了这种 HMR 配置方式，使其能够很好地与 Vite 配合。 - 但 Pinia 也支持其他构建工具的 HMR。 4. 为什么常见于 Vite 项目： - Vite 以其快速的开发服务器和优秀的 HMR 支持而闻名。 - Vue 3 和 Pinia 的许多新项目倾向于使用 Vite，因此这种配置在 Vite 项目中特别常见。 5. 通用性： - 虽然语法可能需要调整，但类似的 HMR 概念可以应用于其他构建系统。 6. Vite 的优势： - Vite 的 HMR 实现特别快速和高效，这使得这种配置在 Vite 项目中特别有价值。 7. 跨平台兼容性： - Pinia 的这种 HMR 配置设计考虑了跨平台兼容性，使得同一套代码可以在不同的构建工具中工作。 总结：\n虽然这种 HMR 配置在 Vite 项目中最为常见和有效，但它并不严格限于 Vite。这是 Pinia 为了提供最佳开发体验而设计的一种通用方法，可以在支持 HMR 的各种现代构建工具中使用。在 Vite 中，它的效果可能最为显著，但这个概念是可以跨平台应用的。"}]},{path:"/content/front/js/Typescript%E4%B8%8B%E5%AE%9A%E4%B9%89export_enum%E5%92%8Cexport_const_enum%E5%93%AA%E4%B8%AA%E5%A5%BD.html",title:"symfony7下关于关于DateTime使用clone",pathLocale:"/",contents:[]},{path:"/content/front/js/Typescript%E4%B8%8B%E7%BB%99HTMLElement%E6%8B%93%E5%B1%95%E5%B1%9E%E6%80%A7.html",title:"Typescript下给HTMLElement拓展属性",pathLocale:"/",contents:[{header:"Typescript下给HTMLElement拓展属性",slug:"typescript下给htmlelement拓展属性",content:`如下代码:
declare global { interface HTMLElement { _tooltipHandlers?: { mouseenter: (event: MouseEvent) => void; mouseleave: () => void; }; _tooltipOptions?: TooltipOptions; }
} 解释:
这段 TypeScript 代码的作用是扩展全局的 HTMLElement 接口，为 HTML 元素对象添加两个可选的自定义属性，用于实现 tooltip（工具提示）功能相关的逻辑。所有 HTML 元素（即所有实现了 HTMLElement 接口的元素）在 TypeScript 类型系统中都会“自动具备”你添加的这两个可选属性。 关键词解析:
declare global
这是 TypeScript 的声明合并语法，用于在全局作用域中扩展已有的类型定义。这段代码通常出现在 .d.ts 类型声明文件中或模块中用于类型扩展。
interface HTMLElement
这是对浏览器内建的 HTMLElement 接口进行扩展。 添加的两个属性:
HTMLElement._tooltipHandlers?
_tooltipHandlers?: { mouseenter: (event: MouseEvent) => void; mouseleave: () => void;
};
一个对象，包含两个事件处理函数：mouseenter 和 mouseleave。
用于手动绑定和解绑 tooltip 的事件监听器。
? 表示该属性是可选的。 HTMLElement._tooltipOptions?
_tooltipOptions?: TooltipOptions;
也是一个可选属性，用于存储与 tooltip 相关的配置项。
TooltipOptions 是一个类型（可能在其他地方声明），用于定义 tooltip 的行为，如延迟时间、位置、内容等。 使用场景
这段代码通常出现在一个实现自定义 tooltip 的系统中，例如:
const el = document.querySelector('.has-tooltip') as HTMLElement; el._tooltipOptions = { content: 'Hello Tooltip', delay: 300,
}; el._tooltipHandlers = { mouseenter: (e) => showTooltip(el, e), mouseleave: () => hideTooltip(el),
}; el.addEventListener('mouseenter', el._tooltipHandlers.mouseenter);
el.addEventListener('mouseleave', el._tooltipHandlers.mouseleave); 总结
这段代码的目的：
✅ 在不修改 DOM 标准接口的前提下，为 tooltip 实现绑定事件处理器和配置项提供了一个干净、类型安全的方式。
✅ 使用可选属性和扩展接口的方式，确保不会对现有代码造成破坏，且保留 TypeScript 类型检查的优势。`}]},{path:"/content/front/js/async%E5%92%8Cawait%E7%9A%84%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%85%A5%E7%A0%94%E7%A9%B6.html",title:"async和await的使用深入研究",pathLocale:"/",contents:[{header:"",slug:"",content:`async和await的使用深入研究:
官方文档: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await#conversion_to_promise // useAuth.ts
interface UserInfo { id: number name: string email: string // 根据实际用户信息结构定义其他属性
} const getUserInfo = async (): Promise<UserInfo> => { try { // 调用获取用户信息 API, 这里测试，直接返回结果，实际课通过 await ￥fetch() 获取数据 const response = {id:1, name: "jerry", email: "ererer@gmai.com"} return response } catch (error) { // 处理错误 console.error(error) throw error }
} const f1 = async () =>{ const user = await getUserInfo() console.log("user is:", user)
} f1(); //
async function f2() { const thenable = { then(resolve: (arg0: string) => void, _reject: any) { resolve("resolved!"); }, }; console.log(await thenable); // "resolved!"
} f2(); //
async function f3() { const y = await 20; console.log(y); // 20 const obj = {}; console.log((await obj) === obj); // true
} f3(); //
async function f4() { try { const z = await Promise.reject(30); } catch (e) { console.error(e); // [ERR]: 30 }
} f4(); 语法:
await expression 关于await的作用:
await is usually used to unwrap promises by passing a Promise as the expression. Using await pauses the execution of its surrounding async function until the promise is settled (that is, fulfilled or rejected). When execution resumes, the value of the await expression becomes that of the fulfilled promise. 使用原理:
The expression is resolved in the same way as Promise.resolve(): it's always converted to a native Promise and then awaited 表达式的三种体现:
1>Native Promise (which means expression belongs to Promise or a subclass, and expression.constructor === Promise): The promise is directly used and awaited natively, without calling then().
2>Thenable object (including non-native promises, polyfill, proxy, child class, etc.): A new promise is constructed with the native Promise() constructor by calling the object's then() method and passing in a handler that calls the resolve callback.
3>Non-thenable value: An already-fulfilled Promise is constructed and used.`}]},{path:"/content/front/js/cookie%E4%B8%8BHttpOnly%E5%B1%9E%E6%80%A7.html",title:"cookie下HttpOnly属性",pathLocale:"/",contents:[{header:"",slug:"",content:`HttpOnly 字段 cookie的httponly属性。若此属性为true，
则只有在http请求头中会带有此cookie的信息，而不能通过 document.cookie 来访问此 cookie。
这样能有效的防止XSS攻击。窃取cookie内容，这样就增加了cookie的安全性。 不能通过任何 js 脚本获取这个值，只能看得到，但是你获取不到，
setcookie 一般用法就是 key，value，这两个属性。
但是 setcookie 第七个属性就是设置 httponly 的，设置后无法通过 js 脚本获取 setcookie 参数如下：
Cookie名称（必填）	Cookie名称必须使用只能用在URL中的字符，一般用字母及数字，不能包含特殊字符，如有特殊字符想要转码。如js操作cookie的时候可以使用escape()对名称转码。
Cookie值（必填）	Cookie值同理Cookie的名称，可以进行转码和加密。
Expires（非必填）	过期日期，一个GMT格式的时间，当过了这个日期之后，浏览器就会将这个Cookie删除掉，当不设置这个的时候，Cookie在浏览器关闭后消失。
Path（非必填）	一个路径，在这个路径下面的页面才可以访问该Cookie，一般设为“/”，以表示同一个站点的所有页面都可以访问这个Cookie。
Domain（非必填）	子域，指定在该子域下才可以访问Cookie，例如要让Cookie在a.test.com下可以访问，但在b.test.com下不能访问，则可将domain设置成a.test.com。
Secure（非必填）	安全性，指定Cookie是否只能通过https协议访问，一般的Cookie使用HTTP协议既可访问，如果设置了Secure（没有值），则只有当使用https协议连接时cookie才可以被页面访问
HttpOnly（非必填）	如果在Cookie中设置了"HttpOnly"属性，那么通过程序(JS脚本、Applet等)将无法读取到Cookie信息。`}]},{path:"/content/front/js/cookie%E4%B9%8Bexpires%E7%9A%84%E9%BB%98%E8%AE%A4%E5%80%BC.html",title:"cookie之expires的默认值",pathLocale:"/",contents:[{header:"",slug:"",content:`cookie之expires的默认值:
如果不设置cookie的过期时间或者设置为0，Cookie会被认为是Session Cookie(打开浏览器 f12 查看cookie信息，可以发现Expires 下的值为session)，
所谓Session就是一次会话，浏览器关闭后该Cookie便会失效，下次打开浏览器后不会再有该Cookie。`}]},{path:"/content/front/js/css%E7%BB%99%E5%B1%9E%E6%80%A7%E6%B7%BB%E5%8A%A0%E8%BF%87%E6%B8%A1%E6%95%88%E6%9E%9C.html",title:"css给属性添加过渡效果",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要改变元素的 margin width 等，又不想变化的很突兀，可以通过 transition 实现:
通过transition添加样式过渡:
'margin-left:0px;transition:margin-left .3s;';
'margin-left: calc((100% - '+that.respWidth+'px)/2);transition:margin-left .3s;'; transition 属性设置元素当过渡效果，四个简写属性为： transition-property #指定CSS属性的name，transition效果
transition-duration #transition效果需要指定多少秒或毫秒才能完成
transition-timing-function #指定transition效果的转速曲线
transition-delay #定义transition效果开始的时候 注意： 始终指定transition-duration属性，否则持续时间为0，transition不会有任何效果。`}]},{path:"/content/front/js/eslint%E6%8F%92%E4%BB%B6unicorn.html",title:"eslint插件unicorn",pathLocale:"/",contents:[{header:"",slug:"",content:`eslint插件unicorn:
eslint-plugin-unicorn 定义的规则:
https://github.com/sindresorhus/eslint-plugin-unicorn/blob/main/docs/rules/prefer-logical-operator-over-ternary.md`}]},{path:"/content/front/js/eslint%E8%A7%84%E5%88%99%E5%A4%A7%E5%85%A8.html",title:"eslint规则大全",pathLocale:"/",contents:[{header:"",slug:"",content:`eslint规则大全:
https://eslint.org/docs/latest/rules
针对vue的：https://eslint.vuejs.org/rules/block-order //eslint-plugin-vue 官网:
https://eslint.org/docs/latest/use/getting-started`}]},{path:"/content/front/js/floatingUI%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"floatingUI的使用",pathLocale:"/",contents:[{header:"floatingUI的使用, 这个主要是解决弹窗等的自适应的问题, 官网：https://floating-ui.com/docs/getting-started",slug:"floatingui的使用-这个主要是解决弹窗等的自适应的问题-官网-https-floating-ui-com-docs-getting-started",content:`//usePatchSelect.ts
import { autoUpdate, flip, offset as offsetMiddleware, shift, useFloating,
} from "@floating-ui/vue"; export const usePatchSelect = () => { const id = useId(); const wrapperElement = ref<HTMLElement | null | undefined>(null); const floatingElement = ref<HTMLElement | null | undefined>(null); const referenceElement = ref<HTMLElement | null | undefined>(null); const floating = useFloating(referenceElement, floatingElement, { placement: "bottom-start", middleware: [offsetMiddleware(0), shift(), flip()], whileElementsMounted: autoUpdate, }); const onBeforeOpen = () => { nextTick(() => { wrapperElement.value = document.querySelector<HTMLElement>( \`[data-app-select-id="\${id}"]\`, ); referenceElement.value = wrapperElement.value?.querySelector<HTMLElement>( ".common-field__dropdown-input", ); floatingElement.value = wrapperElement.value?.querySelector<HTMLElement>( ".common-field__options", ); floating.update(); wrapperElement.value?.classList.add("overflow-hidden"); }); }; const onAfterClose = () => { floatingElement.value = null; floating.update(); }; watch(floating.floatingStyles, (styles) => { wrapperElement.value?.classList.remove("overflow-hidden"); const listBox = floatingElement.value; if (listBox) { if (listBox.classList.contains("transition")) { listBox.classList.remove("transition"); listBox.classList.add("transition-[opacity]"); } Object.assign(listBox.style, styles); } }); return { onBeforeOpen, onAfterClose, "data-app-select-id": id, };
}; const patchedProps = usePatchSelect();
<AppSelect :model-value="perPageSelection" class="min-w-[8rem] md:!w-auto" :items="perPageOptions" v-bind="patchedProps" //重要的是这个，会把usePatchSelect中暴露的 "data-app-select-id": id 绑定到这个元素(有个data-app-select-id属性)，然后后面所有的操作都是基于这个id进行的 @update:model-value="emit('changePerPage', $event as MSelectItem<number>)" /> <!-- AppSelect.vue -->
<template> <div class="app-select-wrapper" v-bind="$attrs"> // vue3使用这个v-bind="$attrs" 来获取需要绑定的属性，这里是data-app-select-id <!-- dropdown, input, etc --> </div>
</template>`}]},{path:"/content/front/js/form%E8%A1%A8%E5%8D%95%E4%B8%8A%E4%BC%A0%E7%9A%84%E6%97%B6%E5%80%99%E8%8E%B7%E5%8F%96file%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E6%B3%95.html",title:"form表单上传的时候获取file对象的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`form表单上传的时候获取file对象的方法:
我有如下vue3的upload方法
const upload = (newFiles: File[] | null) => { if (!newFiles || newFiles.length === 0) { return; } const uploadedFile = newFiles[0]; const formData = new FormData(); formData.append("file", uploadedFile); console.log("formData is:", formData) // 打印出来为空 console.log('file: ', formData.get('file')); // 可以打印出数据，这个很重要
}`}]},{path:"/content/front/js/input%E6%A1%86%E5%85%B3%E4%BA%8Ekeydonw%E5%92%8Ckeyup%E7%9A%84%E4%BD%BF%E7%94%A8%E5%88%86%E6%9E%90.html",title:"input框关于keydonw和keyup的使用分析",pathLocale:"/",contents:[{header:"",slug:"",content:`input框关于keydonw和keyup的使用分析:
@keydown="handleKeyDown($event)"
@keyup="handleKeyUp($event)" const handleKeyDown = (event: KeyboardEvent) => { //这个打印，不会打印出当前输入数据，比如输入1，会打印空，在输入2，会打印1，在输入3，会打印12 console.log("model.value is:", model.value);
}
const handleKeyUp = (event: KeyboardEvent) => {
//这个打印，会打印出当前输入数据，比如输入1，会打印1，在输入2，会打印12，在输入3，会打印123 console.log("model.value is:", model.value);
} 这是keyDown和keyUp的一个重要不同，非常感谢实用，keyDown相当于可以保留之前的输入数据，不会立即更新，但是keyUp可以实时更新. 在做input数据验证的时候非常有用: 如下(这个案例只是其中一种场景，假设用户输入的是整数, 用来禁止用户输入超过指定值的数据，比如不能超过100):
const handleKeyDown = (event: KeyboardEvent) => { lastInputValue.value = model.value || "";
} const handleInteger = (event: InputEvent) => { const currentValue = (event.target as HTMLInputElement).value || ""; if (currentValue > props.maxNumber) { (event.target as HTMLInputElement).value = lastInputValue.value; //由于lastInputValue.value 保留了props.maxNumber之前的数据，所以这里把之前的数据赋值给model.value，实现了禁止输入大于指定值的数据 model.value = lastInputValue.value; event.preventDefault(); }
} <input v-model="model as string | number" @keydown="handleKeyDown($event)" @input="handleInteger($event)" > 总结:
@keydown 事件是在 按键按下 的时候触发的，此时输入框的内容 还没有更新，也就是说，model 的值是 按键按下之前的值。
@keyup 事件是在 按键松开 的时候触发的，此时输入框的内容 已经更新，所以 model 的值会是你当前输入的值。`}]},{path:"/content/front/js/javascript%E5%A4%8D%E5%88%B6%E5%86%85%E5%AE%B9%E5%88%B0%E5%89%AA%E8%B4%B4%E6%9D%BF.html",title:"javascript复制内容到剪贴板",pathLocale:"/",contents:[{header:"",slug:"",content:`javascript复制内容到剪贴板:
<style> #copy-link{ position: relative; z-index: 2; } #copy-button{ display: none; color: #000; position: absolute; left: 50%; transform: translateX(-50%); bottom: -42px; border: 1px solid #bcbcbc; z-index: 3; } .copy-box{ box-sizing: border-box; width: 80px; height: 22px; line-height: 20px; margin: 5px 10px; font-weight: normal; border: 1px solid #1a8d8d; color: #1a8d8d; } .triangle { width: 0; height: 0; border-left: 10px solid transparent; border-right: 10px solid transparent; border-bottom: 10px solid #bcbcbc; position: absolute; top: -10px; left: 50%; transform: translateX(-50%); }
</style> <script> document.addEventListener('DOMContentLoaded', function() { const copyLink = document.getElementById('copy-link'); const copyButton = document.getElementById('copy-button'); copyLink.addEventListener('mouseenter', () => { copyButton.style.display = 'block'; }); copyLink.addEventListener('mouseleave', () => { copyButton.style.display = 'none'; }); copyButton.addEventListener('click', function(event) { event.stopPropagation(); event.preventDefault(); const href = copyLink.getAttribute('href') if (navigator.clipboard && window.isSecureContext){ navigator.clipboard.writeText(href) }else { const tempInput = document.createElement('input'); tempInput.value = href; document.body.appendChild(tempInput); tempInput.select(); try { document.execCommand('copy'); } catch (err) { console.error('Unable to copy link to clipboard:', err); } finally { document.body.removeChild(tempInput); } } }); });
<\/script>`}]},{path:"/content/front/js/js%E4%B8%87%E8%83%BD%E9%82%AE%E7%AE%B1%E6%AD%A3%E5%88%99.html",title:"js万能邮箱正则",pathLocale:"/",contents:[{header:"",slug:"",content:`js万能邮箱正则:
//任何邮箱
let regex = /^[a-zA-Z0-9_-]+(.)*[a-zA-Z0-9_-]*@[a-zA-Z0-9]+\\.com$/; //指定gmail邮箱
let regex = /^[a-zA-Z0-9_-]+(.)*[a-zA-Z0-9_-]*@gmail.com$/;`}]},{path:"/content/front/js/js%E4%B9%8BCSP%E6%A8%A1%E5%BC%8F.html",title:"js之CSP模式",pathLocale:"/",contents:[{header:"",slug:"",content:`js之CSP(Content-Security-Policy)模式:
CSP 的实质就是白名单制度，开发者明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单。
它的实现和执行全部由浏览器完成，开发者只需提供配置.
两种方法可以启用 CSP。一种是通过 HTTP 头信息的Content-Security-Policy的字段。另一种是通过网页的 meta 标签。`}]},{path:"/content/front/js/js%E4%B9%8Bjson%E5%AF%B9%E8%B1%A1%E8%BD%AC%E6%95%B0%E7%BB%84_%E5%AD%97%E7%AC%A6%E4%B8%B2.html",title:"js之json对象转数组_字符串",pathLocale:"/",contents:[{header:"",slug:"",content:`js之json对象转数组_字符串:
1.json对象转字符串
function getStringFromJson(obj) { let str = ""; Object.keys(obj).forEach((v) => { str += v + ":" + obj[v] + "\\n"; }); return str;
} 2.json对象转数组
function getStringFromJson(obj) { const arr = []; Object.keys(obj).forEach((v) => { const o = {}; o[v] = obj[v]; arr.push(o); }); return arr;
}`}]},{path:"/content/front/js/js%E4%B9%8Bpromise%E5%AF%B9%E8%B1%A1.html",title:"js之promise对象",pathLocale:"/",contents:[{header:"",slug:"",content:`最忌做项目遇到问题，接口返回了Promise 对象，如何不能从外面拿到这个对象的属性值，后来发现，这个对象
的属性是不能从外面拿到的，之恶能通过链式操作取值
//假如 foo()返回的是一个Promise对象
foo().then((result) => { console.log(result) }) .catch((error) => { console.log(error) }) //在上面的代码中，当 Promise 对象成功时，控制台将打印 Promise 的结果。如果 Promise 失败，则控制台将打印错误信息。请注意，使用 Promise 的 then 方法时，必须提供成功回调函数，否则 Promise 的结果将被丢弃。 其实promise还有更深的链式操作，如下 getResult 函数有一个 promise 对象的参数：
getResult: function (p) { p.then((result) => { console.log(result) console.log('执行「这个」”'); return new Promise(function (resolve, rejected) { resolve(1) }) }).catch((error) => { console.log('执行「那个」'); return new Promise(function (resolve, rejected) { resolve(0) }) }).then((value) => { console.log(value) //这个 value 可能是 1 也可能是2 ，但是在nuxt3下无法被使用，在单独vue项目应该是能被使用的 }) }`}]},{path:"/content/front/js/js%E4%B9%8Breduce%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90.html",title:"js之reduce方法解析",pathLocale:"/",contents:[{header:"js之reduce方法解析",slug:"js之reduce方法解析",content:"reduce 是 JavaScript 数组中最灵活也最有表现力的方法之一。你可以用它实现很多功能，比如："},{header:"✅ 常见用途举例：",slug:"✅-常见用途举例",content:""},{header:"1. 数组求和",slug:"_1-数组求和",content:"[1, 2, 3, 4].reduce((acc, n) => acc + n, 0) // 10"},{header:"2. 数组转对象",slug:"_2-数组转对象",content:`const arr = [ { id: 1, name: 'Alice' }, { id: 2, name: 'Bob' }
] const obj = arr.reduce((acc, item) => { acc[item.id] = item.name return acc
}, {}) console.log(obj)
// { 1: 'Alice', 2: 'Bob' }`},{header:"3. 统计某个值出现的次数",slug:"_3-统计某个值出现的次数",content:`const colors = ['red', 'blue', 'red', 'green', 'blue', 'blue']
const count = colors.reduce((acc, color) => { acc[color] = (acc[color] || 0) + 1 return acc
}, {}) console.log(count)
// { red: 2, blue: 3, green: 1 }`},{header:"4. 扁平化数组",slug:"_4-扁平化数组",content:`const nested = [[1, 2], [3, 4], [5]]
const flat = nested.reduce((acc, arr) => acc.concat(arr), []) console.log(flat) // [1, 2, 3, 4, 5]`},{header:"📌 小技巧：避免副作用",slug:"📌-小技巧-避免副作用",content:"reduce 中如果要操作对象或数组，最好返回一个新的对象/数组，避免修改 acc 引起难以发现的副作用。 需要的时候也可以嵌套 reduce，结合 map/filter 更强大。如果想用在 Vue/Nuxt 的 computed 中，也非常高效且响应式友好。"},{header:"reduce 的第二个参数就是：初始值（initial value）",slug:"reduce-的第二个参数就是-初始值-initial-value",content:""},{header:"📌 举个最简单的例子：",slug:"📌-举个最简单的例子",content:`const arr = [1, 2, 3, 4]
const sum = arr.reduce((acc, item) => acc + item, 0)
// ↑ ↑
// 初始值 acc 当前项 item console.log(sum) // 10 这里 0 就是初始值，acc 从 0 开始累加。`},{header:"🚨 如果没有提供初始值，会发生什么？",slug:"🚨-如果没有提供初始值-会发生什么",content:"当你 不传第二个参数，reduce 会默认使用数组的 第一个元素作为初始值，从第二个元素开始循环。"},{header:"示例：",slug:"示例",content:`const arr = [1, 2, 3, 4]
const sum = arr.reduce((acc, item) => acc + item)
// 初始 acc = 1（arr[0]）
// 从 item = 2 开始 console.log(sum) // 10 虽然结果是一样的，但：`},{header:"❗为什么推荐总是提供初始值？",slug:"❗为什么推荐总是提供初始值",content:`更安全，避免空数组报错：
[].reduce((acc, item) => acc + item, 0) // ✅ 返回 0
[].reduce((acc, item) => acc + item) // ❌ TypeError: Reduce of empty array with no initial value 更清晰，一眼看出你希望累加/合并成哪种类型的值（数值、对象、数组等）：
arr.reduce((acc, item) => { ... }, {}) // 初始是一个对象
arr.reduce((acc, item) => { ... }, []) // 初始是一个数组
arr.reduce((acc, item) => { ... }, '') // 初始是一个字符串`},{header:"✅ 总结：",slug:"✅-总结",content:`reduce(callback, initialValue) 的第二个参数就是 初始值。
建议：总是显式传初始值，更加健壮、清晰、可维护。特别是在你处理对象或空数组的时候。`}]},{path:"/content/front/js/js%E4%B9%8B%E6%97%A0%E6%84%9F%E7%9F%A5%E4%BF%AE%E6%94%B9%E8%AF%B7%E6%B1%82%E9%93%BE%E6%8E%A5.html",title:"js之无感知修改请求链接",pathLocale:"/",contents:[{header:"",slug:"",content:`js之无感知修改请求链接:
$(document).on('mouseenter', "#subscribe_user_comment", function () { let userId = $(this).data("user"); if ('' === userId) { let searchParams = window.location.search; searchParams = searchParams.split('?')[0]; searchParams = updateSearchParams(searchParams, 'subscribe_comment', true); window.history.pushState('', '', searchParams); } });
//window.history.pushState('', '', searchParams); 是 JavaScript 中用于修改浏览器历史记录的方法之一。这个方法是 HTML5 中引入的，它允许你在不刷新页面的情况下改变浏览器的 URL 和历史记录状态。 function subscribeComment(){ if (-1 !== window.location.search.indexOf("subscribe_comment")){ let ele = $("#subscribe_user_comment"); $('html, body').animate({ scrollTop: ele.offset().top }, 500); ele.trigger("click"); removeSubscribeCommentParam() }
} function removeSubscribeCommentParam() { let currentUrl = window.location.href; let updatedUrl = currentUrl.replace(/([?&])subscribe_comment=[^&]*(&|$)/, function(match, p1, p2) { return p1 === '?' ? p2 : ''; }); if (updatedUrl !== currentUrl) { window.history.replaceState({}, document.title, updatedUrl); }
} //window.history.replaceState 的作用是将当前浏览器历史记录条目的状态修改为提供的状态，并将当前页面的 URL 修改为新的 URL，但并不会导致页面重新加载。这对于在不刷新整个页面的情况下更新 URL 很有用。 window.history.pushState和window.history.replaceState有相似的作用，就上面的需求而言，可以达到相同的效果.`}]},{path:"/content/front/js/js%E5%85%B3%E4%BA%8EObject-entries%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"js关于Object-entries的使用",pathLocale:"/",contents:[{header:"Object.entries() 的作用",slug:"object-entries-的作用",content:`Object.entries() 方法用于将对象的 键值对 转换为 二维数组，其中： 每个键值对都会变成数组的一个元素
数组的第一项是 键（key），第二项是 值（value）`},{header:"语法：",slug:"语法",content:"Object.entries(obj) 参数： obj：要转换的对象。 返回值： 一个包含 [key, value] 数组的数组。"},{header:"示例：",slug:"示例",content:`const obj = { a: 1, b: 2, c: 3
}; console.log(Object.entries(obj));
// 输出: [['a', 1], ['b', 2], ['c', 3]]`},{header:"适用场景：",slug:"适用场景",content:`Object.entries() 适用于： 遍历对象：相比 for...in，它不会遍历原型链上的属性，适用于 纯数据对象。
对象转换为数组：如果你要对对象的数据进行排序、映射等数组操作，可以先用 Object.entries() 转换。
动态访问对象的 key-value：适用于键值未知的情况，如 API 响应。 类似方法： Object.keys(obj): 只返回对象的 键数组。
Object.values(obj): 只返回对象的 值数组。`},{header:"总结：",slug:"总结",content:"Object.entries() 可以把对象转换成一个 键值对数组，便于使用数组的方法（map、filter、sort 等）进行操作。"},{header:"实际项目使用",slug:"实际项目使用",content:`<script setup lang="ts">
import { ref, watch } from 'vue'; const props = defineProps<{ availableTo: string[]
}>(); // 定义类型
interface SectionData { sectionName: string; ticketNames: string[];
} // 初始化 groupedData
const groupedData = ref<Record<string, string[]>>({ specialSection: [],
}); // 初始化 dataList 和条件判断
const dataList = ref<SectionData[]>([]);
const hasSpecialSection = ref(false);
const hasNonEmptySections = ref(false); // 每次 availableTo 更新时重新计算 groupedData 和相关数据
watch( () => props.availableTo, (newAvailableTo) => { // 重新计算 groupedData groupedData.value = { specialSection: [] }; newAvailableTo.forEach(item => { const parts = item.split(' - '); if (parts.length === 2) { const sectionName = parts[0].trim(); const ticketName = parts[1].trim(); if (!groupedData.value[sectionName]) {//sectionName是一个变量 groupedData.value[sectionName] = []; } groupedData.value[sectionName].push(ticketName); } else { groupedData.value.specialSection.push(item.trim());//specialSection是确定的 } }); // 将 groupedData 转换为数组并排序 const sortedData = Object.entries(groupedData.value) .map(([sectionName, ticketNames]) => ({ sectionName, ticketNames })) .sort((currentSection, nextSection) => { if (currentSection.sectionName === 'specialSection') { return 1; // specialSection 排到最后 } if (nextSection.sectionName === 'specialSection') { return -1; // specialSection 排到最后 } return 0; }); // 更新 dataList dataList.value = sortedData; // 判断条件 hasSpecialSection.value = dataList.value.some(item => item.sectionName === "specialSection" && !item.ticketNames.includes('All tickets') ); hasNonEmptySections.value = dataList.value.some(item => item.sectionName !== "specialSection" && item.ticketNames.length > 0 ); }, { immediate: true } // 初始化时也执行一次
);
<\/script> 上面的代码分析:
1>groupedData是一个对象，为什么要使用 groupedData.value[sectionName] 判断，看起来像数组一样,而不是点操作符？
在 JavaScript 中，访问对象的属性有两种方式：点操作符 (.) 和 方括号操作符 ([])，这两者有不同的用法和限制。 点操作符 (groupedData.sectionName):
点操作符用于访问对象的属性时，属性名必须是一个有效的标识符（例如，字母、数字、下划线或美元符号），并且不能是变量。如果属性名是一个动态的字符串或包含空格、特殊字符（如 -）等，无法直接使用点操作符访问。 方括号操作符 (groupedData[sectionName]):
方括号操作符允许访问对象的属性名，无论这个属性名是字符串、变量，还是包含空格、特殊字符等。
你可以通过动态的方式访问属性，例如将 sectionName 作为变量传入。 在你的代码中，sectionName 变量的值来自数据，所以它是一个动态的字符串。如果你直接使用 groupedData.sectionName，它会寻找字面量的 sectionName 属性，而不是变量 sectionName 的值。会找不到。 总结：
如果你访问的是一个固定的属性名（如 groupedData.nonSection），可以使用点操作符。
如果属性名是动态的（如 groupedData[sectionName]），或者包含不符合标识符规则的字符（例如 -），必须使用方括号操作符。 2>细节解析
假如groupedData获取到的数据如下:
const groupedData = { specialSection: ['All tickets'], VIP: ['Ticket A', 'Ticket B'], General: ['Ticket C']
}; 步骤 1：Object.entries(groupedData)
返回
[ ['specialSection', ['All tickets']], ['VIP', ['Ticket A', 'Ticket B']], ['General', ['Ticket C']]
] 可以看到，每个元素是 [key, value] 组成的数组： ['specialSection', ['All tickets']]
['VIP', ['Ticket A', 'Ticket B']]
['General', ['Ticket C']] 步骤 2：map 解构赋值
const dataList = Object.entries(groupedData).map(([sectionName, ticketNames]) => { return { sectionName, ticketNames };
});
等价于
const dataList = [ { sectionName: 'specialSection', ticketNames: ['All tickets'] }, { sectionName: 'VIP', ticketNames: ['Ticket A', 'Ticket B'] }, { sectionName: 'General', ticketNames: ['Ticket C'] }
]; 在 map() 里：
sectionName 对应对象的 key（比如 "specialSection"、"VIP"）。
ticketNames 对应对象的 value（比如 ['All tickets']、['Ticket A', 'Ticket B']）。`},{header:"sort函数分析",slug:"sort函数分析",content:`上面的代码结构:
.sort((a, b) => { if (a.sectionName === 'nonSection') return 1; // 'nonSection' 放到最后 if (b.sectionName === 'nonSection') return -1; // 'nonSection' 放到最后 return 0; // 不改变其他项的顺序
}); 分析:
sort() 是一个用来对数组元素进行排序的 JavaScript 方法。它接受一个排序函数作为参数，这个排序函数决定了数组中元素的顺序。 原理:
sort() 接收的排序函数有两个参数：a 和 b。这两个参数 a 和 b 代表的是相邻的两个元素，用于比较它们的排序顺序。sort() 会根据它们的返回值来决定排序顺序。排序函数会被调用多次，直到所有的元素都按照一定的规则排序完成。
如下:
1>数字排序
array.sort((a, b) => { return a - b; // 升序排序
}); 2>对象数组排序
const users = [ { name: "Alice", age: 30 }, { name: "Bob", age: 20 }, { name: "Charlie", age: 25 }
]; // 按年龄升序排序
users.sort((a, b) => a.age - b.age);
console.log(users); // 按年龄降序排序
users.sort((a, b) => b.age - a.age);
console.log(users); 返回值规则：
如果返回值 小于 0（例如 -1），则 a 会排在 b 前面。
如果返回值 大于 0（例如 1），则 b 会排在 a 前面。
如果返回值 等于 0，则 a 和 b 的顺序不变。 实例具体分析:
第一条规则：if (a.sectionName === 'nonSection') return 1;
这里是判断 a（当前正在比较的元素）的 sectionName 是否等于 'nonSection'。如果是，返回 1，表示 a 应该被排到 b 后面，也就是说 "nonSection" 会被排到最后。 第二条规则：if (b.sectionName === 'nonSection') return -1;
这里是判断 b（另一个正在比较的元素）的 sectionName 是否等于 'nonSection'。如果是，返回 -1，表示 b 应该被排到 a 后面，也就是说 "nonSection" 会被排到最后。 第三条规则：return 0;
如果 a 和 b 都不包含 'nonSection'，则返回 0，表示不改变它们的顺序。`},{header:"some()原理",slug:"some-原理",content:`Array.prototype.some() 是 JavaScript 数组的一个方法，用于检查数组中是否 至少有一个元素 满足给定的测试条件。如果有一个元素满足条件，some() 会立即返回 true，否则返回 false。
语法:
array.some(callback(currentValue, index, array), thisArg);
参数：
callback：必需，函数，定义测试条件，接受以下参数：
currentValue：当前元素的值。
index：当前元素的索引（可选）。
array：当前数组本身（可选）。
thisArg：可选，callback 执行时的 this 值。
返回值：
true：如果回调函数对任意一个元素返回 true。
false：如果回调函数对所有元素都返回 false。 举例:
const numbers = [1, 2, 3, 4, 5]; // 判断是否存在大于 3 的数字
const hasNumberGreaterThanThree = numbers.some(num => num > 3); console.log(hasNumberGreaterThanThree); // true，4 和 5 满足条件`},{header:"every()原理",slug:"every-原理",content:`Array.prototype.every() 是用于遍历数组的每个元素，并对每个元素应用指定的测试函数。它会返回一个布尔值，表示数组中的 所有 元素是否都满足指定的条件。
举例:
const array = [1, 2, 3, 4, 5]; const allPositive = array.every(item => item > 0); console.log(allPositive); // true，因为数组中的所有元素都是正数`}]},{path:"/content/front/js/js%E5%85%B3%E4%BA%8Eclick%E4%BA%8B%E4%BB%B6%E9%97%AE%E9%A2%98.html",title:"js关于click事件问题",pathLocale:"/",contents:[{header:"",slug:"",content:`js关于click事件问题:
<Input v-model="option.name" placeholder="Meal option" @focus="onInputFocus(index)" @blur="onInputBlur" @keydown.enter="onKeyDown(index, option.name, $event)" class="[&_.common-field\\_\\_input]:!h-[2.125rem]" />
<Icon name="delete" size="sm" class="bg-brand-subtlest rounded cursor-pointer absolute -right-6" v-if="currentInput > 0 && currentInput === index && isFocused" @click="clickInputForm"/> 当input获得焦点的时候, 后面的删除icon会展示，当失去焦点的时候，icon会隐藏，但是当我点击icon的时候，也会触发input失去焦点，然后icon的点击事件没法触发.
这是一个常见的问题，原因是当点击 delete 图标时，input 的失去焦点事件 (blur) 被触发，导致图标被隐藏，同时图标的点击事件没有机会执行。`},{header:"解决方法",slug:"解决方法",content:"为了防止 blur 事件导致 icon 无法触发点击事件，可以使用 mousedown 事件代替 click，因为 mousedown 事件发生在 blur 事件之前，这样可以先处理删除图标的点击逻辑。"},{header:"修改后的代码",slug:"修改后的代码",content:`<Input v-model="option.name" placeholder="Meal option" @focus="onInputFocus(index)" @blur="onInputBlur" @keydown.enter="onKeyDown(index, option.name, $event)" class="[&_.common-field\\_\\_input]:!h-[2.125rem]"
/>
<Icon name="delete" size="sm" class="bg-brand-subtlest rounded cursor-pointer absolute -right-6" v-if="currentInput > 0 && currentInput === index && isFocused" @mousedown="clickInputForm"
/>`},{header:"关键点",slug:"关键点",content:"使用 @mousedown 代替 @click: mousedown 事件在 blur 事件之前触发，可以在 input 的失焦之前处理图标的逻辑。 保持逻辑一致性: 在删除逻辑完成后，blur 逻辑依然有效，不会受到干扰。"},{header:"补充：更精细的控制（防止失焦逻辑）",slug:"补充-更精细的控制-防止失焦逻辑",content:`如果希望在 icon 点击时完全阻止 blur 逻辑，可以通过 preventDefault 方法来实现：
<Input v-model="option.name" placeholder="Meal option" @focus="onInputFocus(index)" @blur="onInputBlur" @keydown.enter="onKeyDown(index, option.name, $event)" class="[&_.common-field\\_\\_input]:!h-[2.125rem]"
/>
<Icon name="delete" size="sm" class="bg-brand-subtlest rounded cursor-pointer absolute -right-6" v-if="currentInput > 0 && currentInput === index && isFocused" @mousedown="preventBlur($event)" @click="clickInputForm"
/> methods: { preventBlur(event) { // 阻止失焦 event.preventDefault(); }, clickInputForm() { // 删除逻辑 console.log("Icon clicked"); },
}`},{header:"两种方案对比",slug:"两种方案对比",content:`使用 @mousedown 替代 @click： 简单有效，适合大多数场景。
无需显式阻止 blur 事件，逻辑清晰。 使用 event.preventDefault()： 提供更精细的控制，适合复杂场景。
需要手动阻止 blur，可能会引入额外逻辑。 推荐根据实际需求选择合适的方法。目前使用的是第一种方法，当然第二种方法也是可以的。`}]},{path:"/content/front/js/js%E5%B0%86ascall%E7%A0%81%E8%BD%AC%E5%AD%97%E6%AF%8D.html",title:"js将ascall码转字母",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要将ascall转成对应的字母
String.fromCharCode(num1[, ...[, numN]])
返回值：一个长度为 N 的字符串，由 N 个指定的 UTF-16 代码单元组成 ex:
String.fromCharCode(97) // 'a'
String.fromCharCode(97,98,99) // 'abc' 反过来就是：str.charCodeAt(index)，index默认为下标0 ex:
'a'.charCodeAt() // 97
'abc'.charCodeAt(1) // 98
'abc'.charCodeAt(3) // NAN`}]},{path:"/content/front/js/js%E5%B0%86%E8%BD%AC%E5%8C%96%E4%B8%BA%E6%9F%90%E5%A4%A9%E6%9F%90%E5%B0%8F%E6%97%B6%E6%9F%90%E5%88%86%E9%92%9F%E6%9F%90%E7%A7%92.html",title:"js将转化为某天某小时某分钟某秒",pathLocale:"/",contents:[{header:"",slug:"",content:`js将转化为某天某小时某分钟某秒:
function formatSecToStr(seconds){ let daySec = 24 * 60 * 60; let hourSec= 60 * 60; let minuteSec=60; let dd = Math.floor(seconds / daySec); let hh = Math.floor((seconds % daySec) / hourSec); let mm = Math.floor((seconds % hourSec) / minuteSec); let ss=seconds%minuteSec; if(dd > 0){ return dd + "天" + hh + "小时" + mm + "分钟"+ss+"秒"; }else if(hh > 0){ return hh + "小时" + mm + "分钟"+ss+"秒"; } else if (mm > 0){ return mm + "分钟"+ss+"秒"; }else{ return ss+"秒"; }
}`}]},{path:"/content/front/js/js%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%9D%97%E7%9A%84%E5%86%99%E6%B3%95%E5%8C%BA%E5%88%AB.html",title:"js的两种模块的写法区别",pathLocale:"/",contents:[{header:"",slug:"",content:`js的两种模块的写法区别:
ESM（ECMAScript 模块）和 CommonJS 是两种 JavaScript 模块系统的实现方式，它们有几个关键的区别： 语法差异： ESM 使用 import 和 export 关键字来导入和导出模块。
CommonJS 使用 require() 函数来导入模块，并使用 module.exports 或 exports 对象来导出模块。 加载时机： ESM 是静态加载的，模块在代码解析阶段就会被加载。
CommonJS 是动态加载的，模块在代码执行阶段才会被加载。 模块加载方式： ESM 是异步加载的，因此模块加载的顺序是不确定的，它们在需要时才会被加载。
CommonJS 是同步加载的，模块加载的顺序是确定的，它们在代码执行时立即加载。 作用域： ESM 模块默认是严格模式的，且每个模块都有自己的作用域。
CommonJS 模块默认不是严格模式的，且所有模块共享同一个顶级作用域。 浏览器兼容性： ESM 目前在现代浏览器中得到了广泛支持，但在旧版浏览器中可能需要使用工具进行转换。
CommonJS 通常需要使用工具（如 Browserify、Webpack 等）将模块转换成浏览器可执行的代码。
总的来说，ESM 更符合现代 JavaScript 语言的发展趋势，它的静态加载和模块作用域使得代码更加清晰和可靠。CommonJS 则是 Node.js 长期以来使用的模块系统，在服务器端开发中仍然具有重要的地位。`}]},{path:"/content/front/js/js%E7%A6%81%E7%94%A8f12%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E7%A6%81%E7%94%A8%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95.html",title:"js禁用f12快捷方式以及禁用右键菜单",pathLocale:"/",contents:[{header:"js禁用f12快捷方式以及禁用右键菜单",slug:"js禁用f12快捷方式以及禁用右键菜单",content:`<!DOCTYPE html>
<html lang="en">
<head> <meta charset="UTF-8"> <title>禁止 F12 示例</title> <script> // 禁用右键菜单 document.addEventListener('contextmenu', e => e.preventDefault()); // 禁用常用开发者工具快捷键 document.addEventListener('keydown', function(e) { // F12 if (e.key === 'F12') e.preventDefault(); // Ctrl+Shift+I if (e.ctrlKey && e.shiftKey && e.key.toUpperCase() === 'I') e.preventDefault(); // Ctrl+Shift+C if (e.ctrlKey && e.shiftKey && e.key.toUpperCase() === 'C') e.preventDefault(); // Ctrl+Shift+J if (e.ctrlKey && e.shiftKey && e.key.toUpperCase() === 'J') e.preventDefault(); // Ctrl+U 查看源码 if (e.ctrlKey && e.key.toUpperCase() === 'U') e.preventDefault(); }); <\/script>
</head>
<body> <h1>这是一个示例页面</h1> <p>尝试右键或者按 F12，你会发现被禁止了</p>
</body>
</html>`}]},{path:"/content/front/js/js%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%BB%9A%E5%8A%A8%E6%9D%A1.html",title:"js自定义的滚动条",pathLocale:"/",contents:[{header:"",slug:"",content:`js自定义的滚动条:
//自定义一个开关滚动条 <script setup lang="ts">
const volume = ref(10)
const updateVolume = (val) => { console.log("val is:", val)
}
<\/script>
<template> <div class="volume-container"> <div class="volume-controls"> <span class="volume-control">-</span> <span class="volume-control">+</span> </div> <input type="range" min="10" max="20" v-model="volume" @input="updateVolume" class="volume-slider" /> </div>
</template>
<style scoped>
.volume-container{ max-width: 180px; width: 100%; margin: 60px auto;
}
.volume-controls{
display: flex;
justify-content: space-between;
align-items: center; height: 8px; margin-bottom: 4px;
}
.volume-slider{
max-width: 100%; width: 100%;
}
</style> 官方例子代码:https://github.com/advanced-cropper/vue-advanced-cropper/blob/master/example/docs/.vuepress/components/circle-example.vue`}]},{path:"/content/front/js/lodash%E4%B8%8B%E7%9A%84clamp%E4%BD%BF%E7%94%A8.html",title:"lodash下的clamp使用",pathLocale:"/",contents:[{header:"lodash下的clamp使用",slug:"lodash下的clamp使用",content:'watch( isActive, (active) => { const el = textareaRef.value; if (!el) return; el.style.height = active ? "" : `${clamp(24, el.scrollHeight, 381)}px`; }, { flush: "post" },\n);'},{header:"代码分析",slug:"代码分析",content:`Lodash 的 clamp 函数定义如下： clamp(number, lower, upper) 它的作用是将 number 限制在 lower 和 upper 之间：
如果 number < lower，返回 lower
如果 number > upper，返回 upper
否则返回 number 本身 { flush: "post" }:
表示在 DOM 更新之后 再触发 watch 的回调函数。
用于确保 DOM 变更（例如 v-if, v-show 的切换）已经完成，从而能正确读取 el.scrollHeight。 这个 watch 的主要作用是:
动态调整 <textarea> 的高度，根据是否“激活”来控制。
如果 isActive 为 false，则将 <textarea> 的高度设为其内容高度（受限于 24～381px）。
如果 isActive 为 true，则清除固定高度，让其恢复自动调整（例如用于用户输入时自动扩展）。`}]},{path:"/content/front/js/nodeJs%E6%9F%A5%E7%9C%8Bregistry%E5%9C%B0%E5%9D%80.html",title:"nodeJs查看registry地址",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要产看Node的registry地址，可以通过下面的命令实现:
vagrant@homestead:~/code/duoxiaozhan-www$ npm config list
; "user" config from /home/vagrant/.npmrc registry = "https://registry.npm.taobao.org/" ; "project" config from /home/vagrant/code/duoxiaozhan-www/.npmrc shamefully-hoist = true strict-peer-dependencies = false ; node bin location = /usr/local/bin/node
; node version = v18.16.0
; npm local prefix = /home/vagrant/code/duoxiaozhan-www
; npm version = 9.5.1
; cwd = /home/vagrant/code/duoxiaozhan-www
; HOME = /home/vagrant
; Run \`npm config ls -l\` to show all defaults. 或者直接:
vagrant@homestead:~/code/duoxiaozhan-www$ npm config get registry
https://registry.npm.taobao.org/`}]},{path:"/content/front/js/nodeJs%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7.html",title:"nodeJs版本升级",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目，报node版本过低的问题:
vagrant@homestead:~/code/duoxiaozhan-www$ yarn install
yarn install v1.22.17
info No lockfile found.
[1/4] Resolving packages...
[2/4] Fetching packages...
error @vue-macros/common@1.3.3: The engine "node" is incompatible with this module. Expected version ">=16.14.0". Got "14.19.0" //版本过低
error Found incompatible module.
info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command. 升级nodeJs操作:
Node.js官方提供了一种命令行工具n，可以通过这个工具方便地升级到最新版本的Node.js。 安装 n 命令 vagrant@homestead:~/code/duoxiaozhan-www$ sudo npm install n -g added 1 package, and audited 2 packages in 7s found 0 vulnerabilities 安装要升级的版本 vagrant@homestead:~/code/duoxiaozhan-www$ sudo n latest //这里直接到最新版本，可以指定，比如: 18.1.0 installing : node-v20.2.0 mkdir : /usr/local/n/versions/node/20.2.0 fetch : https://nodejs.org/dist/v20.2.0/node-v20.2.0-linux-x64.tar.xz copying : node/20.2.0 installed : v20.2.0 (with npm 9.6.6) Note: the node command changed location and the old location may be remembered in your current shell. old : /usr/bin/node new : /usr/local/bin/node
If "node --version" shows the old version then start a new shell, or reset the location hash with:
hash -r (for bash, zsh, ash, dash, and ksh)
rehash (for csh and tcsh) 注意上面的 Note，按照提示操作一遍即可解决问题，我直接新开一个terminal 然后执行 hash -r 即可`}]},{path:"/content/front/js/npm%E4%B8%8Bprepare%E5%92%8Cpostinstall%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"npm下prepare和postinstall的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`npm下prepare和postinstall的区别:
1>这两个钩子都是在npm install 完成之后执行
2>prepare 会在 postinstall 后面执行，这是因为 postinstall 是在依赖包被安装后立即执行，而 prepare 则在 postinstall 之后执行。这样的执行顺序设计是为了确保在 postinstall 阶段完成了所有必要的初始化操作之后，再执行 prepare 钩子. 下面是我实际运行的结果:
npm install > postinstall //先执行
> nuxt prepare ✔ Types generated in .nuxt 10:42:54 AM > prepare //后执行
> husky install husky - Git hooks installed added 120 packages, removed 4 packages, and changed 8 packages in 5m`}]},{path:"/content/front/js/npm%E4%B9%8Baudit%E7%9A%84%E4%BD%9C%E7%94%A8.html",title:"npm audit的作用",pathLocale:"/",contents:[{header:"",slug:"",content:`npm audit的作用:
audit命令向默认注册表提交项目中配置的依赖项的描述，并要求提供已知漏洞的报告。如果发现任何漏洞，将计算影响和适当的补救措施。如果提供了fix参数，则修正将应用于程序包树。 如果没有发现漏洞，该命令将退出，退出代码为0。
默认情况下，如果发现任何漏洞，audit命令将以非零代码退出。在CI环境中，包含- audit-level参数来指定导致命令失败的最低漏洞级别可能很有用。此选项不过滤报告输出，它只是更改命令的失败阈值 官方文档: https://docs.npmjs.com/cli/v10/commands/npm-audit`}]},{path:"/content/front/js/npm%E4%BB%93%E5%BA%93%E5%9C%B0%E5%9D%80%E9%85%8D%E7%BD%AE.html",title:"npm仓库地址配置",pathLocale:"/",contents:[{header:"",slug:"",content:`npm仓库地址配置:
获取npm的配置信息:
sp@k8s:~/code/mongodb-dir$ npm get registry
https://registry.npmjs.org/
sp@k8s:~/code/mongodb-dir$ npm config list
; "user" config from /home/sp/.npmrc https-proxy = "http://127.0.0.1:7890" proxy = "http://127.0.0.1:7890" registry = "https://registry.npmjs.org" ; node bin location = /usr/local/bin/node
; node version = v20.15.0
; npm local prefix = /home/sp/code/mongodb-dir
; npm version = 10.7.0
; cwd = /home/sp/code/mongodb-dir
; HOME = /home/sp
; Run \`npm config ls -l\` to show all defaults. 配置为其它地址:
要配置 npm 使用其他仓库，可以通过以下命令来修改 npm 的仓库地址：`},{header:"1. 临时修改仓库地址",slug:"_1-临时修改仓库地址",content:`如果你只想在当前会话中临时使用不同的仓库地址，可以运行：
npm set registry <新的仓库地址> 例如，将 npm 的仓库设置为淘宝的镜像仓库：
npm set registry https://registry.npm.taobao.org 这将修改 npm 配置，指向指定的仓库地址，但仅对当前会话有效。`},{header:"2. 永久修改仓库地址",slug:"_2-永久修改仓库地址",content:`要永久更改仓库地址，可以将配置写入到全局 .npmrc 文件中：
npm config set registry <新的仓库地址> --global 例如：
npm config set registry https://registry.npm.taobao.org --global 这样修改后，所有的 npm 命令都会使用新的仓库地址。`},{header:"3. 直接编辑 .npmrc 文件",slug:"_3-直接编辑-npmrc-文件",content:`你也可以直接编辑 .npmrc 文件，来配置 npm 仓库地址。.npmrc 文件通常位于用户的 home 目录下（全局配置），或者项目根目录下（项目级配置）。
在文件中添加如下内容：
registry=https://registry.npm.taobao.org 这样，你就完成了仓库地址的修改。`},{header:"恢复到默认仓库",slug:"恢复到默认仓库",content:`如果需要恢复到 npm 默认的官方仓库地址，可以运行：
npm config delete registry 这会删除自定义的仓库配置，恢复为默认的 https://registry.npmjs.org/。
代理相关:
//npm设置proxy
npm config set proxy http://your-proxy-address:port
npm config set https-proxy http://your-proxy-address:port //查看proxy:
npm config get proxy
npm config get https-proxy //还报错，可以设置为非严格模式即可
npm config set strict-ssl false`}]},{path:"/content/front/js/npm%E5%92%8Cnpx%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"npm和npx的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`npm和npx的区别:
npx 和 npm 是 Node.js 生态中的两个工具，它们有不同的用途和工作方式。`},{header:"npm（Node Package Manager）",slug:"npm-node-package-manager",content:`主要用途： 管理 Node.js 的包（安装、卸载、更新等）。
用于全局或本地安装依赖包。
管理项目的 package.json 文件中的依赖项。 常用命令： npm install <package> 或 npm i <package>：安装包（默认安装到 node_modules 中）。
npm install -g <package>：全局安装包。
npm run <script>：运行在 package.json 的 scripts 中定义的命令。 特点： 需要先安装包，才能使用包提供的命令行工具。
全局安装的工具会添加到系统路径中，供全局使用。`},{header:"npx",slug:"npx",content:`主要用途： 用于直接运行 Node.js 包，而无需先安装它们。
常用于执行一次性命令，避免安装不必要的全局依赖。
可以自动找到项目中的本地依赖并运行对应的命令。 常用场景： 快速运行一次性命令：npx create-react-app my-app （无需全局安装 create-react-app，直接运行）
调用项目的本地依赖命令：npx eslint . （即使未全局安装 ESLint，npx 会使用本地的 ESLint） 特点： 自动临时下载未安装的工具，并运行它（不污染全局或本地环境）。
默认从本地的 node_modules/.bin 中寻找命令，优先于全局路径。`},{header:"主要区别",slug:"主要区别",content:`特性
npm
npx 作用
管理包的安装和项目依赖
直接执行包或命令 是否安装包
需要先安装才能使用
可以无需安装直接运行 全局安装
需要全局安装才能全局使用工具
不需要全局安装，直接临时运行 优先级
从全局安装的命令中查找
优先使用本地安装的命令`},{header:"何时用 npx？",slug:"何时用-npx",content:`快速运行临时工具： 如果只需要运行某个命令一次，使用 npx 可以避免安装后再删除的麻烦。
示例：npx json-server --watch db.json 避免全局安装： 如果工具是针对单个项目使用的，而非系统范围的工具，npx 可以直接运行，不需全局安装。
示例：npx prettier --write . 确保使用正确版本的工具： 在项目中运行工具时，npx 会优先使用本地版本，避免与全局版本冲突。
示例：npx webpack`},{header:"总结",slug:"总结",content:`使用 npm： 管理依赖包（安装、卸载）和运行项目脚本。全局安装（npm install -g create-react-app）：需要提前安装工具，占用全局环境，并且版本固定。
使用 npx： 直接运行命令行工具，避免安装不必要的全局包，或确保运行项目本地依赖的工具。可能临时下载，这些下载的包会存储在一个临时目录中（通常是系统缓存目录，比如 ~/.npm/_npx），并在完成执行后自动删除，所以很适合项目的初始化。`},{header:"分析如下命令",slug:"分析如下命令",content:`npx degit dcloudio/uni-preset-vue#vite-ts my-vue3-project 这条命令使用 npx 和 degit 工具快速创建一个基于 uni-preset-vue 的 Vue 3 项目，并命名为 my-vue3-project。下面是对命令的详细解析：
这条命令使用 npx 和 degit 工具快速创建一个基于 uni-preset-vue 的 Vue 3 项目，并命名为 my-vue3-project。下面是对命令的详细解析：`},{header:"命令结构：",slug:"命令结构",content:"npx degit dcloudio/uni-preset-vue#vite-ts my-vue3-project"},{header:"分析：",slug:"分析",content:""},{header:"1. npx",slug:"_1-npx",content:`npx 直接运行工具（这里是 degit），无需提前安装。
如果 degit 未安装，npx 会临时下载并运行它，避免全局安装工具。`},{header:"2. degit",slug:"_2-degit",content:`degit 是一个用来快速克隆 Git 仓库的工具，但与 git clone 不同： 它会移除 .git 文件夹，创建一个干净的项目目录。
常用于模板项目的初始化，避免克隆完整的 Git 历史。`},{header:"3. dcloudio/uni-preset-vue#vite-ts",slug:"_3-dcloudio-uni-preset-vue-vite-ts",content:`表示需要克隆的 Git 仓库地址： dcloudio/uni-preset-vue：GitHub 上的仓库路径，属于 dcloudio 组织。
#vite-ts：分支或标签名，指向 vite-ts 分支/标签的代码。 这个分支可能包含基于 Vite 和 TypeScript 的模板代码。`},{header:"4. my-vue3-project",slug:"_4-my-vue3-project",content:`指定克隆后的项目文件夹名称。
最终，degit 会将仓库代码克隆到名为 my-vue3-project 的新目录中。`},{header:"执行效果：",slug:"执行效果",content:"克隆仓库： 从 dcloudio/uni-preset-vue 的 vite-ts 分支下载代码。 移除 .git 文件夹： 新的项目不会保留原仓库的 Git 历史信息，适合用作项目模板。 新建目录： 将模板代码保存到 my-vue3-project 文件夹中。"},{header:"可能的后续步骤：",slug:"可能的后续步骤",content:"进入项目目录：cd my-vue3-project 安装依赖：npm install 启动开发服务器：npm run dev"},{header:"总结：",slug:"总结-1",content:"这条命令通过 degit 克隆了一个基于 uni-preset-vue 的 Vue 3 模板项目（Vite + TypeScript）。degit 是一种快速、无历史记录的克隆方式，适合从模板仓库初始化项目。通过这种方式，可以方便地开始开发符合特定配置的 Vue 3 项目。"}]},{path:"/content/front/js/npm%E6%88%96yarn%E5%AE%89%E8%A3%85%E7%9A%84%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html",title:"npm或yarn安装的报错解决办法",pathLocale:"/",contents:[{header:"",slug:"",content:`在我们拉取到前端的项目的时候，经常需要执行npm install 或者 yarn install，安装必须的依赖，其中会有各种问题，下面我就列出几个常见的，以及对应的解决办法:
1.'vue-cli-service' 不是内部或外部命令，这个问题一般需要安装依赖
vagrant@homestead:~/code/xxx.net$ npm install -g @vue/cli
vagrant@homestead:~/code/xxx.net$ npm install -g @vue/cli-service 可能会报下面的错误：
npm ERR! code EACCES
npm ERR! syscall mkdir
npm ERR! path /usr/lib/node_modules/@vue
npm ERR! errno -13
npm ERR! Error: EACCES: permission denied, mkdir '/usr/lib/node_modules/@vue'
...
... 解决办法是加上 sudo，vagrant@homestead:~/xxx.net$ sudo npm install -g @vue/cli 执行 npm run serve的时候报：transpileDependencies.map is not a function，解决办法如下： 在项目的 vue.config.js配置文件里，做如下修改
module.exports = { ... transpileDependencies: [] //加上这个空的依赖即可解决问题 ...
}`}]},{path:"/content/front/js/npm%E6%9F%A5%E7%9C%8B%E5%B7%B2%E5%AE%89%E8%A3%85%E5%8C%85%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB.html",title:"npm查看已安装包的依赖关系",pathLocale:"/",contents:[{header:"",slug:"",content:`npm查看已安装包的依赖关系:
$ npm info @vee-validate/yup dependencies
{ 'type-fest': '^4.8.3', yup: '^1.3.2', 'vee-validate': '4.14.3' }`}]},{path:"/content/front/js/npm%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6npmrc%E5%92%8Cnvmrc.html",title:"npm的两个配置文件npmrc和nvmrc",pathLocale:"/",contents:[{header:"",slug:"",content:`npm的两个配置文件npmrc和nvmrc:
npmrc相关:
npmrc，可以理解成npm running cnfiguration, 即npm运行时配置文件。我们知道，npm最大的作用就是帮助开发者安装需要的依赖包，但是要从哪里下载？下载哪一个版本的包，把包下载到电脑的哪个路径下？
这些都可以在.npmrc中进行配置。
在设置.npmrc之前，我们需要知道：在你的电脑上，不止存在一个.npmrc文件，而是有多个。在我们安装包的时候，npm按照如下顺序读取这些配置文件: 项目配置文件：你可以在项目的根目录下创建一个.npmrc文件，只用于管理这个项目的npm安装。
用户配置文件：在你使用一个账号登陆的电脑的时候，可以为当前用户创建一个.npmrc文件，之后用该用户登录电脑，就可以使用该配置文件。可以通过 npm config get userconfig 来获取该文件的位置。
全局配置文件： 一台电脑可能有多个用户，在这些用户之上，你可以设置一个公共的.npmrc文件，供所有用户使用。该文件的路径为：$PREFIX/etc/npmrc，使用 npm config get prefix 获取$PREFIX。如果你不曾配置过全局文件，该文件不存在。
npm内嵌配置文件：最后还有npm内置配置文件，基本上用不到，不用过度关注。 用户配置文件:
qinhong@HPDEV-31:~$ npm config get userconfig
/home/qinhong/.npmrc 打开这个配置文件发现是我之前配置的仓库地址:
registry=https://registry.npm.taobao.org 还可以在项目下配置:
#包路劲地址
@qinhong-ui:registry='https://gitlab.qinhong.com:8081/api/v4/projects/800/packages/npm/' #授权地址信息
'//gitlab.qinhong.com:8081/api/v4/projects/800/packages/npm/:_authToken'=ddfr78dsfdggVCd You should now be able to run npm install @qinhong-ui/design-system to install the package. IMPORTANT: DO NOT COMMIT THIS AUTH TOKEN TO THE REPOSITORY. 1. To make the install work in CI, in your Gitlab repository for the project go to Settings => CI/CD => Expand the variables section => add variable. 2. Add a variable of GITLAB_TOKEN with your secret project token. 3. In your gitlab-ci.yml file you can now create a variable that reads this token in CI and will be used during the npm install. variables: GITLAB_TOKEN: $GITLAB_TOKEN nvmrc相关:
Node.js 版本更新速度极快，但未必所有套件都能对应于新的版本，可以通过 nvmrc文件定义当前项目的Node.js版本 cd project-a
touch .nvmrc
echo "12" >> .nvmrc cd ..
cd project-b
touch .nvmrc
echo "16" >> .nvmrc 像我本地的 .nvmrc 文件内容是: lts/hydrogen #这是一个v18的长期维护本版,https://nodejs.org/en/blog/release/v18.12.0`}]},{path:"/content/front/js/npm%E8%AE%BE%E7%BD%AEhttp-https%E4%BB%A3%E7%90%86.html",title:"npm 设置http/https代理",pathLocale:"/",contents:[{header:"",slug:"",content:`npm 设置http/https代理:
npm config set proxy=http://127.0.0.1:7890
npm config set https-proxy http://127.0.0.1:7890 npm 取消设置http/https代理:
npm config delete proxy
npm config delete https-proxy npm 查看仓库配置:
$ npm config get registry
https://registry.npmmirror.com npm 查看配置信息:
$ npm config list
; "user" config from /home/guoshipeng/.npmrc https-proxy = "http://127.0.0.1:7890"
proxy = "http://127.0.0.1:7890"
registry = "https://registry.npmmirror.com" ; node bin location = /home/guoshipeng/.nvm/versions/node/v20.17.0/bin/node
; node version = v20.17.0
; npm local prefix = /home/guoshipeng
; npm version = 10.8.2
; cwd = /home/guoshipeng
; HOME = /home/guoshipeng
; Run \`npm config ls -l\` to show all defaults`}]},{path:"/content/front/js/npm%E9%85%8D%E7%BD%AEtaobao%E9%95%9C%E5%83%8F.html",title:"npm配置taobao镜像",pathLocale:"/",contents:[{header:"",slug:"",content:`npm配置taobao镜像:
D:\\code\\vue-blog>npm config get registry
https://registry.npmjs.org/ D:\\code\\vue-blog>npm config set registry=https://registry.npmmirror.com (原来的在2024.1月过期了) D:\\code\\vue-blog>npm config get registry
https://registry.npmmirror.com/ 安装typescript:
D:\\code\\vue-blog>npm i -g typescript`}]},{path:"/content/front/js/nuxt3.5%E4%B8%8B%E7%9A%84%E5%90%8E%E7%AB%AF%E8%AF%B7%E6%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%E5%92%8C%E4%B9%8B%E5%89%8D%E4%B8%8D%E5%90%8C.html",title:"nuxt3.5下的后端请求代理配置和之前不同",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3.5下的后端请求代理配置和之前不同，最近使用了最新的nuxt3版本，当初使用v3.0的时候，代理和vue下的使用差不多，但是
到了v3.5之后，就彻底不一样了,最新的配置如下:
nitro:{ devProxy: { "/api": { //client发送请求的时候，要用相对地址，以/api开头，否则请求走不到这里，不能被代理，之前测试的这时候直接用的是http://localhost:8088/api/common/upload, 一直请求不通 target: 'http://localhost:8088/api', prependPath: true, changeOrigin: true, } } } 参考链接如下:
https://juejin.cn/post/7201099253498036279
https://nitro.unjs.io/config //nitro网络配置`}]},{path:"/content/front/js/nuxt3%E4%B8%8B_fetch%E5%92%8CuseFetch%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"nuxt3下$fetch和useFetch的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3下$fetch和useFetch的区别:
Nuxt uses ofetch to expose globally the $fetch helper for making HTTP requests within your Vue app or API routes.
During server-side rendering, calling $fetch to fetch your internal API routes will directly call the relevant function (emulating the request), saving an additional API call.
However, using $fetch in components without wrapping it with useAsyncData causes fetching the data twice: initially on the server, then again on the client-side during hydration, because $fetch does not transfer state from the server to the client. Thus, the fetch will be executed on both sides because the client has to get the data again.
We recommend to use useFetch or useAsyncData + $fetch to prevent double data fetching when fetching the component data. 翻译过来就是:
Nuxt 使用 ofetch 全局公开 $fetch 辅助函数，用于在 Vue 应用程序或 API 路由中进行 HTTP 请求。
在服务器端渲染期间，调用 $fetch 来获取内部 API 路由将直接调用相关函数（模拟请求），从而节省额外的 API 调用。
但是，在组件中使用 $fetch 而不使用 useAsyncData 对其进行封装会导致获取两次数据：最初在服务器上，然后在水合过程中再次在客户端，因为 $fetch 不会将状态从服务器传输到客户端。因此，由于客户端必须再次获取数据，因此获取将在两侧执行。
我们建议在获取组件数据时使用 useFetch 或 useAsyncData + $fetch 来防止重复获取数据。 使用示例:
<script setup lang="ts">
// During SSR data is fetched twice, once on the server and once on the client.
const dataTwice = await $fetch('/api/item') // During SSR data is fetched only on the server side and transferred to the client.
const { data } = await useAsyncData('item', () => $fetch('/api/item')) // You can also useFetch as shortcut of useAsyncData + $fetch
const { data } = await useFetch('/api/item')
<\/script>`}]},{path:"/content/front/js/nuxt3%E4%B8%8B_fetch%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF.html",title:"nuxt3下$fetch的使用场景",pathLocale:"/",contents:[{header:"",slug:"",content:`使用原因见(nuxt3在测试环境遇到useFetch数据获取不到的问题)，我认为在middleware中更有使用场景，由于$fetch 会在客户端和服务端各执行一次，为了避免这个问题，我一般会在middleware 中做个 process.server/process.client 判断，然后选择执行位置
下面这个是 middlleware/courseAuth.ts的内容:
// @ts-ignore
import {defineNuxtRouteMiddleware, navigateTo, useRuntimeConfig} from "#app"
import {createError} from "h3"; export default defineNuxtRouteMiddleware(async (to, from) => { // @ts-ignore if (process.client) return const result = await $fetch('/api/course/' + to.params.id, { method: 'get', headers: {'X-Requested-With': 'XMLHttpRequest'}, }) if (result){ if (result.code){ return navigateTo('/', { redirectCode: 403 }) }else if (result.data.status != 2){ throw createError({ statusCode: 404, statusMessage: 'Page Not Found' }) }else { return } }else { throw createError({ statusCode: 404, statusMessage: 'Page Not Found' }) }
})`}]},{path:"/content/front/js/nuxt3%E4%B8%8Bassets%E5%92%8Cpublic%E7%9B%AE%E5%BD%95%E5%8A%9F%E8%83%BD%E6%98%AF%E4%B8%8D%E4%B8%80%E6%A0%B7%E7%9A%84.html",title:"nuxt3下assets和public目录功能是不一样的",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目的时候，发现执行npx run dev 和 npx run build 结果，dev环境下土拍你资源在build后，不能访问了，研究发现是因为资源路径的问题
assets 和public 目录功能是不一样的，官方文档上有说明：
Nuxt uses two directories to handle assets like stylesheets, fonts or images.
The public/ directory content is served at the server root as-is.
The assets/ directory contains by convention every asset that you want the build tool (Vite or webpack) to process.
重点：Nuxt won't serve files in the assets/ directory at a static URL like /assets/my-file.png. If you need a static URL, use the public/ directory.
[官网]https://nuxt.com/docs/getting-started/assets
研究发现：
<img class="avatar" src="~/public/img/user_image.jpg" alt=""> //加了public目录以后，这个写法也可以 (直接把saaets换成public)
<img class="avatar" src="/img/user_image.jpg" alt=""> // 这个才是官方用法，就是直接访问public下的资源`}]},{path:"/content/front/js/nuxt3%E4%B8%8Bswiper%E8%87%AA%E5%8A%A8%E8%BD%AE%E6%92%AD%E4%B8%8D%E7%94%9F%E6%95%88.html",title:"nuxt3下swiper自动轮播不生效",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3下swiper自动轮播不生效:
应该单独引入 Autoplay:
import { Pagination, Autoplay } from 'swiper/modules'; initSwiper: function (tag){ return new Swiper(tag, { direction: 'horizontal', spaceBetween: 30, loop: true, autoplay: { delay: 2500, disableOnInteraction: false, }, pagination: { el: '.swiper-pagination', clickable: true, }, modules:[Pagination, Autoplay] }) }`}]},{path:"/content/front/js/nuxt3%E4%B8%8B%E5%B0%81%E8%A3%85%E5%85%AC%E5%85%B1http%E8%AF%B7%E6%B1%82.html",title:"nuxt3下封装公共http请求",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3下封装公共http请求:
在实际使用nuxt3请求接口的时候，我默认使用的是 useFetch 请求接口，但是有一种情况会失败，就是在created的时候调用的接口，
我后来分析了一下，useFetch其实是以恶搞client端的请求方式，可能在created的时候，页面还没有渲染完全，所以会报错，后来
找到了三种方法解决这个问题，下面一一介绍(这个问题和之前的 解决Nuxt项目中发生在服务端的请求丢失Cookie的问题 一样):
1.改用 $fetch请求接口 使用$fetch请求接口可以解决上面的问题，但是也会产生另外一个问题，就是$fetch会在client和server端都发起请求，导致接口多次调用 2.使用setTimeout延迟，这个方法也可以解决问题，但是延迟多少是个问题 setTimeout(function (){ this.getLearnProgress() }.bind(this), 200) 3.使用 await nextTick() 可以完美的解决问题，对于需要登陆的接口，甚至不用手动在header里传递cookie信息 实际项目中使用:
//[id].vue <template> <!-- course-detail-banner--> <div class="banner-wrapper fix-p-top" v-if="$screen.higherThan('xl', $screen.current.value)" > <img class="banner-img" :src="resourceUrl + '/' + courseDetail.coverPicture" alt="" /> <div class="container banner-cont"> <CourseNav :navs="{ tag: courseDetail.tag }" v-if="courseDetail.id > 0" ></CourseNav> <div class="course-info"> <div class="course-title"> <p class="title white-space">{{ courseDetail.title }}</p> </div> <div class="course-statics"> <ul class="resources clear"> <li>{{ courseStatistics.videoCount }} Videos</li> <li>{{ courseStatistics.articleCount }} Article</li> <li>{{ courseStatistics.estimatedLearningTime }}</li> </ul> <ul class="users"> <li> <img src="~/assets/img/group.png" alt="" /><span >{{ courseStatistics.userCount }} People joined</span > </li> <li v-if="courseDetail.isNeedCertification"> <img src="~/assets/img/card_membership.png" alt="" /><span >With certification earned</span > </li> </ul> </div> <div class="join-action"> <Button @click="joinTheCourse" rounded="none" customColor="#000" customBgColor="#01F0E0" :active="false" variant="quaternary" class="btn-join-style btn" >{{ isJoin ? 'Enter' : 'Join the course' }} </Button> </div> </div> </div> </div> <!-- 手机端页面 --> <div class="banner-wrapper" v-else> <img class="banner-img" :src="resourceUrl + '/' + courseDetail.coverPicture" alt="" /> <div class="container banner-cont p-[20px]"> <CourseNav :navs="{ tag: courseDetail.tag }" v-if="courseDetail.id > 0" ></CourseNav> <div class="course-info" style="padding-left: 0"> <div class="course-title" style="font-size: 18px; margin-top: 20px"> <p class="title white-space" style="font-size: 24px"> {{ courseDetail.title }} </p> </div> <div class="course-statics"> <ul class="resources clear"> <li>{{ courseStatistics.videoCount }} Videos</li> <li>{{ courseStatistics.articleCount }} Article</li> <li>{{ courseStatistics.estimatedLearningTime }}</li> </ul> <ul class="users"> <li> <img src="~/assets/img/group.png" alt="" /><span >{{ courseStatistics.userCount }} People joined</span > </li> <li v-if="courseDetail.isNeedCertification"> <img src="~/assets/img/card_membership.png" alt="" /><span >With certification earned</span > </li> </ul> </div> <div class="join-action" style="width: fit-content"> <Button @click="joinTheCourse" rounded="none" customColor="#000" customBgColor="#01F0E0" :active="false" variant="quaternary" class="btn-join-style btn" >{{ isJoin ? 'Enter' : 'Join the course' }} </Button> </div> </div> </div> </div> <!-- course-detail-content--> <div class="container"> <div class="content-box"> <div class="course-detail"> <p class="title phone-title relin-paragraph-target"> Information for Editors </p> <div class="phone-text" :class="{ 'more-phone-text': exp }"> <div class="detail" v-html="courseDetail.description"></div> </div> <div v-if="!$screen.higherThan('xl', $screen.current.value) && !exp" class="text-[.875rem] text-[#337AB7] pt-[.625rem]" @click="readMore" > Read more </div> <div v-if="!$screen.higherThan('xl', $screen.current.value) && exp" class="text-[.875rem] text-[#337AB7] pt-[.625rem]" @click="fold" > Fold </div> </div> <div class="course-lesson course-phone-lesson"> <p class="title relin-paragraph-targe">Course outline</p> <div class="lesson-box"> <div class="lesson-info"> <p class="num">{{ courseStatistics.lessonCount }} Chapters</p> <p class="times">{{ courseStatistics.estimatedLearningTime }}</p> </div> <div class="lesson-list" v-if="courseManageList.length"> <NotificationModal ref="notify"></NotificationModal> <ul> <li v-for="(item, index) in courseManageList" :key="index" @click="learnTheCourse(item.id, item.type)" > <a> <img src="~/assets/img/play_circle.svg" alt="" v-if="item.type === 'video'" /> <img src="~/assets/img/article_circle.svg" alt="" v-else-if="item.type === 'article'" /> <img src="~/assets/img/quiz_circle.svg" alt="" v-else /> <span class="title three-white-space">{{ item.title }}</span> </a> <span class="times">{{ item.length }}</span> </li> </ul> </div> </div> </div> </div> </div> <!-- action box--> <div class="action-wrapper" v-if="courseDetail.id"> <ShareAndThumb :url="resourceUrl + $route.fullPath" :title="courseDetail.title" ></ShareAndThumb> </div> <!-- toast -->
<!-- <ToastMessage ref="toastMessage"></ToastMessage>--> <ToastMessage v-model:modelValue="isSHow" :toastObj="toastObj"></ToastMessage>
</template> <script setup lang="ts">
import {onMounted, ref} from 'vue'
import {useAwesomeScreen} from "../../composables/use-awesome-screen";
import { definePageMeta, useRuntimeConfig, useRoute, createFetchOptions, useRouter,
} from "../../.nuxt/imports"; definePageMeta({ middleware: ['param-number', 'course-auth']
}) const $screen = useAwesomeScreen() const exp = ref<boolean>(false)
const readMore = () => { exp.value = true
}
const fold = () => { exp.value = false
} const isSHow = ref<boolean>(false)
const toastObj = ref<MessageObj>({variant:'', message:''})
//逻辑
import _ from 'lodash'
import utils from '../../utils/utils'
import { MButton as Button } from '@mdpi-ui/design-system'
import {CourseDetail} from "../../composables/CourseDetail";
import {CourseStatistics} from "../../composables/CourseStatistics";
import {ApiResponse} from "../../composables/ApiResponse";
import {FetchOptions} from "../../composables/FetchOptions";
import {JoinCourse, UserCourse} from "../../composables/UserCourse";
import {MessageObj} from "../../composables/MessageObj";
import {RequestBody} from "../../composables/RequestBody";
import {CourseManage, isCourseManage} from "../../composables/CourseManage";
import httpRequests from "../../composables/useHttp" const courseDetail = ref<CourseDetail>({ id:0, title: '', description: '', coverPicture: '', isNeedCertification: '', tag: ''
})
const courseStatistics = ref<CourseStatistics>({ estimatedLearningTime: '', lessonCount: 0, videoCount: 0, articleCount: 0, userCount: 0
})
const courseManageList = ref([])
const resourceUrl = ref("")
const isJoin = ref<boolean>(false)
const isNotification = ref<boolean>(false)
const config = useRuntimeConfig()
const route = useRoute()
const router = useRouter()
const notify = ref(null); const requestBody1: RequestBody = { id: route.params.id, type: 'course'
} const requestBody3: RequestBody = { id: route.params.id, type: 'course', estimatedLearningTime: 1, lessonCount: 1, videoCount: 1, articleCount: 1, userCount: 1
} const requestBody4: RequestBody = { id: route.params.id, type: 'course'
} const requestBody5: RequestBody = { id: route.params.id, type: 'course'
} const options1: FetchOptions = createFetchOptions(true, requestBody1);
const options2: FetchOptions = createFetchOptions(false);
const options3: FetchOptions = createFetchOptions(false, requestBody3);
const options4: FetchOptions = createFetchOptions(false, requestBody4);
const options5: FetchOptions = createFetchOptions(true, requestBody5); onMounted(() => { resourceUrl.value = config.public.envData.VITE_APP_URL isJoinTheCourse() getCourseDetail() getCourseStatistics() getCourseManage()
}) async function isJoinTheCourse() { if (utils.isLogin()) { // const res: ApiResponse<UserCourse> = await ($fetch as (url: string, options?: FetchOptions) => Promise<ApiResponse<UserCourse>>)( '/api/user/course', options1); // if (res.code == 0 && res.data.id){ // isJoin.value = true // } // 自定义请求方法 // httpRequests.useHttpPost('/api/user/course', { // id: route.params.id, // type: 'course' // }).then((res) => { // if (!res.status){ // isSHow.value = true // toastObj.value = {variant: 'accent', message: res.msg} // }else { // isJoin.value = true // } // }).catch() const res = await httpRequests.useHttpPost('/api/user/course', { id: route.params.id, type: 'course' }) if (!res.status){ isSHow.value = true toastObj.value = {variant: 'accent', message: res.msg} }else { isJoin.value = true } }
} async function getCourseDetail(){ const res: ApiResponse<CourseDetail> = await ($fetch as (url: string, options?: FetchOptions) => Promise<ApiResponse<CourseDetail>>)( '/api/course/'+route.params.id, options2); try { if (res.code){ isSHow.value = true toastObj.value = {variant: 'accent', message: res.msg} }else { courseDetail.value.id = res.data.id courseDetail.value.title = res.data.title courseDetail.value.description = res.data.description courseDetail.value.coverPicture = res.data.coverPicture courseDetail.value.isNeedCertification = res.data.isNeedCertification courseDetail.value.tag = res.data.tag } }catch (error){ isSHow.value = true toastObj.value = {variant: 'error', message: 'require api failed'} }
} async function getCourseStatistics(){ const res: ApiResponse<CourseStatistics> = await ($fetch as (url: string, options?: FetchOptions) => Promise<ApiResponse<CourseStatistics>>)( '/api/course/statistics', options3); try { if (res.code){ isSHow.value = true toastObj.value = {variant: 'accent', message: res.msg} }else { courseStatistics.value.estimatedLearningTime = res.data.estimatedLearningTime courseStatistics.value.lessonCount = res.data.lessonCount courseStatistics.value.videoCount = res.data.videoCount courseStatistics.value.articleCount = res.data.articleCount courseStatistics.value.userCount = res.data.userCount } }catch (error){ isSHow.value = true toastObj.value = {variant: 'error', message: 'require api failed'} }
} async function getCourseManage(){ const res: ApiResponse<number[]> = await ($fetch as (url: string, options?: FetchOptions) => Promise<ApiResponse<number[]>>)( '/api/course/manage', options4); try { if (res.code){ isSHow.value = true toastObj.value = {variant: 'accent', message: res.msg} }else { if (res.data.length) { _.forEach(res.data, (item) => { let obj = {} as CourseManage if (isCourseManage(item)){ obj.id = item.id obj.type = item.type obj.title = item.title obj.length = item.length } courseManageList.value.push(obj) }) } } }catch (error){ isSHow.value = true toastObj.value = {variant: 'error', message: 'require api failed'} }
} function learnTheCourse(item_id, type){ if (utils.isLogin()){ if (isJoin){ if (type === 'video') { router.push({ name: 'course-video', query: { item_id: item_id } }) } else if (type === 'article') { router.push({ name: 'course-article', query: { item_id: item_id } }) } else { router.push({ name: 'course-quiz', query: { item_id: item_id } }) } }else { notify.value.isShow = true; notify.value.id = route.params.id; } }else { isSHow.value = true toastObj.value = {variant: 'accent', message: 'Please login'} }
} async function joinTheCourse(){ if (utils.isLogin()) { const res: ApiResponse<JoinCourse> = await ($fetch as (url: string, options?: FetchOptions) => Promise<ApiResponse<JoinCourse>>)( '/api/join/course', options5); try { if (res.code){ isSHow.value = true toastObj.value = {variant: 'accent', message: res.msg} }else { let type = res.data.type if (type === 'video'){ await router.push({ name: 'course-video', query: {item_id: res.data.itemId} }) }else if (type === 'article'){ await router.push({ name: 'course-article', query: {item_id: res.data.itemId} }) }else { await router.push({ name: 'course-quiz', query: {item_id: res.data.itemId} }) } } }catch (error){ isSHow.value = true toastObj.value = {variant: 'error', message: 'require api failed'} } } else { isSHow.value = true toastObj.value = {variant: 'error', message: 'require api failed'} }
}
<\/script> <style lang="postcss" scoped>
.banner-wrapper { width: 100%; height: 40.6875rem; position: relative; z-index: 10; .banner-img { display: block; width: 100%; height: 45.0625rem; position: absolute; top: -4.375rem; } .banner-cont { position: relative; z-index: 61; .course-info { padding-left: 2.1875rem; } .course-title { margin-top: 7.3125rem; .title { font-weight: 300; font-size: 5.875rem; @media screen and (max-width: 992px) { font-size: 4.875rem; } @media screen and (max-width: 768px) { font-size: 3.875rem; } line-height: 6.4625rem; height: 6.4375rem; color: #fff; } } .course-statics { margin-top: 2.65625rem; .resources { li { float: left; color: #fff; font-size: 0.875rem; line-height: 1.4rem; position: relative; padding-right: 0.5625rem; margin-right: 0.5625rem; font-weight: 400; &:after { content: ''; position: absolute; width: 0.0625rem; height: 1.25rem; right: 0; background: url('/assets/img/split_line.png') no-repeat; } &:last-child:after { content: ''; width: 0; } } } .users { li { margin-top: 1rem; display: flex; align-items: flex-start; color: #fff; img { display: block; width: 1.25rem; height: 1.25rem; } span { font-weight: normal; font-size: 0.875rem; line-height: 1.375rem; margin-left: 0.375rem; } } } } .join-action { margin-top: 1.90625rem; width: 10.875rem; height: 2.75rem; a { display: block; padding: 0.625rem 1.875rem; font-size: 1rem; text-align: center; color: #000; line-height: 1.5rem; background-color: #01f0e0; } } }
}
.content-box { .course-detail { .title { font-weight: 500; font-size: 1.75rem; line-height: 2.4375rem; } .detail { margin-top: 1.875rem; font-weight: normal; font-size: 1rem; line-height: 170%; &:deep(ul) { list-style: disc outside; margin-left: 1rem; } &:deep(ol) { list-style: decimal outside; margin-left: 1.125rem; } } } .course-lesson { .title { font-weight: 400; font-size: 1.75rem; line-height: 2.4375rem; } .lesson-box { margin-top: 1.875rem; width: 28.125rem; @media screen and (max-width: 48rem) { width: 100%; } .lesson-info { display: flex; justify-content: space-between; align-items: center; width: 100%; height: 2.875rem; background-color: #000; color: #fff; .num { width: 10.125rem; font-size: 1rem; line-height: 1.5rem; margin-left: 1.25rem; } .times { width: 5.0625rem; height: 1.625rem; line-height: 1.625rem; font-size: 0.875rem; } } .lesson-list { border: 1px solid #000; position: relative; ul { li { display: flex; align-items: center; justify-content: space-between; height: 5rem; padding: 0.53125rem 1.25rem; box-sizing: border-box; border-bottom: 1px solid #757575; cursor: pointer; a { display: flex; color: #000; align-items: center; img { display: block; width: 1.5rem; height: 1.5rem; margin-right: 0.75rem; } @media (min-width: 48rem) { .title { max-width: 17.1875rem; font-size: 0.875rem; line-height: 150%; } } /* @media (max-width: 768px) { .title { max-width: 14rem; } } */ } .times { margin-left: auto; font-size: 0.875rem; line-height: 1.3125rem; } } } } } }
}
@media (min-width: 48rem) { .content-box { display: flex; justify-content: space-between; margin-top: 6.25rem; color: #000; margin-bottom: 9.125rem; .course-detail { width: 50.625rem; } }
}
@media (max-width: 64rem) { .banner-wrapper { height: 100%; .banner-img { display: block; width: 100%; height: auto; position: absolute; top: -4.375rem; } } .content-box { padding-left: 1.25rem; padding-right: 1.25rem; margin-top: 6.25rem; margin-bottom: 9.125rem; .course-phone-lesson { padding-top: 1.25rem; } } .times { width: auto !important; padding-right: 0.625rem; } .lesson-list { display: block; ul { li { display: block !important; height: 100% !important; a { .title { width: 100%; font-size: 0.875rem !important; line-height: 150%; } } .times { padding-left: 2.2rem; } } } } .relin-paragraph-targe { font-size: 2rem !important; font-weight: 600 !important; } .phone-title { font-size: 2rem !important; font-weight: 600 !important; } .phone-text { display: -webkit-box; -webkit-line-clamp: 9; -webkit-box-orient: vertical; overflow: hidden; &.more-phone-text { -webkit-line-clamp: 999; } }
} .action-wrapper { position: absolute; top: 53.875rem; right: 0;
}
</style> //封装http请求，useHttp.ts文件 import {nextTick, ref} from 'vue'
import {useCookie, useFetch} from '../.nuxt/imports' interface HttpRequestOption { headers?: Record<string, string>, method?: 'GET' | 'POST', body?: {}, lazy?: boolean
} interface HttpResponse { status: boolean; statusCode: number; msg: string; code?: number; data?: any;
} function useGetFetchOptions(options: HttpRequestOption) { // options.key = 'my-key' options.headers = options.headers ? options.headers : {} options.headers['X-Requested-With'] = 'XMLHttpRequest' options.headers['cookie'] = useCookie("DUOXIAOZHANSSESSID").value || "" return options
} export async function useHttpRequest(url: string, options: HttpRequestOption): Promise<HttpResponse> { // 有了 await nextTick()，当用户登录以后, 后面的 options = useGetFetchOptions(options) 也可以不要，就是说不用cookie信息也可以请求成功，可以f12看到接口调用 await nextTick(); options = useGetFetchOptions(options); // 这里使用 useFetch 请求 const res = await useFetch(url, { ...options, //transform是一个 callback 用于处理 useFetch 的响应数据，这里其实没有做任何处理 transform: (res: any) => res }); // 客户端错误处理 //@ts-ignore if (process.client && res.error?.value) { const errorData = res.error.value.data; const statusCode = res.error.value.statusCode; if (statusCode === 401) { location.href = '/login'; } const msg = errorData?.data; if (!options.lazy) { // 如果需要返回错误信息和statusCode，可以在此处进行处理 return { status: false, statusCode: statusCode, msg: msg || '服务端错误', }; } } // 如果没有错误，返回数据 if (res.data.value.code) { return { status: false, statusCode: 200, msg: res.data.value.msg || '请求成功', code: res.data.value.code }; } return { status: true, statusCode: 200, msg: res.data.value.msg || '请求成功', code: res.data.value.code, data: res.data.value.data }
} // GET请求
function useHttpGet(url, params = {}, options: HttpRequestOption = {}): Promise<HttpResponse> { options.method = "GET" return useHttpRequest(url, options)
} // POST请求
function useHttpPost(url, params: {}, options: HttpRequestOption = {}): Promise<HttpResponse> { options.method = "POST" options.body = params return useHttpRequest(url, options)
} function myAsyncFunction() { return new Promise((resolve, reject) => { // Simulate an asynchronous operation setTimeout(() => { resolve("Hello, World!"); }, 1000); });
} // Usage without await
const promise = myAsyncFunction(); // async function myAsyncFunction() {
// return new Promise((resolve, reject) => {
// // Simulate an asynchronous operation
// setTimeout(() => {
// resolve("Hello, World!");
// }, 1000);
// });
// } // Usage with await
// const promise = await myAsyncFunction(); async function testPromise() { promise.then(result => { console.log("result is:", result); // "Hello, World!" }).catch(error => { console.error("error is:", error); }); // try { // const promise = await myAsyncFunction(); // console.log("promise is:", promise); // }catch (error){ // console.error("error is:", error); // } //上面两种情况,下面的 console 的执行顺序是不一样的 console.log(1111111112222222222)
} //重要结论
// it's important to note that an async function can implicitly return a resolved Promise even if the return type is not explicitly Promise<T>. // export {
// useHttpGet,
// useHttpPost
// } const httpRequests = { useHttpGet, useHttpPost, testPromise
}
//
export default httpRequests;`}]},{path:"/content/front/js/nuxt3%E4%B8%8B%E8%B7%AF%E7%94%B1%E8%B7%B3%E8%BD%AC%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92.html",title:"nuxt3下路由跳转参数传递",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3下路由跳转参数传递，组件下：NuxtLink 和 nuxt-link一样
<!-- named route -->
<nuxt-link :to="{ name: 'user', params: { userId: 456 }}">User</nuxt-link> created() { console.log(this.$route.params) console.log(this.$route.params.userId) console.log(this.$nuxt._route.params) console.log(this.$nuxt._route.params.userId)
} <!-- with query, resulting in \`/register?plan=private\` -->
<nuxt-link :to="{ path: 'register', query: { plan: 'eat' }}">Register</nuxt-link> created() { console.log(this.$route.query) console.log(this.$route.query.plan) console.log(this.$nuxt._route.query) console.log(this.$nuxt._route.query.plan)
}`}]},{path:"/content/front/js/nuxt3%E4%B8%A2%E5%A4%B1cookie%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"nuxt3丢失cookie的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`我看NUXT3有提供传递cookie信息的方法:useRequestHeaders，但是只能拿到一个empty对象
官网链接:https://nuxt.com/docs/api/composables/use-request-headers
经过改造，如下plugins/init.server.js：
import { defineNuxtPlugin } from '#app';
function cookieFromRequestHeaders (key) { const headers = useRequestHeaders(['cookie']); if ('cookie' in headers) { const cookie = headers.cookie.split(';').find( c => c.trim().startsWith(\`\${key}=\`) ); if (cookie) { return cookie.split('=')[1]; } } return '';
}
export default defineNuxtPlugin(async (nuxtApp) => { const userinfo = cookieFromRequestHeaders('userinfo'); console.log(userinfo) // 运行以后 是可以拿到userinfo信息的
}); 但是我的 需求是，在发送请求的时候，同时传递cookie，以及自定义header头信息，最后测试发现可以通过：{'X-Requested-With': 'XMLHttpRequest', 'cookie':headers.cookie} 实现
getUserLearnProgress: async function () { const headers = useRequestHeaders(['cookie']);//这个 不能写到 import 同级别，只能放到生命周期函数里，否则会报错：500 nuxt instance unavailable at Module.useRequestHeaders (./node_modules/nuxt/dist/app/composables/ssr.mjs:7:41) if (utils.isLogin()) { let userInfo = utils.getUserInfo() const {data, error} = await useFetch('/api/user/course', { method: 'post', body: {userId: userInfo.id, courseId: this.$route.query.id}, headers: {'X-Requested-With': 'XMLHttpRequest', 'cookie':headers.cookie}, }) if (error._value) { this.$toast.error(error._value.data.msg) } else { if (data._value.code === 0) { this.progress = data._value.data.progress } else { this.$toast.error(data._value.msg) } } } else { this.$toast.info('Please login') } }, 到此，NUXT3 SSR渲染 获取cookie 以及自定义header头信息的问题解决了
下面这个方法是我通过 setTimeout 延迟200ms 调用也是可以解决SSR 渲染拿不到cookie的问题，但事实这个方法有二个问题 就是 这个200ms的选择问题，所以还是推荐上面的方法吧，不容易，搞了好久
setTimeout(function (){ this.getUserLearnProgress() }.bind(this), 200) 最近在重构之前做的项目，我发现了一个新的方案:
//在 useFetch()调用之前，先调用 nextTick() 也可以不用传递cookie就可以调用
//我认为这个和上面的setTimeOut有异曲同工共的作用 await nextTick() //执行顺序：同步代码 > nextTick > Promise> setTimeout
//执行顺序：微任务 > 宏任务
//常见的宏任务有:script setTimeout / setInterval
//常见的微任务有:Promise process.nextTick //一般的promise对象
let promise = new Promise(function (resolve, reject) { if (/* 异步操作成功 */) { resolve(data); } else { /* 异步操作失败 */ reject(error); }
});
//类似构建对象，使用new来构建一个Promise。Promise接受一个「函数」作为参数，该函数的两个参数分别是resolve和reject。这两个函数就是就是「回调函数」，由JavaScript引擎提供。
//Promise实例生成以后，可以用then方法指定resolved状态和reject状态的回调函数。
//promise.then(onFulfilled, onRejected); promise.then(function(data) { // do something when success
}, function(error) { // do something when failure
}); //.catch(),该方法是.then(undefined, onRejected)的别名，用于指定发生错误时的回调函数。
promise.then(function(data) {//注意这个then只有一个回调，那么异常会走到catch那里，如果then有两个回调(如上面的代码)，那么异常会被第二个回调捕获,不会被catch console.log('success');
}).catch(function(error) { console.log('error', error);
}); /*******等同于*******/
promise.then(function(data) { console.log('success');
}).then(undefined, function(error) { console.log('error', error);
}); //任务执行比较
new Promise((resolve) => { console.log(1);//该区域并非回调函数，而是同步代码！ process.nextTick(() => { console.log(2); }); resolve(); process.nextTick(() => { console.log(3); }); console.log(4);//该区域并非回调函数，而是同步代码！
}).then(() => { console.log(5);
}); setTimeout(() => { console.log(6);
}, 0); console.log(7); // 输出顺序
1
4
7
2
3
5
6 关于nuxt3获取数据的几种方式比较:
https://nuxt.com/docs/getting-started/data-fetching
https://nuxt.com/docs/api/utils/dollarfetch 关于需要手动传递cookie的原因:
https://nuxt.com/docs/getting-started/data-fetching#passing-headers-and-cookies
原文这样说:
When we call $fetch in the browser, user headers like cookie will be directly sent to the API. But during server-side-rendering, since the $fetch request takes place 'internally' within the server, it doesn't include the user's browser cookies, nor does it pass on cookies from the fetch response. 关于在nuxt3使用$fetch的时候，会请求两次接口的问题:
在 Nuxt.js 中，如果页面在服务端和客户端都渲染，最终以客户端渲染的数据为准。这是因为客户端渲染会覆盖服务端渲染的内容。当页面在服务端渲染时，Nuxt.js 会将服务端渲染的结果作为 HTML 直接返回给浏览器，然后在浏览器端继续执行客户端渲染。在客户端渲染完成后，浏览器会用客户端渲染的内容替换服务端渲染的内容。
这样做的目的是为了提高页面加载速度和用户体验。服务端渲染可以加速首次加载，而客户端渲染可以提供更好的交互体验。在客户端渲染过程中，由于执行环境发生了变化，可能会触发一些生命周期函数（如 mounted）和数据获取方法（如 $fetch）的再次调用。 具体使用代码:`}]},{path:"/content/front/js/nuxt3%E4%B9%8BNuxtPage%E4%B8%ADkey%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"nuxt3之NuxtPage中key的使用_动态路由",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3之NuxtPage中key的使用:
For example, passing static key, NuxtPage component is rendered only once when it is mounted. <template> <NuxtLayout name="event-subpage" :can-display-sidebar > <NuxtPage page-key="static" /> </NuxtLayout>
</template>
<NuxtPage>: 这是Nuxt.js中用于渲染当前路由页面内容的组件。 page-key="static": 这个属性用于强制组件重新渲染。设置为"static"意味着 <NuxtPage> 组件实例保持不变，但它内部的路由匹配逻辑仍然正常工作，允许子页面根据路由变化而更新。
当在 parent.vue 中使用 <NuxtPage page-key="static" /> 时，整个 parent.vue 组件应该也不会重新渲染。
这包括 parent.vue 中的所有静态内容和 <NuxtPage> 组件本身。 参考: https://nuxt.com/docs/api/components/nuxt-page`}]},{path:"/content/front/js/nuxt3%E4%B9%8Bauth%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"nuxt3之auth组件的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3之auth组件的使用:
1.需要登录的页面
<script setup lang="ts">
definePageMeta({ middleware: "auth", // 没有对 auth 再进行配置
});
<\/script> 2.登录页面
<script setup lang="ts">
definePageMeta({ middleware: "auth", auth: { //这是一个对当前使用 auth 中间件的一个配置，只对当前页面生效 unauthenticatedOnly: true, // 说明 只有无登录的用户才能访问这个页面 navigateAuthenticatedTo: "/account/profile", // 当已登录的用户再次访问这个页面的时候，跳转到 个人profile页面 },
});
<\/script> 3.auth中间件
export default defineNuxtRouteMiddleware(async (to, from) => { if (process.server) return const { isLoggedIn } = useAuthUtils(); const authConfig = to.meta.auth || {}; const unauthenticatedOnly = authConfig.unauthenticatedOnly === true; const navigateAuthenticatedTo = authConfig.navigateAuthenticatedTo || '/'; const isAuthPage = to.path.startsWith('/auth/'); if (!isLoggedIn.value && !isAuthPage) { return navigateTo(\`/auth/login?target=\${to.fullPath}\`); }else if (isLoggedIn.value && unauthenticatedOnly) { return navigateTo(navigateAuthenticatedTo); }
}) 如果不想这么细粒度的控制登录的话，直接处理target情况就可以了
export default defineNuxtRouteMiddleware(async (to, from) => { if (process.server) return const { isLoggedIn } = useAuthUtils(); const isAuthPage = to.path.startsWith('/auth/'); if (!isLoggedIn.value && !isAuthPage) { return navigateTo(\`/auth/login?target=\${to.fullPath}\`); }
}) 再次改进版本:
export default defineNuxtRouteMiddleware(async (to) => { if (import.meta.server) return; const { isLoggedIn } = useAuthUtils(); const isAuthPage = to.path.startsWith("/auth/"); if (!isLoggedIn.value && !isAuthPage) { return navigateTo(\`/auth/login?target=\${to.fullPath}\`, { replace: true, external: true }); }
}); 改进原因: 当用户试图访问需要认证的页面（target 页面）时，系统会将他们重定向到登录页面。然而，如果不进行特殊处理，登录页面会继承目标页面的布局，导致登录页面的显示出现问题。这个是实际开发中遇到的问题.
navigateTo象包含两个属性：
replace: true：这会使用新的 URL 替换当前的历史记录条目，而不是添加一个新的。
external: true：这告诉 Nuxt 将导航视为外部导航，这将导致页面刷新。 4. to.path和 to.fullPath 区别
to.path 和 to.fullPath 是 Vue Router 中两个不同的属性，它们提供了关于目标路由的不同信息 to.path:
只包含 URL 的路径部分。
不包含查询参数和哈希。
例如，对于 URL "/users/profile?id=123#info"，to.path 将只返回 "/users/profile"。 to.fullPath:
包含完整的 URL，包括路径、查询参数和哈希。
是 URL 的完整表示，不包括域名和协议。
对于上面的例子，to.fullPath 将返回 "/users/profile?id=123#info"。 区别总结：
path 只关注 URL 的路径部分。
fullPath 包含路径、查询参数和哈希 使用场景： 使用 to.path 的情况：
当您只需要知道页面的基本路径时。
在不关心查询参数和哈希的情况下进行路由匹配。 使用 to.fullPath 的情况：
当您需要完整的 URL 信息，包括查询参数和哈希。
在需要保留所有 URL 信息进行重定向时。`}]},{path:"/content/front/js/nuxt3%E4%B9%8B%E4%BD%BF%E7%94%A8%E8%B7%AF%E7%94%B1%E5%88%86%E7%BB%84.html",title:"nuxt3之使用路由分组",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3之使用路由分组:
有如下页面：
pages/registration/(sections)/section1/index
pages/registration/(sections)/section2/index
pages/registration/(sections)/section3/index
pages/registration/(sections)/section2/index 解析:
在 Nuxt 3 中，使用方括号 [] 表示动态路由，而使用圆括号 () 表示路由分组。你提到的结构中的 (sections) 是一个路由分组，它可以用来将相关的路由进行组织，但并不会直接影响路由的动态性。`},{header:"具体说明：",slug:"具体说明",content:`动态路由： 使用方括号 [] 可以定义动态路由。例如，pages/registration/[id].vue 可以根据 URL 中的 id 值动态加载对应的页面。 路由分组： 使用圆括号 () 将多个路由分组在一起。这样做的主要好处是可以减少生成的路由路径的复杂性，便于管理和阅读。
在你的例子中，(sections) 表示这是一个路由分组，里面包含了多个具体的路由：section1, section2, 和 section3。`},{header:"实际路径示例：",slug:"实际路径示例",content:`pages/registration/(sections)/section1/index.vue 会生成路径 /registration/section1。
pages/registration/(sections)/section2/index.vue 会生成路径 /registration/section2。
pages/registration/(sections)/section3/index.vue 会生成路径 /registration/section3。`},{header:"注意：",slug:"注意",content:`由于 sections 是一个分组，访问这些页面时不会在 URL 中显示 sections。所以，访问的 URL 只会是 /registration/section1、/registration/section2 和 /registration/section3。 这种结构便于维护，特别是当有多个相关的页面时，你可以通过分组使项目结构更清晰。
注意:
这个分组特性是nuxt3 v3.13.0 之后才有的功能. 目前已经发布。对于 nuxt3可以通过如下配置，测试待发布的版本： https://nuxt.com/docs/guide/going-further/nightly-release-channel
和动态路由最大的区别是，动态路由会出现在路由里`}]},{path:"/content/front/js/nuxt3%E4%B9%8B%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E8%B7%AF%E7%94%B1%E4%BB%A5%E5%8F%8A%E7%B1%BB%E5%9E%8B.html",title:"nuxt3之自动生成路由以及类型",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3之自动生成路由以及类型:
1> 缘起
在使用nuxt3开发项目的时候，一般不需要自己定义路由的，框架会自动根据页面(pages)目录生成相关的路由信息这需要安装特定的包:
nuxt-typed-router
2> 使用以及分析
import type { RoutesNamedLocations, RoutesNamesList } from "@typed-router"; // 分析
RoutesNamesList的作用:
RoutesNamesList 是从 @typed-router 库中导入的类型，其主要作用是定义项目中所有路由名称的字符串集合。它通常用于为项目中的路由名称提供类型检查，确保代码在访问路由时使用的名称是有效且类型安全的。 具体作用：
1.限制路由名称：
RoutesNamesList 的作用是限制开发者只能使用预定义的路由名称。这可以防止在代码中使用不存在或拼写错误的路由名称，减少运行时错误的可能性。 2.自动补全和类型检查：
当你使用 RoutesNamesList 作为路由名称的类型时，IDE 会为你提供自动补全功能，并在你尝试使用无效的路由名称时发出警告。这大大提高了开发效率和代码的可靠性。 3.路由名称集中管理：
使用 RoutesNamesList 可以集中管理项目中的所有路由名称，使得项目结构更清晰。如果需要添加、删除或重命名某个路由，更新这个类型定义可以使整个项目统一反映这个变化。 示例说明：
假设 RoutesNamesList 的定义类似如下：
1.假设 RoutesNamesList 的定义类似如下：
type RoutesNamesList = "home" | "about" | "contact"; 当使用 RoutesNamesList 作为类型时，只能使用 home、about 或 contact 作为合法的路由名称 let routeName: RoutesNamesList; routeName = "home"; // 合法
routeName = "contact"; // 合法
routeName = "login"; // 错误，"login" 不在 RoutesNamesList 中 //重命名路由
export { type RoutesNamesList as AppRouteList } from "@typed-router";
这里将 RoutesNamesList 重新导出为 AppRouteList，这样项目中的其他部分可以使用 AppRouteList 来作为路由名称的类型。它确保了任何使用该类型的地方都只能使用预定义的路由名称。 // 分析
RoutesNamedLocations的作用
RoutesNamedLocations 是从 @typed-router 导入的另一个类型，通常用于定义与路由名称相关的具体路由对象。它不仅包含了路由的名称，还可以包含路由参数、查询参数等信息，帮助你以类型安全的方式构建路由对象。 具体作用：
1.类型安全的路由导航：
RoutesNamedLocations 的作用是为你提供类型化的路由对象，用于路由导航。这样你在生成路由路径时，不仅能指定路由名称，还可以确保传入的参数符合该路由的要求（如动态参数或查询参数）。 2.参数类型检查：
对于带有动态参数的路由，RoutesNamedLocations 允许你通过类型来明确要求的参数。例如，如果某个路由需要一个 id 参数，这个类型会强制你在导航时提供 id，否则会抛出编译错误，确保导航的路径和参数是正确的。 3.导航时的自动补全：
使用 RoutesNamedLocations 作为路由对象的类型时，IDE 可以为你提供智能提示，自动补全路由名称以及相关的参数。这使得在编写导航代码时，不仅能快速选择正确的路由，还能避免传递错误或缺失的参数。 示例说明：
假设你有一组路由配置，比如：
// 假设的路由配置
type RoutesNamedLocations = { home: {}; about: {}; user: { params: { id: string }; query?: { referrer?: string } };
}; home 和 about 路由没有参数要求，而 user 路由需要一个 id 参数，并且可以有一个可选的 query 参数 referrer。 你可以这样使用：
let route: RoutesNamedLocations; // 合法：没有参数要求
route = { name: "home" };
route = { name: "about" }; // 合法：提供了必需的参数
route = { name: "user", params: { id: "123" } }; // 合法：还可以包含可选的查询参数
route = { name: "user", params: { id: "123" }, query: { referrer: "homepage" } }; // 错误：缺少 id 参数
route = { name: "user" }; // TypeScript 报错 // 混合使用
export type AppGenericRoute = RoutesNamedLocations | string;
AppGenericRoute 可以是类型化的 RoutesNamedLocations，也可以是简单的字符串。这意味着在某些场景下你可以使用类型化路由，也可以只使用字符串形式的路由名称。 3> 说明
1.独立使用 @typed-router：如果你不使用 Nuxt.js，而是一个普通的 Vue Router 项目，可以直接安装和使用 @typed-router 来为项目添加类型安全的路由支持。 2.在 Nuxt.js 中在安装了 nuxt-typed-router之后，你不需要直接安装 @typed-router，因为 nuxt-typed-router 已经基于它构建并提供了所有功能。`}]},{path:"/content/front/js/nuxt3%E4%B9%8B%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BD%ACscroll%E5%88%B0%E6%8C%87%E5%AE%9Aanchor.html",title:"nuxt3之页面跳转scroll到指定anchor",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3之页面跳转scroll到指定anchor:
开始看了:https://stackoverflow.com/questions/73932280/nuxt-3-smooth-scrolling-with-hash-links
但是上面这个方法并没有生效
最后自己想到一个好的方法:
在 created 下定义
if (process.client) { if (_.has(this.$route, 'hash') && this.$route.hash){ window.scrollTo({top: this.getTop(this.$route.hash)}) }
} 在 methods下定义如下获取指定anchor元素距离顶部的offSet值
getTop(hash){ const el = document.querySelector(hash) return el.offsetTop
} 这样就可以解决，页面跳转到指定anchor的问题，其实在上面的链接里面，核心的也就是获取元素的offSet的值，单独拿出来看看:
import { defineNuxtPlugin } from "#app"; export default defineNuxtPlugin((nuxtApp) => { nuxtApp.$router.options.scrollBehavior = async (to, from, savedPosition) => { if (savedPosition) { return savedPosition; } const findEl = async (hash, x = 0) => { return ( document.querySelector(hash) || new Promise((resolve) => { if (x > 0) { return resolve(document.querySelector("#app")); } setTimeout(() => { resolve(findEl(hash, 1)); }, 300); }) ); }; if (to.hash) { const el = await findEl(to.hash); if ("scrollBehavior" in document.documentElement.style) { console.log("hash path hit scroll to"); return window.scrollTo({ top: el.offsetTop, behavior: "smooth" }); } else { return window.scrollTo(0, el.offsetTop); } } return { left: 0, top: 0, behaviour: "smooth" }; };
})`}]},{path:"/content/front/js/nuxt3%E4%BD%BF%E7%94%A8NuxtPage%E5%AE%9E%E7%8E%B0%E5%AD%90%E9%A1%B5%E9%9D%A2%E5%B5%8C%E5%A5%97%E6%B8%B2%E6%9F%93_%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1.html",title:"nuxt3使用NuxtPage实现子页面嵌套渲染_动态路由",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3使用NuxtPage实现子页面嵌套渲染_动态路由:
-| pages/
---| parent/
------| child.vue
---| parent.vue 最终渲染后的route:
[ { path: '/parent', component: '~/pages/parent.vue', name: 'parent', children: [ { path: 'child', component: '~/pages/parent/child.vue', name: 'parent-child' } ] }
]
上面这个有一个非常好用的场景就是，当站点有sidebar的时候，可以把sidebar定义为上面这种格式，通过不同的child去渲染页面 //To display the child.vue component, you have to insert the <NuxtPage> component inside pages/parent.vue
pages/parent.vue:
<template> <div> <h1>I am the parent view</h1> <NuxtPage :foobar="123" /> </div>
</template> pages/parent/child.vue:
<script setup lang="ts">
const props = defineProps(['foobar']) console.log(props.foobar)
<\/script> 参考：https://nuxt.com/docs/guide/directory-structure/pages`}]},{path:"/content/front/js/nuxt3%E4%BD%BF%E7%94%A8pinia%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE.html",title:"nuxt3使用pinia存储数据",pathLocale:"/",contents:[{header:"",slug:"",content:`主要是vue3以后，不能通过 params 传递参数，以前路由跳转的时候，通过 params 传递参数很好用，官方建议用pinia
import { defineStore } from 'pinia' export const useCourseVideoStore = defineStore({ id: 'toCourseVideo', state: () => { return { courseId:0, } }, actions: { setCourseId(val){ this.courseId = val } }, getters: { getCourseId(){ return this.courseId } },
}) //使用
import { useCourseVideoStore } from '~/store/course-video' const courseVideoStore = useCourseVideoStore() courseVideoStore.setCourseId(this.$route.params.id) const courseVideoStore = useCourseVideoStore() let courseId = courseVideoStore.getCourseId`}]},{path:"/content/front/js/nuxt3%E4%BD%BF%E7%94%A8swiper%E5%9C%A8vue%E4%B8%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%9C%BA.html",title:"nuxt3使用swiper在vue下的初始化时机",pathLocale:"/",contents:[{header:"",slug:"",content:`由于nuxt3是一个SSR 渲染方式，所以可以直接在mount钩子函数初始化swiper对象，或者在 created 钩子函数里，加上
if(process.client){
//在这里面初始化 swiper 对象
}`}]},{path:"/content/front/js/nuxt3%E4%BD%BF%E7%94%A8%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E9%97%AE%E9%A2%98.html",title:"nuxt3使用动态路由的时候，遇到一个蛋疼的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3使用动态路由的时候，遇到一个蛋疼的问题，如下:
navigateTo({ name: "user-dashboard-event-series-edit-detail-id", params:{ id: id } }) 使用 nuxtlink的时候一直报错，后来发现 to 参数里也是需要 params的
<NuxtLink :to="{ name: 'user-dashboard-event-series-edit-detail-id'}" class="flex items-center gap-2 hover:text-color-link-bolder" :class="index === 0 ? 'font-semibold' : 'ml-5'" > <MIcon v-if="linkItem.icon" :name="linkItem.icon" size="sm" /> <span class="text-sm transition-colors"> {{ linkItem.name }} </span> </NuxtLink> 改为:
const route = useRoute()
const id = route.params.id <NuxtLink :to="{ name: 'user-dashboard-event-series-edit-detail-id', params: { id: id }}" class="flex items-center gap-2 hover:text-color-link-bolder" :class="index === 0 ? 'font-semibold' : 'ml-5'" > <MIcon v-if="linkItem.icon" :name="linkItem.icon" size="sm" /> <span class="text-sm transition-colors"> {{ linkItem.name }} </span> </NuxtLink>
就不报错了`}]},{path:"/content/front/js/nuxt3%E5%9C%A8components%E4%B8%AD%E5%AE%9A%E4%B9%89%E7%9A%84vue%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8definePageMeta%E4%B8%8D%E7%94%9F%E6%95%88%E5%8F%AA%E8%83%BD%E5%9C%A8pages%E4%B8%8B%E7%9A%84vue%E9%A1%B5%E9%9D%A2%E4%BD%BF%E7%94%A8.html",title:"在components中定义的vue组件使用definePageMeta不生效只能在pages下的vue页面使用",pathLocale:"/",contents:[{header:"",slug:"",content:`在 Nuxt 3 中，如果你在 components/ 目录中定义了一个 Vue 组件，并在该组件中使用 definePageMeta 来设置页面元数据，可能会出现不生效的情况。 这是因为在 Nuxt 3 中，页面元数据只能在页面组件（位于 pages/ 目录中）中生效。如果你想在组件中使用 definePageMeta，你需要将该组件转化为一个页面组件。 要将一个组件转化为一个页面组件，你可以在 pages/ 目录中创建一个与该组件同名的文件，并将其作为页面组件来使用。例如，如果你在 components/ 目录中创建了一个名为 my-component.vue 的组件，并在其中使用了 definePageMeta，那么你可以在 pages/ 目录中创建一个名为 my-component.vue 的文件，并将其作为页面组件来使用。然后在页面组件中使用 definePageMeta 来设置页面元数据。 例如，在 pages/my-component.vue 文件中，你可以这样定义页面组件：
<template> <div> <h1>My Component Page</h1> <my-component /> </div>
</template> <script>
import MyComponent from '@/components/my-component.vue' export default { components: { MyComponent }, async definePageMeta($meta) { $meta.title = 'My Component Page' $meta.description = 'This is a page for My Component' }
}
<\/script> 在上面的例子中，我们在 pages/my-component.vue 文件中定义了一个页面组件，并在其中使用了 definePageMeta 来设置页面元数据。这样，当用户访问 /my-component 页面时，将会自动应用该页面组件，并使用其中定义的页面元数据。 但是感觉上面这样转换意义不大，还是不如直接写在pages页面里`}]},{path:"/content/front/js/nuxt3%E5%9C%A8middleware%E4%B8%AD%E8%AF%B7%E6%B1%82api.html",title:"nuxt3在middleware中请求api，获取数据，判断用户登录状态",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3在middleware中请求api，获取数据，判断用户登录状态，这个功能主要是，有些页面是需要用户登录以后才能访问的，避免用户直接访问到
需要登陆的页面，所以就在需要登的页面设置middleware，进行控制，具体代码如下，我自定义的
middleware/learnAuth.ts:
// @ts-ignore
import {defineNuxtRouteMiddleware, navigateTo, useRuntimeConfig} from "#app"
import utils from '../utils/utils' import {} from "nuxt/app";// 开始将 navigateTo, useRuntimeConfig 全部都放在这个里面，但是一运行就报：Failed to import dynamic modules，后来在官方的issue 有人直接放到了 #app, 我也这样改了，再运行就不会报错了,这里 import {} 是为了的代码不报红，去掉import {} from "nuxt/app" 也是可以的，只是下面的代码会报红，很不舒服，所以就加上了; 或者在报红的代码那里加上：// @ts-ignore 也是可以的 import {createError} from "h3"; // async function isJoinTheCourse(id){
// let userInfo = utils.getUserInfo()
// await $fetch('/api/user/course', {
// method: 'post',
// body: {userId: userInfo.id, courseId: id},
// headers: {'X-Requested-With': 'XMLHttpRequest'},
// })
// }
export default defineNuxtRouteMiddleware(async (to, from) => { if (process.server) return // 跳过server端验证 直接验证client 端 let isLogin = utils.isLogin() const config = useRuntimeConfig() let loginUrl = config.public.envData.VITE_LOGIN_URL if (isLogin){ console.log(loginUrl) // window.location.href = loginUrl; } // isJoinTheCourse(to.query.id).then(r => { // console.log(r) // }) const result = await $fetch('/api/user/test') // 调用api 只能通过$fetch 这个全局方法实现 console.log(result) if (result.code != 0){ if (result.code == 1){ return navigateTo('/', { redirectCode: 403 }) }else { throw createError({ statusCode: 404, statusMessage: 'Page Not Found' }) } }else { return }
}) //精简以后的版本，只做是否登录验证，接口调用去掉了
// @ts-ignore
import {defineNuxtRouteMiddleware, navigateTo, useRuntimeConfig} from "#app"
import utils from '../utils/utils'
export default defineNuxtRouteMiddleware(async (to, from) => { // @ts-ignore if (process.client) return let isLogin = utils.isLogin() const config = useRuntimeConfig() let loginUrl = config.public.envData.VITE_LOGIN_URL if (!isLogin){ return navigateTo(loginUrl, { redirectCode: 403 , external: true}) }
}) 当初按之前的写法一直报：Failed to import dynamic modules，后来查看issue 发现另外一种写法，就如上所示`}]},{path:"/content/front/js/nuxt3%E5%9C%A8%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E9%81%87%E5%88%B0useFetch%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E4%B8%8D%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"nuxt3在测试环境遇到useFetch数据获取不到的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3 获取接口数据遇到的问题，通过useFetch 在测试服务器没法获取到数据，但是 $fetch 可以；不知道为什么，设置server:false的时候 是可以拿到数据的，本地环境 dev/build 都是没问题的，但是放到测试服务器就有问题，不知道是不是和nodejs 版本有关，我本地是：v19.3.0 测试环境是:v18.15.0 created() { this.getCourseDetail(); },
methods: { getCourseDetail: async function () { const res = await $fetch('/api/course/' + this.$route.params.id, { method: 'get', headers: {'X-Requested-With': 'XMLHttpRequest'}, }) console.log(res) if (res){ if (res.code == 0){ this.courseDetail.id = res.data.id this.courseDetail.title = res.data.title }else { this.$toast.info(res.msg) } }else { this.$toast.error('require api failed') } // const {data, error} = await useFetch('/api/course/' + this.$route.params.id, { // method: 'get', // headers: {'X-Requested-With': 'XMLHttpRequest'}, // }) // if (error._value) { // this.$toast.error(error._value.data.msg) // } else { // if (data._value.code === 0) { // console.log(11111) // this.courseDetail.id = data._value.data.id // this.courseDetail.title = data._value.data.title // } else { // this.$toast.info(data._value.msg) // } // } } }`}]},{path:"/content/front/js/nuxt3%E5%AE%9E%E7%8E%B0%E5%80%92%E8%AE%A1%E6%97%B6.html",title:"nuxt3实现倒计时",pathLocale:"/",contents:[{header:"",slug:"",content:"wait ..."}]},{path:"/content/front/js/nuxt3%E5%BC%95%E7%94%A8%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html",title:"nuxt3引用报错解决办法",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3引用报错解决办法:
1.执行
$ npx nuxi dev
报错:
✘ [ERROR] Could not resolve "#build/app.config.mjs" node_modules/nuxt/dist/app/config.mjs:3:24: 3 │ import __appConfig from "#build/app.config.mjs"; ╵ ~~~~~~~~~~~~~~~~~~~~~~~ The package import "#build/app.config.mjs" is not defined in this "imports" map: node_modules/nuxt/package.json:23:13: 23 │ "imports": { ╵ ^ You can mark the path "#build/app.config.mjs" as external to exclude it from the bundle, which will remove this error. 原因：
在我的utils/utils.js下引入了nuxt/app
import {useCookie} from "nuxt/app"; 解决办法:
import {useCookie} from "#imports"; 这样再次执行就不会报错了,不明白为什么`}]},{path:"/content/front/js/nuxt3%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E5%BA%94%E7%94%A8%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E7%94%B1.html",title:"nuxt3获取当前应用的所有路由",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3获取当前应用的所有路由:
1.通过RoutesNamesList获取类型
表示命名路由的列表
是命名路由的键组成的联合类型（如 'home' | 'user'）。 // Example
type RoutesNamesList = "home" | "user"; 实际使用:
import type { RoutesNamesList } from "@typed-router"; // 在nuxt3框架下，会自动生成相关的路由，不需要自己处理 2.通过vue-router的router获取 const router = useRouter();//vue-router的组合函数
console.log(router.getRoutes().map((r) => r.name)); // 打印所有路由名称 const routeNames = router.getRoutes().map((route) => route.name).filter(Boolean); //filter 过滤掉无效值
console.log(routeNames); //验证 filter(Boolean) 的作用
const routes = [ { name: "home" }, { name: "about" }, { name: undefined }, { name: "user" },
]; const routeNames = routes.map((route) => route.name);
console.log(routeNames);
// 输出: ["home", "about", undefined, "user"] const filteredRouteNames = routes.map((route) => route.name).filter(Boolean);
console.log(filteredRouteNames);
// 输出: ["home", "about", "user"] 拓展两个重要的路由信息:
import type { RoutesNamedLocations, RoutesNamesList } from "@typed-router"; 在 Nuxt 3 中使用 @typed-router，通过 RoutesNamedLocations 和 RoutesNamesList 来定义和操作类型化的路由，是一种更安全和可维护的方式。以下是对这两个类型的简要说明和如何使用它们的例子：`},{header:"类型说明",slug:"类型说明",content:`RoutesNamedLocations
表示命名路由的参数和查询参数类型的映射。
每个命名路由都有相应的路径参数和查询参数的类型定义。
// Example
type RoutesNamedLocations = { home: {}; // 无参数的路由 user: { params: { id: string }; query?: { referrer?: string } }; // 有路径和查询参数的路由
}; RoutesNamesList
表示命名路由的列表。
是命名路由的键组成的联合类型（如 'home' | 'user'）。
// Example
type RoutesNamesList = "home" | "user";`},{header:"如何在代码中使用",slug:"如何在代码中使用",content:""},{header:"示例：跳转到命名路由",slug:"示例-跳转到命名路由",content:`你可以在代码中使用 RoutesNamedLocations 和 RoutesNamesList 提供的类型化支持：
import { useTypedRouter } from "@typed-router";
import type { RoutesNamedLocations } from "@typed-router"; export default defineComponent({ setup() { const router = useTypedRouter(); // 跳转到具体的命名路由 const goToUser = () => { const userRoute: RoutesNamedLocations["user"] = { params: { id: "123" }, query: { referrer: "google" }, }; router.push({ name: "user", // 类型安全的路由名 ...userRoute, }); }; return { goToUser }; },
});`},{header:"示例：获取当前路由信息",slug:"示例-获取当前路由信息",content:`通过 RoutesNamesList 确保访问的命名路由是有效的：
import { useTypedRoute } from "@typed-router";
import type { RoutesNamesList } from "@typed-router"; export default defineComponent({ setup() { const route = useTypedRoute(); // 当前路由是否是 "user" const isUserRoute = computed(() => { return route.name === "user" as RoutesNamesList; // 类型安全 }); return { isUserRoute }; },
});`},{header:"优势",slug:"优势",content:`类型安全：避免拼写错误导致的运行时问题。
自动补全：在 IDE 中提供命名路由的自动补全功能。
更好维护性：如果路由参数或命名路由发生变更，编译器会提示更新相关代码。 如果你需要进一步扩展，请提供更多具体的路由配置或使用场景！`}]},{path:"/content/front/js/nuxt3%E8%8E%B7%E5%8F%96%E6%8E%A5%E5%8F%A3%E4%BC%A0%E9%80%92%E8%BF%87%E6%9D%A5%E7%9A%84cookie%E4%BF%A1%E6%81%AF.html",title:"nuxt3获取接口传递过来的cookie信息",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3获取接口传递过来的cookie信息，封装到utils/utils.js内容如下:
import {useCookie} from "#imports";
import _ from "lodash" export default { isLogin: function () { let cookie = useCookie('userInfo') return _.has(cookie.value, 'id'); }, getUserInfo: function () { let cookies = useCookie('userInfo') let userInfo = {} if (_.has(cookies.value, 'id')) { userInfo.id = cookies.value.id userInfo.email = cookies.value.email userInfo.firstName = cookies.value.firstName userInfo.lastName = cookies.value.lastName userInfo.image = cookies.value.image userInfo.isAdmin = cookies.value.isAdmin userInfo = cookies._rawValue //userInfo = cookies._rawValue 也可以直接这样整个赋值,不用像上面一样一个一个赋值 } return userInfo; }, deleteUserInfo: function (){ let cookies = useCookie('userInfo') cookies.value = null }
} 接口基于symfony5开发，代码如下:
public function onAuthenticationSuccess(Request $request, TokenInterface $token): RedirectResponse|Response { /** @var User $user */ $user = $token->getUser(); $userInfo = []; if ($user) { $userInfo['id'] = $user->getId(); $userInfo['email'] = $user->getEmail(); $userInfo['firstName'] = $user->getFirstName(); $userInfo['lastName'] = $user->getLastName(); $userInfo['isAdmin'] = count($user->getRoles()) > 1 ? 1 : 0; $userInfo['image'] = $user->getImage(); $userInfo['avatar'] = $user->getAvatar(); } //注意expire 是个时间戳，这里设置过期时间 $response = $this->httpUtils->createRedirectResponse($request, $this->determineTargetUrl($request)); $cookie = new Cookie('userInfo', json_encode($userInfo), 1677812596, '/', null, null, false); $response->headers->setCookie($cookie); return $response; } 设置了cookie过期时间的话，当cookie过期的时候 会自动删除，cookie自动删除主要有如下几种场景:
①会话 cooke (Session cookie) 在会话结束时（浏览器关闭）会被删除
②持久化 cookie（Persistent cookie）在到达失效日期时会被删除
③如果浏览器中的 cookie 数量达到限制，那么 cookie 会被删除以为新建的 cookie 创建空间。`}]},{path:"/content/front/js/nuxt3%E8%B7%AF%E7%94%B1%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89.html",title:"nuxt3路由参数定义",pathLocale:"/",contents:[{header:"",slug:"",content:"nuxt3路由参数定义 https://juejin.cn/post/7204735957777449020 tailwindcss,自定义样式规则使用 https://tailwindcss.com/docs/functions-and-directives"}]},{path:"/content/front/js/nuxt3%E9%80%9A%E8%BF%87%E6%8E%A5%E5%8F%A3%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE.html",title:"nuxt3通过接口获取数据",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3通过接口获取数据
methods:{ // getCourseDetail: async function () { // let data = await useFetch('/api/course-detail?id='+this.$route.query.id) // console.log('data is:', data) // } // getCourseDetail: function () { // let data = useFetch('/api/course-detail', {query: {id:this.$route.query.id}}) // console.log('data is:', data) // } getCourseDetail: async function () { let data = await useFetch('/api/course-detail', {method: 'post', body: {id: this.$route.query.id}, server: false}) console.log('data is:', data.data._value.data) console.log('data is:', data.data._value.code) console.log(data) console.log(utils.isLogin()) console.log(utils.getUserInfo()) } } 注意useFetch 后的接口地址一定要加 / ，否则就是相对地址，可能会被自动添加前缀，导致接口报错，泪奔呀。。。，比如：useFetch('/api/course-detail', {query: {id:this.$route.query.id}}) 写成了useFetch('api/course-detail', {query: {id:this.$route.query.id}})，那么最后接口地址可能变成了：course/api/course-detail,而不是 api/course-detail`}]},{path:"/content/front/js/nuxt3%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86.html",title:"nuxt3配置代理",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3配置代理:
nitro: { devProxy: { "/api": { target: 'http://127.0.0.1:3001/', prependPath: true, changeOrigin: true, } } }`}]},{path:"/content/front/js/nuxt3%E9%A1%B9%E7%9B%AE%E6%9C%80%E5%85%A8%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.html",title:"nuxt3项目最全目录结构",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3项目最全目录结构:
Nuxt3
├── .husky # Git hooks 工具配置
├── .vscode # vscode配置
├── doc # 项目文档
├── build # 工程化构建相关配置
├── src
│ ├── api # 接口请求服务管理
│ │ └── modules # 接口模块
│ ├── assets # 工程化处理的静态资源
│ ├── components # 项目组件
│ ├── composables # 响应式共享状态
│ ├── enums # 枚举管理
│ ├── layouts # 布局组件
│ ├── middleware # 路由中间件
│ ├── pages # 页面视图
│ ├── plugins # 项目公共插件
│ ├── public # 不需要工程化处理的静态资源
│ ├── store # 状态管理
│ ├── utils # 静态工具函数
│ └── app.vue # 入口页面
├── .commitlintrc.json # git提交规范检查配置
├── .editorconfig # 编辑器配置
├── .env # 环境变量(默认/开发环境)
├─ .env.local # 本地环境变量
├── .env.pre # 预发布环境变量
├── .env.prod # 生产环境变量
├── .env.test # 测试环境变量
├── .eslintignore # eslint忽略文件检查的配置
├── .eslintrc.js # eslint代码规范检查配置
├── .gitignore # git仓库提交忽略配置
├── .lintstagedrc.js # git提交代码规范检查配置
├── .ls-lint.yml # 文件命名检查配置
├── .prettierignore # prettier忽略格式化的配置
├── .prettierrc.js # prettier格式化配置
├── .stylelintignore # 样式规范忽略检查的配置
├── .stylelintrc.js # 样式规范检查配置
├── nuxt.config.js # Vite 构建配置入口
├── package.json # 项目包管理文件
├── pnpm-lock.yaml # pnpm包版本管理锁定
├── postcss.config.js # postcss配置
├── README.md # 项目说明
├── tailwind.config.js # tailwind配置
└── tsconfig.json # TS编译的配置 参考：https://juejin.cn/post/7236635191379509308`}]},{path:"/content/front/js/nuxt3%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2.html",title:"nuxt3项目部署",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt3项目部署方式主要有两种: pm2部署，这个我之前已经记录过了
supervisor部署 duo_frontend.conf
[program:duoFrontend]
command=node /var/www/git/branches/duo/dev/frontend/.output/server/index.mjs # 这个js是通过 yarn build 打包后生成的
user=www-data
numprocs=1
autostart=true
autorestart=true
process_name=%(program_name)s_%(process_num)02d 运行之后会默认监听3000端口，通过这种方式并不好修改这个端口，通过pm2部署的很容易修改`}]},{path:"/content/front/js/nuxt_auth%E4%BE%9D%E8%B5%96%E5%8C%85%E6%96%87%E6%A1%A3.html",title:"nuxt_auth依赖包文档",pathLocale:"/",contents:[{header:"",slug:"",content:`nuxt_auth依赖包文档:
https://github.com/sidebase/nuxt-auth
https://sidebase.io/nuxt-auth/getting-started/installation
https://sidebase.io/nuxt-auth/configuration/nuxt-config
https://dev.to/geraldmuvengei06/how-to-setup-nuxt-auth-v6-authentication-with-the-local-provider-on-nuxt3-project-3970 //使用参考，但是还是有问题`}]},{path:"/content/front/js/nuxtjs-tailwindcss%E5%92%8C%E5%8D%95%E7%8B%AC%E5%AE%89%E8%A3%85tailwindcss%E7%9A%84%E4%B8%8D%E5%90%8C.html",title:"nuxtjs-tailwindcss和单独安装tailwindcss的不同",pathLocale:"/",contents:[{header:"",slug:"",content:`@nuxtjs/tailwindcss 和单独安装 tailwindcss 的不同:
在使用 Nuxt 3 的项目中,如果您已经安装了 @nuxtjs/tailwindcss 模块,通常不需要再单独安装 tailwindcss。
@nuxtjs/tailwindcss 是一个 Nuxt 模块,它为您的 Nuxt 3 项目集成了 Tailwind CSS。这个模块会自动处理 Tailwind CSS 的安装和配置,包括:
1. 安装必要的依赖(包括 tailwindcss 本身)
2. 创建 Tailwind 配置文件
3. 设置 PostCSS
4. 注入 Tailwind 指令到您的 CSS 中 安装 @nuxtjs/tailwindcss 后,您只需要在 nuxt.config.js 文件中启用该模块: \`\`\`typescript
export default defineNuxtConfig({ modules: ['@nuxtjs/tailwindcss']
}) 这样就可以在您的 Nuxt 3 项目中使用 Tailwind CSS 了,无需额外的安装步骤。如果您想要自定义 Tailwind 的配置,可以在项目根目录创建一个 tailwind.config.js 文件。@nuxtjs/tailwindcss 模块会自动识别并使用这个配置文件。
如果单独安装了 tailwindcss 而没有 @nuxtjs/tailwindcss， 那么需要手动配置: 只安装 Tailwind CSS：
当您只安装 tailwindcss 包时，它确实不会自动生效。这是因为 Tailwind CSS 需要通过 PostCSS 来处理才能在您的项目中发挥作用。 配置 PostCSS 后生效：
您发现配置 PostCSS 后 Tailwind CSS 生效了，这是正确的。PostCSS 是一个用 JavaScript 工具和插件转换 CSS 代码的工具。Tailwind CSS 就是作为 PostCSS 的一个插件来工作的。 手动配置步骤：
如果不使用 @nuxtjs/tailwindcss 模块，您需要手动完成以下步骤：
a. 安装必要的包：
npm install -D tailwindcss postcss autoprefixer b. 创建 Tailwind 配置文件：
npx tailwindcss init c. 配置 PostCSS（在 nuxt.config.js 中）：
export default defineNuxtConfig({ postcss: { plugins: { tailwindcss: {}, autoprefixer: {}, }, },
}) d. 在您的 CSS 文件中添加 Tailwind 指令：
@tailwind base;
@tailwind components;
@tailwind utilities; 使用 @nuxtjs/tailwindcss 的优势：
@nuxtjs/tailwindcss 模块自动处理了上述所有步骤，这就是为什么使用它会更加方便。它不仅安装了必要的依赖，还自动配置了 PostCSS 和其他必要的设置。`}]},{path:"/content/front/js/sass%E5%92%8Csass-embedded%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"sass和sass-embedded的关系",pathLocale:"/",contents:[{header:"sass和sass-embedded的关系",slug:"sass和sass-embedded的关系",content:"sass 和 sass-embedded 是 Sass 编译体系中两个密切相关但职责不同的模块。下面我会从概念、角色、关系、用法四个方面给你完整梳理。"},{header:"🧩 一句话总结",slug:"🧩-一句话总结",content:`sass 是 JS 层的 API 接口，提供编译入口；
sass-embedded 是 Dart Sass 的高性能后端，实现实际的 Sass 编译逻辑。`},{header:"✅ 各自的角色详解",slug:"✅-各自的角色详解",content:`名称
类型
作用描述 sass
JS 库（npm 包）
提供 JavaScript 编译接口，供工具链（Vite、Webpack、Nuxt）调用 sass-embedded
编译器后端
是 Dart Sass 的“嵌入式实现”，sass 可以选择调用它来提升编译性能`},{header:"🔗 它们之间的关系",slug:"🔗-它们之间的关系",content:""},{header:"🧠 类比理解：",slug:"🧠-类比理解",content:`类比组成
sass
sass-embedded 你写的 JS 项目
调用者
被调用者（底层工具） 浏览器 + V8
应用逻辑
底层执行引擎 所以： sass 是你调用的 npm 包，提供接口如 render()、compile()
如果发现你装了 sass-embedded，它会选择用它来执行底层编译任务
如果没有安装 sass-embedded，它就使用内置 Dart CLI 编译器`},{header:"🧪 工作流程图",slug:"🧪-工作流程图",content:"你的 Nuxt/Vite 项目 │ ▼ 使用 `.scss` 文件 │ ▼ Vite 调用 sass (JS) │ ├── 若发现安装了 sass-embedded → 调用它（更快 ✅） └── 否则使用 Dart Sass CLI （也能正常跑 ✅）"},{header:"🔧 是否需要都安装？",slug:"🔧-是否需要都安装",content:`场景
安装建议 一般使用
只装 sass 即可 ✅ 想提升构建性能
sass + sass-embedded ✅ 只装 sass-embedded
❌ 无法运行，会报错 用 Webpack/Vite/Nuxt 构建 .scss
✅ 需要 sass 提供 JS 接口`},{header:"📦 安装方式",slug:"📦-安装方式",content:`npm install -D sass # 必须
npm install -D sass-embedded # 可选，用于提升性能`},{header:"🧪 是否启用 sass-embedded，怎么查看？",slug:"🧪-是否启用-sass-embedded-怎么查看",content:`SASS_LOG=debug npm run dev 输出含有：
[info] Using Embedded Dart Sass 就说明 sass-embedded 生效了 ✅`},{header:"✅ 总结对比表",slug:"✅-总结对比表",content:`特性
sass
sass-embedded 是否必须
✅ 是
⚠️ 可选 提供 JS API？
✅ 提供 (render)
❌ 不提供 是否能单独使用？
✅ 可以
❌ 不可以（依赖 sass 调用） 是否用于加速？
⚠️ 本身不加速
✅ 是（提升 Dart 编译速度） 谁调用谁？
sass 调用它
被动执行 对于 sass 和 sass-embedded 这类构建时使用的依赖，应该将它们放在 devDependencies 下 ✅。`},{header:"✅ 结论：sass 和 sass-embedded 应该放在 devDependencies",slug:"✅-结论-sass-和-sass-embedded-应该放在-devdependencies",content:`npm install -D sass sass-embedded
# or
yarn add -D sass sass-embedded 原因如下：`},{header:"🧠 它们只在构建阶段用，不在运行时使用",slug:"🧠-它们只在构建阶段用-不在运行时使用",content:`包名
用途
运行时是否需要
放在哪 sass
编译 .scss 到 CSS
❌ 不需要
devDependencies ✅ sass-embedded
Dart Sass 的底层优化后端
❌ 不需要
devDependencies ✅`},{header:"🚀 Nuxt/Vite 构建流程中它们的作用：",slug:"🚀-nuxt-vite-构建流程中它们的作用",content:`开发阶段 / 构建阶段： .scss 文件被加载
vite 使用 sass 作为 CSS 预处理器，调用 sass 编译器
sass 检测是否存在 sass-embedded，如果有则使用它提升性能 构建完成后： 所有 .scss 已被编译为 .css
运行时根本不需要 sass 或 sass-embedded`},{header:"🧪 Nuxt 项目中实际表现",slug:"🧪-nuxt-项目中实际表现",content:`// nuxt.config.ts
export default defineNuxtConfig({ css: ['~/assets/styles/main.scss'], vite: { css: { preprocessorOptions: { scss: { additionalData: '@use "@/assets/styles/variables.scss" as *;' } } } }
}) 这段配置在 dev 或 build 阶段需要 sass，但生成的 .output/public/_nuxt/*.css 早已是纯 CSS，不需要任何 Sass 依赖。`},{header:"📦 总结：依赖分类建议",slug:"📦-总结-依赖分类建议",content:`类型
放在 dependencies？
放在 devDependencies？
备注 sass
❌
✅
构建工具 sass-embedded
❌
✅
编译加速器 vue
✅
❌
运行时必须依赖 tailwindcss
❌
✅
只编译时用`},{header:"✅ 最佳实践",slug:"✅-最佳实践",content:`你的 package.json 应该像这样：
{ "devDependencies": { "sass": "^1.77.0", "sass-embedded": "^1.77.0", "tailwindcss": "^3.4.1", "nuxt": "^3.10.0" }
} 在 Nuxt 3 中，不需要手动安装 sass 和 sass-embedded。
Nuxt 3 对 Sass 的支持是开箱即用的，它内置了对 Sass/SCSS 的处理能力。你只需要： 直接使用 .scss 或 .sass 文件：
<style lang="scss" scoped>
$primary-color: #007bff; .my-component { color: $primary-color;
}
</style> 或者在组件中直接写 SCSS：
<style lang="scss">
// 你的 SCSS 代码
</style> Nuxt 3 会自动检测到你使用了 Sass，并在需要时自动安装相关依赖。
什么时候需要手动安装？
只有在以下情况下才可能需要手动安装： 你遇到了特定的版本兼容性问题
你需要使用特定版本的 Sass
你的项目有特殊的构建需求 如果遇到 Sass 相关的错误，那时候再考虑手动安装：
npm install -D sass`}]},{path:"/content/front/js/swiper%E5%88%A4%E6%96%AD%E5%B7%A6%E6%BB%91%E8%BF%98%E6%98%AF%E5%8F%B3%E6%BB%91.html",title:"swiper判断左滑还是右滑",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要判断当前滑动是向左还是向右，可以通过下面的方法实现:
通过判断 swiper.swipeDirection 可以判断左滑，还是右滑，但是这个方法，目前只能在 touchEnd 后进行回调。//尤其是PC 鼠标滑动 非常有用
所以我们可以在 slidePreTransitionEnd 和 slideNextTransitionEnd 来进行向右滑还是向左滑的回调。//这个没怎么用过，应该是触摸还没结束之前就判断出来了`}]},{path:"/content/front/js/swiper%E6%8F%92%E4%BB%B6%E8%AE%BE%E7%BD%AE%E7%A6%81%E6%AD%A2%E9%BC%A0%E6%A0%87%E6%8B%96%E5%8A%A8.html",title:"swiper插件设置禁止鼠标拖动",pathLocale:"/",contents:[{header:"",slug:"",content:`swiper插件设置禁止鼠标拖动，可以在swiper-container 加个类 swiper-no-swiping 即可
<div class="swiper-container swiper-no-swiping"> <div class="swiper-wrapper"> <div class="swiper-slide"> <p>1</p> </div> <div class="swiper-slide"> <p>2</p> </div> </div> <div class="swiper-button-next"></div> <div class="swiper-button-prev"></div> </div> 这个 swiper-no-swiping 类应该是内置的`}]},{path:"/content/front/js/tailwindcss%E4%B9%8B%E5%88%86%E7%BB%84%E9%80%89%E6%8B%A9%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"tailwindcss之分组选择器的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`tailwindcss之分组选择器的使用:
对当前元素的子元素使用:
class="[&_.common-field\\_\\_input]:!w-[8.75rem]" //这个需要转义下划线(_)
解析:
[&_.common-field__input]：这是 Tailwind 的 “分组选择器” 语法，意味着它将样式应用于 .common-field__input 子元素。& 表示当前元素，_ 表示选择 .common-field__input 子元素，因此这一部分的意思是：当前元素内的 .common-field__input 子元素 将被作用此样式。 当前元素使用:
<div class="bg-blue-500 [&:hover]:bg-red-500">Hover me</div>
<div class="[&.active]:bg-green-500">Click me</div>`}]},{path:"/content/front/js/ts%E4%B8%ADconst%E5%88%86%E6%9E%90.html",title:"ts中const分析",pathLocale:"/",contents:[{header:"",slug:"",content:`ts中const分析:
例子：
const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
} as const; 1.在 TypeScript 中，as const 是一种常见的类型断言，它用于将一个对象的 字面量值 转换为一个 更具体的类型，而不仅仅是其类型的宽泛表示。
你提到的例子：
const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
} as const; 这里的 as const 是必须的，因为它会改变 timezonesMap 的类型推断，确保 TypeScript 将对象的值保持为字面量类型，而不是更宽泛的类型。让我们逐步分析一下：`},{header:"1. const 关键字的作用",slug:"_1-const-关键字的作用",content:"使用 const 声明的变量会使该变量 不可重新赋值，即它是常量。但它不会影响对象的 属性类型。即使你用 const 声明一个对象，TypeScript 依然会将该对象的值推断为 可变的类型，例如字符串。"},{header:"没有 as const 的情况",slug:"没有-as-const-的情况",content:`const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
}; TypeScript 会推断出 timezonesMap 的类型如下：
{ 1: string; 2: string; 3: string;
} 这意味着 timezonesMap[1] 可以是任何字符串，而不是限定为 "Europe/Berlin"。它会推断为一个 宽泛的 string 类型。`},{header:"2. as const 的作用",slug:"_2-as-const-的作用",content:`当你添加 as const 后，TypeScript 会将 timezonesMap 中的所有属性值的类型推断为 字面量类型，而不是 string 类型。这就使得每个属性的类型更加精确，变成了具体的字符串值。
const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
} as const; 在这种情况下，timezonesMap 的类型将被推断为：
{ 1: "Europe/Berlin"; 2: "America/New_York"; 3: "Asia/Shanghai";
} 这意味着 timezonesMap[1] 的类型是 "Europe/Berlin"，timezonesMap[2] 的类型是 "America/New_York"，而不是通用的 string 类型。`},{header:"3. 为什么需要 as const？",slug:"_3-为什么需要-as-const",content:`没有 as const：对象的值会被推断为更宽泛的类型（例如 string），允许你将任何字符串赋给这些属性。
使用 as const：对象的值会被推断为字面量类型，这样可以确保值的精确性，并避免值被误用为其他类型。`},{header:"示例对比",slug:"示例对比",content:""},{header:"没有 as const（普通的 const）",slug:"没有-as-const-普通的-const",content:`const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
}; // 这里 timezonesMap[1] 被推断为 string 类型
timezonesMap[1] = "Europe/Paris"; // 这是允许的，因为它的类型是 string`},{header:"使用 as const",slug:"使用-as-const",content:`const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
} as const; // 这里 timezonesMap[1] 被推断为 "Europe/Berlin" 字面量类型
timezonesMap[1] = "Europe/Paris"; // 这是错误的，因为类型是 "Europe/Berlin"，不能赋值为其他字符串`},{header:"总结",slug:"总结",content:`as const 的作用是让 TypeScript 更严格地推断对象的属性类型，并使属性值保持字面量类型，而不是推断为更宽泛的类型（如 string）。这样做的好处是能够在类型层面确保值的准确性和可预测性，避免赋值错误。
2.对于 const timezonesMap 是不可变的， const 使得变量 不可重新赋值，但它并不会使对象的属性变成 不可变。在 TypeScript 中，const 关键字只是确保变量本身不可重新赋值，而不会影响该对象的内部结构或属性类型。
3.as const 和 const 是两个不同的概念，目的也不同：
const 让变量不可重新赋值，但不会影响对象的属性类型。
as const 会将对象的属性值的类型转为字面量类型（literal type），从而使得对象的属性值更加严格，不能再随意修改成其他值。`}]},{path:"/content/front/js/ts%E4%B8%AD%E7%9A%84record%E5%88%86%E6%9E%90.html",title:"ts中的record分析",pathLocale:"/",contents:[{header:"",slug:"",content:`ts中的record分析:
Record 是 TypeScript 中的一个高级类型，它用于构建一个具有特定键和值类型的对象类型。Record 类型使得你可以方便地为对象定义一个键的类型范围和相应的值类型。`},{header:"语法",slug:"语法",content:`Record<K, T> K: 键的类型，通常是字符串或数字类型，可以是任何可以作为对象键的类型。
T: 值的类型，可以是任何有效的类型。`},{header:"说明",slug:"说明",content:"Record<K, T> 表示一个对象，它的键类型是 K，值类型是 T。你可以将 Record 看作是一个用于指定对象结构的模板类型。"},{header:"示例",slug:"示例",content:`####1.基本使用
type Timezones = Record<number, string>; const timezonesMap: Timezones = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
}; 这里我们定义了一个 Record<number, string> 类型的对象 timezonesMap，其键是数字类型，值是字符串类型。
####2. 传入字符串类型作为键
type UserRoles = Record<string, string>; const userRoles: UserRoles = { admin: "Administrator", user: "Regular User", guest: "Guest User"
}; 在这个例子中，Record<string, string> 定义了一个键为 string 类型、值为 string 类型的对象，userRoles 对象包含了不同角色的名称。
####3.使用联合类型作为键
type Config = Record<'host' | 'port' | 'protocol', string>; const config: Config = { host: "localhost", port: "8080", protocol: "http"
}; 这里使用了 Record 和联合类型作为键（'host' | 'port' | 'protocol'），定义了一个对象，强制它包含三个指定的键和相应的字符串值。
####4.用于枚举值
enum Status { Active = "active", Inactive = "inactive", Suspended = "suspended"
} type StatusMessages = Record<Status, string>; const statusMessages: StatusMessages = { [Status.Active]: "Active", [Status.Inactive]: "Inactive", [Status.Suspended]: "Suspended"
}; 这里，我们用 Record 来创建一个对象，其中键是 Status 枚举类型，值是 string 类型。`},{header:"关键特点",slug:"关键特点",content:'灵活的键和值类型： Record 类型允许你使用任何类型作为键和任何类型作为值。常见的情况是使用 string 或 number 作为键类型。 类型推断： TypeScript 会根据你传入的类型推断出具体的类型。例如，Record<"a" | "b", number> 会推断出 { a: number, b: number }。 简化代码： Record 提供了一种简洁的方式来创建具有特定键类型和值类型的对象，避免了冗长的手动类型声明。'},{header:"注意事项",slug:"注意事项",content:"键类型的限制： Record<K, T> 中的 K 必须是一个可以作为对象键的类型。通常，K 会是 string、number 或它们的联合类型。如果你使用其他类型作为键（如 boolean 或 symbol），可能会遇到类型错误。 值类型的灵活性： T 的类型可以是任何有效的类型，包括基础类型、联合类型、甚至是复杂的自定义类型。"},{header:"进阶示例",slug:"进阶示例",content:""},{header:"1. 使用 Record 和对象的嵌套",slug:"_1-使用-record-和对象的嵌套",content:`type NestedObject = Record<string, Record<string, number>>; const nestedObject: NestedObject = { category1: { item1: 10, item2: 20 }, category2: { itemA: 30, itemB: 40 }
}; 在这个例子中，我们创建了一个 Record<string, Record<string, number>> 类型的对象，这意味着对象的值是另一个对象，且该对象的值是 number 类型。`},{header:"2. 使用 Record 与类型推断",slug:"_2-使用-record-与类型推断",content:`const timezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
} as const; type TimezonesMap = Record<keyof typeof timezonesMap, string>; const timezoneMessages: TimezonesMap = { 1: "Europe/Berlin", 2: "America/New_York", 3: "Asia/Shanghai"
}; 这里我们通过 as const 将 timezonesMap 定义为常量对象，并利用 keyof typeof timezonesMap 来推断 Record 的键类型。`},{header:"总结",slug:"总结",content:"Record 类型在 TypeScript 中非常强大，它使得你能够快速创建具有指定键和值类型的对象。通过灵活的键类型和值类型定义，它能够简化代码，确保类型安全，并避免手动编写重复的对象类型。"}]},{path:"/content/front/js/ts%E4%B9%8BRecord%E7%B1%BB%E5%9E%8B.html",title:"ts之Record类型",pathLocale:"/",contents:[{header:"",slug:"",content:`ts之Record类型:
Record是TypeScript中的一个实用工具类型。它用于创建一个对象类型，其属性键为K类型，属性值为T类型。Record的基本语法如下： 语法:
Record<K, T> 使用:
type Product = { name: string; price: number;
}; const products: Record<string, Product> = { apple: { name: 'Apple', price: 0.5 }, banana: { name: 'Banana', price: 0.25 },
}; console.log(products.apple); // { name: 'Apple', price: 0.5 } 参考:
https://gibbok.github.io/typescript-book/zh-cn/book/type-manipulation/ //类型操作
https://gibbok.github.io/typescript-book/zh-cn/book/generics/ https://sourcegraph.com/github.com/wangdoc/typescript-tutorial/-/blob/docs/utility.md //很多md文档语法可以参考`}]},{path:"/content/front/js/ts%E4%B9%8BReturnType%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"ts之ReturnType的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`ts之ReturnType的使用:
如：type Field = ReturnType<typeof useField>;
这段 TypeScript 代码定义了一个类型 Field，它是 useField 函数的返回类型。`},{header:"关键部分",slug:"关键部分",content:`typeof useField： typeof 是 TypeScript 中的操作符，用于获取某个变量、函数或类的类型。
在这里，typeof useField 获取了 useField 函数的类型。 ReturnType<typeof useField>： ReturnType<T> 是 TypeScript 提供的一个内置泛型类型，用于获取类型 T 的返回值类型。
因此，ReturnType<typeof useField> 获取了 useField 函数的返回值类型。`},{header:"总结",slug:"总结",content:`这段代码的作用是：Field 被定义为 useField 函数返回值的类型。简单来说，它是根据 useField 函数的返回类型动态生成的类型。
例如，如果 useField 返回一个对象 { value: string }，那么 Field 的类型就是 { value: string }。`},{header:"注意",slug:"注意",content:"这里的 T 必须是一个函数类型, 不能是一个常规的类型，比如这里如果 typeof useField 不是一个方法，而是一个自定义类型，使用 ReturnType<typeof useField> 会导致 TypeScript 报错或者产生不符合预期的结果。让我们来具体分析一下。"},{header:"具体分析",slug:"具体分析",content:""},{header:"1. ReturnType<T> 作用",slug:"_1-returntype-t-作用",content:`ReturnType<T> 是 TypeScript 的内置泛型工具类型，它的目的是获取类型 T 的 返回值类型。它要求 T 必须是一个 函数类型。
例如：
type MyFunction = () => string;
type Result = ReturnType<MyFunction>; // Result 会是 string 这里，ReturnType<MyFunction> 会得到 MyFunction 返回的类型，即 string。`},{header:"2. 如果 typeof useField 不是函数类型",slug:"_2-如果-typeof-usefield-不是函数类型",content:`假设 useField 不是一个函数，而是一个普通的类型或接口，像这样：
type useField = { field: string; value: number;
}; 在这种情况下，typeof useField 获取的将是一个 对象类型，而不是一个函数类型。此时 ReturnType<typeof useField> 会报错，因为 ReturnType 只适用于函数类型。
type Field = ReturnType<typeof useField>; // 会报错，不能对非函数类型使用 ReturnType`},{header:"3. 解决方案",slug:"_3-解决方案",content:`如果你要使用 ReturnType，确保 useField 是一个函数。如果 useField 只是一个类型或接口，你不能直接使用 ReturnType，而是可以将其作为一个类型本身： type Field = typeof useField; // 直接使用类型本身 如果 useField 是一个工厂函数（返回对象的函数），你可以使用 ReturnType 来获取其返回值类型： function useField() { return { field: "name", value: 42 };
} type Field = ReturnType<typeof useField>; // Field 类型会是 { field: string, value: number }， 注意 typeof useField 也很重要，必须要先获取useField这个函数的类型`},{header:"总结",slug:"总结-1",content:`ReturnType<T> 只能用于函数类型。
如果 typeof useField 是一个类型或接口（非函数），直接使用 ReturnType 会导致报错。
对于非函数类型，直接使用 typeof useField 或者其他方式来获取类型。`},{header:"直接type Field = typeof useField;和 type Field = ReturnType<typeof useField>;啥区别？",slug:"直接type-field-typeof-usefield-和-type-field-returntype-typeof-usefield-啥区别",content:"这两者的区别在于 typeof useField 和 ReturnType<typeof useField> 表达的含义不同，它们分别代表不同的类型信息。让我们逐一分析它们的区别："},{header:"1. type Field = typeof useField;",slug:"_1-type-field-typeof-usefield",content:`typeof useField 获取的是 useField 这个变量本身的 类型，也就是它作为一个值的类型（通常是函数类型）。
如果 useField 是一个函数，typeof useField 就是该函数的类型。 例如，如果 useField 是一个函数：
function useField() { return { field: "example", value: 42 };
} type Field = typeof useField; // Field 的类型是 () => { field: string, value: number } 这里，Field 会被推断为 useField 函数的类型，即 () => { field: string; value: number }。这个类型描述了 useField 作为一个 函数 的签名。`},{header:"2. type Field = ReturnType<typeof useField>;",slug:"_2-type-field-returntype-typeof-usefield",content:`ReturnType<T> 是 TypeScript 内置的工具类型，它用于提取 函数 T 的 返回值类型。
ReturnType<typeof useField> 会获取 useField 函数返回的对象的类型。 继续上面的例子：
type Field = ReturnType<typeof useField>; // Field 的类型是 { field: string, value: number } 这里，Field 会被推断为 useField 函数的 返回值类型，即 { field: string; value: number }。`},{header:"区别总结",slug:"区别总结",content:`typeof useField 是获取 useField 函数的 函数签名（包括函数参数和返回值），也就是 useField 作为一个 函数 的类型。
ReturnType<typeof useField> 是获取 useField 函数的 返回值类型，即 useField 函数执行后返回的内容的类型。`},{header:"示例对比",slug:"示例对比",content:`假设有以下代码：
function useField() { return { field: "name", value: 42 };
} type Field1 = typeof useField; // Field1 的类型是 () => { field: string, value: number }
type Field2 = ReturnType<typeof useField>; // Field2 的类型是 { field: string, value: number } Field1 是 useField 函数的类型，描述了函数本身的签名：一个无参函数，返回 { field: string, value: number }。
Field2 是 useField 函数的 返回值类型，即 { field: string, value: number }，它是函数执行后返回的对象类型。`},{header:"总结",slug:"总结-2",content:`typeof useField：获取 useField 的类型（函数类型）。
ReturnType<typeof useField>：获取 useField 函数返回值的类型。`}]},{path:"/content/front/js/ts%E4%B9%8Blet_const_var%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"ts之let_const_var的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`ts之let_const_var的区别:
1.使用 let 声明变量
关键字 let 是 ES6 中新增的特性，它的出现是为了解决 var 变量声明所存在的一些问题，let 声明变量的语法和 var 的很像，例如： let a = 1;
其实 let 与 var 的关键的区别不在于语法，而在于语义。 在 let 中引入了块级作用域（也可称为词法作用域）。块级作用域是什么意思呢？我们知道使用大括号 {} 包围代码可以叫做代码块，举个例子，比如说 if、for 等语句的执行代码都是通过一个大括号 {} 包围对吧，这个大括号中的就是代码块。如果我们在大括号中使用 let 关键字声明一个变量，那么这个变量的作用域就只在这个大括号中，在大括号之外不能使用，这就是块级作用域了。 所以这一点也是 let 和 var 之间的区别，如果同样是在某个函数中的 if 语句内声明变量，var 声明的变量作用域范围在整个函数，而 let 声明的变量的范围仅在 if 语句中。 示例：
我们可以看下面这段代码，在函数 myFunc 中使用 let 声明了一个变量 a，且在 if 语句中声明了一个变量 b： function myFunc(){ let a = 10; if(a > 5) { let b = a; return b; } return b;
}
根据我们上面讲的块级作用域，可以知道变量 a 的作用域就在整个 myFunc() 函数中，而变量 b 的作用域在 if 语句块中，变量 a 可以在函数内使用，但是如果我们在 if 语句以外的地方使用变量 b，则会出错 2.变量提升
当我们使用关键字 var 声明变量时会进行变量提升，而使用关键字 let 来声明变量可以帮助我们解决这个问题。 变量提升是什么意思呢，就是变量可以在使用后声明，也就是变量可以先使用再声明。但是要注意哟，变量提升只会提升声明，不会提升变量的初始化哟。 示例：
例如下面这段代码，我们先使用了变量 a ，然后才声明它： console.log(a);
var a = 1; // 声明并赋值
运行代码后，会输出 undefined（变量的默认值为 undefined） ，这说明关键字 var 会进行变量提升，但是从输出结果不是 1 可以看出，这仅提升了变量的声明，没有提升变量的初始化。 而如果我们将关键字 var 换成 let，同样的代码 ： console.log(a);
let a = 1;
此时执行代码，会输出 ReferenceError: Cannot access 'a' before initialization。这说明使用 let 声明的变量并不会进行变量提升。 3.多次声明一个变量 在使用 var 声明变量的时候，我们可以同时声明某个变量多次，但是只有最后一个生效。 而 let 不支持这样做，使用 let 声明变量，一个变量同时只能声明一次，否则会报错。 示例： 例如使用 var 将变量 a 声明 3 次，执行代码后，只有最后一次生效，所以代码的输出结果为 3： var a = 1; var a = 2; var a = 3; console.log(a); // 输出：3 而如果使用 let 重复声明一个变量，则会报错，报错信息告诉我们已经声明过了这个变量： let a = 1; let a = 2; let a = 3; console.log(a); // Identifier 'a' has already been declared 4.const 声明变量 const 与 let 声明变量时一致，如下所示： const num = 9; const 也是块级作用域，它与 let 唯一不同在于，const 声明的变量只能在声明时被赋值，之后不能再次被赋值，也就是说通过 const 声明的变量被赋值后不能再改变。 使用 const 声明变量，不是说被声明的变量的值不能被改动，而是这个变量所指向的那个内存地址不能改动。使用 const 声明数值、字符串、布尔值等数据类型，可以理解为常量，因为这些初始类型的值就保存在变量所指向的那个内存地址。 示例： 例如使用 const 声明不同类型的变量： const num = 9; // 数字类型 const username = 'xkd'; // 字符串类型 const my = true; // 布尔类型 但是对于数组和对象等复合类型的数据来说，变量所指向的内存地址保存的只是一个指针，const 可以让其指针不变，但是数组元素和对象的属性值可以被修改。`}]},{path:"/content/front/js/ts%E5%A4%8D%E7%94%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"ts复用类型的两种方式",pathLocale:"/",contents:[{header:"",slug:"",content:`// ts 类型定义的两种方式，结果却不同
import type { dashboardItemNames } from "~/constants/dashboard/dasboardItemNames"; type Items = { label: string; name: keyof typeof dashboardItemNames; icon?: string | null; children?: Items;
}[]; export type UserDashboardRolesResponse = { label: string; items: Items;
}[]; export type ExtendedUserDashboardRolesResponse = UserDashboardRolesResponse[number] & { roles: number[];
}[]; import type { dashboardItemNames } from "~/constants/dashboard/dasboardItemNames"; type Items = { label: string; name: keyof typeof dashboardItemNames; icon?: string | null; children?: Items;
}[]; export type UserDashboardRolesResponse = { label: string; items: Items;
}[]; type ExtendedUserDashboardRole = UserDashboardRolesResponse[number] & { roles: number[];
}; export type ExtendedUserDashboardRolesResponse = ExtendedUserDashboardRole[]; 使用:
const roles = ref<ExtendedUserDashboardRolesResponse>([]);
一个会报 never[], 一个不报错. 主要是ts类型检查(涉及到类型推断)的时候有问题，使用上没有问题`}]},{path:"/content/front/js/ts%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E9%9D%A2%E9%87%8F%E8%81%94%E5%90%88%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"ts字符串字面量联合类型的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`ts字符串字面量联合类型的使用:
direction.ts:
export type Direction = "north" | "south" | "east" | "west"; // 在 TypeScript 中有一个专业术语来描述它：字符串字面量联合类型（String Literal Union Type） export const directions: Direction[] = ["north","south","east","west"]; 分析：
这里，"north"、"south"、"east" 和 "west" 都是字符串字面量类型。 与 const 断言的结合：
从 TypeScript 3.4 开始，你还可以使用 as const 来创建只读的字符串字面量联合类型：
const directions = ["north","south","east","west"] as const;
export type Direction = typeof directions[number]; 这种方法的优点：
类型安全：只允许使用预定义的方向。
自动完成：IDE 可以提供方向的自动完成。
单一数据源：数组和类型定义在一起，易于维护。
可扩展：添加新方向只需修改数组。`}]},{path:"/content/front/js/ts%E7%94%A8%E6%B3%95%E6%80%BB%E8%AE%A1.html",title:"ts用法总计",pathLocale:"/",contents:[{header:"",slug:"",content:`ts用法总计: 高级写法: const headers = (options.headers ||= {}) 这一行代码是一个逻辑表达式，其目的是确保在获取 options.headers 前将其初始化为空对象（如果它尚未定义），以避免后续操作中出现 undefined 或 null 引发的错误。
让我们逐步解释这个表达式： options.headers 是一个对象，用于存储请求的头部信息。
||= 是一个赋值操作符，表示如果左侧的值为假（例如 null、undefined 或者 false），则将右侧的值赋给左侧变量。
因此，(options.headers ||= {}) 的含义是，如果 options.headers 为假（即未定义或者为空），则将一个空对象 {} 赋给 headers 变量，否则将保持 options.headers 的原有值。
这样做的目的是确保在设置请求头部信息之前，headers 变量始终指向一个对象，以便后续的操作不会因为 headers 为 undefined 或者 null 而出错。 nuxt3的 $fetch 是基于 https://github.com/unjs/ofetch`}]},{path:"/content/front/js/ts%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"ts类型检查的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`ts类型检查的问题:
如下代码, ts type checking 会报:error TS18046: 'route.params' is of type 'unknown'.
const route = useRoute();
const eventId = computed(() => { return route.params.id;
});
但是改为:
const route = useRoute("events-id-event-settings-session");
const eventId = computed(() => { return route.params.id;
});
什么原因呢? 这个问题涉及到 Vue Router 的类型推断。让我为您解释一下这两种情况的区别，以及为什么第二种方式不会报错。
1.第一种情况:
const route = useRoute();
const eventId = computed(() => { return route.params.id;
}); 在这种情况下，useRoute() 没有提供任何参数。因此，TypeScript 无法推断出 route.params 的具体结构。它被推断为 unknown 类型，这是一种安全的类型，需要进行类型检查或断言才能使用。
2.第二种情况:
const route = useRoute("events-id-event-settings-session");
const eventId = computed(() => { return route.params.id;
}); 在这种情况下，您为 useRoute() 提供了一个路由名称作为参数。这让 Vue Router 能够推断出该路由的参数类型。假设 "events-id-event-settings-session" 路由定义中包含一个 id 参数，TypeScript 就能正确推断 route.params.id 的类型，因此不会报错。
解决方案:
1.如果您知道路由名称，使用第二种方式是最好的，因为它提供了最精确的类型推断。
2.如果您不知道具体的路由名称，或者需要处理多种可能的路由，您可以使用类型断言:
const route = useRoute();
const eventId = computed(() => { return (route.params as { id: string }).id;
});`}]},{path:"/content/front/js/typescript%E4%B8%8B%E4%BD%BF%E7%94%A8lodash.html",title:"typescript下使用lodash",pathLocale:"/",contents:[{header:"",slug:"",content:`typescript下使用lodash:
import * as _ from 'lodash' 如果想通过下面的方式引用:
import _ from 'lodash'
需要在 tsconfig.json 添加如下配置 "esModuleInterop": true`}]},{path:"/content/front/js/typescript%E4%B8%8B%E7%9A%84Infinity.html",title:"typescript下的Infinity",pathLocale:"/",contents:[{header:"typescript下的Infinity:",slug:"typescript下的infinity",content:`在 TypeScript 中，Infinity 是 JavaScript 的一个全局属性，表示“无穷大”。它是 number 类型的一个特殊值。你可以直接使用它，不需要导入或声明。
示例:
let max: number = Infinity;
console.log(max); // 输出: Infinity console.log(1 / 0); // 输出: Infinity
console.log(-1 / 0); // 输出: -Infinity console.log(Infinity > 1000000); // true
console.log(Infinity === Infinity); // true 特点：
Infinity 是一个数字类型的值，表示正无穷大。
-Infinity 表示负无穷大。
typeof Infinity === 'number' 是 true。
它是不可变的全局值，等价于 Number.POSITIVE_INFINITY。`}]},{path:"/content/front/js/typescript%E4%B8%8B%E9%80%9A%E8%BF%87URL%E8%8E%B7%E5%8F%96href%E9%93%BE%E6%8E%A5.html",title:"typescript下通过URL获取href链接",pathLocale:"/",contents:[{header:"typescript下通过URL获取href链接",slug:"typescript下通过url获取href链接",content:`new URL("@/assets/images/without-doi.svg", import.meta.url).href 很好问题，来详细解释一下这段代码中的核心：
new URL("@/assets/images/without-doi.svg", import.meta.url).href`},{header:"✅ import.meta.url 是什么？",slug:"✅-import-meta-url-是什么",content:`在 Vite（Nuxt 3 默认构建工具） 中，import.meta.url 表示当前模块文件的完整 URL 路径。
例如，如果你有一个文件路径是：
/src/components/DoiIcon.vue 在浏览器里运行时，import.meta.url 会变成类似这样的字符串：
http://localhost:3000/src/components/DoiIcon.vue 这个 URL 是当前文件本身的路径。Vite 在构建时会保留这种模块路径。`},{header:"✅ new URL(..., import.meta.url) 的作用",slug:"✅-new-url-import-meta-url-的作用",content:`这是 JS 原生的用法，表示根据当前模块的路径来解析另一个资源的相对路径，确保资源引用是正确的。
例如：
new URL('@/assets/images/without-doi.svg', import.meta.url).href 由于 @ 是 Nuxt 的路径别名，最终 Vite 会解析成类似：
new URL('/src/assets/images/without-doi.svg', import.meta.url) 然后将这个路径转换成正确的完整路径 URL，例如：
http://localhost:3000/src/assets/images/without-doi.svg 并通过 .href 获取到的是最终字符串形式的 URL。`},{header:"✅ 为什么不用 import image from '@/assets/images/xxx.svg'？",slug:"✅-为什么不用-import-image-from-assets-images-xxx-svg",content:"因为 new URL(..., import.meta.url).href 可以在 运行时动态拼接路径，而 import ... from 是编译时静态导入，不能拼接。\n例如这个不能动态：\nimport icon from `@/assets/images/${iconName}.svg`; // ❌ 不支持变量拼接 而 new URL 是合法的：\nconst iconPath = new URL(`@/assets/images/${iconName}.svg`, import.meta.url).href;"},{header:"✅ 总结",slug:"✅-总结",content:`表达式
含义 import.meta.url
当前模块的完整路径 URL new URL(..., import.meta.url)
以当前模块为基准解析其他相对资源路径 .href
最终资源的字符串 URL，可用于 <img> 等 如你想支持更高级的 SVG 处理（如变色、内嵌），可以配合 Nuxt 的 vite-svg-loader 使用 import icon from '...svg?component'，那是另一个方向。需要我说明这部分吗？ 简单理解:
mport.meta.url 就像是 “当前文件的 GPS 坐标”
new URL(relativePath, import.meta.url) 就像是 “以这个 GPS 为参考点找其它文件” 举个例子:
完全正确 ✅！
你可以这样理解：`},{header:"🧭 import.meta.url 就像是 “当前文件的 GPS 坐标”",slug:"🧭-import-meta-url-就像是-当前文件的-gps-坐标",content:"它提供了你代码文件本身的完整 URL。"},{header:"🧰 new URL(relativePath, import.meta.url) 就像是 “以这个 GPS 为参考点找其它文件”",slug:"🧰-new-url-relativepath-import-meta-url-就像是-以这个-gps-为参考点找其它文件",content:"它会根据当前文件的路径去定位其它相对路径下的资源，比如 SVG 图片。"},{header:"🌐 举个例子：",slug:"🌐-举个例子",content:`假设你的文件结构如下：
- src/ - components/ - DoiIcon.vue ← 当前文件 - assets/ - images/ - without-doi.svg 在 DoiIcon.vue 中写：
new URL('@/assets/images/without-doi.svg', import.meta.url).href Vite 会解析为：
new URL('/src/assets/images/without-doi.svg', 'http://localhost:3000/src/components/DoiIcon.vue') 最终生成：
http://localhost:3000/src/assets/images/without-doi.svg`},{header:"✅ 用途总结：",slug:"✅-用途总结",content:`📍 import.meta.url: 确定“我在哪里”
🔗 new URL(...): 找“我要用的资源在哪”
🔄 .href: 拿到这个资源的最终 URL 字符串，可用于 <img> 等 HTML 属性 如果你将来图片改为放 CDN 或从后端接口返回路径，也可以用这个方式临时加载本地资源进行过渡或占位，非常灵活。需要我帮你封装一个 useDoiIcon(props.item) 的小组合函数也可以。`}]},{path:"/content/front/js/typescript%E5%85%A8%E5%B1%80%E5%AE%89%E8%A3%85%E5%92%8C%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85.html",title:"typescript全局安装和本地安装",pathLocale:"/",contents:[{header:"typescript全局安装和本地安装",slug:"typescript全局安装和本地安装",content:`全局安装命令: npm install -g typescript
$ tsc --version
Version 5.3.2 本地安装命令: npm install typescript --save-dev
$ npx tsc --version
Version 5.6.3 要生成预填充推荐设置的 tsconfig.json 文件，可以使用以下命令(一般都是在当前项目下执行的)：
tsc --init 在线运行环境:
https://www.typescriptlang.org/play/`}]},{path:"/content/front/js/vee-validate%E4%B8%8Bmeta%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"vee-validate下meta的使用",pathLocale:"/",contents:[{header:"vee-validate下meta的使用",slug:"vee-validate下meta的使用",content:`const password = useField<string>("password"); const passwordHint = computed(() => { if (password.meta.dirty) { return ""; } return "This should contain 8 to 128 characters with a mix of uppercase letters, lowercase letters and numbers.";
}); 可以通过 password.meta.dirty 来判断 password输入是否发生改变,这两个属性是vee-validate提供的.`}]},{path:"/content/front/js/vee-validate%E9%AA%8C%E8%AF%81%E4%B9%8Bcontext%E4%BD%BF%E7%94%A8.html",title:"vee-validate验证之context使用",pathLocale:"/",contents:[{header:"",slug:"",content:`vee-validate验证之context使用:
vee-validate验证，通过context获取表单上下文信息:
let schema = string(); schema = schema.test( "is-price-set-with-condition", errorMessage, function (value, context) { console.log("context is:", context); // 打印出来是一个对象，其中有个 parent 属性，包括了当前表单的所有数据。还有path属性，这个path定义了当前验证字段名称 const fieldValue = context.parent[fieldForCondition]; // 也可以通过function的第二个参数 context 来获取，很有用 // const fieldValue = this.parent[fieldForCondition]; //之前用过 this.parent获取表单的其它字段 console.log("fieldValue is:", fieldValue) return !(fieldValue && !value); }, );`}]},{path:"/content/front/js/veeValidate%E4%B8%AD%E7%9A%84%E9%AA%8C%E8%AF%81%E5%AE%9A%E4%B9%89%E7%BB%86%E8%8A%82.html",title:"veeValidate中的验证定义细节",pathLocale:"/",contents:[{header:"",slug:"",content:`vee-validate中的验证定义细节:
discountName: string().required(), //这个required没加额外信息，默认就是，验证提示就是 discountName is a required field
discountName: string().required("ha ha"), // 这个required加了提示信息，验证提示就是 ha ha, 这会覆盖默认的msg，即使加了label也会被覆盖，discountName: string().required("ha ha").label("name"), 最后还是 ha ha.
discountName: string().required().label("name"), //这个required没加额外信息，但是加了label信息，验证提示就是 name is a required field 其它验证细节:
//yup条件验证 when的使用
1.单条件
vatCountries: array().when("displayPaymentMethods", { is: true, then: schema => schema.test( "at-least-one-vat-country", verifyHint.fieldRequired, (value) => value.length > 0, ), otherwise: schema => schema.notRequired(), }),
vat: number().when("displayPaymentMethods", { is: true, then: schema => schema.required(verifyHint.fieldRequired), otherwise: schema => schema.notRequired(),
}), 2.多条件(同时满足，需要解构)
invoiceReceiverInformation: string().when( ["displayPaymentMethods", "isWireTransfer"], { is: ([displayPaymentMethods, isWireTransfer]) => displayPaymentMethods && isWireTransfer, then: (schema) => schema.required(verifyHint.fieldRequired), otherwise: (schema) => schema.notRequired(), }
) 多条件(任意一个满足，下面这个只是一个特例，其实最好不要这么用)
invoiceReceiverInformation: string().when( ["displayPaymentMethods", "isWireTransfer"], { is: true, then: (schema) => schema.required(verifyHint.fieldRequired), otherwise: (schema) => schema.notRequired(), }
) 3.使用字符串
paymentMethod: string().when("paymentType", { is: "credit_card", then: (schema) => schema.required("Credit card details are required"), otherwise: (schema) => schema.notRequired(),
}); 或者
someField: string().when("otherField", { is: value => { console.log(value); // 需要打印值 return value === "someValue"; // 需要 return }, then: schema => schema.required("Required"),
}); 源码:
type ConditionConfig<T extends ISchema<any>> = { is: any | ((...values: any[]) => boolean); then?: (schema: T) => ISchema<any>; otherwise?: (schema: T) => ISchema<any>;
}; 可以知道 is 字段支持两种类型：
直接传入值（例如 true、false、字符串等）
传入一个函数（可接收多个 values 并返回 boolean） //数组验证
vee-validate 提供了 useFieldArray 这个 API，专门用于处理 数组类型的表单字段，比如 动态添加或删除输入项。 使用示例:
<script setup lang="ts">
import { useFieldArray } from "vee-validate"; const { fields: reminders, push, remove } = useFieldArray<{ message: string }>("reminders"); // 添加一项
const addReminder = () => { push({ message: "" });
}; // 删除一项
const deleteReminder = (index: number) => { remove(index);
};
<\/script> <template> <div v-for="(reminder, index) in reminders" :key="reminder.key"> <input v-model="reminder.value.message" placeholder="Enter reminder" /> <button @click="deleteReminder(index)">Delete</button> </div> <button @click="addReminder">Add Reminder</button>
</template> 实际使用示例(单独定义验证层):
const { fields: reminders, push, remove, replace,
} = useFieldArray<RegistrationPaymentsReminder>("reminders"); 代码分析:
reminders 绑定到 表单字段 reminders（即数组）
push(item) 新增一项
remove(index) 删除某一项
replace(newArray) 替换整个数组 useFieldArray 核心特点
fields 是一个响应式数组，每个项都有 key 和 value：
{ key: Symbol(), value: { message: "" } } 还有个问题，如果有多个 useFieldArray 需要区分push这些,可以按照下面几种方式定义：
1.分别定义多个useFieldArray, 给 push remove 等操作取名字， 上面的其实使用的默认名称 push remove 等， 适用于逻辑不同的
<script setup lang="ts">
import { useFieldArray } from "vee-validate"; // 处理 reminders
const { fields: reminders, push: pushReminder, remove: removeReminder } = useFieldArray<{ message: string }>("reminders"); // 处理 notifications
const { fields: notifications, push: pushNotification, remove: removeNotification } = useFieldArray<{ title: string }>("notifications"); // 添加 reminder
const addReminder = () => { pushReminder({ message: "" });
}; // 添加 notification
const addNotification = () => { pushNotification({ title: "" });
}; // 删除 reminder
const deleteReminder = (index: number) => { removeReminder(index);
}; // 删除 notification
const deleteNotification = (index: number) => { removeNotification(index);
};
<\/script> <template> <div> <h3>Reminders</h3> <div v-for="(reminder, index) in reminders" :key="reminder.key"> <input v-model="reminder.value.message" placeholder="Reminder" /> <button @click="deleteReminder(index)">Delete</button> </div> <button @click="addReminder">Add Reminder</button> </div> <div> <h3>Notifications</h3> <div v-for="(notification, index) in notifications" :key="notification.key"> <input v-model="notification.value.title" placeholder="Notification" /> <button @click="deleteNotification(index)">Delete</button> </div> <button @click="addNotification">Add Notification</button> </div>
</template> 2.集中定义，适用于逻辑类似的
<script setup lang="ts">
import { useFieldArray } from "vee-validate"; const fieldArrays = { reminders: useFieldArray<{ message: string }>("reminders"), notifications: useFieldArray<{ title: string }>("notifications"),
}; // 添加项
const addItem = (fieldName: keyof typeof fieldArrays, item: any) => { fieldArrays[fieldName].push(item);
}; // 删除项
const removeItem = (fieldName: keyof typeof fieldArrays, index: number) => { fieldArrays[fieldName].remove(index);
};
<\/script> <template> <div> <h3>Reminders</h3> <div v-for="(reminder, index) in fieldArrays.reminders.fields" :key="reminder.key"> <input v-model="reminder.value.message" placeholder="Reminder" /> <button @click="removeItem('reminders', index)">Delete</button> </div> <button @click="addItem('reminders', { message: '' })">Add Reminder</button> </div> <div> <h3>Notifications</h3> <div v-for="(notification, index) in fieldArrays.notifications.fields" :key="notification.key"> <input v-model="notification.value.title" placeholder="Notification" /> <button @click="removeItem('notifications', index)">Delete</button> </div> <button @click="addItem('notifications', { title: '' })">Add Notification</button> </div>
</template>`}]},{path:"/content/front/js/vee_validate%E5%B0%86API%E8%BF%94%E5%9B%9E%E7%9A%84%E9%94%99%E8%AF%AF%E6%B8%B2%E6%9F%93%E5%88%B0%E6%8C%87%E5%AE%9AFile%E4%B8%8A.html",title:"vee_validate将API返回的错误渲染到指定File上",pathLocale:"/",contents:[{header:"",slug:"",content:`vee_validate将API返回的错误渲染到指定File上:
示例代码:
const { handleSubmit, setFieldError, setErrors } = useForm();
const onSubmit = handleSubmit(async values => { // Send data to the API const response = await client.post('/users/', values); // all good if (!response.errors) { return; } // set single field error, 这个是我需要的 if (response.errors.email) { setFieldError('email', response.errors.email); } // set multiple errors, assuming the keys are the names of the fields // and the key's value is the error message， 这个还没试过，但是应该很好用，相当于 laravel的form验证错误渲染了 setErrors(response.errors);
}); 参考:https://vee-validate.logaretm.com/v4/guide/composition-api/handling-forms/ 下的 Setting Errors Manually 部分 开始我是这样:
email.errorMessage.value = "User account already exists";
没有生效，应该:
setFieldError("email", "User account already exists");`}]},{path:"/content/front/js/vee_validate%E6%96%87%E6%A1%A3.html",title:"vee_validate文档",pathLocale:"/",contents:[{header:"",slug:"",content:`vee_validate文档:
现在的前端项目使用vee-validate进行表单的验证 参考文档: https://vee-validate.logaretm.com/v4/`}]},{path:"/content/front/js/vite_vs_webpack.html",title:"vite_vs_webpack",pathLocale:"/",contents:[{header:"",slug:"",content:`vite_vs_webpack:
为甚记录这个，主要是看到 laravel将打包工具从之前的 webpack换为vite，就想仔细了解一下
原文: https://www.vuemastery.com/blog/vite-vs-webpack/
vite官网: https://vitejs.dev/`}]},{path:"/content/front/js/vitest%E7%BB%84%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6.html",title:"vitest组件测试框架",pathLocale:"/",contents:[{header:"",slug:"",content:`vitest组件测试框架:
https://vitest.dev/ 直接通过storyBook做测试
https://storybook.js.org/docs/writing-tests/component-testing 测试
https://testing-library.com/ 参考文章
https://kentcdodds.com/blog/write-tests
https://kentcdodds.com/blog/common-mistakes-with-react-testing-library`}]},{path:"/content/front/js/vue3%E4%B8%8Bfilter%E5%92%8Cmap%E8%81%94%E5%90%88%E4%BD%BF%E7%94%A8.html",title:"vue3下filter和map联合使用",pathLocale:"/",contents:[{header:"vue3下filter和map联合使用",slug:"vue3下filter和map联合使用",content:`//通过map实现遍历返回数组对象
const meals = mealOptions.value.map(({ id, title }) => ({ id, title })); //通过filter实现数据的过滤，这里是过滤掉title为空的对象
const meals = mealOptions.value.filter(({ title }) => title).map(({ id, title }) => ({ id, title })); //上面的filter实际上可以展开为如下内容
(item) => { const title = item.title; return title;
} //分析
const arr = [ { title: 'Hello' }, { title: '' }, { title: 'World' }, { title: null },
]; const result = arr.filter(item => { const title = item.title; return title; // 实际上会被转成 Boolean(title)
}); console.log(result);
输出: [ { title: 'Hello' }, { title: 'World' } ] //原理
因为 filter 的机制是这样的：
array.filter(callback) // callback 要返回 true（保留）或 false（过滤掉） //以下是转换结果
Boolean('abc') // true
Boolean('') // false
Boolean(null) // false
Boolean(undefined) // false
Boolean(0) // false
Boolean(1) // true //关于解构和返回值
filter(({ title }) => title) // 参数其实是item对象的展开, 这里只需要title, 返回普通值（比如字符串、布尔、数字、变量）不用括号 map(({ id, title }) => ({ id, title })) // 参数其实是item对象的展开，这里需要id 和 title, 返回“对象字面量”要加括号 { id, title } 等给于 { id:id, title:title } //原理
JavaScript 对象属性的简写规则：
当你写对象字面量时，如果：键名和变量名相同，就可以省略 key: value 中的 value 解构是按需取字段，不需要全取；
解构对象时字段顺序无所谓；
没有解构的字段就不会创建变量，省内存、提性能，也更干净！ //直接赋值使用obj1 和 obj2 内容是等价的
const id = 1;
const title = 'Hello'; const obj1 = { id, title };
const obj2 = { id: id, title: title };`}]},{path:"/content/front/js/vue3%E4%B8%8Binput%E6%A1%86%E9%99%90%E5%88%B6%E5%8F%AA%E5%85%81%E8%AE%B8%E8%BE%93%E5%85%A5%E6%95%B0%E5%AD%97%E5%92%8C%E5%B0%8F%E6%95%B0.html",title:"vue3下input框限制只允许输入数字和小数",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下input框限制只允许输入数字和小数:
export const filterInvalidCharacters = (value: string): string => { const reg = /[^0-9.]/g; return value.replaceAll(reg, "");
}; [^0-9.]：表示匹配所有不是数字（0-9）和小数点（.）的字符。
replaceAll：将所有匹配的非法字符替换为空字符，从而实现过滤。 但是这个还有问题，就是如果使用中文输入法，比如搜狗，在windows操作系统下，还是可以输入汉字，以及拼音。解决办法就是加一个 @compositionend 事件 实际使用:
const handleInteger = (event: InputEvent) => { const currentValue = (event.target as HTMLInputElement).value || ""; const filterValue = filterInvalidCharacters(currentValue); if (filterValue === currentValue) { const currentNumberValue = Number(currentValue) || 0; if (props.maxNumber && currentNumberValue > props.maxNumber) { (event.target as HTMLInputElement).value = lastInputValue.value; model.value = lastInputValue.value; event.preventDefault(); } } else { event.preventDefault(); model.value = filterValue; }
}; const handleInput = (event: InputEvent) => { const currentValue = (event.target as HTMLInputElement).value || ""; const filterValue = filterInvalidCharacters(currentValue); if (filterValue !== currentValue) { event.preventDefault(); model.value = filterValue; } if (currentValue.includes(".")) { const numbersAfterDecimalPoint = currentValue.split(".")[1]; if (numbersAfterDecimalPoint.length > props.decimalPlaces) { (event.target as HTMLInputElement).value = lastInputValue.value; model.value = lastInputValue.value; event.preventDefault(); } }
}; <MInput v-model="model as string | number" outlined hide-state-icons type="text" :name :label :disabled :placeholder :hint="field?.errorMessage.value || hint" :state :class="dynamicClasses" :autocomplete @keydown="handleKeyDown($event)" @keyup.enter="emit('enter')" @input="onlyInteger ? handleInteger($event) : handleInput($event)" @compositionend="onlyInteger ? handleInteger($event) : handleInput($event)"
/> @compositionend 是什么？
@compositionend 是 Vue 绑定的 compositionend 事件，它在 输入法（IME）输入完成后 触发，通常用于处理拼音输入、日语假名输入等情况。
作用：
用于监听输入法输入完成的时机
防止输入法候选字符未完全提交时触发 @input
解决 @input 在部分输入法（如 Windows 下的搜狗输入法）中的兼容性问题 为什么 @compositionend 很重要？
在 Windows 系统（特别是中文输入法）中： 用户在输入 "你好" 时，输入法会先输入 n，然后 i，但这时输入框内的值 还未最终确定，候选框还在变化。
直到用户按下 空格或回车，才会提交最终的「你好」。
但 @input 可能会在未完成拼写时触发，导致错误的处理。
在 Linux/macOS 上，一些输入法在输入过程中不会触发 @input，导致字符无法正确过滤。 为了解决这个问题，我们可以监听 compositionend 事件，在输入法输入完成后再进行处理。`}]},{path:"/content/front/js/vue3%E4%B8%8Bref%E5%8E%9F%E7%90%86.html",title:"vue3下ref原理",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下ref原理:
Notice that we did not need to append .value when using the ref in the template. For convenience, refs are automatically unwrapped when used inside templates 参考：https://vuejs.org/guide/essentials/reactivity-fundamentals`}]},{path:"/content/front/js/vue3%E4%B8%8Bref%E5%92%8Creactive%E5%9C%A8watch%E9%87%8C%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"vue3下ref和reactive在watch里的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下ref和reactive在watch里的区别:
Vue 会自动解包 ref，所以可以直接 watch(count)，不需要 watch(() => count.value)
1.ref 在 watch 里可以省略 .value:
const count = ref(0);
watch(count, (newValue) => { console.log("Count changed:", newValue);
}); 2.reactive 需要 watch 某个具体属性:
const state = reactive({ count: 0 });
watch(() => state.count, (newValue) => { console.log("State.count changed:", newValue);
});`}]},{path:"/content/front/js/vue3%E4%B8%8B%E4%BD%BF%E7%94%A8ref%E8%B0%83%E7%94%A8%E5%AD%90%E7%BB%84%E4%BB%B6%E6%96%B9%E6%B3%95%E7%9A%84%E6%97%B6%E5%80%99%E5%AF%B9ts%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%88%A4%E6%96%AD.html",title:"vue3下使用ref调用子组件方法的时候对ts类型的判断",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下使用ref调用子组件方法的时候对ts类型的判断:
//paraernt.vue下调用子组件 UserDashboardEventSeriesTable.vue const eventSeriesTable = ref<InstanceType< typeof UserDashboardEventSeriesTable
> | null>(null); <UserDashboardEventSeriesTable ref="eventSeriesTable" :query-content="search" />
对于 eventSeriesTable 这个常量，我开始是这样定义类型的:
interface ChildComponentMethod { getEventSeriesItems: () => void;
} 然后:
const eventSeriesTable = ref<ChildComponentMethod | null>(null); 但是后来，发现可以直接通过 typeof 获取组件类型，当然为了更安全，可以通过 InstanceType 实现 官方文档:https://vuejs.org/guide/typescript/composition-api.html#typing-component-template-refs`}]},{path:"/content/front/js/vue3%E4%B8%8B%E4%BD%BF%E7%94%A8swiper.html",title:"vue3下使用swiper",pathLocale:"/",contents:[{header:"",slug:"",content:`最近一直在弄轮播图，然后使用的是swiper v9版本，主要是两个使用场景
1.纯 vue环境
<template> <div class="course-list-wrapper" id="course-list"> <div class="course-list-box" id="gpk"> <div class="container"> <p class="category-title">General Publishing Knowledge</p> <div class="swiper-button-box"> <div class="swiper-c1-next-button"> <img src="~/assets/img/arrow_right_alt.svg" class="abs-center" alt=""> </div> <div class="swiper-c1-pre-button"> <img src="~/assets/img/arrow_left_alt.svg" class="abs-center" alt=""> </div> </div> </div> <div class="swiper" :style="widthChange"> <div class="swiper-wrapper"> <div class="swiper-slide" style="background-color: #00ABCF;">Slide 1</div> <div class="swiper-slide" style="background-color: #1BDFB1;">Slide 2</div> <div class="swiper-slide" style="background-color: #2d8cf0;">Slide 3</div> <div class="swiper-slide" style="background-color: #3B2F40;">Slide 4</div> <div class="swiper-slide" style="background-color: #8E9192;">Slide 5</div> <div class="swiper-slide" style="background-color: #337AB7;">Slide 6</div> </div> </div> </div> </div>
</template> <script>
import Swiper, { Navigation } from 'swiper';
// import Swiper and modules styles
import 'swiper/css';
import 'swiper/css/navigation';
import 'swiper/css/pagination'; export default { name: 'index', components: {Button}, data(){ return { banner:{}, gpkList:[], faList:[], frList:[], resourceUrl: '', respWidth: 1410, widthChange: '' //这个主要是为了计算 轮播区域的左侧margin的 } }, created() { //本来是在 nuxt3下使用的，但是下面这个方式 和纯vue环境 是一样的，完全按照官方文档来调用的 if (process.client){ const swiper = new Swiper('.swiper', {//实例化一个 Swiper对象，然后初始化,传递需要的配置参数 direction: 'horizontal', freeMode: true, loop: false, slidesPerView: 4.03, spaceBetween: 10, modules: [Navigation], navigation: { nextEl: '.swiper-c1-next-button', prevEl: '.swiper-c1-pre-button', }, breakpoints: { 576: { slidesPerView: 4.01, spaceBetween: 30 }, 640: { slidesPerView: 4.01, spaceBetween: 30 }, 768: { slidesPerView: 4.01, spaceBetween: 30 }, 992: { slidesPerView: 4.01, spaceBetween: 30 }, 1200: { slidesPerView: 4.01, spaceBetween: 30 }, 1410: { slidesPerView: 4.01, spaceBetween: 30 } } }); let that = this swiper.on('slideChange', function (swiper) { if (swiper.activeIndex !== 0 ){ that.widthChange = 'margin-left:0px'; }else { that.widthChange = 'margin-left: calc((100% - '+that.respWidth+'px)/2)'; } }.bind(that)); swiper.on('breakpoint', function (swiper, breakpointParams) { that.respWidth = swiper.currentBreakpoint this.widthChange = 'margin-left: calc((100% - '+this.respWidth+'px)/2)' }.bind(that)); } this.widthChange = 'margin-left: calc((100% - '+this.respWidth+'px)/2)' }, methods: { }
} <\/script> 2.nuxt3框架下使用，主要是通过 Swiper 和 SwiperSlide 组件实现
<template> <!-- home-page-banner--> <div class="banner-wrapper" v-if="banner.coverPicture"> <div class="video-box" v-if="banner.playUrl"> <Video class="video-player" :src="\`\${resourceUrl+'/'+banner.playUrl}\`" type="video/mp4" autoplay="autoplay" loop="loop" muted="muted"></Video> </div> <div class="container banner-course-wrapper"> <div class="banner-course-box"> <p class="title">{{banner.title}}</p> <p class="desc"> {{banner.description}} </p> </div> </div> </div> <div class="course-list-wrapper" id="course-list"> <div class="course-list-box" id="gpk"> <div class="container"> <p class="category-title">General Publishing Knowledge</p> <div class="swiper-button-box"> <div class="swiper-c1-next-button"> <img src="~/assets/img/arrow_right_alt.svg" class="abs-center" alt=""> </div> <div class="swiper-c1-pre-button"> <img src="~/assets/img/arrow_left_alt.svg" class="abs-center" alt=""> </div> </div> </div> <div class="swiper-container-wrapper" v-if="gpkList.length > 0"> <swiper :sticky="true" :slides-per-view="4.03" :centeredSlides="true" :initialSlide="1" :space-between="30" :loop="false" :enabled="gpkList.length > 3" :modules="modules" :navigation="{prevEl: '.swiper-c1-pre-button', nextEl: '.swiper-c1-next-button'}" @slideChange="slideGpkChange"> <swiper-slide v-for="(item, index) in gpkList" :class="{'sp-img': gpkList.length < 2}"> <NuxtLink :to="\`\${'/course/'+item.id}\`"> <img :src="\`\${resourceUrl+'/'+item.coverPicture}\`" alt=""> <p class="title">{{item.title}}</p> <div class="statistics"> <p class="time">{{item.estimatedLearningTime}}</p> <p class="certification" v-if="item.needCertification">certification</p> </div> </NuxtLink> </swiper-slide> </swiper> </div> </div> <div class="course-list-box" id="fa"> <div class="container"> <p class="category-title">For Authors</p> <div class="swiper-button-box"> <div class="swiper-c2-next-button"> <img src="~/assets/img/arrow_right_alt.svg" class="abs-center" alt=""> </div> <div class="swiper-c2-pre-button"> <img src="~/assets/img/arrow_left_alt.svg" class="abs-center" alt=""> </div> </div> </div> <div class="swiper-container-wrapper" v-if="faList.length > 0"> <swiper :sticky="true" :slides-per-view="4.03" :centeredSlides="true" :initialSlide="1" :space-between="30" :loop="false" :enabled="faList.length > 3" :modules="modules" :navigation="{prevEl: '.swiper-c2-pre-button', nextEl: '.swiper-c2-next-button'}" @slideChange="slideFaChange"> <swiper-slide v-for="(item, index) in faList" :class="{'sp-img': faList.length < 2}"> <NuxtLink :to="\`\${'/course/'+item.id}\`"> <img :src="\`\${resourceUrl+'/'+item.coverPicture}\`" alt=""> <p class="title">{{item.title}}</p> <div class="statistics"> <p class="time">{{item.estimatedLearningTime}}</p> <p class="certification" v-if="item.needCertification">certification</p> </div> </NuxtLink> </swiper-slide> </swiper> </div> </div> <div class="course-list-box" id="fr"> <div class="container"> <p class="category-title">For Reviewers</p> <div class="swiper-button-box"> <div class="swiper-c3-next-button"> <img src="~/assets/img/arrow_right_alt.svg" class="abs-center" alt=""> </div> <div class="swiper-c3-pre-button"> <img src="~/assets/img/arrow_left_alt.svg" class="abs-center" alt=""> </div> </div> </div> <div class="swiper-container-wrapper" v-if="frList.length > 0"> <swiper :sticky="true" :slidesPerView="4.03" :centeredSlides="true" :initialSlide="1" :spaceBetween="30" :loop="false" :enabled="frList.length > 3" :modules="modules" :navigation="{prevEl: '.swiper-c3-pre-button', nextEl: '.swiper-c3-next-button'}" @slideChange="slideFrChange"> <swiper-slide v-for="(item, index) in frList" :class="{'sp-img': frList.length < 2}"> <NuxtLink :to="\`\${'/course/'+item.id}\`"> <img :src="\`\${resourceUrl+'/'+item.coverPicture}\`" alt=""> <p class="title">{{item.title}}</p> <div class="statistics"> <p class="time">{{item.estimatedLearningTime}}</p> <p class="certification" v-if="item.needCertification">certification</p> </div> </NuxtLink> </swiper-slide> </swiper> </div> </div> </div>
</template> <script setup>
import { Navigation, FreeMode } from 'swiper';
const modules = [Navigation, FreeMode];
const config = useRuntimeConfig()
const resourceUrl = config.public.envData.VITE_APP_URL
<\/script> <script>
import {Button} from "@qinghong-ui/design-system"
import { Swiper, SwiperSlide } from 'swiper/vue';
export default { name: 'index', components: {Button,Swiper,SwiperSlide}, data(){ return { banner:{}, gpkList:[], faList:[], frList:[], resourceUrl: '' } }, created() { this.getResourceList() }, methods: { getResourceList: async function () { const res = await $fetch('/api/index/resource', { method: 'get', headers: {'X-Requested-With': 'XMLHttpRequest'} }) if (res){ if (res.code){ this.$toast.error(res.msg) }else { this.banner = res.data.banner this.gpkList = res.data.gpk this.faList = res.data.fa this.frList = res.data.fr } }else { this.$toast.error('require api failed') } }, slideGpkChange: function (swiper){ this.slideChange(swiper, 'gpk') }, slideFaChange: function (swiper){ this.slideChange(swiper, 'fa') }, slideFrChange: function (swiper){ this.slideChange(swiper, 'fr') }, slideChange: function (swiper, type){ let num = 0; if (type === 'gpk'){ num = this.gpkList.length; }else if (type === 'fa'){ num = this.faList.length; }else { num = this.frList.length; } if (num > 1){ if (num === 2 ){ if (swiper.activeIndex === 0 ){ swiper.slideTo(1); } } if (num === 3){ if (swiper.activeIndex === 0 ){ swiper.slideTo(1); }else if (swiper.activeIndex === 2){ swiper.slideTo(1); } } if (num > 3){ if (swiper.activeIndex === 0 ){ swiper.slideTo(1); }else if (swiper.activeIndex === (num - 1)){ swiper.slideTo(num - 2); } } } } }
}
<\/script>`}]},{path:"/content/front/js/vue3%E4%B8%8B%E4%BD%BF%E7%94%A8v_model%E5%92%8Cmodel_value%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"vue3下使用v_model和model_value的区别",pathLocale:"/",contents:[{header:"",slug:"",content:'vue3使用 v-model和 :model-value 的区别:\n在 Vue 3 中, `v-model` 和 `:model-value` 都用于实现双向数据绑定,但有一些细微差别: 1>. **语法** - `v-model` 是一个语法糖,相当于 `:value="valueFromParent" @input="valueFromParent = $event"` - `:model-value` 和 `@update:modelValue` 分别用于显式设置组件的 value 属性和更新事件 2>. **自定义修饰符** - `v-model` 支持 `.trim`、`.number` 等修饰符,可以对绑定值进行转换 - `:model-value` 不支持修饰符,如需转换需自行处理 3>. **默认 Prop 名称** - 使用 `v-model` 时,默认会匹配名为 `modelValue` 的 prop 和 `update:modelValue` 事件 - 使用 `:model-value` 时,直接使用提供的 prop 和事件名称 4>. **语义** - `v-model` 语义上表达了"双向绑定",易于理解 - `:model-value` 语义更加明确,分离了传入值和更新事件 总的来说,`v-model` 是一个更简洁的语法,适用于大多数场景。而 `:model-value` 则更灵活,可以自定义 prop 和事件名称,因此在一些特殊情况下更有用,如果需要与 Vue 2 的 `v-model` 行为保持一致也可以使用它。'}]},{path:"/content/front/js/vue3%E4%B8%8B%E4%BD%BF%E7%94%A8videojs%E8%87%AA%E5%AE%9A%E4%B9%89%E6%92%AD%E6%94%BE%E5%99%A8.html",title:"vue3下使用videojs自定义播放器",pathLocale:"/",contents:[{header:"",slug:"",content:"wait..."}]},{path:"/content/front/js/vue3%E4%B8%8B%E5%A4%8D%E5%88%B6%E5%88%B0%E5%89%AA%E8%B4%B4%E6%9D%BF.html",title:"vue3下复制到剪贴板",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下复制到剪贴板:
<template> <div class="font-normal flex"> <!-- 链接容器 --> <div ref="linkText" class="max-w-[220px] overflow-hidden text-ellipsis whitespace-nowrap"> https://github.com/gspgsp </div> <!-- 图标按钮 --> <MIcon name="content_copy" size="sm" @click="copyToClipboard" /> </div>
</template> <script setup lang=ts>
import { ref } from 'vue'; // 用于获取链接内容的 ref
const linkText = ref(null); // 复制到剪贴板的方法
const copyToClipboard = () => { if (linkText.value) { // 获取链接的文本内容 const textToCopy = linkText.value.textContent; // 使用 Clipboard API 复制文本 navigator.clipboard.writeText(textToCopy) .then(() => { alert('链接已复制到剪贴板！'); }) .catch(err => { console.error('复制失败：', err); }); }
};
<\/script> 分析:
navigator.clipboard.writeText 是 Web Clipboard API 的一部分，用于将文本写入用户的剪贴板。这是一个现代浏览器中提供的异步方法，可以安全、便捷地完成剪贴板操作。 参数
text: 要复制到剪贴板的字符串。 返回值
Promise<void>: 返回一个 Promise，表示复制操作的完成状态。
如果成功，Promise 会被解析。
如果失败，Promise 会被拒绝，并返回错误。 将上面的方法封装到utils里:
// /utils/clipboard.ts
export const copyToClipboard = async (text: string): Promise<boolean> => { try { await navigator.clipboard.writeText(text); return true; } catch (err: any) { console.error("copy failed:", err); return false; }
}; 使用:
import { copyToClipboard } from '@/utils/clipboard'; const isToastVisible = ref(false);
const linkText = ref(null);
const handleCopy = async () => { if (linkText.value) { const textToCopy = linkText.value.textContent || ""; const result = await copyToClipboard(textToCopy); if (result) { isToastVisible.value = true; } }
}; 分析:
Promise<boolean> 是对一个 返回值类型为 boolean 的 Promise 的声明，表示函数是异步的，并且会返回一个带有 boolean 类型值的 Promise。 具体含义
Promise: 是 JavaScript 中表示异步操作结果的对象。
它的状态可以是 pending（进行中）、fulfilled（已成功） 或 rejected（已失败）。
boolean 类型: 这里 boolean 指定了 Promise 被 fulfilled（成功）时解析的值是 true 或 false。
如果 Promise 被 rejected（失败），它不会返回 boolean 值，而是进入 catch 块。 关于Promise拓展:
function getData(condition: boolean): Promise<string> { if (condition) { return Promise.resolve("Immediate response"); // 如果满足条件，直接返回完成的 Promise } else { return new Promise((resolve) => setTimeout(() => resolve("Delayed response"), 1000)); // 模拟异步 }
} // 使用
getData(true).then(console.log); // 输出: Immediate response
getData(false).then(console.log); // 1 秒后输出: Delayed response`}]},{path:"/content/front/js/vue3%E4%B8%8B%E6%A0%BC%E5%BC%8F%E5%8C%96%E9%87%91%E9%A2%9D%E4%B8%BA%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E7%9A%84%E6%95%B0%E6%8D%AE.html",title:"vue3下格式化金额为逗号分隔的数据",pathLocale:"/",contents:[{header:"vue3下格式化金额为逗号分隔的数据",slug:"vue3下格式化金额为逗号分隔的数据",content:`function formatNumber(value) { return new Intl.NumberFormat().format(value);
} console.log("formatNumber(123456789) is:", formatNumber(123456789));
输出:
formatNumber(123456789) is: 123,456,789`}]},{path:"/content/front/js/vue3%E4%B8%8B%E7%9A%84v-model%E5%92%8Cvue2%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"vue3下的v-model和vue2的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3下的v-model和vue2的区别:
//子组件:TimeOutModel.vue
<script setup lang="ts">
import {computed} from "vue"; interface Props { modelValue: boolean;
} const props = defineProps<Props>(); const emit = defineEmits<{ (e: "update:model-value", show: boolean): void;//真正的 emit 方法在这里， show 只是参数名称，可以自定义为自己想要的
}>(); const isModalVisible = computed({ get: () => props.modelValue, //当前组件的值发生变化的时候，通过emit通知父组件，实现双向绑定,这一步可以对value 做一定的处理，比如:set: (value) => emit("update:title-info", value.charAt(0).toUpperCase() + value.slice(1)), //注意，我开始以为需要可以在父组件里定义 @update:model-value="otherFun()"，然后在otherFun()里获取这个 value,后来发现不行，感觉前面这个写法相当于是内置的，就只用于v-model的双向绑定，@update:model-value //不需要在父组件里写,可以参考最下面的链接 set: (value) => emit("update:model-value", value),
});
<\/script> <template> <QModal v-model="isModalVisible" :hideCloseIcon="true" :persistent="true"> <template #header> <div class="infoHear"> <img src="~/assets/img/notice.svg" class="notice-img"/> <h3>Time is up!</h3> </div> </template> <template #body> <p class="body-info">Do you want to submit or discard changes</p> </template> <template #footer> <div class="flex gap-2"> <QButton size="sm" class="flex-1" variant="secondary" @click="close">Discard</QButton> <QButton size="sm" class="flex-1" variant="primary" @click="submit">Submit</QButton> </div> </template> </QModal>
</template> <script lang="ts"> export default { name: "DsModal", methods: { close(){ this.$emit('close') //还是可以在这里定义对外的emit方法 }, submit(){ this.$emit('submit') } }
}
<\/script> <style scoped lang="postcss">
.infoHear{ display: flex; flex-direction: column; align-items: center; .notice-img{ display: block; width: 3.3125rem; height: 3.625rem; }
} .body-info{ display: flex; justify-content: center; padding: 1.25rem 0.625rem;
}
</style> 上面的vue组件，要求 script setup 中的 lang 和 script 中的 lang 要定义相同
参考：https://v3-migration.vuejs.org/breaking-changes/v-model.html //经过改造以后，实现子组件修改数据，触发set方法 ，主要是通过 @click="tt" 修改字符串的内容，这样就验证了，这个set 方法中的emit的作用，实现双向绑定
<script setup lang="ts">
import {computed} from "vue"; interface Props { modelValue: boolean, titleInfo: string
} const props = defineProps<Props>(); const emit = defineEmits<{ (e: "update:model-value", show: boolean): void; (e: "update:title-info", str: string): void;
}>(); const isModalVisible = computed({ get: () => props.modelValue, set: (value) => emit("update:model-value", value),
}); const titleStr = computed({ get: () => props.titleInfo, set: (value) => emit("update:title-info", value.charAt(0).toUpperCase() + value.slice(1)),
}) const tt = () => { titleStr.value = "good bye" + (new Date())
}
<\/script> <template> <QModal v-model="isModalVisible" :hideCloseIcon="true" :persistent="true"> <template #header> <div class="infoHear"> <img src="~/assets/img/notice.svg" class="notice-img"/> <h3 @click="tt">{{titleStr}}</h3> </div> </template> <template #body> <p class="body-info">Do you want to submit or discard changes</p> </template> <template #footer> <div class="flex gap-2"> <QButton size="sm" class="flex-1" variant="secondary" @click="close">Discard</QButton> <QButton size="sm" class="flex-1" variant="primary" @click="submit">Submit</QButton> </div> </template> </QModal>
</template> <script lang="ts"> export default { name: "DsModal", methods: { close(){ this.$emit('close') }, submit(){ this.$emit('submit') } }
}
<\/script> <style scoped lang="postcss">
.infoHear{ display: flex; flex-direction: column; align-items: center; .notice-img{ display: block; width: 3.3125rem; height: 3.625rem; }
} .body-info{ display: flex; justify-content: center; padding: 1.25rem 0.625rem;
}
</style> //vue3下v-model 自定义数据预处理，有时候我们需要在用户输入内容的的时候，对输入的数据做预处理，比如 去掉空格，转大写等
参考：https://vuejs.org/guide/components/v-model.html#handling-v-model-modifiers //我自己测试失败了`}]},{path:"/content/front/js/vue3%E4%B8%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AAFile%E5%AF%B9%E8%B1%A1.html",title:"vue3下自定义一个File对象",pathLocale:"/",contents:[{header:"vue3下自定义一个File对象:",slug:"vue3下自定义一个file对象",content:`在实际香红木开发过程中，有时候会用到 File 类型做文件的上传，一个标准的 File 对象，一般包含如下信息:
属性名 | 类型 | 说明
name | string | 文件名，例如 example.jpg
lastModified | number | 文件最后修改时间的时间戳（毫秒）
lastModifiedDate | Date（已废弃） | 已废弃的属性，请使用 lastModified
webkitRelativePath | string | 如果通过 <input webkitdirectory> 选择目录时的相对路径
size | number | 文件大小（字节数）
type | string | 文件 MIME 类型，例如 image/png、application/pdf
arrayBuffer() | Promise<ArrayBuffer> | 获取文件内容的 ArrayBuffer 表示
slice() | 方法 | 用于从文件中提取部分内容
stream() | 方法 | 返回一个可读的 ReadableStream，用于流式读取内容
text() | Promise<string> | 返回文件内容的文本形式（例如 .txt 文件） 但是有时候，我们可能需要自己定义一个 File 类型，比如定义了了一个其它的属性name2，这样代码是可以执行的，但是 ts 类型检查会报错，因为类型不一致. 为了解决这个问题，可以通过如下方式解决，
function createFakeFileWithSize(name: string, size: number, type: string): File { const blobContent = new Uint8Array(size); // 此时的array大小就是这个 size 的大小 console.log("blobContent:", blobContent); return new File([blobContent], name, { type, lastModified: Date.now(), // 可以不要，默认就是当前时间 });
} console.log("fakeFile is:", createFakeFileWithSize("placeholder.pdf", 2048, "application/pdf")); 主要逻辑就是，将自定义的File, 重新伪造一个标准的File对象，这里通过 Uint8Array 生成一个 blod 对象，主要用来保存这个 size 的大小，不能之间诶给File对象传递sise,这个size和content大小，他表示的是[内容]数组的大小
所以这里通过这个blob对象模拟一个相同大小的size对象, 上面的 placeholder.pdf(可以是name2，这里赋值给标准File) 其实就是标准File的名称，application/pdf 为文件类型 //使用 Blod 声明一个blob对象
const blob = new Blob(["Hello World"], { type: "text/plain"
}); console.log("blob is:", blob)`}]},{path:"/content/front/js/vue3%E4%B8%8B%E9%80%9A%E8%BF%87ts%E7%9A%84defineProps%E7%88%B6%E5%AD%90%E4%BC%A0%E5%80%BC.html",title:"vue3下通过ts的defineProps父子传值",pathLocale:"/",contents:[{header:"",slug:"",content:`父组件向子组件传值:
defineProps 是 Vue3 中一种新的组件数据传递方式，可以用于在子组件中定义接收哪些父组件的 props。当父组件的 props 发生变化时，子组件也会随之响应。
在子组件中可以使用 defineProps 声明该组件需要接收的 props，示例如下：
//父组件
<script setup lang="ts">
import { ref } from 'vue'
import ChildComponent from './ChildComponent.vue' const count = ref(0)
const add = () => { count.value++
}
<\/script>
<template> <button @click="add">+</button> <ChildComponent :count="count"></ChildComponent>
</template> //子组件
<script setup lang="ts">
const props = defineProps({ count: Number
})
<\/script>
<template> <div> {{ props.count }} </div>
</template> 子组件向夫组件传值:
defineEmits用于在setup中注册自定义事件，是一个宏函数，使用时无需导入
defineEmits接受一个数组，元素为自定义事件名
defineEmits返回一个触发器，用于触发事件，第一个参数是具体事件，第二个是传递的值
//父组件
<script setup lang="ts">
import { ref } from 'vue'
import ChildComponent from './ChildComponent.vue' const count = ref(0)
const changeFn = (val: number) => { console.log(val) count.value = count.value + val
}
<\/script>
<template> <ChildComponent :count="count" @add="changeFn"></ChildComponent>
</template> //子组件
<script setup lang="ts">
const props = defineProps({ count: Number
})
const emit = defineEmits(['add'])
const change = () => { emit('add', 1)
}
<\/script>
<template> <div> {{ props.count }} </div> <button @click="change">+</button>
</template> 其实用的最多的，还是v-model双向绑定的问题，解决办法就是defineProps配合defineEmits使用，实现父子相互赋值:
v-model cannot be used on a prop, because local prop bindings are not writable.
Use a v-bind binding combined with a v-on listener that emits update:x event instead. 相关代码如下:`}]},{path:"/content/front/js/vue3%E4%B8%ADslot%E4%B8%8D%E7%94%9F%E6%95%88%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"vue3中slot不生效的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`问题1：在子组件中定义一个具名插槽，在父组件中使用，但是内容并不能渲染出来。
原因：Vue在2.6.0,版本更新了有关插槽的大量内容,具名插槽和作用域插槽引入了一个新的语法v-slot来取代slot和slot-scope这两个已废弃但未移除的属性。所以使用原来的写法内容不能被渲染出来。
修改：使用的每一个slot都需要一个 template 包裹，且 slot=“名称” 修改为 v-slot:名称
如下：`}]},{path:"/content/front/js/vue3%E4%B9%8BTransition%E7%BB%99%E5%85%83%E7%B4%A0%E6%B7%BB%E5%8A%A0%E5%8A%A8%E7%94%BB.html",title:"vue3之Transition给元素添加动画",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之Transition给元素添加动画，有时候v-show的元素展示太突然，需要加个过度效果，vue有Transition可以实现这一点
<Transition name="fade"> //code here...
</Transition> 对于一个有名字的过渡效果，对它起作用的过渡 class 会以其名字而不是 v 作为前缀。比如，上方例子中被应用的 class 将会是 fade-enter-active 而不是 v-enter-active。这个“fade”过渡的 class 应该是这样： .fade-enter-active, .fade-leave-active { transition: opacity 0.5s ease; } .fade-enter-from, .fade-leave-to { opacity: 0; }`}]},{path:"/content/front/js/vue3%E4%B9%8Bcodemirror6%E4%BD%BF%E7%94%A8.html",title:"vue3之codemirror6使用",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之codemirror6使用:
1>安装依赖
npm i vue-codemirror6 codemirror 2>安装语言
$ npm install @codemirror/lang-javascript @codemirror/lang-php @codemirror/lang-go @codemirror/lang-json 3>安装主题
npm i @codemirror/theme-one-dark`}]},{path:"/content/front/js/vue3%E4%B9%8BmodelValue%E6%9B%B4%E6%96%B0%E4%BA%8B%E4%BB%B6.html",title:"vue3之modelValue更新事件",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之modelValue更新事件:
1>传递参数(原生写法)
<template> <MyComponent v-model="modelValue" @update:model-value="(value) => onValueChange(ticket.id, value)" />
</template> 2>传递参数(简洁写法)
<template> <MyComponent v-model="modelValue" @update:model-value="onValueChange(ticket.id, $event)" />
</template> 3>如果没有自定义参数可以直接传递 $event 或者 什么参数也不传递，默认就是 $event, 在onValueChange 方法中直接可以获取
<template> <MyComponent v-model="modelValue" @update:model-value="onValueChange($event)" />
</template>
或
<template> <MyComponent v-model="modelValue" @update:model-value="onValueChange" />
</template> 对应方法:
<script setup>
const onSectionCheckboxChanged = (id: number, value: boolean) => { console.log("section is:", id); console.log("section checked:", value)
};
<\/script> <script setup>
const onSectionCheckboxChanged = (value: boolean) => { console.log("section is:", id); console.log("section checked:", value)
};
<\/script>`}]},{path:"/content/front/js/vue3%E4%B9%8Bsetup()%E5%92%8C%E8%84%9A%E6%9C%ACsetup%E7%9A%84%E5%BE%AE%E5%A6%99%E4%B8%8D%E5%90%8C.html",title:"vue3之setup()和脚本setup的微妙不同",pathLocale:"/",contents:[{header:"",slug:"",content:`不要为已经可以用 <script setup> 定义的选项使用单独的 <script> 部分，如 props 和 emits。
在 <script setup> 中创建的变量不会作为属性添加到组件实例中，这使得它们无法从选项式 API 中访问。我们强烈反对以这种方式混合 API。//重点是这句话，就是不能混合开发，实际上这样的需求还少，无奈...
如果你发现自己处于以上任一不被支持的场景中，那么你应该考虑切换到一个显式的 setup() 函数，而不是使用 <script setup>`}]},{path:"/content/front/js/vue3%E4%B9%8Bslot%E7%9A%84%E6%8B%93%E5%B1%95.html",title:"vue3之slot的拓展",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之slot的拓展:
1.通过slot获取slot属性
//父组件
<div> <AppDashboardFloatingFilters v-if="dashboardFilters" v-slot="slotProps" > <MyDashboardEventProposalsFilters v-model:search="searchModel" :query-params :status-types="statusItems" :is-floating="slotProps.isFloating" @change-status="changeStatus" @change-search="changeSearch" /> </AppDashboardFloatingFilters>
</div> //子组件 AppDashboardFloatingFilters.vue
<template> <transition enter-from-class="-translate-y-[100%]" leave-to-class="-translate-y-[100%]" enter-active-class="transition-transform duration-[.5s]" leave-active-class="transition-transform duration-[.5s]" > <div v-if="!dashboardProposalFiltersVisible && !isMobileViewport()" class="fixed right-0 top-[4.3rem] z-1 bg-white px-5 shadow-md" :style="[\`left: \${sidebarWidth}\`]" > <slot :is-floating="true" /> </div> </transition> <slot v-if="dashboardProposalFiltersVisible || isMobileViewport()" :is-floating="false" />
</template> 分析: 上面的 v-slot="slotProps" 作用是，通过 slotProps 获取组件自身定义的 slot 属性(有个前提，必须是可以展示的slot), 如果有多个slot, 可以获取每个slot的共同属性，也可以获取各自特有的属性, 然后拿到这个属性在后面的代码里使用，如 :is-floating="slotProps.isFloating", 这种场景只有在 只有default slot的时候才能这么用,如下补充说明 2.通过slot判断组件定义的slot使用情况
//组件
...
...
//ts
const slots = defineSlots<{ default: () => void; loader: () => void; noData: () => void; footer: () => void; footerLeft: () => void; footerRight: () => void; pagination: () => void;
}>(); const hasAnyFooterSlots = computed(() => { return ( !!slots.footer || !!slots.footerLeft || !!slots.footerRight || !!slots.pagination );
}); //页面信息
<slot v-if="hasAnyFooterSlots" name="footer" > <div class="mt-11 flex w-full flex-wrap items-center justify-center gap-2 text-sm empty:hidden lg:min-h-16" > <div v-if="$slots.footerLeft" class="flex flex-wrap items-center justify-center gap-2 lg:mr-auto" > <slot name="footerLeft" /> </div> <div v-if="$slots.footerRight || $slots.pagination" class="flex flex-wrap items-center justify-center gap-2 lg:ml-auto" > <slot name="footerRight"> <slot v-if="hasTableData" name="pagination" /> </slot> </div> </div> </slot>
...
... 分析:
上面的 defineSlots 用来定义当前组件内所有的 slot信息，然后可以通过 slots 获取指定的slot, 用来做判断，比如计算属性 hasAnyFooterSlots，以及后面的代码里使用 v-if="$slots.footerLeft" 进行动态判断 订正一下:
上面的 defineSlots 用来定义当前组件内所有的 slot信息，然后可以通过 slots 获取指定的slot, 用来做判断，比如计算属性 hasAnyFooterSlots，以及后面的代码里使用 v-if="$slots.footerLeft" 进行动态判断，注意 v-if="$slots.footerLeft" 中的 $slots 并不是前面定义的 slots, 前面那个课取任何名称。但是后面的 $slots 是 Vue 中的一个对象，包含了所有传递到当前组件的插槽。 关于 $slots 对象:
如果某个插槽被父组件填充了，$slots['插槽名'] 会返回一个内容函数（Vue 渲染函数）。
如果插槽未被填充，$slots['插槽名'] 通常是 undefined
v-if="$slots['left-icon']" 的作用
v-if="$slots['left-icon']" 用来检查： 当前组件是否接收到了一个名为 left-icon 的插槽。
如果接收到了，则渲染对应的模板。
这段代码确保只有当父组件提供了 left-icon 插槽时，组件才会尝试渲染 #left-icon 的 <template> 内容。 两种写法:
v-if="$slots.left-icon" 的写法是完全合法的，并且常用于动态判断插槽是否存在。
使用 $slots['left-icon'] 比 $slots.left-icon 更加通用，因为它适用于所有插槽名称，而不仅限于固定名称。 对于有 ts 类型检查的项目，需要先声明slot，如下:
defineSlots<{ "left-icon"?: () => void; "right-icon"?: () => void;
}>(); 如果没有 ts 类型检查，可以不用声明，完全可以正常运行。 最新测试表明，还需要注意如下问题:
vue3中 v-slot="slotProps" 的用法: \`v-slot\`指令是Vue 3中用于接收插槽内容的一种方式。当一个组件传递数据到它的插槽时,我们可以使用\`v-slot\`来访问这些数据。 这里是一个简单的例子来说明它的用法: \`\`\`vue
<!-- 父组件 -->
<template> <ChildComponent> <template v-slot="slotProps"> {{ slotProps.item }} </template> </ChildComponent>
</template> <!-- 子组件 (ChildComponent) -->
<template> <div> <slot :item="{ name: 'Vue 3', version: '3.0' }"></slot> </div>
</template> 在这个例子中: 子组件(ChildComponent)定义了一个插槽,并通过:item属性向插槽传递了一个对象。 父组件使用v-slot="slotProps"来接收这个传递的数据。slotProps是一个包含所有插槽属性的对象。 然后,我们可以在父组件中通过slotProps.item来访问子组件传递的数据。 v-slot指令还有一些其他的用法: 具名插槽:
<template v-slot:header="headerProps"> {{ headerProps.title }}
</template> 解构插槽 prop:
<template v-slot="{ item }"> {{ item.name }}
</template> 缩写语法 (#):
<template #header="{ item }"> {{ item.name }}
</template> 这就是v-slot="slotProps"的基本使用方法。它允许我们在使用组件时,灵活地接收和使用组件传递给插槽的数据。
还有一种非常特殊的用法:
<!-- 父组件 -->
<template> <ChildComponent v-slot="slotProps"> //这个时候可以拿到子组件中 slot 属性的值，在调用子组件里面的任何地方使用 {{ slotProps.item }} // 如果又调用了其它组件，可以把 slotProps.item 传递到 其它组件的props里面 </ChildComponent>
</template> <!-- 子组件 (ChildComponent) -->
<template> <div> <slot :item="{ name: 'Vue 3', version: '3.0' }"></slot> </div>
</template> 上面这种适用于，子组件只有一个 default solt 的情况，并且这个default slot 没有名称，如果子组件有多个slot, 那么上面的写法就会报错: Codegen node is missing for element/if/for node. Apply appropriate transforms first.
并且 slotProps 可以换成任何有意义的名称，比如上面的 headerProps，这只是一个名称. 注意: 1> 父组件通过 props 向子组件传值(包括子组件中的 slot的参数值) 2> 子组件中的 slot, 可以通过 上面的三种 v-slot 用法给父组件传值，注意：不能直接在 <template> 里给slot 传值，因为只能通过 slot 给父组件传值，这个是单向的. 这个问题困扰了我很久，我发现是我想的简单了。`}]},{path:"/content/front/js/vue3%E4%B9%8Bwatch%E5%92%8Ccomputed%E6%96%B9%E6%B3%95.html",title:"vue3之watch和computed方法",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之watch和computed方法:
1.computed相关
ex1:
const isLoggedIn = computed(() => status.value === "authenticated"); // 这种对于简单操作是很方便的 ex2:
const isLoggedIn = computed(() => { return status.value === "authenticated"; // 对于复杂的逻辑操作还是通过完整的方法体处理
}); ex3:默认情况下，计算属性仅为 getter(如上面的两种使用方式，其实都是getter的简写调用方式)。如果试图为计算属性赋新值，可以通过提供一个 getter 和一个 setter 来创建计算属性：
<script setup>
import { ref, computed } from 'vue' const firstName = ref('John')
const lastName = ref('Doe') const fullName = computed({ // getter get() { return firstName.value + ' ' + lastName.value }, // setter set(newValue) { // Note: we are using destructuring assignment syntax here. [firstName.value, lastName.value] = newValue.split(' ') }
})
<\/script> 现在，当运行 fullName.value = 'Jerry Tom'时，setter 将被调用，firstName 和 lastName 也会相应更新。 computed 返回值是一个 computed ref， s所以这里可以使用 isLoggedIn.value，还有很重要一点，computed 中使用的属性应该是 reactive(ref) 的，这个和vue2不一样，原因在于 vue3 使用了大量组合式API.
重要的是要记住，计算型获取函数只能执行纯粹的计算，不能有任何副作用。例如，不要在计算型获取函数中更改其他状态、进行异步请求或更改 DOM！将计算属性视为声明性地描述如何根据其他值推导出一个值，它唯一的职责就是计算并返回该值.
计算属性的返回值是派生状态。把它想象成一个临时快照--每次源状态发生变化，就会创建一个新的快照。更改快照是没有意义的，因此计算的返回值应被视为只读，绝不能更改，而应更新它所依赖的源状态，以触发新的计算. 参考: https://vuejs.org/guide/essentials/computed.html 2.watch相关:
watch's first argument can be different types of reactive "sources": it can be a ref (including computed refs), a reactive object, a getter function, or an array of multiple sources, 第二个参数是一个 callback. ex:
const x = ref(0)
const y = ref(0) // single ref
watch(x, (newX) => { console.log(\`x is \${newX}\`)
}) // getter
watch( () => x.value + y.value, (sum) => { console.log(\`sum of x + y is: \${sum}\`) }
) // array of multiple sources
watch([x, () => y.value], ([newX, newY]) => { console.log(\`x is \${newX} and y is \${newY}\`)
}) 实际使用例子:
ex1:
watch( () => isAdditionalFacetsExpanded.value, (newVal) => { if (!newVal) { clearSearch(); abortByKey(ABORT_CONTROLLER_KEY); } else { loadData(); // 可以异步请求数据 } }
); ex2:
watch( () => route.path, () => { headerNav.setMobileDrawerVisibility(false); // 修改 pinia 中的状态 }
); ex3: watch( () => isMetricsError.value, () => { error.value = isMetricsError.value; }, { immediate: true, }
); ex4:
watch( source, (newValue, oldValue) => { // when \`source\` changes, triggers only once }, { once: true }
) watch 默认是 "懒惰 "的：在被监视源发生变化之前不会调用回调。但在某些情况下，我们可能希望紧急运行相同的回调逻辑，例如，我们可能希望获取一些初始数据，然后在相关状态发生变化时重新获取数据. 我们可以通过传递 immediate: true 选项来强制立即执行观察者的回调.
watch 默认只要被监视源发生变化，监视器的回调就会执行。如果希望回调只在源更改时触发一次，请使用 once: true 选项. 参考: https://vuejs.org/guide/essentials/watchers.html`}]},{path:"/content/front/js/vue3%E4%B9%8B%E6%8B%96%E6%8B%BD%E6%8F%92%E4%BB%B6.html",title:"vue3之拖拽插件",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之拖拽插件:
安装: npm install vue-draggable-plus
使用:
<template> <VueDraggable ref="el" v-model="list"> <div v-for="item in list" :key="item.id"> {{ item.name }} </div> </VueDraggable>
</template> <script setup lang="ts">
import { ref } from 'vue'
import { VueDraggable } from 'vue-draggable-plus' const list = ref([ { name: 'Joao', id: 1 }, { name: 'Jean', id: 2 }, { name: 'Johanna', id: 3 }, { name: 'Juan', id: 4 }
])
<\/script> 这个插件非常好用，只要包裹住目标内容，即可实现拖拽功能
排序事件:
import { VueDraggable, type DraggableEvent, type SortableEvent,
} from "vue-draggable-plus"; const onSort = async (event: SortableEvent) => { const draggableEvent = event as DraggableEvent; console.log("event id is:", draggableEvent.data.id); console.log("event sort is:", draggableEvent.newIndex);
}; <VueDraggable v-model="sessionList" class="mb-8 flex flex-col gap-xl" @sort="onSort"
> vue-draggable-plus可以定义拖拽点，而不必整个页面生效:
https://vue-draggable-plus.pages.dev/demo/handle/ 也可以做表格拖拽:
https://vue-draggable-plus.pages.dev/demo/target-container/ 典型 issue:
https://github.com/Alfred-Skyblue/vue-draggable-plus/issues/86 如果想实现表格的部分列拖拽，而不是所有列，可以按照如下方式处理:
允许部分td 拖拽，而不必整行都拖拽
import { VueDraggable } from "vue-draggable-plus"; <VueDraggable v-model="addonsList" target=".handle-addons" filter=".unable-drag"
> <AppTable class="w-full"> <thead> <tr class="h-12"> <AppTableHeading class="w-[35rem]" title="Name" /> <AppTableHeading class="w-[12.5rem]" title="Price (CHF)" /> <AppTableHeading class="w-[12.5rem]" title="Issued" /> <AppTableHeading class="w-[28rem]" title="Available to" /> <AppTableHeading class="w-[12.5rem]" title="Action" /> </tr> </thead> <tbody class="handle-addons text-xs"> <tr v-for="addons in addonsList" :key="\`\${addons.name}_\${addons.id}\`" class="select-text" > <td> {{ addons.name }} </td> <td class="unable-drag"> {{ addons.price }} </td> <td class="unable-drag">{{ addons.issued }}</td> <td class="unable-drag"> {{ addons.availableTo }} </td> <td class="unable-drag"> <EventSettingsRegistrationTicketsAction :id="addons.id" @edit="showEditAddons" @delete="showDeleteAddons" /> </td> </tr> </tbody> </AppTable>
</VueDraggable> 主要是通过 filter 属性定义的class来排除; 同时给每个tr添加 class="select-text" , 这样可以选中td中的文字，否则选不了，但是和 filter 一起使用的时候，会发现，只有可 drag 的元素才能被选中，被过滤的还是不能被选中，非常蛋疼. 关于 vue-draggable-plus 插件的几个属性，可以参考，虽然不是一个包，但是都用了sortable.js:
https://github.com/SortableJS/Sortable //这里面也有介绍 结论：
1>无论哪种drag插件，最后都是 sortable.js, 并且 vuedraggable@next 是 sortable.js的 vue3实现方式， 这个 vue-draggable-plus 文档说 sortable.js不支持vue3是错误的
2>select-text 属性还是没有在 不是drag 元素上实现，怎么测试都不行 原生的drag库:
https://interactjs.io/`}]},{path:"/content/front/js/vue3%E4%B9%8B%E6%B3%9B%E5%9E%8B%E8%84%9A%E6%9C%AC.html",title:"vue3之泛型脚本",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3之泛型脚本:
在 <script setup lang="ts" generic="T"> 中，generic="T" 的作用是告诉 TypeScript 这个 <script setup> 脚本是泛型的，可以接受一个类型参数 T。这是 Vue 3.3+ 中引入的一种语法糖，用于在 <script setup> 中声明泛型类型。
通常情况下，泛型用于使组件或函数更通用和可复用，能够处理不同的类型。以下是具体的解释和用法：`},{header:"1. 作用",slug:"_1-作用",content:'generic="T" 声明了 <script setup> 是一个泛型脚本，T 是其泛型类型参数。这允许你在组件中定义依赖于某种类型的逻辑，并在使用该组件时动态传递具体的类型。'},{header:"2. 用法示例",slug:"_2-用法示例",content:""},{header:"基本示例",slug:"基本示例",content:`<script setup lang="ts" generic="T">
defineProps<{ items: T[] }>(); const firstItem = computed(() => props.items[0]);
<\/script> <template> <div>{{ firstItem }}</div>
</template> 当你使用这个组件时，可以指定 T 的具体类型，例如：
<MyComponent :items="[1, 2, 3]" />
<!-- 在这个例子中，T 自动推导为 number --> <MyComponent :items="['a', 'b', 'c']" />
<!-- 在这个例子中，T 自动推导为 string -->`},{header:"搭配类型推导",slug:"搭配类型推导",content:`泛型还可以通过函数返回值或参数的类型来推导：
<script setup lang="ts" generic="T">
defineProps<{ value: T }>(); const double = (input: T): T => { return input; // 示例逻辑
};
<\/script> <template> <div>{{ double(props.value) }}</div>
</template>`},{header:"更复杂的用例",slug:"更复杂的用例",content:`当组件需要根据不同的类型呈现不同的内容时：
<script setup lang="ts" generic="T">
defineProps<{ data: T }>(); const renderData = (data: T) => { if (typeof data === 'string') { return \`String: \${data}\`; } else if (typeof data === 'number') { return \`Number: \${data}\`; } return 'Unknown type';
};
<\/script> <template> <div>{{ renderData(props.data) }}</div>
</template>`},{header:"3. 关键点",slug:"_3-关键点",content:`generic="T" 等价于在普通 TypeScript 文件中通过 <T> 声明泛型。
泛型使组件更灵活，支持不同类型的数据结构。
需要 TypeScript 支持（通过 lang="ts"）。
这是 Vue 3.3+ 的功能，确保使用的 Vue 版本支持这一特性。`},{header:"4. 对比传统写法",slug:"_4-对比传统写法",content:`传统写法中，泛型需要通过函数或类显式定义，例如：
function useData<T>(data: T): T { return data;
} 而 <script setup> 的 generic 属性简化了这一过程，直接将泛型融入到组件的逻辑中，避免了复杂的定义和导入。
关于typescript的 generic(泛型) 的其它用法:
https://www.freecodecamp.org/news/how-typescript-generics-work/
其它文档:
https://wangdoc.com/typescript/generics`}]},{path:"/content/front/js/vue3%E4%B9%8B%E9%83%A8%E5%88%86%E6%B8%B2%E6%9F%93.html",title:"vue3之部分渲染",pathLocale:"/",contents:[{header:"",slug:"",content:'vue3之部分渲染:\nvue3中，渲染数据(一半变化 一半固定):\n:label="`${singularSessionTerm} title`"'}]},{path:"/content/front/js/vue3%E4%BD%BF%E7%94%A8props%E5%90%8C%E6%97%B6%E5%AE%9A%E4%B9%89%E9%BB%98%E8%AE%A4%E5%80%BC%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"vue3使用props同时定义默认值的两种方式",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3使用props同时定义默认值的两种方式:
1>通过definePropsWithDefaults
const props = definePropsWithDefaults<{ cancelText?: string; submitText?: string; isSubmitLoading?: boolean; disabled?: boolean;
}>({ cancelText: "Cancel", submitText: "Submit",
}); 2>解构前为属性添加默认值
const { isFirstStep = false, isLastStep = false, isAllRegistrationSaved = false,
} = defineProps<{ isFirstStep?: boolean, isLastStep?: boolean, isAllRegistrationSaved?: boolean,
}>();`}]},{path:"/content/front/js/vue3%E4%BD%BF%E7%94%A8provide-inject%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%B1%82%E7%BB%84%E4%BB%B6%E5%B5%8C%E5%A5%97%E4%BC%A0%E5%80%BC%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"vue3使用provide-inject解决多层组件嵌套传值的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3使用provide-inject解决多层组件嵌套传值的问题，主要解决 多个emit一层一层的传递:
https://vuejs.org/guide/components/provide-inject`}]},{path:"/content/front/js/vue3%E4%BD%BF%E7%94%A8vite%E6%89%93%E5%8C%85%E7%9A%84%E5%8E%9F%E7%90%86.html",title:"vue3使用vite打包的原理",pathLocale:"/",contents:[{header:"vue3使用vite打包的原理",slug:"vue3使用vite打包的原理",content:`缘起:
Vue3 + Vite 为什么 npm run dev 一跑就能看到访问连接：`},{header:"1. Vite 的核心原理",slug:"_1-vite-的核心原理",content:`Vite 的名字来自法语 "vite" = 快速。它的核心理念就是利用浏览器原生 ES Module 能力，避免传统构建工具（Webpack/Rollup）那种“先打包再启动”的流程。 传统打包工具（Webpack）： 启动时会把整个项目打包成一个 bundle 文件（或多个 chunk）。
大项目启动时要等很久才能看到页面。 Vite： 启动时不打包，只是起一个开发服务器。
浏览器请求哪个文件，就按需即时编译（on-demand transformation），用 ES Module 直接返回。
这样启动速度非常快。`},{header:"2. 为什么 npm run dev 就能看到链接",slug:"_2-为什么-npm-run-dev-就能看到链接",content:`通常在 package.json 里会有这样一行：
"scripts": { "dev": "vite"
} 当你执行 npm run dev 时，本质上是调用了 vite CLI（开发服务器）。它的执行流程是这样的： 读取配置 Vite 会读取 vite.config.ts 或 vite.config.js（如果有）。
同时识别项目入口（默认是 index.html）。 启动开发服务器 Vite 内置了一个基于 connect 的 dev server。
监听一个端口（默认 5173）。
输出类似 http://localhost:5173/ 的访问链接。 拦截浏览器请求 浏览器访问 http://localhost:5173/ 时，Vite 会返回 index.html。
当 index.html 里引用了 src/main.ts，Vite 就会动态编译这个文件，并以 ESM 模块的形式返回给浏览器。
如果 main.ts 又 import 了 Vue 组件，Vite 会继续即时编译这些 .vue 文件（通过 @vitejs/plugin-vue 插件）。 热更新 (HMR) Vite 内置 WebSocket 连接。
当文件修改时，Vite 只会重新编译变动的文件，并通过 HMR 更新浏览器里的模块，而不是整个页面刷新。
这就是为什么改一个组件页面能秒级看到变化。`},{header:"3. 为什么能直接访问 Vue3 代码",slug:"_3-为什么能直接访问-vue3-代码",content:`因为 Vite 把 Vue 文件和 TypeScript 等等转译成浏览器可运行的 ESM： .vue 文件 → 转成 JS 模块（render function + script）
.ts 文件 → 用 esbuild 转成 JS
依赖包（比如 vue）→ 预构建成单个 ESM（用 esbuild 优化） 所以浏览器收到的都是标准的 JS 模块，能直接运行。
✅ 总结： npm run dev 启动的是 Vite 的开发服务器。
Vite 的原理是 利用浏览器原生 ES Modules，做到即开即用、按需编译。
浏览器访问链接后，Vite 会按需编译并返回文件，同时通过 HMR 实现热更新。`},{header:"什么是ES Moudle？",slug:"什么是es-moudle",content:`关键点：ESM 模块。
npm run dev 之所以能让 Vue3 + Vite 立即跑起来，核心就在 ESM（ES Modules，原生模块化标准）。我给你拆一下：`},{header:"1. 什么是 ESM 模块",slug:"_1-什么是-esm-模块",content:`ESM 是 浏览器和 Node.js 官方支持的模块化规范，用 import / export 来组织代码。
例如：
// math.js
export function add(a, b) { return a + b
} // main.js
import { add } from './math.js'
console.log(add(2, 3)) 📌 关键点： 浏览器可以 原生识别 import（不用打包工具）
每个模块文件就是一个 独立作用域
按需加载，避免一次性打包成大文件`},{header:"2. Vite 为什么要用 ESM",slug:"_2-vite-为什么要用-esm",content:`Vite 在开发模式下，完全依赖浏览器的 ESM 特性： 你访问 http://localhost:5173/ 时，index.html 里会写：
<script type="module" src="/src/main.ts"><\/script> 浏览器看到 type="module"，就会去请求 /src/main.ts。 Vite 拦截这个请求： 如果是 .ts → 用 esbuild 转译成 JS
如果是 .vue → 用插件转成 JS 模块（render + script）
如果是依赖（如 vue）→ 提前 预构建 成 ESM（避免 node_modules 太多小文件导致请求过多） 浏览器再按需加载这些 JS 模块，形成一个 模块依赖树。 改一个文件，Vite 只需要重新编译这个文件，并通过 HMR 替换模块，而不是整个页面刷新。`},{header:"3. 为什么 ESM = Vite 极速开发体验",slug:"_3-为什么-esm-vite-极速开发体验",content:`不用一次性打包 → 启动极快
模块天然分割 → 修改一个模块时，只更新这个模块（HMR）
浏览器直接支持 → 少了一层构建的中间步骤 ✅ 总结：
Vite 的核心就是基于浏览器原生 ESM 模块，把每个 .vue、.ts、依赖都当作独立的 ESM 来处理。
这也是它比 Webpack/Gulp 那些工具快得多的根本原因。`},{header:"ES Modules 分类",slug:"es-modules-分类",content:`在 Vite 的 开发模式 下，最后所有代码都会变成 ES Modules (ESM)，再交给浏览器去执行。
不过这里要分三类情况来看：`},{header:"1. 你的源码（.vue、.ts、.js）",slug:"_1-你的源码-vue、-ts、-js",content:`.vue 文件 → 通过 @vitejs/plugin-vue 编译成 JS 模块：
// App.vue → 编译后
export default { render() { ... }, setup() { ... }
} .ts 文件 → 用 esbuild 转成 JS，再包装成 ESM：
// main.ts
import { createApp } from 'vue' → 转译后仍然是 import 语法，浏览器直接识别。 👉 最终：每个源码文件就是一个 独立的 ESM 模块。`},{header:"2. 依赖包（node_modules 里的第三方库）",slug:"_2-依赖包-node-modules-里的第三方库",content:`这里是 Vite 的一个 优化点： node_modules 里的库（例如 vue, lodash-es）有的不是 ESM 格式，而是 CommonJS 或 UMD。
Vite 会在启动时做依赖预构建（dependency pre-bundling），把这些库用 esbuild 转换成 ESM 格式。 比如 vue 最终会被处理成一个 ESM 文件放在：
node_modules/.vite/deps/vue.js 👉 所以即便原始库不是 ESM，Vite 也会先帮你“转译成 ESM”，保证浏览器能用。`},{header:"3. 最终效果",slug:"_3-最终效果",content:`开发模式下：
所有请求的文件（Vue/TS/依赖包）最后都是 ES Modules，浏览器原生加载。 生产模式下（vite build）：
Vite 会调用 Rollup，把所有模块打包、拆分优化（代码分块、Tree Shaking、压缩）。
最终线上跑的不是一堆 ESM 文件，而是构建后的 bundle，这样减少网络请求数、提升性能。 📌 总结一句话： 开发模式：所有 .vue、.ts、依赖包 → 全部转成 ESM，浏览器直接按需加载。
生产模式：Vite 会再把这些 ESM 模块交给 Rollup 打包优化，生成少量高效的产物。`},{header:'type="module"的作用',slug:"type-module-的作用",content:'好问题 👍，<script type="module"> 正是 Vite 能在浏览器里直接跑的关键。'},{header:"1. 背景",slug:"_1-背景",content:`在最早的浏览器里，JavaScript 只有 全局脚本：
<script src="main.js"><\/script> 所有变量、函数都挂在 window 上，容易冲突，也没办法分模块管理。
后来有了各种 模块化方案： CommonJS（Node.js 用的 require()）
AMD/UMD（浏览器异步模块加载）
但这些都是“约定俗成”，浏览器并不原生支持。 直到 ESM（ECMAScript Modules） 标准推出，浏览器原生支持 import/export，才有了今天的 <script type="module">。`},{header:'2. type="module" 的作用',slug:"_2-type-module-的作用",content:`当你写：
<script type="module" src="/src/main.js"><\/script> 它和普通 <script> 有这些区别：`},{header:"✅ 支持 ESM 语法",slug:"✅-支持-esm-语法",content:`可以在浏览器里直接写：
import { createApp } from 'vue'
import App from './App.vue' createApp(App).mount('#app') 浏览器会自动去请求并执行这些模块。`},{header:"✅ 默认是 延迟加载 (defer)",slug:"✅-默认是-延迟加载-defer",content:`等 DOM 解析完再执行，避免阻塞页面加载。
（普通 <script> 会阻塞解析）`},{header:"✅ 每个模块有自己的作用域",slug:"✅-每个模块有自己的作用域",content:`不会像普通 <script> 那样污染全局变量。
模块之间通过 import/export 明确依赖关系。`},{header:"✅ 自动开启严格模式 (use strict)",slug:"✅-自动开启严格模式-use-strict",content:"提升代码安全性，比如不能随便用未声明的变量。"},{header:"✅ 可以加载远程模块",slug:"✅-可以加载远程模块",content:`甚至可以直接写 CDN 地址：
<script type="module"> import _ from "https://cdn.skypack.dev/lodash-es" console.log(_.join(["Hello", "Vite"], " "))
<\/script> （这也是 Vite 为什么可以直接利用浏览器的能力。）`},{header:"3. 在 Vite 里的意义",slug:"_3-在-vite-里的意义",content:`当 Vite 返回 index.html 时，它会自动插入：
<script type="module" src="/src/main.ts"><\/script> 👉 浏览器一看到 type="module" 就会触发 原生 ESM 加载流程： 请求 /src/main.ts
里面 import App from './App.vue'
浏览器继续请求 /src/App.vue（Vite 会在后台把它编译成 ESM） 最终整个 Vue 项目就跑起来了。
✅ 一句话总结：
type="module" 的作用是告诉浏览器： 这个脚本是一个 ESM 模块，请按模块化规则加载（支持 import/export、作用域隔离、延迟执行）。`},{header:"关于connect",slug:"关于connect",content:`https://github.com/senchalabs/connect
connect是一个 Node.js 里的 HTTP 中间件框架。`},{header:"1. 什么是 connect",slug:"_1-什么是-connect",content:`connect 是一个非常轻量的 Node.js 库，用来快速创建 HTTP 服务器。
它本质上是基于 Node.js 的 http 模块，在其上增加了 中间件机制。
Express（很流行的 Node 框架）就是在 connect 的基础上扩展出来的。 简单示例：
import connect from 'connect'
import http from 'http' const app = connect() // 注册中间件
app.use((req, res, next) => { console.log('Request URL:', req.url) next()
}) app.use((req, res) => { res.end('Hello from Connect server')
}) // 启动 HTTP 服务
http.createServer(app).listen(3000, () => { console.log('Server running at http://localhost:3000')
}) 运行后，你就有了一个 http://localhost:3000 的服务。`},{header:"2. Vite 为什么用 connect",slug:"_2-vite-为什么用-connect",content:`当你执行 npm run dev 启动 Vite 开发服务器时： Vite 底层会创建一个 connect 应用 然后注册各种中间件，例如： 处理静态文件请求（返回 index.html、图片、CSS 等）
处理 ESM 请求（拦截 .vue、.ts 转译成 JS）
HMR WebSocket 通信 最终由 Node.js 内置的 http 模块把这个服务跑起来 所以你能在浏览器访问 http://localhost:5173，但真正的服务是 Node.js + connect 起的。`},{header:"3. 总结",slug:"_3-总结",content:`connect 是 Node.js 里的 HTTP 框架，不是浏览器的。
它给 Vite 提供了一个可扩展的 中间件体系。
浏览器只是作为客户端，请求 Vite 用 connect 起的本地服务。这个是重点，只负责启动一个本地服务。`}]},{path:"/content/front/js/vue3%E5%85%B3%E4%BA%8Ewatch%E5%92%8CwatchEffect%E7%9A%84%E4%B8%8D%E5%90%8C.html",title:"vue3关于watch和watchEffect的不同",pathLocale:"/",contents:[{header:"vue3关于watch和watchEffect的不同",slug:"vue3关于watch和watcheffect的不同",content:`最近在检查代码的时候，发现有人使用watchEffect，导致县把灌木有一些奇怪的问题，如下:
watchEffect(() => { if (selectedRoleItem.value && roles.value.length) { fetchTableData(); }
}); 分析:
watchEffect：
watchEffect 是 Vue 3 中用于响应式数据变化的 API。当其依赖的响应式数据发生变化时，传入的函数会被重新执行。在这个例子中，watchEffect 会观察 selectedRoleItem.value 和 roles.value 的变化。 selectedRoleItem.value：
这是一个响应式的引用变量（可能是通过 ref 或 reactive 创建的）。selectedRoleItem.value 会是某个选中的角色项，可能是从角色列表中选择的当前角色。 roles.value.length：
这是另一个响应式数据，代表角色列表的长度。它检查当前角色列表中是否有角色。 fetchTableData()：
这是在条件满足时调用的一个函数。fetchTableData 很可能是一个异步函数，用于获取与当前选中的角色相关的表格数据。它在 selectedRoleItem.value 有值且 roles.value 数组非空时被触发。 逻辑:
这段代码的核心逻辑是：当 selectedRoleItem 选择了一个角色且 roles 列表非空时，会触发 fetchTableData() 函数来加载表格数据。
依赖项：watchEffect 会在 selectedRoleItem.value 和 roles.value 的值发生变化时重新执行。如果 selectedRoleItem 发生变化，或者 roles 数组的长度变化，watchEffect 会重新执行其内部函数。 问题:
当我点击页面上的跳转按钮的时候，调到其它页面，watchEffect里的当法仍然会被调用，导致错误的请求 原因分析:
watchEffect 是一个自动依赖收集的工具。它会监视所有在它内部访问的响应式数据。这个特性意味着，如果在页面跳转后，selectedRoleItem 或 roles 的值发生变化，即便页面内容已经更新，它也会再次执行 fetchTableData()。`},{header:"解决办法,使用watch",slug:"解决办法-使用watch",content:`当使用 watch 时，可以显式地指定你关注的依赖数据，并且 只在这些数据变化时执行 特定的副作用（比如 fetchTableData()）。这样，只有当你显式传入的响应式数据发生变化时，fetchTableData() 才会被调用，避免了页面跳转后不必要的调用。 watch([selectedRoleItem, roles], ([currentRole, availableRoles]) => { if (currentRole && availableRoles.length) { fetchTableData(); }
});`},{header:"watchEffect vs watch",slug:"watcheffect-vs-watch",content:`自动依赖收集 vs 显式依赖声明：
watchEffect 会自动追踪其内部访问的所有响应式数据，并在这些数据发生变化时重新执行。它不需要显式声明需要观察的依赖，Vue 会自动帮你做。
watch 需要你显式声明依赖的变量，只有在这些变量发生变化时，watch 才会触发回调。 触发时机：
watchEffect 会在组件初始化时立即执行一次，然后随着依赖变化重新执行。这意味着它是即时响应依赖变化的。
watch 默认不会立即执行，除非你显式设置了 immediate: true，它会等待监听的值变化才执行回调。 回到你的问题：
在你使用 watchEffect 时，你并没有显式声明需要监控的变量，而是让 watchEffect 自动依赖 selectedRoleItem 和 roles。当其中一个发生变化时，watchEffect 会自动触发并调用 fetchTableData()。
但如果页面跳转时，你发现 fetchTableData() 被多次调用，这很可能是由于 watchEffect 会监控到 selectedRoleItem 或 roles 的任何变化，甚至是页面的重新渲染，也会触发不必要的调用。即便页面的 selectedRoleItem 或 roles 发生了变化，它也会重新触发副作用。 为什么 watch 更适合你的需求：
watch 允许你显式指定依赖项，并且你可以控制何时触发副作用。通过比较新旧值，你可以避免页面跳转时的重复请求（如果不需要），并且能更精确地控制哪些变量变化时需要执行回调。`},{header:"使用watch的优点",slug:"使用watch的优点",content:`精确控制触发条件：通过明确判断 newRole 和 newRoles.length，可以确保只有在这两个值都有效时才执行数据加载。这可以避免在无效或空数据的情况下发起不必要的请求。
自动依赖更新：由于使用了 watch，它会自动跟踪 selectedRoleItem 和 roles 的变化，确保在这两个变量变化时及时触发回调。
多依赖项的监控：watch 可以接受一个数组作为第一个参数，表示对多个变量进行监听，确保在多个响应式数据变化时都有适当的反应。`},{header:"watchEffect 最适合的场景是：",slug:"watcheffect-最适合的场景是",content:`自动依赖收集：当你不想显式声明要监控的响应式数据，只想让它自动跟踪并在数据变化时执行副作用。
简化副作用管理：适合简单的副作用，尤其是当你不关心数据变化的具体顺序时。
快速开发：在快速开发和原型阶段，watchEffect 提供了一个简洁的方式来处理响应式数据变化引起的副作用。`},{header:"watchEffect返回值：",slug:"watcheffect返回值",content:`const stop = watchEffect(() => {})
const { stop, pause, resume } = watchEffect(() => {}) (3.5之后才有的,之前就是一个stop) 参考链接:https://vuejs.org/api/reactivity-core.html#watcheffect`}]},{path:"/content/front/js/vue3%E5%87%A0%E7%A7%8Dfor%E5%BE%AA%E7%8E%AF%E5%AF%B9%E6%AF%94.html",title:"vue3几种for循环对比",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3几种for循环对比: vue3 对数据列表循环,修改指定下标的值
1>forEach循环
const setItemsInactive = (index: number) => { list.value.forEach((item, idx) => { if (idx !== index) { item.isActive = false; } });
}; 2>for...of循环
const showSectionAction = (index: number) => { for (const [idx, item] of ticketList.value.entries()) { if (idx !== index) { item.showAction = false; } } ticketList.value[index].showAction = !ticketList.value[index].showAction;
};`},{header:"forEach 和 for...of 的对比",slug:"foreach-和-for-of-的对比",content:`forEach 简洁性：在需要遍历每个元素并访问索引的情况下，forEach 确实更简洁，不需要解构。
for...of 的灵活性：在某些场景下，for...of 提供了更多控制流的灵活性。比如，可以在循环中使用 break 和 continue，而 forEach 不支持这些控制流操作（如果需要提前退出循环时，for...of 更方便）。`},{header:"选择的建议",slug:"选择的建议",content:`如果遍历逻辑简单而且不涉及复杂的控制流（如提前退出），forEach 是非常好的选择。您可以放心地使用 forEach，除非项目的 lint 或格式化工具有特定的要求。
3>经典的for循环
for(let i = 0; i < list.value.length;i++){
//逻辑
}
原生 for 循环可以避免迭代器创建（如 forEach 或 for...of 循环），在处理大量数据时性能稍有提升，特别适合对性能要求高的项目。 4>for...in循环
适用于：主要用于遍历对象的可枚举属性，不推荐用于数组，因为它遍历的是属性名而不是数组值。
特性：遍历对象的键（属性名），可用于对象的动态属性操作。
局限性：for...in 会遍历对象原型链上的所有可枚举属性（除非使用 hasOwnProperty 进行检查），可能带来意外结果。
const obj = { a: 1, b: 2, c: 3 };
for (const key in obj) { if (obj.hasOwnProperty(key)) { // 逻辑 }
} 总结:
选择建议
数组遍历：优先考虑 forEach 或 for...of，尤其是在写法简洁性和可读性更重要的情况下。
复杂控制流：当需要在循环中提前退出或跳过某些元素时，for...of 更合适。
对象遍历：如果是普通对象，推荐使用 for...in 或 Object.keys 结合 forEach。
性能和灵活性：在高性能要求的场景下，传统的 for 循环（for (let i = 0; i < length; i++)）依然是一个非常好的选择。`}]},{path:"/content/front/js/vue3%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%85%83%E7%B4%A0%E5%AE%BD%E5%BA%A6.html",title:"vue3动态计算元素宽度",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要动态计算元素的css属性，比如说 margin width 等
可以按下面的方式做
<div :style="'width:'+ num * 3.4 +'%;'"></div> <div :style="'width:'+ (100 - num * 3.4) +'%;'"></div> 还有就是配合 calc()，动态计算`}]},{path:"/content/front/js/vue3%E5%AE%9A%E4%B9%89slot.html",title:"vue3定义slot",pathLocale:"/",contents:[{header:"vue3定义slot",slug:"vue3定义slot",content:`defineSlots<{ label?: () => string; labelText?: () => string; default?: () => string;
}>();
不合理(虽然可以运行)，应该是
defineSlots<{ label?: () => VNode; labelText?: () => VNode; default?: () => VNode;
}>(); slot的返回值最好是VNode，而不是其它，因为最后slot总是被渲染的`}]},{path:"/content/front/js/vue3%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%B1%9E%E6%80%A7%E4%BB%A3%E7%90%86.html",title:"vue3定义一个属性代理",pathLocale:"/",contents:[{header:"vue3定义一个属性代理",slug:"vue3定义一个属性代理",content:`有如下定义:
type ContributionType = { id: number; name: string; isChecked: boolean;
}; export class FakeContributionType { readonly id: number; readonly name: string; readonly binding: { get: () => boolean; set: (value: boolean) => void; }; constructor({ id, name, binding, }: Omit<ContributionType, "isChecked"> & { binding: { get: () => boolean; set: (value: boolean) => void; }; }) { this.id = id; this.name = name; this.binding = binding; } get isChecked() { return this.binding.get(); } set isChecked(value: boolean) { this.binding.set(value); }
} 例子:
const checkboxBinding = { get: () => someReactiveStore[id], set: (val: boolean) => (someReactiveStore[id] = val),
}; const item = new FakeContributionType({ id: 1, name: "Contributor", binding: checkboxBinding,
}); console.log(item.isChecked); // 实际调用 checkboxBinding.get()
item.isChecked = true; // 实际调用 checkboxBinding.set(true) 这个类的作用：
解耦：让 isChecked 不直接依赖原始模型，而是通过传入的 binding 控制；
灵活：可以连接到任意状态管理（如 Vue 的 ref、React 的 useState 等）；
结构清晰：使用 getter/setter 显得像普通属性，但内部实际上是绑定逻辑 实际使用:
//test.vue
<script setup lang="ts">
definePageMeta({ middleware: ["authentication", "dashboard"], permission: "event_overview_access",
}); const checkboxStatus = ref(true); const fakeStatus = new FakeContributionType({ id: -1, name: "Oral", binding: { get: () => checkboxStatus.value, set: (value: boolean) => { checkboxStatus.value = value; }, },
}); // 注意不要使用 click 事件，因为 click不能在数据修改之后触发，而是在数据修改前触发
const change = () => { console.log("fakeStatus.value is:", fakeStatus.isChecked);
}
<\/script> <template> <div>Event Overview</div> <input type="checkbox" v-model="fakeStatus.isChecked" @change="change" />
</template> 将 fakeStatus 的 isChecked 属性 代理到了 checkboxStatus.value 上。
所以当访问：
fakeStatus.isChecked
它实际上等价于：
checkboxStatus.value 同样，当赋值：
fakeStatus.isChecked = true
它会触发：
checkboxStatus.value = true 更复杂的逻辑
//test.vue
<script setup lang="ts">
const age = ref(17);
const agreed = ref(false); const isEligible = new FakeContributionType({ id: -6, name: "Eligibility", binding: { get: () => agreed.value && age.value >= 18, set: (value: boolean) => { if (!value) { agreed.value = false; } else { if (age.value >= 18) { agreed.value = true; } else { alert("You must be at least 18 to agree."); } } }, },
}); const click = () => { isEligible.isChecked = true;// 会触发 You must be at least 18 to agree.
} <\/script> <template> <div>Event Overview</div> <button @click="click">修改</button>
</template>`}]},{path:"/content/front/js/vue3%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%8C%87%E4%BB%A4.html",title:"vue3定义一个指令",pathLocale:"/",contents:[{header:"vue3定义一个指令",slug:"vue3定义一个指令",content:`// 使用vue3定义一个 dompurify 指令 utils/directives/dompurify-html.ts
import type { App, Plugin } from "vue";
import { buildVueDompurifyHTMLDirective } from "vue-dompurify-html"; export const vDompurifyHtml = buildVueDompurifyHTMLDirective({ namedConfigurations: { removeClasses: { FORBID_ATTR: ["class", "className"], }, },
}); export const dompurifyHtmlPlugin: Plugin = { install(app: App) { app.directive("dompurify-html", vDompurifyHtml); },
}; // 在Nuxt3下作为插件引入
export default defineNuxtPlugin((nuxtApp) => { nuxtApp.vueApp.directive('dompurify-html', vDompurifyHtml)
}) export default defineNuxtPlugin((nuxtApp) => { nuxtApp.vueApp.use(dompurifyHtmlPlugin)
}) //传统应用中
import { createApp } from "vue";
import App from "./App.vue";
import { dompurifyHtmlPlugin } from "./path-to-plugin"; const app = createApp(App);
app.use(dompurifyHtmlPlugin);
app.mount("#app");
\`\`\``}]},{path:"/content/front/js/vue3%E5%AF%8C%E6%96%87%E6%9C%AC%E6%B8%B2%E6%9F%93%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98.html",title:"vue3富文本渲染安全问题",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3富文本渲染安全问题:
默认可以使用v-html渲染html，但是这个有xss安全问题，解决办法是使用
https://github.com/LeSuisse/vue-dompurify-html
基于 DOMPurify 包 包，这个包可以解决xss安全问题`}]},{path:"/content/front/js/vue3%E6%94%AF%E6%8C%81%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8usetemplateref%E6%9D%A5%E5%BC%95%E7%94%A8ref.html",title:"vue3支持组件使用usetemplateref来引用ref",pathLocale:"/",contents:[{header:"vue3.5支持组件使用 usetemplateref 来引用 ref",slug:"vue3-5支持组件使用-usetemplateref-来引用-ref",content:`https://vuejs.org/api/composition-api-helpers.html#usetemplateref
如:
<script setup>
import { useTemplateRef, onMounted } from 'vue' const inputRef = useTemplateRef('input') onMounted(() => { inputRef.value.focus()
})
<\/script> <template> <input ref="input" />
</template> 之前使用的是:
import { ref, onMounted } from 'vue';
const containerRef = ref<HTMLElement | null>(null); <div ref="containerRef"></div>`}]},{path:"/content/front/js/vue3%E6%95%B0%E7%BB%84%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"vue3数组引用传递的问题",pathLocale:"/",contents:[{header:"vue3数组引用传递的问题",slug:"vue3数组引用传递的问题",content:`//如下定义了一个ref类型的数组:
const selectedData = ref<number[]>([6, 7, 8, 9]); const modifySelectedData = (data: Ref<number[]>) => { data.value.splice(1, 1); // 修改了传入的 Ref 数组，删除一个元素
}; modifySelectedData(selectedData); console.log(selectedData.value); // 结果是 [6, 8, 9]`},{header:"如何解决副作用",slug:"如何解决副作用",content:`const modifySelectedData = (data: Ref<number[]>) => { const copiedData = [...data.value]; // 创建副本 copiedData.splice(1, 1); // 修改副本 console.log(copiedData); // 修改后的副本
}; const selectedData = ref<number[]>([6, 7, 8, 9]); modifySelectedData(selectedData); console.log(selectedData.value); // 原始数据未被修改 [6, 7, 8, 9]
const modifySelectedData = (data: Ref<number[]>) => { const copiedData = [...data.value]; // 创建副本，可以通过传递副本来避免这种副作用 copiedData.splice(1, 1); // 修改副本 console.log(copiedData); // 修改后的副本
}; const selectedData = ref<number[]>([6, 7, 8, 9]); modifySelectedData(selectedData); console.log(selectedData.value); // 原始数据未被修改 [6, 7, 8, 9]`}]},{path:"/content/front/js/vue3%E7%88%B6%E7%BB%84%E4%BB%B6%E8%B0%83%E7%94%A8%E5%AD%90%E7%BB%84%E4%BB%B6%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95.html",title:"vue3父组件调用子组件中的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3父组件调用子组件中的方法:
我在子组件里定义的 const someMethod = () => {} 可以被调用吗
在组合式API中,如果在子组件中仅仅是定义了一个常量或方法 const someMethod = () => {}，那么该方法是无法被父组件直接调用的。
这是因为在组合式API中，子组件需要通过 defineExpose 主动暴露出需要给外部访问的属性或方法。如果没有使用 defineExpose，那么子组件内部定义的常量、方法等都是私有的，外部无法直接访问。
所以，为了让父组件可以调用子组件中定义的方法，你需要在子组件中这样做： <script setup>
const someMethod = () => { console.log('Child method called')
} // 使用defineExpose将someMethod暴露给外部
defineExpose({ someMethod
})
<\/script> 在上面的代码中，我们使用了 defineExpose 函数，将 someMethod 方法暴露给了外部。这样，父组件就可以通过模板ref或者渲染器refs来调用该方法了。
如果子组件中有多个需要暴露给外部的属性或方法，可以将它们作为对象的属性传递给 defineExpose：
defineExpose({ someMethod, someData, ...
}) Vue3组合式API 父组件调用子组件的方法:
<template> <child-component ref="childComponent" /> <button @click="callChildMethod">Call Child Method</button>
</template> <script setup>
import ChildComponent from './ChildComponent.vue'
import { ref, onMounted } from 'vue' const childComponent = ref(null) const callChildMethod = () => { childComponent.value.someMethod()
} onMounted(() => { // 在mounted钩子中,childComponent.value已经是子组件的实例 console.log(childComponent.value)
})
<\/script>`}]},{path:"/content/front/js/vue3%E7%88%B6%E7%BB%84%E4%BB%B6%E9%80%9A%E8%BF%87%E7%BB%84%E5%90%88%E5%BC%8FAPI%E8%B0%83%E7%94%A8%E5%AD%90%E7%BB%84%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95.html",title:"vue3父组件通过组合式API调用子组件的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3父组件通过组合式API调用子组件的方法:
<!-- 父组件 app.vue -->
<template> <div class="itxst"> <!-- 使用 ref 指令关联子组件 --> <child ref="childComp"/> <button @click="onTry">点击试一试</button> </div>
</template>
<script setup>
import { reactive, ref } from "vue";
import child from "./child.vue";
//定义子组件实例，名称要和上面的ref相同，这个很重要
const childComp = ref(null); //访问demo组件的方法或对象
const onTry = () => { //获取到子组件的 title 数据 let msg = childComp.value.state.title; //调用子组件的 play方法 childComp.value.play();
};
<\/script> <!--子组件名称 child.vue -->
<template> <div class="itxst"> {{ state.title }} </div>
</template>
<script setup>
import { ref, reactive } from "vue";
//定义一个变量
const state = reactive({ title: "www.itxst.com",
});
//定义一个方法
const play = () => { state.title = "你调用了子组件的方法";
}; //暴露state和play方法，下面这种方法用的不多，一般都是defineProps()
defineExpose({ state, play,
});
<\/script> 传统的(vue2)语法:
<!-- 父组件 app.vue -->
<template> <div class="itxst"> <!-- 使用 ref 命令 --> <child ref="childComp"/> <button @click="onClick">点击试一试</button> </div>
</template>
<script >
import child from "./child.vue";
export default { name: "app", //注册组件 components: { child, }, methods: { onClick: function () { //获取到 子组件的 数据 let msg = this.$refs.childComp.message; //执行了子组件的 play方法 this.$refs.childComp.play(); }, },
};
<\/script> <!-- 子组件 child.vue -->
<template> <div class="itxst"> {{ title }} </div>
</template>
<script>
//选项式默认当前实例是全部暴露
export default { name: "demo", //默认全部暴露 也可以通过expose控制那些需要暴露 //expose: ['play'], data() { return { title: "www.itxst.com", }; }, methods: { play: function () { this.title = "你调用了子组件的方法"; }, },
};
<\/script>`}]},{path:"/content/front/js/vue3%E7%9A%84slot%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"vue3的slot调用的两种方式",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3的slot调用的两种方式
先定义一个组件 UserCenter：
<template> <div class="user-center-wrapper"> <!-- slot --> <slot name="user_wrapper"></slot> </div>
</template> 调用这个组件:
<template> <div > //other code ... </div> <UserCenter> <!-- 调用方式1 --> <template #user_wrapper> <div class="img-box"> <img class="person abs-center" src="~/assets/img/profile-person.svg" alt=""> </div> </template> </UserCenter>
</template> <template> <div > //other code ... </div> <UserCenter> <!-- 调用方式2 --> <template v-slot:user_wrapper> <div class="img-box"> <img class="person abs-center" src="~/assets/img/profile-person.svg" alt=""> </div> </template> </UserCenter>
</template>`}]},{path:"/content/front/js/vue3%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7.html",title:"vue3组件使用技巧",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3组件使用技巧:
//有如下自组件，假如为 Child.vue
withDefaults( defineProps<{ isOverflowVisible?: boolean; }>(), { isOverflowVisible: false, }
); <TModal v-model="isModalVisible" :max-width class="app-modal [&_.m-modal\\_\\_panel]:gap-md" :class="{ 'app-modal--visible': isOverflowVisible, }" :hide-close-icon :persistent > ... ... </TModal> <style lang="scss"> .app-modal { &--visible { .m-modal__panel { @apply overflow-visible; } } }
</style> //父组件使用
<template> <Child is-overflow-visible> </Child> </template> 这里直接使用 is-overflow-visible， 而没有定义相关的变量(比如定义一个 isOverflowVisible, 用来赋值， 类似 :is-overflow-visible=isOverflowVisible)，这样的话子组件里的 isOverflowVisible 会渲染为 true, 这是一个很有用的细节，对于一个 bool 类型的 prop，如果父组件没有通过属性赋值，那么会被熏染为 true. 上面的例子还有一个细节，就是:
:class="{ 'app-modal--visible': isOverflowVisible, }" 这个主要是动态加载 app-modal--visible 这个类，注意命名，有个前缀 app-modal, 后面是 --visible, 这种风格的命名，有个好处是，在scss文件里，可以实现样式嵌套，如下: <style lang="scss"> .app-modal { &--visible {// 这里虽然有两级，但是实际上还是改的父级样式, 这个主要是用于动态修改同级元素的样式的时候； 也可以用于子元素， 当子元素也以相同的前缀开始的话，在样式里就可以直接使用过 & 开头定义样式 .m-modal__panel { @apply overflow-visible; } } }
</style>`}]},{path:"/content/front/js/vue3%E7%BB%84%E5%90%88%E5%BC%8FAPI%E4%B8%8B%E4%BD%BF%E7%94%A8watch.html",title:"vue3组合式API下使用watch",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3组合式API下使用watch:
let router = useRouter() // 监听当前路由变化 watch( () => router.currentRoute.value, () => { console.log("路由变化了") } ); 还有一个注意点:
vue3的watch细节:
watch( () => props.isOverflowVisible, (val) => { console.log("props is:", val) }, { immediate: true }
)
这种写法有以下几点需要注意： 我们使用了一个函数 () => props.isOverflowVisible 来返回要监视的值，而不是直接传递 props.isOverflowVisible。这是因为在组合式 API 中，我们需要使用函数来访问 reactive 对象的属性。
第二个参数是回调函数，它会在监视的值变化时被调用。
第三个参数是一个选项对象，我们在这里设置 immediate: true。 使用这种方式，watch 将会在组件挂载时立即执行一次，输出当前的 isOverflowVisible 值，然后在每次 isOverflowVisible 改变时再次执行。
这对于调试很有用，可以让你立即看到初始值，而不需要等待值的第一次变化。它也适用于那些你需要基于 prop 的初始值执行某些操作的场景。`}]},{path:"/content/front/js/vue3%E8%87%AA%E5%AE%9A%E4%B9%89modal%E7%AA%97%E5%8F%A3.html",title:"vue3自定义modal窗口",pathLocale:"/",contents:[{header:"",slug:"",content:"wait ..."}]},{path:"/content/front/js/vue3%E8%87%AA%E9%80%82%E5%BA%94%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%A9%E6%94%BE%E7%99%BE%E5%88%86%E6%AF%94.html",title:"vue3自适应浏览器缩放百分比",pathLocale:"/",contents:[{header:"",slug:"",content:`在实际项目开发过程中，如果做了div约束或者自适应的话，页面的缩放可能没有问题，但是直接设置为100%的话，页面缩放可能就有问题了
解决办法就是，实时计算页面缩放的百分比，然后将当前div的宽度设置为对应的百分比，代码如下: <template>
<div class="course-list-wrapper" :style="{'width': courseListWidth}" id="course-list">
</template> <script>
export default { data(){ return { courseListWidth: '100%' } }, mounted() { this.windowZoom(); window.onresize = () => { return (() => { this.windowZoom() })() }; }, methods:{ windowZoom (){ let ratio = 1, screen = window.screen, ua = navigator.userAgent.toLowerCase(); if (window.devicePixelRatio !== undefined) { ratio = window.devicePixelRatio; }else if (~ua.indexOf('msie')) { if (screen.deviceXDPI && screen.logicalXDPI) { ratio = screen.deviceXDPI / screen.logicalXDPI; } }else if (window.outerWidth !== undefined && window.innerWidth !== undefined) { ratio = window.outerWidth / window.innerWidth; } if (ratio){ ratio = Math.round(ratio * 100); } this.courseListWidth = ratio+'%'; } }
}
<\/script> 关于 window.devicePixelRatio Window接口的devicePixelRatio返回当前显示设备的物理像素分辨率与CSS像素分辨率的比率。 这个值也可以理解为像素大小的比率：一个CSS像素的大小与一个物理像素的大小。更简单地说，这告诉浏览器应该用多少屏幕上的实际像素来绘制一个CSS像素。 这在处理标准显示器与HiDPI或Retina显示器的渲染差异时非常有用，后者使用更多的屏幕像素来绘制相同的对象，从而使图像更清晰。`}]},{path:"/content/front/js/vue3%E8%8E%B7%E5%8F%96%E7%BB%84%E4%BB%B6%E7%9A%84%E5%B1%9E%E6%80%A7.html",title:"vue3获取组件的属性",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3获取组件的属性:
主要通过这个包实现:
npm i vue-component-type-helpers npm地址:https://www.npmjs.com/package/vue-component-type-helpers
官方介绍:Some very simple type helpers used behind vue-component-meta for extract component props, slots, emit, exposed types.
这个包很实用，抓哟可以用老获取组件的props, slots, emit, exposed types，很牛逼 官网例子:
//组件HelloWorld.vue
<template> <slot name="header" :num="123" /> <slot name="footer" str="abc" />
</template> <script lang="ts" setup>
defineProps<{ msg: string
}>()
<\/script> //使用
import HelloWorld from './HelloWorld.vue'
import type { ComponentProps, ComponentSlots } from 'vue-component-type-helpers' type Props = ComponentProps<typeof HelloWorld> // { msg: string }
type Slots = ComponentSlots<typeof HelloWorld> // { header(_: { num: number; }): any; footer(_: { str: string; }): any; } 实际使用:
import type AppStepper from "~/components/app/stepper/AppStepper.vue";
import type { ComponentProps } from 'vue-component-type-helpers' const steps: ComponentProps<typeof AppStepper>["steps"] = [
{ label: "Tickets", value: "tickets", route: { name: "events-id-event-settings-registration-tickets", params: route.params, }, }, { label: "Add-ons", value: "addons", route: { name: "events-id-event-settings-registration-addons", params: route.params, }, },
]; 其它vue工具:
https://github.com/vuejs/language-tools`}]},{path:"/content/front/js/vue3%E8%A3%81%E5%89%AA%E7%BB%84%E4%BB%B6.html",title:"vue3裁剪组件",pathLocale:"/",contents:[{header:"",slug:"",content:`vue-advanced-cropper 裁剪组件的使用:
// 其中需要的样式，我做了全局导入，当然直接在当前不额页面直接 import 'vue-advanced-cropper/dist/style.css'; 也是可以的
// 这两个组件 CircleStencil, RectangleStencil 主要用来设置 stencil-component 的，主要设置矩形裁剪还是圆形裁剪，默认是 RectangleStencil
// :stencil-props 用于设置在不同裁剪类型下的属性，分别参考
// https://advanced-cropper.github.io/vue-advanced-cropper/components/rectangle-stencil.html#props 和 https://advanced-cropper.github.io/vue-advanced-cropper/components/circle-stencil.html#props
// 还可以通过 backgroundClass 设置背景样式类 <script setup lang="ts">
import { MModal, MButton
} from "@mdpi-ui/design-system";
import {Cropper, CircleStencil, RectangleStencil} from 'vue-advanced-cropper'; interface Props { src: string, isCropperVisible: boolean
}
withDefaults(defineProps<Props>(), { src: "", isCropperVisible: false
})
const emit = defineEmits<{ cancel: void, save: string
}>() const cropper = ref<Cropper | null>(null)
const hint = ref("")
const cancel = () => { hint.value = "" emit('cancel')
}
const saveCropper = () => { hint.value = "" const { canvas } = cropper.value.getResult(); if (canvas) { const form = new FormData(); const timestamp = new Date().getTime(); const filename = \`\${timestamp}.png\`; canvas.toBlob(async blob => { form.append('file', blob, filename); let img = new Image(); img.src = URL.createObjectURL(blob) img.onload = function () { let width = img.width let height = img.height console.log("img is:", width, '----',height) if (width < 1200){ hint.value = "Images should be at least 1200px wide" }else { hint.value = "" } if (hint.value){ return } console.log("form is:", form.get('file')) setTimeout(function (){ hint.value = "Server error" }, 2000) // after save success, return src to parent // emit("save", "xxxxxxx.png") } }) }
}
<\/script>
<template> <MModal :model-value="isCropperVisible" :hideCloseIcon="true" maxWidth="90rem" > <template #header> <div class="flex justify-center"> Customize your image </div> </template> <template #body> <Cropper ref="cropper" :src="src" :stencil-component="RectangleStencil" :stencil-props="{aspectRatio: 3}" backgroundClass="background" /> <div v-if="hint" class="my-2 font-normal text-sm"> {{ hint }} </div> <div class="flex justify-end gap-4 mt-6"> <MButton variant="secondary" @click="cancel()" class="md:!w-[8.4375rem]" > Cancel </MButton> <MButton variant="primary" @click="saveCropper" class="md:!w-[12.3125rem]" > Create </MButton> </div> </template> </MModal>
</template> cropper组件文档:https://advanced-cropper.github.io/vue-advanced-cropper/components/cropper.html#props 补充:
//cropper固定圆大小:
:stencil-size="{ width: 100, height: 100, }" //限制最小裁剪宽度和高度
:min-width="200"
:min-height="200" //下面是这个是一个官方的滚动条的例子
https://advanced-cropper.github.io/vue-advanced-cropper/guides/showcase.html#twitter`}]},{path:"/content/front/js/vue3%E9%80%9A%E8%BF%87ts%E8%AF%AD%E6%B3%95%E4%BD%BF%E7%94%A8%E7%BB%84%E5%90%88%E5%BC%8FAPI%E5%AE%9A%E4%B9%89props%E7%9A%84%E6%97%B6%E5%80%99%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC%E7%9A%84%E6%96%B9%E6%B3%95.html",title:"vue3通过ts语法使用组合式API定义props的时候设置默认值的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3通过ts语法使用组合式API定义props的时候,设置默认值的方法：
export interface Props { msg: string labels: string[]
} const props = withDefaults(defineProps<Props>(), { msg: 'hello', //简单类型直接赋值 labels: () => ['one', 'two'] //由于是数组，所以可以直接这样赋值， 也可以通过匿名函数返回 ['one', 'two']
}) //先定义MessageObj.ts
export interface MessageObj{ variant: string, message: string
} //使用
interface MyComponentProps { modelValue: boolean; toastObj: MessageObj; timeOut: number;
} const props = withDefaults(defineProps<MyComponentProps>(), { timeOut: 1500,//简单类型直接赋值 modelValue: false,//简单类型直接赋值 toastObj: () => { // 这里需要通过匿名函数的形式返回数据 return { variant: 'accent', message: '请求成功' } }
}); //错误使用代码
const props = withDefaults(defineProps<MyComponentProps>(), { timeOut: 1500,//简单类型直接赋值 modelValue: false,//简单类型直接赋值 toastObj: { // 这样是错误用法，我开始一直想这么用，但是一直报错，后来通过官网才找到解决办法，因为 defineProps 返回的是一个readonly类型的数据，不知道为什么，对于复杂类型，不能这么用，但是普通数据类型是可以的 variant: 'accent', message: '请求成功' }
}); 总结就是:普通的数据类型，可以直接赋值，比如 bool string 等，对于复杂类型需要通过匿名函数返回，但是所有的类型都是可以通过匿名函数返回数据的. 完整解释:
在这里，defineProps<MyComponentProps>() 返回一个包含了你定义的组件属性的只读属性对象。然后，withDefaults 函数被用来为这些属性提供默认值。 关于 timeOut 和 modelValue，它们的默认值被设置为简单类型（1500 和 false），这是因为这些属性的默认值可以直接使用，而不会触发 TypeScript 的只读属性错误。你可以直接在属性对象上设置简单类型的默认值，这是 TypeScript 允许的。 关于 toastObj，这是一个对象类型，你想为它提供默认值。但是，由于 TypeScript 的只读属性特性，如果你直接在对象中提供默认值，TypeScript 会认为这个对象是只读的，而不能被修改。 为了绕开这个问题，你使用了一个匿名函数 () => {...} 来延迟 toastObj 的创建。这样，这个函数会在需要 toastObj 的默认值时被调用，生成一个新的对象。这个新对象并不是定义时的只读属性对象的一部分，因此不会触发 TypeScript 的只读属性错误。实际上，你是在运行时生成了 toastObj 的默认值，而不是在定义时。 所以，总体来说，通过使用函数来延迟对象的创建，你规避了 TypeScript 对只读属性的限制，使得在需要时才生成对象的默认值。这是一种常见的解决方案，确保你能够为对象类型的属性提供默认值而不触发 TypeScript 的只读属性错误。 参考：https://cn.vuejs.org/api/sfc-script-setup.html#default-props-values-when-using-type-declaration`}]},{path:"/content/front/js/vue%E4%B8%AD_router%E5%92%8C_route%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"vue中$router和$route的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`一直在用这两个属性，有时候就忘了区别，特地记一下：
$route：当前激活的路由的信息对象。每个对象都是局部的，可以获取当前路由的 path, name, params, query 等属性。 $router：全局的 router 实例。通过 vue 根实例中注入 router 实例，然后再注入到每个子组件，从而让整个应用都有路由功能。其中包含了很多属性和对象（比如 history 对象），任何页面也都可以调用其 push(), replace(), go() 等方法。`}]},{path:"/content/front/js/vue%E4%B9%8Bexcel%E5%AF%BC%E5%85%A5%E6%8C%87%E5%AE%9A%E5%BC%80%E5%A7%8B%E8%A1%8C.html",title:"vue之excel导入指定开始行",pathLocale:"/",contents:[{header:"",slug:"",content:"基于 XLSX 的excel导入功能，通过 设置 {range:1} 参数 来确定开始行"}]},{path:"/content/front/js/vue%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E9%AA%8C%E8%AF%81%E8%A7%84%E5%88%99.html",title:"vue代码格式验证规则",pathLocale:"/",contents:[{header:"",slug:"",content:`vue代码格式验证规则:
https://eslint.vuejs.org/user-guide/ // 在nuxt下好像直接使用 @nuxt/eslint 不用安装 eslint-plugin-vue
https://eslint.vuejs.org/rules/require-explicit-slots`}]},{path:"/content/front/js/vue%E4%BD%BF%E7%94%A8iframe%E5%8A%A0%E8%BD%BD%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6.html",title:"vue使用iframe加载本地文件",pathLocale:"/",contents:[{header:"",slug:"",content:`vue使用iframe加载本地文件:
<template> <iframe ref="frame" scrolling="no" frameborder ="0" width="100%" :height="height" v-bind:src = "src" @load="onLoad" > </iframe>
</template> //这里的src可以替换为本地链接`}]},{path:"/content/front/js/vue%E5%9B%BD%E5%A4%96%E5%B9%B3%E5%8F%B0%E5%88%86%E4%BA%AB%E6%8F%92%E4%BB%B6.html",title:"vue国外平台分享插件vue-social-sharing",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目需要分享功能，主要是几个国外的平台，需要分享到的平台:Facebook, LinkedIn,Twitter,Email
我是在nuxt3上使用的
安装：
//Yarn
yarn add vue-social-sharing@next
//Npm
npm install --save vue-social-sharing@next
使用：
//In your nuxt.config.js file:
modules: [
'vue-social-sharing/nuxt'
]
上面这个方法有问题，会报：Cannot restart nuxt: Cannot read properties of undefined (reading 'Index') 错误
查看issue，有人给出了方案，自定义了
plugins/vue-social-sharing.ts
import { defineNuxtPlugin } from '#app'
import VueSocialSharing from "vue-social-sharing";
export default defineNuxtPlugin((nuxtApp) => { nuxtApp.vueApp.use(VueSocialSharing);
}); vue页面引入： <div> <ShareNetwork network="Facebook" url="https://news.vuejs.org/issues/180" title="Say hi to Vite! A brand new, extremely fast development setup for Vue." description="This week, I’d like to introduce you to 'Vite', which means 'Fast'. It’s a brand new development setup created by Evan You." quote="The hot reload is so fast it\\'s near instant. - Evan You" hashtags="vuejs,vite" > Share on Facebook </ShareNetwork> </div> <div> <ShareNetwork network="LinkedIn" url="https://news.vuejs.org/issues/180" > Share on LinkedIn </ShareNetwork> </div> <div> <ShareNetwork network="Twitter" url="https://news.vuejs.org/issues/180" title="Say hi to Vite! A brand new, extremely fast development setup for Vue." hashtags="vuejs,vite" twitter-user="thinkers_go" > Share on Twitter </ShareNetwork> </div> <div> <ShareNetwork network="Email" url="https://news.vuejs.org/issues/180" title="Say hi to Vite! A brand new, extremely fast development setup for Vue." description="This week, I’d like to introduce you to 'Vite', which means 'Fast'. It’s a brand new development setup created by Evan You." > Share on Email </ShareNetwork> </div> 即可使用，完美!!!! [官方链接](https://github.com/nicolasbeauvais/vue-social-sharing)`}]},{path:"/content/front/js/wangeditor%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87.html",title:"wangeditor上传图片",pathLocale:"/",contents:[{header:"",slug:"",content:`大部分时候，需要自定义wangeditor上传以后的json返回值的格式,注意本版号，下面这个是基于V4版本:
//默认格式
return $this->json([ 'errno' => 0, 'data' => [$prefix . $url], ]);
//自定义格式 return $this->json([ 'code' => 0, 'msg' => 'operate success', 'data' => ['url' => $prefix . $url], ]); //自定义返回格式，需要修改customInsert 这个方法 中对result的取值方式 this.editor.config.uploadImgHooks = { // 上传图片之前 before: function(xhr) { console.log(xhr) // 可阻止图片上传 // return { // prevent: true, // msg: '需要提示给用户的错误信息' // } }, // 图片上传并返回了结果，图片插入已成功 success: function(xhr) { console.log('success', xhr) }, // 图片上传并返回了结果，但图片插入时出错了 fail: function(xhr, editor, resData) { console.log('fail', resData) }, // 上传图片出错，一般为 http 请求的错误 error: function(xhr, editor, resData) { console.log('error', xhr, resData) }, // 上传图片超时 timeout: function(xhr) { console.log('timeout') }, // 图片上传并返回了结果，想要自己把图片插入到编辑器中 // 例如服务器端返回的不是 { errno: 0, data: [...] } 这种格式，可使用 customInsert customInsert: function(insertImgFn, result) { // result 即服务端返回的接口 console.log('customInsert', result) // insertImgFn 可把图片插入到编辑器，传入图片 src ，执行函数即可 insertImgFn(result.data.url) }
}`}]},{path:"/content/front/js/window.scrollTo%E6%BB%9A%E5%8A%A8.html",title:"window.scrollTo滚动",pathLocale:"/",contents:[{header:"",slug:"",content:`window.scrollTo滚动:
滚动到文档中的某个坐标(x,y 向右向下为正) window.scrollTo(x-coord,y-coord )
window.scrollTo(options) 参数:
x-coord 是文档中的横轴坐标。
y-coord 是文档中的纵轴坐标。 options 是一个包含三个属性的对象：
top 等同于 y-coord
left 等同于 x-coord
behavior 类型 String，表示滚动行为，支持参数 smooth(平滑滚动),instant(瞬间滚动),默认值 auto`}]},{path:"/content/front/js/yarn_build%E5%92%8Cnpm_run_build%E5%8C%BA%E5%88%AB.html",title:"yarn_build和npm_run_build区别",pathLocale:"/",contents:[{header:"",slug:"",content:`yarn_build和npm_run_build区别:
没区别，yarn build === yarn run build === npm run build`}]},{path:"/content/front/js/yarn%E5%AE%89%E8%A3%85nuxt3%E6%8A%A5%E9%94%99%E4%B9%8Bhttps%E9%97%AE%E9%A2%98.html",title:"yarn安装nuxt3报错之https问题",pathLocale:"/",contents:[{header:"",slug:"",content:`执行 yarn add nuxt 可能会报如下问题：
error An unexpected error occurred: "https://registry.npmmirror.com/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz: read ECONNRESET".
这个也是https的问题，配置一下就好了:
$ yarn config set "strict-ssl" false -g`}]},{path:"/content/front/js/yarn%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98.html",title:"yarn安装依赖报错问题",pathLocale:"/",contents:[{header:"",slug:"",content:`在做开发的时候，比如PHP 会执行yarn命令安装相关的依赖，但是总会报各种各样的问题，如下：
1."EPROTO: protocol error, symlink '../../../parser/bin/babel-parser.js'
执行：yarn install vagrant@homestead:~/code/duoxiaozhan-admin$ yarn install
yarn install v1.22.17
[1/4] Resolving packages...
[2/4] Fetching packages...
[3/4] Linking dependencies...
warning " > sass-loader@7.3.1" has unmet peer dependency "webpack@^3.0.0 || ^4.0.0".
error An unexpected error occurred: "EPROTO: protocol error, symlink '../../../parser/bin/babel-parser.js' -> '/home/vagrant/code/duoxiaozhan-admin/node_modules/@babel/core/node_modules/.bin/parser'".
info If you think this is a bug, please open a bug report with the information provided in "/home/vagrant/code/duoxiaozhan-admin/yarn-error.log".
info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command. 原因分析：
npm默认会使用 symbolic links来安装组件，也即我们在linux系统里经常用的软链接（ln -s）或硬链接(ln)，但是有些文件系统不支持文件链接，比如 Windows（或者说出于安全原因禁用了），有时候linux 系统运行在有 windows分区的硬盘上也不支持链接，比如virtualbox在windows主机上默认禁止在共享文件夹里使用 symbolic links ,当然也是出于安全考虑。
那么 npm install 默认需要使用 symbolic link，而且这也本身也是 npm 比较重要的一个特性，但如果我们的系统不支持这一属性的话，就会报上面的错误了。当然，你也可以整体设置一下npm，让它默认不再使用文件链接功能了，执行： 这样了以后，再执行相关命令就可以不用带–no-bin-links了。 2.yarn 查看配置
1、查看版本
yarn -v 2、查看配置
yarn config list 3、配置淘宝镜像
yarn config set registry https://registry.npm.taobao.org/`}]},{path:"/content/front/js/%E4%B8%80%E6%AE%B5%E5%85%B8%E5%9E%8B%E7%9A%84typeScript%E4%BB%A3%E7%A0%81.html",title:"一段典型的typeScript代码",pathLocale:"/",contents:[{header:"一段典型的typeScript代码",slug:"一段典型的typescript代码",content:`export function useDataTable<T>(input: MaybeRef<UseDataTableOptions<T>>) { const options = computed(() => toValue(input)); const withoutPagination = computed(() => options.value.pagination === false);
} typeScript的自动类型推导:
在调用 useDataTable 的时候，可以不用传递T的类型，可以通过参数 input 自动推断出 T 的类型，前提是 input 定义了类型或者ts很容易推导出类型 关于MaybeRef<T>: 根据官网可以知道这是 T | Ref<T> 的别名, 原文: MaybeRef<T>: Alias for T | Ref<T>
针对上面的， input可以是 UseDataTableOptions<T> 类型，也可以是 Ref<UseDataTableOptions<T>> 类型, 比如是一个computed 的 UseDataTableOptions<T> 对象 关于tovalue:
将值/引用/获取器规范化为值。(Normalizes values / refs / getters to values.) 官方定义:
function toValue<T>(source: T | Ref<T> | (() => T)): T 例子:
toValue(1) // --> 1
toValue(ref(1)) // --> 1
toValue(() => 1) // --> 1 相关参考:
https://vuejs.org/api/utility-types#mayberef
https://vuejs.org/api/reactivity-utilities.html#tovalue`}]},{path:"/content/front/js/%E4%BD%BF%E7%94%A8pm2%E9%83%A8%E7%BD%B2nuxt3%E9%A1%B9%E7%9B%AE.html",title:"使用pm2部署nuxt3项目",pathLocale:"/",contents:[{header:"",slug:"",content:`使用pm2部署nuxt3项目，操作步骤如下:
①安装
npm install -g pm2 (可能需要 sudo) pm2 -v 查看安装结果 ②pm2使用方式
pm2 主要有 2 种方式：命令行和配置文件 本项目采用配置文件的方式运行(在项目的更目录下运行):
www@HPDEV-31:~/code/project/frontend$ pm2 ecosystem
File /home/www/code/project/frontend/ecosystem.config.js generated //ecosystem.config.js，下面这个是一个标准格式
module.exports = { apps : [{ script: 'index.js', watch: '.' }, { script: './service-worker/', watch: ['./service-worker'] }], deploy : { production : { user : 'SSH_USERNAME', host : 'SSH_HOSTMACHINE', ref : 'origin/master', repo : 'GIT_REPOSITORY', path : 'DESTINATION_PATH', 'pre-deploy-local': '', 'post-deploy' : 'npm install && pm2 reload ecosystem.config.js --env production', 'pre-setup': '' } }
}; //ecosystem.config.js，编辑为项目需要的格式
//这个默认的 exec_mode: 'fork'
module.exports = { apps : [{ name: 'project', script: './.output/server/index.mjs', watch: '.' //监听目录用于当指定监听目录文件发生变化时，pm2 将会自动重启应用。实际表现为:当项目发生更改，比如 vue 页面变化了，修改完以后 执行yarn run build，会生成新的.output/server/index.mjs 文件，那么这个就会被watch ,然后自动更新，并且生效。但是在实际使用中，我发现，pm2 自动重启应用以后，页面访问总是会出问题，主要表现在js报错上(可以通过pm2 logs查看)。不得已 手动重启一下才不会有问题。 }]
}; //改为 exec_mode: 'cluster'
module.exports = { apps : [{ name: 'project', exec_mode: 'cluster', //修改exec_mode 为 cluster，默认为 fork模式，只有 node 项目才支持cluster模式，官网介绍：https://pm2.keymetrics.io/docs/usage/cluster-mode/ instances: 'max', //配置cluster模式下实例的个数，这里配置为 max 即为 cpu总核数，我查看了我的电脑：12th Gen Intel® Core™ i7-1260P × 16 (12核16线程) ，那么就会启动 16 个实例，实验证明也是这样的结果 script: './.output/server/index.mjs', watch: '.' //监听目录用于当指定监听目录文件发生变化时，pm2 将会自动重启应用，事实上仍然有问题，见上面分析 }]
}; //上面的watch 问题，我加了 ignore_watch 之后就正常了，好奇怪
module.exports = { apps : [{ name: 'project', script: './.output/server/index.mjs', watch: '.', ignore_watch : [ // 从监控目录中排除 "node_modules" ], }]
}; ③运行文件
www@HPDEV-31:~/code/project/frontend$ pm2 start ecosystem.config.js [PM2][WARN] Applications project not running, starting...
[PM2] App [project] launched (1 instances)
┌────┬────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐
│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │
├────┼────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤
│ 0 │ project │ default │ 0.0.0 │ fork │ 41744 │ 0s │ 0 │ online │ 0% │ 46.9mb │ www │ enabled │
└────┴────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘ ④配置nginx反向代理
// /etc/nginx/sites-available/test.conf
server { listen 80; listen [::]:80; root /home/www/code/project/public; #网站根目录，既index.php入口文件所在目录，结尾不加 / index index.php index.html; server_name project.web.test; # 域名或者ip地址 location ~ /img/user_image/(.*) { alias /var/www/dms/profiles/$1;
} location ~ /(login|logout|admin|api|sso|build|upload|statics|(user/register)|(verify/email)|(user/profile-image)|_wdt|_profiler|otp){ try_files $uri $uri/ /index.php?$query_string;
} location ~ \\.php$ { # 支持php， 下面的配置是默认的，我只是删掉了没用的，并接触了注释。 include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php8.1-fpm.sock; # 这里对应着上面安装的php7.0
} location / { proxy_pass http://localhost:3000; #这个3000端口就是nuxt3项目运行的默认端口
}
} ⑤查看应用列表:pm2 list / pm2 status / pm2 ls
www@HPDEV-31:~/code/project/frontend$ pm2 list
┌────┬────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐
│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │
├────┼────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤
│ 0 │ project │ default │ 0.0.0 │ fork │ 41744 │ 32m │ 0 │ online │ 0% │ 79.3mb │ www │ enabled │
└────┴────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘ ⑥查看指定应用信息:pm2 describe [id number]
www@HPDEV-31:~/code/project/frontend$ pm2 describe 0 Describing process with id 0 - name project ┌───────────────────┬───────────────────────────────────────────────────────────┐
│ status │ online │
│ name │ project │
│ namespace │ default │
│ version │ 0.0.0 │
│ restarts │ 0 │
│ uptime │ 36m │
│ script path │ /home/www/code/project/frontend/.output/server/index.mjs │
│ script args │ N/A │
│ error log path │ /home/www/.pm2/logs/project-error.log │
│ out log path │ /home/www/.pm2/logs/project-out.log │
│ pid path │ /home/www/.pm2/pids/project-0.pid │
│ interpreter │ node │
│ interpreter args │ N/A │
│ script id │ 0 │
│ exec cwd │ /home/www/code/project/frontend │
│ exec mode │ fork_mode │
│ node.js version │ 19.3.0 │
│ node env │ N/A │
│ watch & reload │ ✔ │
│ unstable restarts │ 0 │
│ created at │ 2023-03-22T07:02:19.692Z │
└───────────────────┴───────────────────────────────────────────────────────────┘ Revision control metadata ┌──────────────────┬────────────────────────────────────────────────┐
│ revision control │ git │
│ remote url │ ssh://git@gitlab.www.com:9922/dev/project.git │
│ repository root │ /home/www/code/project │
│ last update │ 2023-03-22T07:02:19.748Z │
│ revision │ 15b8f2de003ad56a977a261016ea13a7159e3db9 │
│ comment │ home page │
│ branch │ guoshipeng │
└──────────────────┴────────────────────────────────────────────────┘ Actions available ┌────────────────────────┐
│ km:heapdump │
│ km:cpu:profiling:start │
│ km:cpu:profiling:stop │
│ km:heap:sampling:start │
│ km:heap:sampling:stop │
└────────────────────────┘ Trigger via: pm2 trigger project <action_name> Code metrics value ┌────────────────────────┬──────────────────────┐
│ Used Heap Size │ 21.52 MiB │
│ Heap Usage │ 93.26 % │
│ Heap Size │ 23.08 MiB │
│ Event Loop Latency p95 │ 1.19 ms │
│ Event Loop Latency │ 0.43 ms │
│ Active handles │ 4 │
│ Active requests │ 0 │
│ HTTP │ 0 req/min │
│ HTTP P95 Latency │ 16.54999999999999 ms │
│ HTTP Mean Latency │ 0 ms │
└────────────────────────┴──────────────────────┘ Divergent env variables from local env Add your own code metrics: http://bit.ly/code-metrics Use \`pm2 logs project [--lines 1000]\` to display logs Use \`pm2 env 0\` to display environment variables Use \`pm2 monit\` to monitor CPU and Memory usage project ⑦其它命令:pm2 logs / pm2 monit / pm2 plus(跳转到在线检测平台:https://id.keymetrics.io) ⑧停止应用:pm2 stop [id number / name / all]
www@HPDEV-31:~/code/project/frontend$ pm2 stop 0
[PM2] Applying action stopProcessId on app [0](ids: [ '0' ])
[PM2] [project](0) ✓
┌────┬────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐
│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │
├────┼────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤
│ 0 │ project │ default │ 0.0.0 │ fork │ 0 │ 0 │ 0 │ stopped │ 0% │ 0b │ www │ disabled │
└────┴────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘ ⑨重启应用:pm2 reload [id number / name / all]
www@HPDEV-31:~/code/project/frontend$ pm2 reload 0
Use --update-env to update environment variables
[PM2] Applying action reloadProcessId on app [0](ids: [ '0' ])
[PM2] [project](0) ✓
www@HPDEV-31:~/code/project/frontend$ pm2 reload project
Use --update-env to update environment variables
[PM2] Applying action reloadProcessId on app [project](ids: [ 0 ])
[PM2] [project](0) ✓
www@HPDEV-31:~/code/project/frontend$ pm2 reload all
Use --update-env to update environment variables
[PM2] Applying action reloadProcessId on app [all](ids: [ 0 ])
[PM2] [project](0) ✓ ⑩删除应用:pm2 delete [id number / name / all]
删除应用几乎不会造成任何后果，只是在管理列表中删除了这一项，并不会删除项目文件 ⑪通过pm2支持的npm启动方式启动项目:
www@HPDEV-31:~/code/project/frontend$ pm2 start npm --name project -- run start --watch
[PM2] Starting /usr/local/bin/npm in fork_mode (1 instance)
[PM2] Done.
┌────┬────────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐
│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │
├────┼────────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤
│ 0 │ project │ default │ N/A │ fork │ 0 │ 0 │ 15 │ errored │ 0% │ 0b │ www │ enabled │
│ 1 │ project │ default │ N/A │ fork │ 11949 │ 0s │ 0 │ online │ 0% │ 31.4mb │ www │ enabled │
└────┴────────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘ id 为0的那个是通过 pm2 start yarn --name project -- run start --watch, 证明通过pm2 通过yarn 启动是有问题的，报：
0|project | /usr/share/yarn/bin/yarn:2
0|project | argv0=$(echo "$0" | sed -e 's,\\\\,/,g')
0|project | ^^^^
0|project | 0|project | SyntaxError: missing ) after argument list id 为1的那个是通过npm 启动的，没任何问题 但是这种方式，watch 还是会出问题，还是觉得通过配置文件启动比较靠谱 ⑫通过最普通的 nohup 执行命令，这种现在过时了
www@HPDEV-31:~/code/project/frontend$ nohup node .output/server/index.mjs & //默认会在当前路径下生成nohup.out文件
[2] 17471
www@HPDEV-31:~/code/project/frontend$ nohup: ignoring input and appending output to 'nohup.out'
^C
www@HPDEV-31:~/code/project/frontend$ netstat -anlp | grep 17471
(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)
tcp6 0 0 :::3000 :::* LISTEN 17471/node www@HPDEV-31:~/code/project/frontend$ kill 17471
www@HPDEV-31:~/code/project/frontend$ [2]- Terminated nohup node .output/server/index.mjs ⑬本地启动pm2-web服务
sudo npm install -g pm2-web 当前项目下执行:pm2-web`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Ejs%E7%9A%84map%E5%87%BD%E6%95%B0.html",title:"关于js的map函数",pathLocale:"/",contents:[{header:"",slug:"",content:`关于js的map函数:
Array.map() 会一次性遍历数组的所有元素，并返回一个新的数组，其中每个元素是原数组元素经过提供的回调函数处理后的结果。map 方法会立即对整个数组进行操作并返回一个新数组，这个过程是同步的。 工作原理:
map() 会一次性遍历整个数组并返回新数组。它不会等到某个元素的处理完成才继续下一个元素，而是并行处理整个数组。注意: map() 不会改变原始数组，而是返回一个新的数组。 语法:
const newArray = array.map((element, index, array) => { // 返回新元素 return newElement;
}); 异步操作:
如果在 map() 的回调函数中执行异步操作（如 setTimeout 或 Promise），map() 会立即返回新数组，但异步操作会在未来的某个时刻完成，可能不会按预期顺序执行。若需要处理异步操作，可以结合 Promise.all 来确保异步操作完成后再处理结果。 示例:
const fetchData = async (id: number) => { return new Promise(resolve => { setTimeout(() => { resolve(\`Data for ID: \${id}\`); }, 1000); });
}; const main = async () => { const ids = [1, 2, 3]; const results = await Promise.all(ids.map(async (id) => { const data = await fetchData(id); return data; })); console.log(results); // ["Data for ID: 1", "Data for ID: 2", "Data for ID: 3"]
}; main(); 开始没有使用 main 包一下，结果报：
await is only valid in async functions and the top level bodies of modules
原因是await 只能在以下两种环境中使用：
1.异步函数 (async 函数) 内。
2.模块的顶层代码（type="module" 或 .mjs 文件）。 如下 .mjs 文件:
const fetchData = async (id) => { return new Promise(resolve => { setTimeout(() => { resolve(\`Data for ID: \${id}\`); }, 1000); });
}; const ids = [1, 2, 3];
const results = await Promise.all(ids.map(async (id) => { const data = await fetchData(id); return data;
})); console.log(results); // ["Data for ID: 1", "Data for ID: 2", "Data for ID: 3"] 如下 html 中:
<script type="module"> const fetchData = async (id) => { return new Promise(resolve => { setTimeout(() => { resolve(\`Data for ID: \${id}\`); }, 1000); }); }; const ids = [1, 2, 3]; const results = await Promise.all(ids.map(async (id) => { const data = await fetchData(id); return data; })); console.log(results); // ["Data for ID: 1", "Data for ID: 2", "Data for ID: 3"]
<\/script> 使用 Promise.all 的好处
1.并行执行:
Promise.all 会并行执行所有异步任务，效率更高。
例如，上述代码中所有 fetchData 调用会在同一时间触发，而不是逐个等待。 2.统一处理结果:
如果需要一次性获得所有结果，可以直接使用 Promise.all，无需手动遍历。 3.简洁性:
代码更简单，逻辑更清晰。 相关使用场景:
1.并行获取多个数据:
例如从多个 API 请求数据时：
const urls = ['https://api.example.com/user', 'https://api.example.com/posts'];
const results = await Promise.all(urls.map(url => fetch(url).then(res => res.json())));
console.log(results); // [user data, posts data] 2.批量处理文件或任务: 当有一组任务需要并行执行时，Promise.all 是最佳选择：
const files = ['file1.txt', 'file2.txt', 'file3.txt'];
const contents = await Promise.all(files.map(file => readFile(file, 'utf8')));
console.log(contents); // [content1, content2, content3] 当 任何一个 Promise 被拒绝（rejected），Promise.all 会立即抛出错误，并停止收集结果:
const promises = [ Promise.resolve('Task 1 success'), Promise.reject('Task 2 failed'), // 会中断整个 Promise.all Promise.resolve('Task 3 success')
]; try { const results = await Promise.all(promises); console.log(results); // 不会被执行
} catch (error) { console.error('Error:', error); // 输出 "Error: Task 2 failed"
} 如果希望 Promise.all 在某些任务失败时依然返回其他任务的结果，可以使用 .catch 捕获错误:
const promises = [ Promise.resolve('Task 1 success'), Promise.reject('Task 2 failed').catch(err => err), // 捕获错误，返回默认值 Promise.resolve('Task 3 success')
]; const results = await Promise.all(promises);
console.log(results); // ["Task 1 success", "Task 2 failed", "Task 3 success"] 总结:
async 函数返回一个 Promise：
即使返回的是普通值，也会被隐式包裹成 Promise。
示例：return 42 相当于 return Promise.resolve(42)。 await 暂停代码执行：
它会等待一个 Promise 被解决，并直接返回结果。
只能在 async 函数中使用，因为 async 提供了处理 Promise 的上下文。
优势： 简化异步代码逻辑，使其更接近同步代码风格。
提升可读性，避免 then 链式调用的复杂嵌套。 也就是说: 使用了 await，意味着它后面的表达式一定是一个 Promise 或者一个可以被隐式转换为 Promise 的值。await 的核心作用就是等待一个 Promise 的解决，并直接返回它的结果，这样可以让我们用一种更直观的方式来处理异步操作。`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Enuxt3%E4%B8%8B%E8%BF%90%E8%A1%8C%E5%9C%A8localhost%E7%9A%84%E6%9C%8D%E5%8A%A1.html",title:"关于nuxt3下运行在localhost的服务",pathLocale:"/",contents:[{header:"nuxt3下运行在 localhost:3000 的服务不是 Vite 本身直接提供的，而是 Nuxt 3 使用 Nitro 提供的 SSR 服务，Vite 只是参与了前端部分的构建和热更新。",slug:"nuxt3下运行在-localhost-3000-的服务不是-vite-本身直接提供的-而是-nuxt-3-使用-nitro-提供的-ssr-服务-vite-只是参与了前端部分的构建和热更新。",content:"以下是根据 Nuxt 3 架构绘制的简洁图示："},{header:"✅ Nuxt 3 架构图：开发、构建 和 部署阶段角色分工",slug:"✅-nuxt-3-架构图-开发、构建-和-部署阶段角色分工",content:""},{header:"🛠️ 开发阶段架构图（npm run dev）",slug:"🛠️-开发阶段架构图-npm-run-dev",content:"+-----------------------------+ | Your Browser | | (localhost:3000) | +-----------------------------+ ▲ │ SSR 渲染 + API 响应 │ +-------------+ | Nitro Dev | ← Nuxt 提供的 Dev Server | (Node 运行) | (使用 H3 框架) +-------------+ ▲ │ 请求 Vue 页面 / API │ │ 静态资源构建 │ +-------------------------+ | Vite | ← 负责： | - Vue 解析 | ✔ HMR 热重载 | - TS、SASS 构建 | ✔ 模块编译（.vue/.ts/.scss） | - HMR 推送 | +-------------------------+"},{header:"🏗️ 构建阶段（npm run build）",slug:"🏗️-构建阶段-npm-run-build",content:"Nuxt CLI │ ├── 前端构建（Vite） │ → 输出静态资源到 `.output/public/_nuxt` │ └── 后端构建（Nitro） → 输出 SSR/API 代码到 `.output/server`"},{header:"🚀 部署阶段（npm run preview 或生产环境）",slug:"🚀-部署阶段-npm-run-preview-或生产环境",content:"请求: https://your-domain.com │ ▼ +--------------------+ | Nitro Production | ← 运行在 Node、Cloudflare、Vercel 等上 | - SSR 渲染页面 | | - API 路由 | | - Middleware | +--------------------+ │ ▼ +------------------------+ | .output/public/_nuxt | ← 静态资源（CSS、JS、图片） +------------------------+"},{header:"🧠 核心组件总结",slug:"🧠-核心组件总结",content:`组件
作用
所在阶段 Vite
编译 .vue / .ts / .scss，热更新
开发、构建 Nitro
提供 Dev Server / SSR / API
开发、构建、部署 Nuxt CLI
管理命令、调度构建任务
所有阶段 .output
最终构建产物（用于部署）
构建后`},{header:"✅ 你只需要记住：",slug:"✅-你只需要记住",content:`localhost:3000 是由 Nitro Server 提供的 SSR 服务
Vite 负责 Vue 页面、组件、样式的构建和热更新（开发用）
最终部署的是 .output 目录下的构建产物 在没有nuxt的项目里，是由node提供的服务:`},{header:"🧭 没有 Nuxt 的情况下 —— 如果你只是用 Vite 搭配 Vue 或其他框架开发前端项目：",slug:"🧭-没有-nuxt-的情况下-——-如果你只是用-vite-搭配-vue-或其他框架开发前端项目",content:""},{header:"→ 运行在 localhost:5173 或其他端口的服务，是由 Vite 本身通过 Node 启动的开发服务器提供的。",slug:"→-运行在-localhost-5173-或其他端口的服务-是由-vite-本身通过-node-启动的开发服务器提供的。",content:""},{header:"📦 举个例子：一个不使用 Nuxt 的 Vite + Vue 项目",slug:"📦-举个例子-一个不使用-nuxt-的-vite-vue-项目",content:`npm create vite@latest my-vite-app --template vue
cd my-vite-app
npm install
npm run dev 输出可能是： VITE v5.2.0 ready in 345ms ➜ Local: http://localhost:5173/`},{header:"📌 这个 localhost:5173 服务由谁提供？",slug:"📌-这个-localhost-5173-服务由谁提供",content:`✅ 就是 Vite 自己！
在内部，它使用的是 vite.createServer() 启动了一个 Node HTTP 服务： 用于开发调试
支持热模块替换（HMR）
支持 .vue、.scss 等预处理器
不含 SSR，也不包含任何后端 API 功能（除非你手动加）`},{header:"🔧 生产部署呢？",slug:"🔧-生产部署呢",content:`默认情况下： 运行 vite build 会把项目构建为静态资源（HTML + JS + CSS）
可以用任何 HTTP 静态服务器（如 nginx、Vercel、Netlify、Express）来部署这些构建产物`},{header:"✅ 小结对比",slug:"✅-小结对比",content:`场景
提供本地开发服务的服务端是谁？ 使用 Nuxt 3
Nitro + Vite（协同） 只用 Vite + Vue/React
Vite 自己启动 Node Server`},{header:"Nuxt 3 构建体系:",slug:"nuxt-3-构建体系",content:`服务端（API/SSR） Nitro Nuxt 3 新的轻量级服务端引擎
SCSS 等预处理器 Vite 调用 sass 默认自动处理`},{header:"执行 npm run dev 有如下日志输出:",slug:"执行-npm-run-dev-有如下日志输出",content:`✔ Nuxt Nitro server built in 6233 ms 说明 Nuxt 的后端（API/SSR）部分是用 Nitro 引擎构建的。 ℹ Vite client warmed up in 2ms 表示客户端部分使用 Vite，完成了预热。 ℹ Vite server warmed up in 5118ms
表示 Vite 的开发服务器（用于热重载/模块热更新）已准备好。`},{header:"打印调试日志:",slug:"打印调试日志",content:"$ DEBUG=nuxt:* npx nuxi dev"}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Epackage-json%E6%96%87%E4%BB%B6%E9%87%8C%E7%9A%84peerDependencies%E7%9A%84%E7%94%A8%E9%80%94.html",title:"关于package-json文件里的peerDependencies的用途",pathLocale:"/",contents:[{header:"关于package.json下 peerDependencies 的用途",slug:"关于package-json下-peerdependencies-的用途",content:`主要列出需要用户自己安装的依赖的列表，如vite包:
"peerDependencies": { "vue": "^3.3.0", "sass": "*"
},
"devDependencies": { "vue": "^3.3.4", "sass": "^1.77.0"
} 但是一般，会在devDependencies下发现有依赖，这个是用来包自身测试用的，不是给用户用的
关系图:
┌────────────────────────────────────┐
│ 使用者项目（如 Nuxt 项目） │
│ │
│ ┌────────────────────────────┐ │
│ │ my-ui-lib │◄───┤ ← 安装你的库
│ │ │ │
│ │ dependencies: │ │ ✔ 会被打包进生产代码中
│ │ axios │ │
│ │ │ │
│ │ peerDependencies: │ │ ⚠️ 用户必须自己安装
│ │ vue │ │ 否则运行时报错
│ │ sass │ │
│ │ │ │
│ │ devDependencies: │ │ 🛠️ 仅开发和测试用
│ │ vite, vitest, vue, sass │ │
│ │ │ │
│ │ optionalDependencies: │ │ ❓ 可以用，但不是必须
│ │ tailwindcss │ │
│ └────────────────────────────┘ │
└────────────────────────────────────┘ 可以通过如下命令查看npm安装的包的情况:
如查看sass包和sass-embedded包的安装
$ npm ls sass
$ npm ls sass-embedded 如上，如果用户没有自己安装，那么即使执行了上面的命令，也没有输出`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Ets%E7%9A%84%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98.html",title:"关于ts的细节问题",pathLocale:"/",contents:[{header:"",slug:"",content:`关于ts的细节问题:
1>元数组
元组类型是一种表示具有固定数量的元素及其相应类型的数组的类型。元组类型以固定顺序强制执行特定数量的元素及其各自的类型。当您想要表示具有特定类型的值的集合时，元组类型非常有用，其中数组中每个元素的位置都有特定的含义。 例子:
type Point = [number, string, string]; const aa: Point = [123, "456"] // 必须三个参数
const bb: Point = [123, "456", 789] //数据类型必须为string
const cc: Point = [123, "456", "789"] 2>在使用泛型的时候，函数形式的话可以用 <T>或者<T,>，但是对于箭头函数必须要用<T,>否则报错
// function identity<T>(arg: T): T {
// return arg;
// } function identity<T,>(arg: T): T { return arg;
} // const identity = <T,>(arg: T): T => arg const a = identity('x');
console.log("a is:", a)`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Evue3%E7%9A%84component%E6%A0%87%E7%AD%BE%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"关于vue3的component标签的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`关于vue3的component标签的使用:
<component>、<slot> 和 <template> 是类似组件的功能，也是模板语法的一部分。它们不是真正的组件，在模板编译过程中会被编译掉。因此，它们在模板中通常以小写字母书写。 https://vuejs.org/api/built-in-special-elements.html#component
https://vuejs.org/guide/essentials/component-basics.html#dynamic-components`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Evue3%E7%9A%84reactive%E5%92%8Cref%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"关于vue3的reactive和ref的区别",pathLocale:"/",contents:[{header:"关于vue3的reactive和ref的区别",slug:"关于vue3的reactive和ref的区别",content:"在 Vue 3 中，reactive 和 ref 是响应式系统的核心工具，但它们有一些重要的区别，下面详细解释："},{header:"1. ref 是用于 基本类型（也可以用于对象）",slug:"_1-ref-是用于-基本类型-也可以用于对象",content:`import { ref } from 'vue'; const count = ref(0); console.log(count.value); // 0 count.value++; // 修改响应式值 //模板中使用
<template> <div>{{ count }}</div>
</template> ref 的特点： ref(0) 创建的是一个响应式包装对象：{ value: 0 }
访问和修改值要通过 .value
在模板中使用时，Vue 会自动解包 .value，可以直接用 {{ count }} 适合用于 字符串、数字、布尔值、null、undefined 等基本类型。`},{header:"2. reactive 是用于 对象、数组、Map 等引用类型",slug:"_2-reactive-是用于-对象、数组、map-等引用类型",content:`import { reactive } from 'vue'; const state = reactive({ count: 0, name: 'Vue3'
}); console.log(state.count); // 0 state.count++; // 响应式更新 //模板中使用
<template> <div>{{ state.count }}</div>
</template> reactive 的特点： 返回的是原始对象的 Proxy 代理
可以直接读写属性，无需 .value
只能用于对象（不能传基本类型，如 reactive(1) 会警告）`},{header:"3. 对比总结",slug:"_3-对比总结",content:`特性
ref
reactive 类型支持
基本类型和引用类型
只支持引用类型 解包方式
.value（模板中自动解包）
直接访问属性 内部结构
{ value: xxx }
代理原对象 使用场景
单个值、基本类型
结构化对象（如 state、form） 响应性兼容
在数组、对象中使用需解包
自身是响应式`},{header:"4. 混合使用",slug:"_4-混合使用",content:`const state = reactive({ count: ref(0), // ref 嵌套在 reactive 中
}); console.log(state.count.value); // 访问 ref 内部的值 state.count.value++; // 修改 ref 值 但推荐在组合式 API 中： 基本值使用 ref
对象用 reactive
不要将 ref 包在 reactive 里（嵌套 .value 可能会让代码变复杂）`},{header:"5. 实用建议",slug:"_5-实用建议",content:`如果你不确定用哪个，可以参考这个经验法则： 你要声明的是 一个独立变量（数字、字符串等） → 用 ref
你要声明的是 一个结构化状态对象（例如表单、用户信息等） → 用 reactive`}]},{path:"/content/front/js/%E5%85%B3%E4%BA%8Evue3%E7%9A%84v_model%E5%8F%8C%E5%90%91%E7%BB%91%E5%AE%9A.html",title:"关于vue3的v_model双向绑定",pathLocale:"/",contents:[{header:"",slug:"",content:`关于vue3的v_model双向绑定:
v3.4之前使用 defineProps
v3.4之后使用 defineModel 文档:https://vuejs.org/guide/components/v-model.html 主要用法如下:
1>常规的单属性双向绑定
ex:
定义子组件Child.vue: <script setup lang="ts">
const title = defineModel({ default: "我是title的默认值",// 设置v-moddel的默认值 // required: true, // 设置为必传属性，当在父组件使用的时候
}); const change = () => { title.value = "我是title的新值"; //这里改变 v-model 的值，会在下面同步修改
}
<\/script> <template> <Button @click="change">修改...</Button> <div>parent bound v-model is: {{ title }}</div>
</template> 2>通过父子组件使用
ex:
定义父组件Parent.vue: <script setup lang="ts">
const count = ref("haha");
const say = () => { count.value = "world";
};
<\/script> <template> <Button @click="say">添加</Button> <input type="text" :value="count">// 同时，v-model的值会在这里展示，如果 子组件 触发了 change 事件，那么 父组件的count值也会改变 <Child v-model="count"></Child> // 这里通过count给v-model传值，当count 没有值 比如 onst count = ref(); 的时候 ，会使用 子组件定义的 default 值
</template> 3>可以在通过 defineModel 定义 v-model 的时候，限定 v-model的类型,如下:
const title = defineModel<boolean>(); // 指定为 bool 型 4>可以通过给 v-model 绑定参数，可以实现为 v-model 定义名称，在一个组件下有多个 v-model 属性的时候，必须要这么做, 单个的时候直接 defineModel()就可以了，可能是因为默认名称只能有一个吧
ex:
常规使用：
子组件:
<script setup>
const firstName = defineModel('haha')
const lastName = defineModel('hehe')
<\/script> <template> <input type="text" v-model="firstName" /> <input type="text" v-model="lastName" />
</template> 父组件:
<script setup>
import { ref } from 'vue'
import UserName from './UserName.vue' const first = ref('John')
const last = ref('Doe')
<\/script> <template> <h1>{{ first }} {{ last }}</h1> <UserName v-model:haha="first" v-model:hehe="last" />
</template> 添加额外属性使用:
子组件:
<script setup>
const firstName = defineModel('haha')
const lastName = defineModel('hehe', { default: "这个是默认值", //required: true
}) const change = () => { lastName.value = "做个修改"
}
<\/script> <template> <input type="text" v-model="firstName" /> <input type="text" v-model="lastName" /> <button @click="change">修改一下</button>
</template> 父亲组件:
<script setup>
import { ref } from 'vue'
import UserName from './UserName.vue' const first = ref('John')
const last = ref('Doe')
<\/script> <template> <h1>{{ first }} {{ last }}</h1> <UserName v-model:haha="first" />
</template> 5>可以为 v-model 定义修改器(modifiers)，一个v-model 属性上只能定义一个修改器，定义多个不生效
ex:
父组件:
<script setup>
import { ref } from 'vue'
import MyComponent from './MyComponent.vue' const myText = ref('')
<\/script> <template> This input capitalizes everything you enter: <p>{{ myText }}</p> <MyComponent v-model.firtToUpper="myText" />
</template> 子组件:
<script setup>
import { computed } from 'vue' const [title, modifiers] = defineModel({ set(value) { if (modifiers.firtToUpper) { return value.charAt(0).toUpperCase() + value.slice(1) } return value }
}) const change = () => { title.value = "change the value"
}
<\/script> <template> <button @click="change">修改</button> <input type="text" v-model="title" />
</template> 我发现 modifiers 参数是可以自定义的，可以定义为其它的，比如我这里改为 dodo:
<script setup>
import { computed } from 'vue' const [title, dodo] = defineModel({ set(value) { if (dodo.firtToUpper) { return value.charAt(0).toUpperCase() + value.slice(1) } return value }
}) const change = () => { title.value = "change the value"
}
<\/script> <template> <button @click="change">修改</button> <input type="text" v-model="title" />
</template> 6> 将修改器使用到多个 v-model 属性，下面这个是官网的例子，我认为没什么用，只是做了 console 打印，我以为可以像上面一样，对数据处理，需要自己尝试
ex:
子组件:
<UserName v-model:haha.capitalize="first" v-model:hehe.uppercase="last"
/> 父组件:
<script setup>
const [firstName, firstNameModifiers] = defineModel('haha')
const [lastName, lastNameModifiers] = defineModel('hehe') console.log(firstNameModifiers) // { capitalize: true }
console.log(lastNameModifiers) // { uppercase: true}
<\/script>`}]},{path:"/content/front/js/%E5%85%B8%E5%9E%8Bts%E4%BC%98%E5%8C%96.html",title:"典型ts优化",pathLocale:"/",contents:[{header:"",slug:"",content:`有如下ts类型定义:
ListResponse.ts
原始写法:
export type RawSection = { value: number; label: string;
}; export type RawTicket = { id: number; title: string; section: RawSection;
}; export type RawAddonsEditResponse = { id: number; title: string; price: string; quantity: number; additionalInformation: string; tickets: RawTicket[];
} export type Section = { id: number; title: string;
}; export type Ticket = { id: number; title: string; section: Section;
}; export type AddonsEditResponse = { id: number; title: string; price: string; quantity: number; additionalInformation: string; tickets: Ticket[];
}; 优化后:
type BaseTicket<S> = { id: number; title: string; section: S;
}; type BaseAddonsEditResponse<T> = { id: number; title: string; price: string; quantity: number; additionalInformation: string; tickets: T[];
}; export type RawSection = { value: number; label: string;
}; export type RawTicket = BaseTicket<RawSection>; export type RawAddonsEditResponse = BaseAddonsEditResponse<RawTicket>; export type Section = { id: number; title: string;
}; export type Ticket = BaseTicket<Section>; export type AddonsEditResponse = BaseAddonsEditResponse<Ticket>; 优化分析:
提取通用类型：将 BaseSection, BaseTicket, 和 BaseAddonsEditResponse 定义为通用类型，并通过泛型参数增强复用性。
复用性提升：通过泛型参数 S 和 T，将类型从依赖具体的 RawSection 或 Section，转变为可以适配不同上下文的通用类型。
最终类型定义清晰化：后面的三个最终类型 (Section, Ticket, AddonsEditResponse) 依然保留原样，保持清晰的业务含义。
这样可以减少重复代码，并使代码更具扩展性。如果需要新增类似的类型，维护起来也更简单。`}]},{path:"/content/front/js/%E5%90%84%E7%A7%8Dform%E6%95%B0%E6%8D%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"各种form数据之间的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`各种form数据之间的区别: application/x-www-form-urlencoded 这应该是最常见的 POST 提交数据的方式了。浏览器的原生 form 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据。
<form action="form_action.asp" enctype="text/plain"> <p>First name: <input type="text" name="fname" /></p> <p>Last name: <input type="text" name="lname" /></p> <input type="submit" value="Submit" />
</form> 此时可以看到，
Content-Type: application/x-www-form-urlencoded;charset=utf-8
title=test&sub%5B%5D=1&sub%5B%5D=2&sub%5B%5D=3 首先，Content-Type 被指定为 application/x-www-form-urlencoded；其次，提交的数据按照 key1=val1&key2=val2 的方式进行编码，key 和 val 都进行了 URL 转码。 multipart/form-data 这也是常见的post请求方式，一般用来上传文件 application/json application/json 将请求数据以json的形式传输，现在很多时候也把它作为请求头，用来告诉服务端消息主体是序列化的JSON字符串。`}]},{path:"/content/front/js/%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE%E4%B9%8Bmedium-zoom%E4%BD%BF%E7%94%A8.html",title:"图片缩放之medium-zoom使用",pathLocale:"/",contents:[{header:"",slug:"",content:`这个主要是解决nuxt3下的图片缩放的问题的，本来使用viewerjs挺好的，但是奈何nuxt3太调皮了，问题多，转而使用这个zoom
1.安装
yarn add --dev medium-zoom 2.配置
Add following client-side (file name suffix .client.(ts|js)) plugin: ./plugins/medium-zoom.client.ts
注意这个client前缀，表示当process.client的时候才会加载,还是很有用的，之前一直没能弄明白这个前缀干啥用的
import { defineNuxtPlugin } from '#app'
import mediumZoom, { Zoom } from 'medium-zoom'
export default defineNuxtPlugin((nuxtApp) => { const selector = '.image-zoomable' const zoom: Zoom = mediumZoom(selector, {}) // (re-)init for newly rendered page, also to work in SPA mode (client-side routing) nuxtApp.hook('page:finish', () => { zoom.detach(selector) .attach(selector) }) // make available as helper to NuxtApp nuxtApp.provide('mediumZoom', zoom)
}) 3.解释
Now for each page rendered / client-side navigated to, medium-zoom is applied accordingly for all images in the DOM matching the chosen selector. In our plugin we chose a CSS selector to match all img elements with the class image-zoomable.
You can find all supported selector types in the module's docs.
Running on nuxt - client-side app navigation is done via vue-router. For medium-zoom to do it's magic, it has to be 're-attached' following changes to image on the page. We use the page:finish nuxt3 lifecycle hook as a trigger.
Finally, we also provide the mediumZoom instance as a helper. 4.使用
<img src="/images/fluffy-cat.jpg" alt="A fluffy cat" class="image-zoomable" />，必须加上 class="image-zoomable"，方便上面的ts选择图片 5.注意
需要特别注意的是，这个img的src内容，需要再页面加载完成的时候，或者 之前就把img的src数据渲染出来，不能使用await 获取数据，否则上面的ts 不生效，我分析了原因
可能是上面的ts 会在 nuxtApp添加 hook page:finish，所以我的解决办法是通过middleware 调用 获取数据存储到localstorage 然后在mounted 中取出数据，进行渲染。`}]},{path:"/content/front/js/%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE%E4%B9%8Bviewerjs%E4%BD%BF%E7%94%A8.html",title:"图片缩放之viewerjs使用",pathLocale:"/",contents:[{header:"",slug:"",content:`安装:
yarn add viewerjs //创建image.js
//引入:
import 'viewerjs/dist/viewer.js'
import 'viewerjs/dist/viewer.css'
import Viewer from 'viewerjs/dist/viewer.esm'; //加上这行，不然一直报Viewer is not defined,参考:https://github.com/fengyuanchen/viewerjs/issues/136 //使用：
$(function () { /* img viewer * */ const viewer = new Viewer(document.getElementById('certificationImages'), { url:'data-original', //这个参数挺重要的，如果不设置的话 默认就是 src的值；但是这个插件实现的一个条件是，img 上会有两个图片地址，一个用来展示原图，一个用来缩放，所以二者不能是同一张图，不然当缩放的图片关闭的时候，原图也会被关闭，就是这个小问题 搞得我莫名其妙. toolbar: false, navbar:false });
}); 页面:
<tbody id="certificationImages">
{% for course in pagination %} <tr class="row_list center-content"> <td>{{ course.id }}</td> <td> <img data-original="{{ asset(course.certificationUrl)}}" src="{{ asset(course.certificationUrl)|imagine_filter('squared_thumbnail_small') }}" style="display: inline-block;width: 50px; height: 33px; cursor: pointer;" alt=""> </td> </tr>
{% endfor %}
</tbody>`}]},{path:"/content/front/js/%E5%B0%81%E8%A3%85%E4%B8%80%E4%B8%AAvue3%E7%9A%84%E8%A1%A8%E6%A0%BC%E6%8B%96%E6%8B%BD%E5%8A%9F%E8%83%BD.html",title:"封装一个vue3的表格拖拽功能",pathLocale:"/",contents:[{header:"",slug:"",content:`封装一个vue3的表格拖拽功能:
1.在utils下创建dragDropManager.ts
interface DragConfig { draggableColumns?: string[]; // 可拖拽列的名称 undraggableRows?: number[]; // 禁止拖拽的行索引
} export class TableDragManager<T> { private list: T[]; // 数据源 private config: DragConfig; // 拖拽配置 private draggingIndex: number | null = null; //当前拖动元素的索引 private onDropCallback?: (draggedId: number, newList: any[]) => void; //回调 constructor(list: T[], config: DragConfig) { this.list = list; this.config = config; } // 设置拖拽完成之后的回调方法，用于调用API，保存拖拽之后的数据 setOnDropCallback(callback: (draggedId: number, newList: any[]) => void) { this.onDropCallback = callback; } onDragStart(index: number, column: string | null, event: DragEvent): void { if (this.config.undraggableRows?.includes(index)) { event.preventDefault(); return; } if (column && this.config.draggableColumns && !this.config.draggableColumns.includes(column)) { event.preventDefault(); return; } this.draggingIndex = index; } // targetIndex： 将要拖动到的位置的索引 event： 拖拽事件 canDrop：用于判断能否拖拽到指定位置(因为有些行不允许拖拽，也就意味着别的行也不能拖拽到对应位置) onDrop(targetIndex: number, event: DragEvent, canDrop: (index: number) => boolean): void { event.preventDefault(); console.log("targetIndex is:", targetIndex); console.log("draggingIndex is:", this.draggingIndex); if (this.draggingIndex !== null && this.draggingIndex !== targetIndex && canDrop(targetIndex)) { const draggedItem = this.list[this.draggingIndex]; this.list.splice(this.draggingIndex, 1); this.list.splice(targetIndex, 0, draggedItem); if (this.onDropCallback) { this.onDropCallback(draggedItem.id, this.list); } } this.draggingIndex = null; } onDragOver(event: DragEvent): void { event.preventDefault(); // 必须阻止默认行为以允许放置 }
} 2.在vue3页面test.vue调用
1>禁止部分行拖拽以及指定字段可拖拽
<script setup lang="ts">
import { TableDragManager } from '~/utils/dragDropManager'; interface TableRow { id: number; name: string; age: number;
} const list = ref<TableRow[]>([ { id: 1, name: 'Row 1', age: 25 }, { id: 2, name: 'Row 2', age: 30 }, { id: 3, name: 'Row 3', age: 35 }, { id: 4, name: 'Row 4', age: 55 },
]); // 配置
const config = { draggableColumns: ['id'], // 仅允许 ID 列拖拽 undraggableRows: [0,1], // 第 0 1 行禁止拖拽 (默认按顺序禁止)
}; // 实例化拖拽管理器
const dragManager = new TableDragManager(list.value, config); const canDrop = (index: number) => { // 禁止前两行行拖拽 if (config.undraggableRows && index < config.undraggableRows.length) { return false; } return true;
}; const handleDrop = (draggedId: number, newList: any[]) => { console.log("draggedId is:", draggedId); console.log("newList is:", newList);
} onMounted(() => { dragManager.setOnDropCallback(handleDrop);
});
<\/script> <template> <table> <thead> <tr> <th>ID</th> <th>Name</th> <th>Age</th> </tr> </thead> <tbody> <tr v-for="(row, index) in list" :key="row.id" > <td :draggable="true" @dragstart="dragManager.onDragStart(index, 'id', $event)" @dragover="dragManager.onDragOver($event)" @drop="dragManager.onDrop(index, $event, canDrop)" > {{ row.id }} </td> <td>{{ row.name }}</td> <td>{{ row.age }}</td> </tr> </tbody> </table>
</template> 2>常规拖拽(没有任何限制)
<script setup lang="ts">
import { TableDragManager } from '~/utils/dragDropManager'; interface TableRow { id: number; name: string; age: number;
} const list = ref<TableRow[]>([ { id: 1, name: 'Row 1', age: 25 }, { id: 2, name: 'Row 2', age: 30 }, { id: 3, name: 'Row 3', age: 35 }, { id: 4, name: 'Row 4', age: 55 },
]); // 配置
const config = { draggableColumns: [], // 仅允许 ID 列拖拽 undraggableRows: [], // 第 0 1 行禁止拖拽 (默认按顺序禁止)
}; // 实例化拖拽管理器
const dragManager = new TableDragManager(list.value, config); const canDrop = (index: number) => { // 禁止前两行行拖拽 if (config.undraggableRows && index < config.undraggableRows.length) { return false; } return true;
}; const handleDrop = (draggedId: number, newList: any[]) => { console.log("draggedId is:", draggedId); console.log("newList is:", newList);
} onMounted(() => { dragManager.setOnDropCallback(handleDrop);
});
<\/script> <template> <table> <thead> <tr> <th>ID</th> <th>Name</th> <th>Age</th> </tr> </thead> <tbody> <tr v-for="(row, index) in list" :key="row.id" :draggable="true" @dragstart="dragManager.onDragStart(index, null, $event)" @dragover="dragManager.onDragOver($event)" @drop="dragManager.onDrop(index, $event, canDrop)" > <td > {{ row.id }} </td> <td>{{ row.name }}</td> <td>{{ row.age }}</td> </tr> </tbody> </table>
</template> 3>关于splice的使用分析
//
let lists = ['A', 'B', 'C', 'D'];
// 假设要把 'B' 移动到 'D' 前面 // 1. 保存 'B'
const draggedItem = lists[1]; // 'B' // 2. 删除索引1的 'B'
lists.splice(1, 1); // list 现在是 ['A', 'C', 'D'] // 3. 在索引2处插入 'B'
lists.splice(2, 0, draggedItem); // list 变成 ['A', 'C', 'B', 'D']`}]},{path:"/content/front/js/%E6%B5%8F%E8%A7%88%E5%99%A8cookie%E5%92%8Csession.html",title:"浏览器cookie和session",pathLocale:"/",contents:[{header:"",slug:"",content:`浏览器cookie和session:
关于cookie的设置问题:
1>后端symfony7 // 创建 Cookie 对象 $cookie = Cookie::create('user_tt_token') ->withValue('fdsfssdfsdfsdfsdfsdf') ->withExpires(strtotime('tomorrow')) ->withPath('/') ->withDomain('localhost') // 设置域名 ->withSecure(false) // 是否仅在 HTTPS 下传输 ->withHttpOnly(false) // 是否禁止 JavaScript 访问 ->withSameSite('lax'); // $response 为一个jsonResponse对象 $response->headers->setCookie($cookie); 2>前端是一个 nuxt3的SSR的 get 请求 try { let res = await $fetch<SessionTermDetailResponse>.raw( \`/api/admin/events/\${id}/event-session/term\`, { headers: { "X-SCIFORUM-API-TOKEN": config.sciforum.apiToken, "X-Switch-User": event.headers.get("X-Switch-User") ?? "", authorization: event.headers.get("authorization") ?? "", }, baseURL: config.sciforum.apiBaseUrl, } ); let cc = getCookie(event, "user_tt_token") console.log("cc is:", cc) return res; } catch (error: any) { return errorHandler(error); } 经测试，当 sameSite为lax,同时请求为 get 的时候，可以成功将cookie设置到浏览器， 但是实际上需要跨域设置cookie的时候，这种方式是不行的，需要如下修改 // 创建 Cookie 对象 $cookie = Cookie::create('user_tt_token') ->withValue('fdsfssdfsdfsdfsdfsdf') ->withExpires(strtotime('tomorrow')) ->withPath('/') ->withDomain('localhost') // 设置域名 ->withSecure(true) // 是否仅在 HTTPS 下传输 ->withHttpOnly(false) // 是否禁止 JavaScript 访问 ->withSameSite('none'); // $response 为一个jsonResponse对象 $response->headers->setCookie($cookie); 即 SameSite 为 none, 同时 Secure 为 true，但是这个需要 https 环境，目前还没有测试. 看了其它的网站，都是这么处理的，这也可以叫允许三方网站cookie。 还有需要注意的是
1> $fetch 请求，需要 raw 请求，这样才能有 cookie 相关的response。
2>如果在不指定 expires 或 maxAge 时，浏览器会自动将其视为一个 Session Cookie。这类 Cookie 的生命周期仅限于当前的浏览器会话。当用户关闭浏览器后，Session Cookie 会被移除。也就是说cookie按照过期时间可以分为两类:
Session Cookie：如果未设置 expires 或 maxAge 属性，浏览器会将该 Cookie 当作 Session Cookie。这类 Cookie 的生命周期仅限于当前的浏览器会话。当用户关闭浏览器后，Session Cookie 会被移除。
持久性 Cookie：如果设置了 expires（指定过期日期）或 maxAge（指定从当前时间起的秒数），则 Cookie 会在指定的时间之后过期，无论浏览器会话是否仍在进行。 何时使用 Session Cookie
Session Cookie 常用于敏感信息（如登录会话），因为当用户关闭浏览器时，数据会被自动清除，从而提供额外的安全性。 何时使用持久性 Cookie
如果您希望用户在关闭浏览器后保持登录状态，或希望保存某些偏好设置，您可以使用持久性 Cookie，并为其设置具体的过期时间。`}]},{path:"/content/front/js/%E6%B5%8F%E8%A7%88%E5%99%A8cookie%E8%AE%BE%E7%BD%AE%E5%A4%B1%E6%95%88%E6%97%B6%E9%97%B4%E4%B8%8D%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98.html",title:"浏览器cookie设置失效时间不生效问题",pathLocale:"/",contents:[{header:"",slug:"",content:`今天在弄cookie的时候，需要设置过期时间，如下是我的代码:
public function onAuthenticationSuccess(Request $request, TokenInterface $token): RedirectResponse|Response { /** @var User $user */ $user = $token->getUser(); $userInfo = []; if ($user) { $userInfo['id'] = $user->getId(); $userInfo['email'] = $user->getEmail(); $userInfo['firstName'] = $user->getFirstName(); $userInfo['middleName'] = $user->getMiddleName(); $userInfo['lastName'] = $user->getLastName(); $userInfo['isAdmin'] = count($user->getRoles()) > 1 ? 1 : 0; $userInfo['image'] = $user->getImage(); $userInfo['avatar'] = $user->getAvatar(); } //设置过期时间，symfony5.4 框架会把下面这个时间戳格式化为UTC格式，北京时间少八个小时 //开始我为了测试用 time() + 60; 然后盯着(期间也不停地刷新浏览器)浏览器等待60s，却发现最然设置了过期时间，但是 //cookie数据还在，后来我想是不是 UTC的缘故，又把时间设置为:time() + 8 * 3600 + 60， //多加8小时，也不行，其实 虽然加了8小时，但是cookie过期的时间格式依然是:2023-05-09T00:46:49.518Z (UTC) //所以，time() + 60; 这样就可以了，然后关闭浏览器，再打开，再看，大约60s，以后 数据自动清除 //总结就是：这个过期时间会在关闭浏览器再打开才会体现出来. $expireTime = time() + 3600; $response = $this->httpUtils->createRedirectResponse($request, $this->determineTargetUrl($request)); $cookie = new Cookie('userInfo', json_encode($userInfo), $expireTime, '/', null, null, false); $response->headers->setCookie($cookie); return $response; }`}]},{path:"/content/front/js/%E8%A7%A3%E5%86%B3vue%E8%B7%AF%E7%94%B1%E8%B7%B3%E8%BD%AC%E5%90%8C%E4%B8%80%E9%A1%B5%E9%9D%A2%E9%A1%B5%E9%9D%A2%E4%B8%8D%E5%88%B7%E6%96%B0%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"解决vue路由跳转同一页面，携带不同参数，页面不刷新的问题",pathLocale:"/",contents:[{header:"",slug:"",content:"解决方法就是，通过watch 监听路由的变化 created() { this.itemId = this.$route.query.item_id this.getUserInfo() }, watch: { '$route'(to, from) { if (to.name === 'user-info'){// if 防止页面跳转到其它路由，多次触发的问题 this.itemId = this.$route.query.item_id this.getUserInfo() } } },"}]},{path:"/content/front/js/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Elint-staged%E5%92%8Cprettier%E4%BD%BF%E7%94%A8%E7%9A%84%E4%BE%8B%E5%AD%90.html",title:"记录一个关于lint-staged 配合 prettier使用的例子",pathLocale:"/",contents:[{header:"",slug:"",content:`记录一个关于lint-staged 配合 prettier使用的例子:
1>在package.json下添加如下依赖
"lint-staged": "^13.3.0",
"prettier": "^3.2.5", 然后安装依赖 npm install 2>在 .husky下的 pre-commit文件下加如下内容(无需在package.json的 scripts 下添加 "lint-staged": "lint-staged")
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh" npx lint-staged 3>配置 .lintstagedrc.js 文件 // 这个配置文件使用的是标准的 JavaScript 模块语法 (module.exports)。
module.exports = { "*.{js,ts,vue}": ["prettier --write", "eslint --cache --fix"], "*.{scss, md}": ["prettier --write"],
}; 或者 .lintstagedrc.mjs // 这是一个 ECMAScript 模块 (ES 模块)
export default { "*.{js,ts,vue}": ["prettier --write", "eslint --cache --fix"], "*.{scss,md}": ["prettier --write"],
} .mjs 后缀名表示这是一个 ECMAScript 模块 (ES 模块)。ES 模块是 JavaScript 模块系统的官方标准化版本,它具有以下特点: 导入/导出语法不同: ES 模块使用 import 和 export 语法,而不是 require() 和 module.exports。
文件扩展名: 具有 .mjs 扩展名的文件被认为是 ES 模块。这有助于与旧版本的 Node.js 区分开来。
严格模式: ES 模块自动运行在严格模式下。
顶层 this 为 undefined: 在 ES 模块的顶层作用域中, this 的值为 undefined。
无节点环境污染: ES 模块通过各自的命名空间来组织其内部元素。 如果您使用的是较新版本的 Node.js (>12 版本),并且想要尝试使用 ES 模块语法,可以为配置文件指定 .mjs 扩展名。然后您可以使用 import/export 语法来定义配置,而不是 module.exports。 4>修改代码
只是修改一些格式的话，提交会报下面的错误
报:lint-staged prevented an empty git commit 问题
原因是:
lint-stage error out saying it was an empty git commit - a commit with no changes. No changes because all the changes I made were formatting changes, which were wrong according to prettier and it fixed it back and on doing so, there was no changes left to even be committed to git.
翻译过来就是:
lint-stage 出错，说这是一个空的 git 提交--一个没有改动的提交。没有改动是因为我做的所有改动都是格式上的改动，而根据 prettier，这些改动都是错误的，它把这些改动都改回来了，这样一来，就没有任何改动可以提交到 git 了。 所以验验证 lint-staged 是否生效，不要只修改代码格式，比如故意敲空格什么的，要真正的修改代码内容，同时如果在修改了代码内容的时候，改了代码格式的话，lint-staged 就会生效，自动格式化代码，并且不会报错 参考:
https://stackoverflow.com/questions/71420124/how-do-i-solve-this-empty-git-commit-warning
https://karuppiah7890.github.io/blog/posts/lint-staged-lint-your-staged-files/
https://git-scm.com/docs/git-commit#Documentation/git-commit.txt---no-verify`}]},{path:"/content/llm/ai/dify%E5%B7%A5%E5%85%B7.html",title:"dify工具",pathLocale:"/",contents:[{header:"",slug:"",content:`dify工具:
https://dify.ai/`}]},{path:"/content/llm/ai/ollama%E6%9C%AC%E5%9C%B0%E5%88%9D%E6%AC%A1%E5%B0%9D%E8%AF%95%E4%BD%BF%E7%94%A8.html",title:"ollama本地初次尝试使用",pathLocale:"/",contents:[{header:"",slug:"",content:`ollama本地初次尝试使用: 安装 $ curl -fsSL https://ollama.com/install.sh | sh
>>> Installing ollama to /usr/local
>>> Downloading Linux amd64 CLI
######################################################################## 100.0%##O=# # >>> Making ollama accessible in the PATH in /usr/local/bin
>>> Creating ollama user...
>>> Adding ollama user to render group...
>>> Adding ollama user to video group...
>>> Adding current user to ollama group...
>>> Creating ollama systemd service...
>>> Enabling and starting ollama service...
Created symlink /etc/systemd/system/default.target.wants/ollama.service → /etc/systemd/system/ollama.service.
>>> The Ollama API is now available at 127.0.0.1:11434.
>>> Install complete. Run "ollama" from the command line.
WARNING: No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode. 查看版本 $ ollama --version
ollama version is 0.3.6 访问服务 可以通过如下访问本地ollama服务:
http://127.0.0.1:11434/ 修改service文件,在环境变量后添加 "OLLAMA_HOST=0.0.0.0", 这样便于后续在容器中运行的OpenWebUI可以访问到Ollama API服务 $ sudo vim /etc/systemd/system/ollama.service
[Unit]
Description=Ollama Service
After=network-online.target [Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=.:/usr/local/jdk-17/jdk-17.0.7/bin:/usr/local/jdk-17/jdk-17.0.7/lib:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/usr/local/go/bin:/home/guoshipeng/Documents/go/bin" "OLLAMA_HOST=0.0.0.0" [Install]
WantedBy=default.target
修改后执行:
systemctl daemon-reload
systemctl restart ollama ollama 相关命令 $ ollama --help
Large language model runner Usage: ollama [flags] ollama [command] Available Commands: serve Start ollama create Create a model from a Modelfile show Show information for a model run Run a model pull Pull a model from a registry push Push a model to a registry list List models ps List running models cp Copy a model rm Remove a model help Help about any command Flags: -h, --help help for ollama -v, --version Show version information Use "ollama [command] --help" for more information about a command. ollama 模型库 ollama模型库:https://ollama.com/library 使用 ollama 跑一个模型 $ ollama run qwen2:1.5b ollama 列出本地易安装模型 ollama list //用于列出本地安传的model
NAME ID SIZE MODIFIED qwen2:1.5b	f6daf2b25194	934 MB	About an hour ago ollama api使用文档 https://github.com/ollama/ollama/blob/main/docs/api.md //非常详细的介绍了api的使用，包含各种操作，增删改查都有
其中这个:
Send a chat message with a conversation history. You can use this same approach to start the conversation using multi-shot or chain-of-thought prompting.
curl http://localhost:11434/api/chat -d '{ "model": "llama3", "messages": [ { "role": "user", "content": "why is the sky blue?" }, { "role": "assistant", "content": "due to rayleigh scattering." }, { "role": "user", "content": "how is that different than mie scattering?" } ]
}' 这个主要是把chat的上下文再每次chat的时候一起传递给接口，用于创建语境，我打算用另一种方式实现，到时候新开一篇 本地docker部署open-webui $ docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
^[[CUnable to find image 'ghcr.io/open-webui/open-webui:main' locally
main: Pulling from open-webui/open-webui
e4fff0779e6d: Already exists d97016d0706d: Pull complete 53db1713e5d9: Pull complete a8cd795d9ccb: Pull complete de3ba92de392: Pull complete 6f4d87c224b0: Pull complete 4f4fb700ef54: Pull complete dd92a6022ddb: Pull complete bbbfed48a772: Pull complete a825beebdb5b: Pull complete 638c7f4708d7: Pull complete dcd98ca2af09: Pull complete a3a183a1eb40: Pull complete a3b19b039cc9: Pull complete f86974dcccd6: Pull complete d026397a4a16: Pull complete Digest: sha256:d05b69e71c8011d3031c159aff1ed4942d3c0d98d1c531ae267962bcdcb603a6
Status: Downloaded newer image for ghcr.io/open-webui/open-webui:main
25c7f24d49b7b4de3d1924e6c36354d5895fcefbd47e5b8889636a2fe2f9bf9e 然后可以通过 http://localhost:3000/ 访问open-webui，首次需要注册账号，然后可以选择本地已经安装的模型进行对话，我发现通过这个webui可以实现上下文对话，但是直接通过之前提到的API确不行，不知道为什么，后来发现是因为每次把之前的chat记录一起发给后台了，我想这个对于普通服务器来说，压力还是很大的，因为有很多数据需要处理和存储。 总结一下:
首先，想玩大模型，不管他天花乱坠整各种黑话什么Agent、ChatBot，其实我们要看的核心组件无非就是两个：训练好的大模型，以及UI界面。于是就有各种开源大佬在这两方面下手了。大模型的收集和调用方面，由ollama提供支持（ollama一键在本地运行大模型，被运行的模型可以像API一样被调用），而UI界面方面，则有open-webui、lobe-chat等。本次主要关注ollama和open-webui。`}]},{path:"/content/llm/ai/pythos3%E5%90%AF%E5%8A%A8http%E6%9C%8D%E5%8A%A1.html",title:"pythos3启动http服务",pathLocale:"/",contents:[{header:"pythos3启动http服务",slug:"pythos3启动http服务",content:`在当前项目下，运行如下命令$ python3 -m http.server 8089
Serving HTTP on 0.0.0.0 port 8089 (http://0.0.0.0:8089/) ...
127.0.0.1 - - [17/Oct/2025 09:44:37] "GET /books.xml HTTP/1.1" 200 -
127.0.0.1 - - [17/Oct/2025 09:44:37] "GET /style-reporter.xsl HTTP/1.1" 200 -
127.0.0.1 - - [17/Oct/2025 09:44:37] code 404, message File not found
127.0.0.1 - - [17/Oct/2025 09:44:37] "GET /favicon.ico HTTP/1.1" 404 -
127.0.0.1 - - [17/Oct/2025 09:45:23] "GET /books.xml HTTP/1.1" 304 -
127.0.0.1 - - [17/Oct/2025 09:45:23] "GET /style-reporter.xsl HTTP/1.1" 304 -
127.0.0.1 - - [17/Oct/2025 09:46:42] "GET /books.xml HTTP/1.1" 304 -
127.0.0.1 - - [17/Oct/2025 09:46:42] "GET /style-reporter.xsl HTTP/1.1" 200 然后可以直接通过 服务地址，比如： http://0.0.0.0:8089/ 打开静态文件`}]},{path:"/content/llm/ai/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B7%A5%E5%85%B7.html",title:"大模型工具",pathLocale:"/",contents:[{header:"",slug:"",content:`大模型工具:
使用 gguf 格式的开源模型:
https://huggingface.co/models?library=gguf&sort=trending FROM ./LongWriter-llama3.1-8b-IQ2_M.gguf 使用 huggingface 中的模型:
https://cloud.tencent.com/developer/article/2440918 gemma2模型:
https://huggingface.co/blog/zh/gemma2
https://huggingface.co/models?sort=downloads&search=gguf+gemma2 优秀博客，可以用来借鉴:
https://www.cnblogs.com/obullxl/p/18280727/NTopic2024070201 google 博客:
https://blog.google/technology/developers/google-gemma-2/ llava模型(主要有图片分析功能):
https://ollama.com/library/llava https://ollama.com/library/minicpm-v ollama使用指南:
https://github.com/datawhalechina/handy-ollama/blob/main/docs/C4/1.%20Ollama%20API%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.md 技术网站:
https://www.jiqizhixin.com/ 魔塔社区：
https://modelscope.cn/home yolo图像识别，这个好像没有官网，都是各个大学自己实现的版本:
https://pjreddie.com/darknet/yolo/ //介绍
https://www.yoloworld.cc/ //实用(腾讯出品)
https://github.com/THU-MIG/yolov10 //清华大学的 excalidraw画板工具:
https://github.com/excalidraw/excalidraw
https://excalidraw.com/ obsidian 笔记软件:
https://obsidian.md/ 上面两者配合使用:
https://www.bilibili.com/video/BV1pm421V7Ux`}]},{path:"/content/other/git/centos7%E4%B8%8Bgithub%E7%9A%84ssl%E9%93%BE%E6%8E%A5%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"centos7下github的ssl链接失败的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`centos7下使用wget github资源，可能会报如下错误:
Resolving github.com (github.com)... 20.205.243.166
Connecting to github.com (github.com)|20.205.243.166|:443... connected.
Unable to establish SSL connection.
解决办法如下加上：--no-check-certificate 即可:
[root@worker1 local]# wget https://github.com/Dreamacro/clash/releases/download/v1.14.0/clash-linux-amd64-v1.14.0.gz --no-check-certificate`}]},{path:"/content/other/git/github%E4%B8%8A%E6%8B%89%E5%8F%96%E8%87%AA%E5%B7%B1%E7%9A%84%E7%A7%81%E6%9C%89%E9%A1%B9%E7%9B%AE.html",title:"github上拉取自己的私有项目",pathLocale:"/",contents:[{header:"",slug:"",content:`github上拉取自己的私有项目，现在不允许使用 password方式，改用ssh方式
1>将自己主机上的 ~/.ssh/id_rsa.pub 复制出来，粘贴到github的个人settings下的 ssh key下
2>直接 git clone git@github.com:xxx/vue-blog.git
可能会报:
Cloning into 'vue-blog'...
ssh: connect to host github.com port 22: Connection timed out
fatal: Could not read from remote repository. Please make sure you have the correct access rights
and the repository exists. 这个可能是本机的22端口被屏蔽(通过 telnet github.com 22 测试一下，大概率超时)，解决方案使用443：
$ sudo vim ~/.ssh/config
在里面配置如下内容(port也可以配置为22，然后试一试):
Host github.com
Hostname ssh.github.com
User git
Port 443
IdentityFile ~/.ssh/id_rsa 然后保存，通过下面的命令测试是否可以连接github
$ ssh -T git@github.com
Hi gspgsp! You've successfully authenticated, but GitHub does not provide shell access. 3>再次执行 git clone git@github.com:xxx/vue-blog.git 就可以拉下代码 4>配置分析
User git 这一行表示 连接 GitHub 时使用 git 用户，这是 GitHub SSH 访问的标准方式。
在 ~/.ssh/config 里，User git 告诉 SSH 连接 GitHub 时使用 git 用户
相当于让 SSH 在执行 ssh git@github.com 时 默认使用 git 作为用户名。
ssh -T git@github.com
这里等价于
ssh -T github.com
因为 ~/.ssh/config 里已经指定 User git 5>如果需要重新生成ssh-key,可以执行
ssh-keygen -t rsa -b 4096 -C "your-email@example.com"
也可以执行
ssh-keygen -t ed25519 -C "your_email@example.com" 二者对比:
RSA:
算法：RSA（Rivest–Shamir–Adleman）
密钥长度：你指定了 -b 4096（推荐，默认是 2048）
兼容性：适用于所有 SSH 服务器和旧系统（兼容性最好）
安全性：4096 位密钥仍然安全，但 RSA 算法随着计算能力提升，未来可能不如更现代的算法
速度：相比 Ed25519，RSA 密钥较长，加密/解密稍慢
适用场景：如果你需要在一些 旧系统（比如老版本 OpenSSH） 上使用 SSH，建议选 RSA Ed25519（更现代的算法):
算法：Ed25519（基于椭圆曲线）
密钥长度：固定 256 位（更短，但安全性比 4096 位 RSA 还强）
兼容性：需要 OpenSSH 6.5+（2014 年之后的系统一般都支持）
安全性：比 RSA 2048/4096 更安全，抗量子攻击能力更强
速度：更快（计算效率高，适合高并发）
适用场景：适用于 GitHub、GitLab、服务器 SSH 登录，如果你不需要支持 非常旧的 SSH 服务器，推荐使用 Ed25519`}]},{path:"/content/other/git/github%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E5%88%86%E6%94%AF%E5%90%8D%E7%A7%B0.html",title:"github查看当前分支名称",pathLocale:"/",contents:[{header:"git查看当前分支名称:",slug:"git查看当前分支名称",content:`$ git branch --show-current
dev`},{header:"git本地分支模糊查询",slug:"git本地分支模糊查询",content:`$ git branch --list | grep 1638
* feat/TG-1638_adjust-style-token`},{header:"git远程分支模糊查询",slug:"git远程分支模糊查询",content:"$ git branch -r --list | grep 1584 origin/feat/TG-1584_stepper-api"}]},{path:"/content/other/git/gitkeep%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%9C%E7%94%A8.html",title:"gitkeep文件的作用",pathLocale:"/",contents:[{header:"",slug:"",content:`gitkeep文件的作用:
.gitkeep 在代码库中是很常见的，如果需要让 Git 追踪一个空文件夹，那其中一般会有这个文件。 这个虚拟文件的名字不一定总是 .gitkeep，也可以看到.gitignore， 其实是一样的作用。但是 .gitignore是由自己的真是作用的，就是说明哪些
文件需要被忽略掉，所以推荐使用 .gitkeep`}]},{path:"/content/other/git/gitlab-runner%E4%BD%BF%E7%94%A8.html",title:"gitlab-runner使用",pathLocale:"/",contents:[{header:"",slug:"",content:`gitlab-runner使用:
安装/部署:
https://www.cnblogs.com/scajy/p/15661187.html https://juejin.cn/post/6844903937091321864 一个基于php的hook.php
<?php
set_time_limit(90); //这一行将当前请求的 $_SERVER 变量的内容以 JSON 格式写入到 /tmp/hook.out 文件中，可能是为了调试或者记录请求的信息。
file_put_contents('/tmp/hook.out', json_encode($_SERVER)); //这里定义了一组被允许的 Git 仓库路径，使用 GitLab Token 作为索引。如果请求中的 Token 不在这个列表中，脚本会提前结束。
$allowedTokens = [ 'pj1' => '/var/www/git/branches/pj1/dev', 'pj2' => '/var/www/git/branches/pj2t/dev',
]; $token = isset($_SERVER['X-Gitlab-Token']) ? $_SERVER['X-Gitlab-Token'] : ''; if (!isset($allowedTokens[$token])) { return;
} //执行 Git Pull 命令
$cmd = "cd $allowedTokens[$token] && git pull";
var_dump(shell_exec($cmd)); 上面这个只是一个基于gitlab-runner的php脚本程序，其实还有更灵活的方法实现，后面再整理一个`}]},{path:"/content/other/git/gitlab%E4%B9%8Bgitlab_server_hook.html",title:"gitlab之gitlab_server_hook",pathLocale:"/",contents:[{header:"",slug:"",content:`gitlab之gitlab_server_hook:
https://github.com/gitlabhq/gitlabhq/blob/667c0a909bde1cf71f21d8ec9768e98b1c489030/doc/hooks/custom_hooks.md
https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks#Server-Side-Hooks
https://gitbook.curiouser.top/origin/gitlab-server-hook.html //文章
https://docs.gitlab.com/ee/administration/server_hooks.html //官网`}]},{path:"/content/other/git/gitlab%E4%B9%8B%E5%88%9B%E5%BB%BAaccess_token.html",title:"gitlab之创建access_token",pathLocale:"/",contents:[{header:"",slug:"",content:`gitlab之创建access_token:
参考文档: https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html`}]},{path:"/content/other/git/gitlab%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BA%E5%88%86%E6%94%AF%E6%97%A5%E5%BF%97.html",title:"gitlab服务器创建分支日志",pathLocale:"/",contents:[{header:"",slug:"",content:`gitlab服务器创建分支日志(主要涉及 通过git push 在远程创建分支的记录):
k8s@HPDEV-31:~/code/yizhi-frontend-v2$ git push origin yizhi-821:yizhi-821
Total 0 (delta 0), reused 0 (delta 0), pack-reused 0
remote: remote: To create a merge request for yizhi-821, visit:
remote: https://gitlab.k8s.com:8081/dev/yizhi-frontend-v2/-/merge_requests/new?merge_request%5Bsource_branch%5D=yizhi-821
remote: remote: Sending mail...
remote: clone new project
remote: Creating branch yizhi-frontend-v2@yizhi-821
remote: Loading git hook: /var/www/gitlab-hooks/hooks/yizhi-frontend-v2.sh
remote: Creating new branch yizhi-821 ...
remote: Cloning into 'yizhi-821'...
remote: Warning: Permanently added '[gitlab.k8s.com]:9922' (ED25519) to the list of known hosts.
remote: Run npm install or composer install here after a new branch is created, branch: yizhi-821.
remote: npm WARN ERESOLVE overriding peer dependency
remote: npm WARN While resolving: @typescript-eslint/eslint-plugin@7.13.0
remote: npm WARN Found: eslint@9.5.0
remote: npm WARN node_modules/eslint
remote: npm WARN dev eslint@"^9.5.0" from the root project
remote: npm WARN 20 more (@eslint-community/eslint-utils, ...)
remote: npm WARN ...
...
remote: └─ .output/server/package.json (1.66 kB) (759 B gzip)
remote: Σ Total size: 25.1 MB (9.24 MB gzip)
remote: [nitro] ✔ You can preview this build using node .output/server/index.mjs
remote: ┌────┬───────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐
remote: │ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │
remote: └────┴───────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘
remote: [PM2][WARN] Applications yizhiFrontend not running, starting...
remote: [PM2][ERROR] Error: Script not found: /app/.output/server/index.mjs
To ssh://gitlab.k8s.com:9922/dev/yizhi-frontend-v2.git * [new branch] yizhi-821 -> yizhi-821 这个日志主要是为了说明，在gitlab push创建分支的时候，使用到自定义的git hook(git server端)，创建指定的分支，以及初始化分支项目,关于 git hook 脚本我在另一篇文章中有介绍`}]},{path:"/content/other/git/git%E4%B9%8BFast-forward%E6%A8%A1%E5%BC%8F.html",title:"git之Fast-forward模式",pathLocale:"/",contents:[{header:"",slug:"",content:`git之Fast-forward模式:
1. 问题
git merge branch 没有产生新的提交信息，而是直接将 dev branch 的提交信息直接迁移过去。如何才能 merge branch 的时候，产生一次新的提交呢？ 2. 原因
为什么直接 merge 没有产生一次新的提交呢？
如果我们的祖先分支以 master 为例，再 checkout 一个新的分支（bugfix）后，产生了新的提交，与此同时，其他的开发分支没有往 master 合并新的提交。
这样，新的分支与 master 分支的最新提交历史是共同的祖先。但这种模式下，删除分支后，会丢掉分支信息。
此时，merge bugfix 分支后， master 拥有 bugfix 全部的提交，所以当合并到master 分支后，master 的 HEAD 会直接指向最新的 bugfix 提交历史上。不会产生新的提交。git 采用的模式即称为 fast-forward 模式（快进模式） 3. 解决方案
在合并的时候，我们可以禁用 fast-forward 这种合并策略即可。操作指令如下：
# --no-ff 即 no-fast-forward 禁用快进模式
$ git merge --no-ff -m "merge with no-ff" dev //这里将 dev 分支合并到 master 分支，同时启用 --no-ff 模式，这样就可以在master分支上看到一条新的合并记录 git之ort策略:
在实际使用中，查看git log 会发现：merge dev: Merge made by the 'ort' strategy，一时不知道这个ort策略是干啥的，所以记录一下
ort 策略是 Git 发布v2.33.0 版本时新增的一种合并策略。
ort 策略实际上是此前 recursive 策略（与之相对的另一种通常是 fast-forward策略）的重构，解决了一些功能问题和性能问题。
GitHub 报告称 merge-ort 能够在有许多文件重命名场景的合并过程中加速超过 500 倍，在一些具有 rebase 操作的情况能加速 9000 倍。总而言之，这个 merge-ort 策略稳定地比现有的合并代码方案更高效。 原文:
Git 2.33 brings the latest patches around geometric repacking, "merge-ort" as a new merge strategy for handling Git merges across branches, and a number of bitmap-related optimizations. There is also the usual assortment of fixes and smaller items.
Git's new merge-ort strategy is a scratch rewrite of its recursive strategy but addresses correctness and performance problems. GitHub reports merge-ort can be as much as a "500x" speed-up for large merges with many renames. Merge-ort for merges in a re-base operation can be a speed-up of over 9000x. The new merge-ort should perform consistently faster than the existing merge code.`}]},{path:"/content/other/git/git%E4%B9%8BPR%E5%92%8CMR%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"git之PR和MR的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`git之PR和MR的区别:
- 什么是Pull Request? PR 的全称是Pull Request，经常用 Github 的同学对这个肯定很熟悉了。Github 聚集了4000万开发者，过亿的开源项目，如果想给别人的开源仓库贡献代码，通常是先 fork 别人的项目，然后本地修改完成提交到自己的个人 fork 仓库，最后提交 PR 等待别人合入你的代码。 既然 Github 坚持叫“pull request”，我们试着理解一下它的思路，小明写完代码了心里肯定是在想：原作者大神，我改了点东西，你快把我的修改拉回去吧。站在原作者的角度思考，叫pull request好像也说得过去，每天有大量的人从我这里 fork 代码走，我只会拉取我感兴趣的代码回来。 - 什么是 Merge Request?
MR 的全称是 Merge Request，相信玩过 Gitlab 的同学都知道这个 总结一下:
Github 是玩 fork 模式的，开发者提交自己的代码新建 Pull Request，请求原作者：“把我的代码拉回去吧”。 Gitlab 是玩分支模式的，开发者提交自己的代码新建 Merge Request，想将自己的特性分支合并到主干。`}]},{path:"/content/other/git/git%E4%B9%8Bcheckout%E7%9A%84%E5%A4%9A%E4%B8%AA%E7%94%A8%E9%80%94.html",title:"git之checkout的多个用途",pathLocale:"/",contents:[{header:"",slug:"",content:`使用git checkout除了可以切换分支外，还可以迁出(恢复)指定文件
git checkout 恢复文件
www@HPDEV-31:~/code/www/frontend$ git checkout pages/index.vue //以前常用方式,最简单的方式
Updated 1 path from the index www@HPDEV-31:~/code/www/frontend$ git checkout -- pages/index.vue //使用 -- 方式, 不指定分支，默认是当前分支
www@HPDEV-31:~/code/www/frontend$ git checkout guoshipeng -- pages/index.vue //使用 -- 方式, 指定分支`}]},{path:"/content/other/git/git%E4%B9%8Bclone%E4%BB%A3%E7%A0%81.html",title:"git之clone代码",pathLocale:"/",contents:[{header:"",slug:"",content:`git之clone代码:
git clone -b <远程分支名> <远程仓库地址> [<本地分支名>]`}]},{path:"/content/other/git/git%E4%B9%8Binit%E6%97%B6%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98.html",title:"git之init时用户权限问题",pathLocale:"/",contents:[{header:"",slug:"",content:`git之init时用户权限问题:
执行 git init 的时候，如果当前项目已经存在，同时项目的所有者和用户组不是当前用户的时候，会报错，解决办法：修改当前项目的 owner:group 为当前用户
如： $ sudo chown -R k8s:k8s ./docker-script/`}]},{path:"/content/other/git/git%E4%B9%8Borigin%E7%9A%84%E5%90%AB%E4%B9%89.html",title:"git之origin的含义",pathLocale:"/",contents:[{header:"",slug:"",content:"git之origin的含义: 简单的来说就是给远程主机取了一个别名，由于远程主机一般是一个url，太长了，操作起来挺麻烦，所以就给它起了一个名字，默认一般叫 origin"}]},{path:"/content/other/git/git%E4%B9%8Bort%E6%A8%A1%E5%BC%8F.html",title:"git之ort模式",pathLocale:"/",contents:[{header:"",slug:"",content:`git之ort模式:
当 GitHub 创建合并提交时，比如测试一个拉取请求是否能被干净合并，
或者实际合并一个拉取请求，它现在使用 merge-ort 策略。 merge-ort 是一种相对较新的 Git 合并策略，它的速度明显更快（例如，
以前需要 5 秒或更长时间才能创建的复杂合并提交，现在只需不到 200 毫秒即可创建），并解决了 merge-recursive 策略中发现的细微的正确
性问题。此外，在最新发布的 Git 中，merge-ort 是默认的合并策略，
因此合并结果在本地机器和 GitHub 之间更可预测，也更一致。 //手动指定策略
git merge -s ort <branch>`}]},{path:"/content/other/git/git%E4%B9%8Bpost-merge%E9%92%A9%E5%AD%90%E5%87%BD%E6%95%B0.html",title:"git之post-merge钩子函数",pathLocale:"/",contents:[{header:"",slug:"",content:`git之post-merge钩子函数:
在使用这个钩子函数之前，先补充一个git pull 的原理:
git pull 包含两个操作，git fetch和git merge
git fetch：将远程仓库拉取到本地仓库
git merge：将本地仓库与分支进行merge
git pull执行时，会先向远程发送git-upload-pack请求，携带是本地仓库commit的记录，如果一样就不需要拉取，不一样就将远程仓库拉取下来。
所以可以通过git pull或者 git merge 触发这个钩子函数.
打开项目的 .git目录，然后打开里面的hooks目录，会发现各种 .sample结尾的钩子函数.
vim post-merge 新建文件，根据项目pull之后需要执行的操作，添加脚本，这里给个例子:
#!/bin/bash echo 'composer install'
php8.1 /usr/bin/composer install echo "invoking schema update"
php8.1 bin/console doctrine:migrations:migrate #yarn
echo 'build admin resource'
yarn run dev #web
echo 'build web resource'
cd web-project
yarn build #restart service
supervisorctl restart web:web_project_00 exit 0 经过上面的操作，php 安装指定的依赖 数据库迁移 以及相关静态资源的打包；nuxt 打包资源; supervisorctl 重启守护进程`}]},{path:"/content/other/git/git%E4%B9%8Bprune.html",title:"git之prune",pathLocale:"/",contents:[{header:"",slug:"",content:`git之prune:
git remote prune 命令用于删除远程追踪的已不存在的远程引用。当你从远程仓库获取数据时,Git会自动为你存储远程分支引用,以便于你可以随时访问它们。但有时,某些远程分支可能已经被删除,此时,本地的远程分支引用就变成了悬空引用。
执行 git remote prune 可以清理掉这些已经被删除的远程分支引用。具体作用如下: 1>查询远程仓库,获取远程分支的更新信息。
2>将本地已不存在于远程的远程分支引用全部删除。
3>如果使用 git remote prune <远程名>的形式,则只针对指定的远程进行 prune 操作。 通常在获取远程更新前执行 git remote prune 是一个好习惯,可以确保本地仓库的远程分支引用保持最新、有效的状态。不过,这并不会影响已经拉取到本地的远程分支代码。
需要注意的是,git remote prune 只会删除远程分支引用,不会删除本地分支。如果你想删除本地分支,需要使用 git branch -D <分支名>。 实操:
$ git remote prune
usage: git remote prune [<options>] <name> -n, --dry-run dry run 这个报错是因为你执行 git remote prune 命令时没有指定远程仓库名称。
正确的用法是:
git remote prune <远程仓库名称>
例如，如果你的远程仓库名称是 origin，那么命令应该是:
git remote prune origin
这个命令会删除本地存储的已不存在于远程 origin 仓库的远程分支引用。
如果你想查看哪些分支将被删除而不实际执行删除操作,可以使用 --dry-run 选项:
git remote prune --dry-run origin
它会显示将要被删除的远程分支引用列表,但不会真的删除它们。
所以总结一下,正确的用法是: 1>git remote prune <远程仓库名称> - 删除指定远程仓库不存在的远程分支引用`}]},{path:"/content/other/git/git%E4%B9%8Bpull%E5%88%86%E6%94%AF%E6%8A%A5%E9%94%99fatalNeedToSpecifyHowToReconcileDivergentBranches.html",title:"git之pull分支报错fatalNeedToSpecifyHowToReconcileDivergentBranches",pathLocale:"/",contents:[{header:"",slug:"",content:`git pull 分支报错 fatal: Need to specify how to reconcile divergent branches...
分析：这是由于你拉取pull分支前，进行过merge合并更新分支操作，而其他人在你之前已经push过一个版本，导致版本不一致
第一种解决方法：比较简单 执行git config pull.rebase false
默认将pull下来的代码与现有改动的代码进行合并
但是可能会造成代码冲突，需要处理下这个问题，代码冲突如果2个人都改了同一个文件，需要联系之前push的同学，看看这块代码怎么保存 第二种解决方法：回退到合并之前的代码，在进行pull拉取最新代码 git pull 语法记录:
git pull <远程主机名> <远程分支名>:<本地分支名>
例如执行下面语句： git pull origin master:brantest 将远程主机origin的master分支拉取过来，与本地的brantest分支合并。 后面的冒号可以省略： git pull origin master //这种方式在之前公司里，新手特别喜欢使用 表示将远程origin主机的master分支拉取过来和本地的当前分支进行合并。 上面的pull操作用fetch表示为： git fetch origin master:brantest git merge brantest 相比起来git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。`}]},{path:"/content/other/git/git%E4%B9%8Bpull%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98.html",title:"git之pull报错问题",pathLocale:"/",contents:[{header:"git之pull报错问题",slug:"git之pull报错问题",content:`1.今天在做code review的时候，发现个问题，开发修改了代码，然后我拉取的时候一直报: hint: You have divergent branches and need to specify how to reconcile them. hint: You can do so by running one of the following commands sometime before hint: your next pull: hint: hint: git config pull.rebase false # merge (the default strategy) hint: git config pull.rebase true # rebase hint: git config pull.ff only # fast-forward only hint: hint: You can replace "git config" with "git config --global" to set a default hint: preference for all repositories. You can also pass --rebase, --no-rebase, hint: or --ff-only on the command line to override the configured default per hint: invocation. Need to specify how to reconcile divergent branches. 这个很奇怪，我本地没有任何修改，怎么就报这个呢，后来才知道，我之前做过一次git pull(习惯性pull一下最新代码)，但是Git 可能在后台帮我生成了一个 merge commit（未提交状态）。
所以现在本地分支比远程“多了一个提交”，哪怕自己没改代码。
这个报错是因为在 git pull 的时候，本地分支和远程分支产生了 分歧 (divergent branches)，Git 不知道是想用 merge、rebase 还是只允许 fast-forward。 通过如下命令可以查看本地状态：
git status
git log --oneline --graph --decorate -n 10`},{header:"报错信息已经给出了三种解决方式：",slug:"报错信息已经给出了三种解决方式",content:""},{header:"1. 直接指定一次性解决方式",slug:"_1-直接指定一次性解决方式",content:`合并 (merge, 默认行为)：
git pull --no-rebase 会生成一个 merge commit。 变基 (rebase)：
git pull --rebase //我使用这种方式解决问题,非常有用 会把本地提交“放到”远程提交之后，保持提交线性。 只允许快进 (fast-forward only)：
git pull --ff-only 如果不能直接快进，就会报错，不会自动合并。`},{header:"2. 永久修改配置",slug:"_2-永久修改配置",content:`如果想以后都用某种策略，可以设置 git config： 所有仓库都生效（推荐，除非某仓库有特殊需求）：
git config --global pull.rebase false # 默认 merge
git config --global pull.rebase true # 默认 rebase
git config --global pull.ff only # 只允许 fast-forward 只对当前仓库生效：
git config pull.rebase true`},{header:"git pull --no-rebase 和 --rebase的区别:",slug:"git-pull-no-rebase-和-rebase的区别",content:"这两个参数就是 Git 在遇到“本地有提交 + 远程也有提交”时，如何把两边历史对齐的两种方式："},{header:"1. git pull --no-rebase （默认行为：merge）",slug:"_1-git-pull-no-rebase-默认行为-merge",content:`做法：先 git fetch，然后把远程分支合并进来，生成一个新的 merge commit。
结果： 提交历史可能出现分叉。
会多一个 “Merge branch 'xxx' of origin/xxx” 的提交。 优点： 历史完整，能看出谁在什么时候合并了远程代码。 缺点： 历史不够线性，可能很多 merge commit，看起来杂乱。 📌 举个例子：
A---B---C (你的本地提交) \\ D---E (远程提交) 执行 git pull --no-rebase 后：
A---B---C---M (merge commit) \\ / D---E`},{header:"2. git pull --rebase （历史线性化：rebase）",slug:"_2-git-pull-rebase-历史线性化-rebase",content:`做法：先 git fetch，然后把你本地的提交“拿掉”，把远程的提交放进来，再把你的提交“重新应用”在远程提交之后。
结果： 提交历史是直线的。
不会生成额外的 merge commit。 优点： 历史干净，容易阅读。 缺点： 会改写提交的 hash（因为 rebase 会重放提交）。
如果已经 push 过，再 rebase 可能要强推（git push -f），这对协作有风险。 📌 举个例子：
A---B---C (你的本地提交) \\ D---E (远程提交) 执行 git pull --rebase 后：
A---B---D---E---C' (C 被“重放”，变成新的提交 C')`},{header:"🔑 总结",slug:"🔑-总结",content:`--no-rebase：保留真实的合并历史，适合强调“分支合并点”的团队。
--rebase：让历史线性、干净，适合强调“整洁提交线”的团队。 👉 通常： 开源项目 / 大团队：偏向 merge（避免重写别人提交的历史）。
小团队 / 自己的项目：偏向 rebase（历史整洁）。`},{header:"git pull --ff-only的理解:",slug:"git-pull-ff-only的理解",content:""},{header:"🚀 什么是 fast-forward (快进合并)",slug:"🚀-什么是-fast-forward-快进合并",content:`Git 有两种主要的合并方式： 普通合并 (merge) 如果两个分支有分叉，Git 会创建一个新的 merge commit 来把两条线合并在一起。 快进合并 (fast-forward) 如果当前分支的 HEAD 落后于远程分支，而且 本地没有额外的提交，Git 就可以“直接把 HEAD 向前移动到远程最新提交”。
这种情况不需要生成新的 commit，历史就像直接从远程走过来的一样。`},{header:"📌 举个例子",slug:"📌-举个例子",content:`远程分支：
A---B---C---D (origin/main) 本地分支：
A---B---C (main) 这时执行：
git pull --ff-only Git 会直接把 main 指针移动到 D，结果是：
A---B---C---D (main, origin/main) 没有产生额外的 commit，历史是线性的。`},{header:"🛑 如果不能快进会怎样？",slug:"🛑-如果不能快进会怎样",content:`比如本地有提交：
A---B---C---X (main) \\ D---E (origin/main) 这种情况 没法快进（因为有分叉），
执行 git pull --ff-only 会报错：
fatal: Not possible to fast-forward, aborting. 这样避免了 Git 自动生成 merge commit，让你自己决定是要 --rebase 还是 --no-rebase。`},{header:"✅ 总结理解",slug:"✅-总结理解",content:`git pull --ff-only = 只允许快进更新，不允许自动 merge。
适用场景： 你本地没有提交，只是想更新远程代码。
想确保历史干净，不要多余的 merge commit。 好处：安全、整洁。不会悄悄帮你合并。
坏处：如果有分叉，它会报错，你得自己决定怎么解决。`},{header:"和 git pull的区别:",slug:"和-git-pull的区别",content:""},{header:"1️⃣ git pull 默认行为",slug:"_1️⃣-git-pull-默认行为",content:`默认其实是相当于： git fetch
git merge origin/当前分支 也就是说，如果本地和远程有分歧（divergent branches），Git 会 生成一个 merge commit 来合并两边的历史。
优点：保证不会丢提交，安全
缺点：可能产生额外的 merge commit，历史不够干净`},{header:"2️⃣ git pull --ff-only",slug:"_2️⃣-git-pull-ff-only",content:`只允许 快进更新，不会生成 merge commit
如果本地分支有任何提交（包括 Git 自动生成的 merge commit），就会报错
优点：历史干净、线性
缺点：不是快进的情况必须手动处理`},{header:"3️⃣ 为什么不直接用 git pull？",slug:"_3️⃣-为什么不直接用-git-pull",content:`直接 git pull 会自动 merge，如果你本地有 意外的 commit（例如 Git 自动生成的 merge commit），就可能： 生成新的 merge commit
导致历史不干净 有些团队或个人非常强调 提交历史线性，不希望出现多余的 merge commit，这时候就会选择 --ff-only 或 --rebase`},{header:"4️⃣ 总结理解",slug:"_4️⃣-总结理解",content:`命令
本地干净
本地有提交
历史结果
安全性/清洁度 git pull
✅
✅
merge commit 可能出现
安全，但历史可能杂乱 git pull --ff-only
✅
❌（报错）
快进，历史线性
历史干净，但不能有本地提交 git pull --rebase
✅
✅
历史线性
历史干净，但重写本地提交，需注意 push 💡 核心理解： git pull = 安全默认，但可能产生 merge commit
--ff-only = 历史干净，但严格要求本地无提交
--rebase = 历史干净，可处理本地提交，但改写历史`}]},{path:"/content/other/git/git%E4%B9%8Bpush%E6%88%96%E8%80%85pull.html",title:"git之push或者pull",pathLocale:"/",contents:[{header:"",slug:"",content:`git之push或者pull: git pull 1.命令
git pull <远程主机名> <远程分支名>:<本地分支名>
2.操作
git pull origin master:brantest // 也可以直接 git pull origin master，实现的效果也是取回 origin/master 分支，再与本地的 brantest 分支合并，本地分支不传递的话，默认就是当前分支名称
这个操作包括两个部分：先 fetch 再merge，表现就是：将远程主机 origin 的 master 分支拉取过来，与本地的 brantest 分支合并
所以工作中有人合并代码，就是通过直接 git pull 别的分支到当前分支，这其实有些问题的，我还是习惯相同的源做 pull/push 操作 git push
1.命令
git push <远程主机名> <本地分支名>:<远程分支名> 2.操作
git push origin brantest:dev
这个操作将本地的 brantest 分支推送到 origin 主机的 dev 分支`}]},{path:"/content/other/git/git%E4%B9%8Brebase%E8%A7%A3%E5%86%B3%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81.html",title:"git之rebase解决代码冲突",pathLocale:"/",contents:[{header:"",slug:"",content:`开发过程中经常要进行代码的合并，然而合并的时候会有冲突，下面通过rebase实现冲突的解决，这个目前是最好的方式:
git rebase 解决分支冲突的操作[适用于很多分支，很多功能一起开发的场景，前提是在已经知道有冲突的情况下，通过这种方式解决冲突，比如 gitlab下新增了merge request]
k8s@root:~/code/sciforum.net$ git rebase origin/dev
fatal: It seems that there is already a rebase-merge directory, and
I wonder if you are in the middle of another rebase. If that is the
case, please try git rebase (--continue | --abort | --skip)
If that is not the case, please rm -fr ".git/rebase-merge"
and run me again. I am stopping in case you still have something
valuable there. #如果报上面的提示，可能之前执行过rebase,这里我就执行 rm -fr ".git/rebase-merge"，然后再次执行git rebase origin/dev，那么就会提示哪些地方冲突了，直接修改文件，解决冲突 #当冲突解决完了，直接 [git add .] 然后， git commit -m 'fix conflict' [如果是首次提交的话，需要 add， 如果已经将分支推送到远程仓库，那就直接commit] k8s@root:~/code/sciforum.net$ git rebase --continue //必须要执行
dropping 43672c0b5a9a08108cd72e6ea07cf7c6f79047a2 SCIF-211 -- patch contents already upstream
Successfully rebased and updated refs/heads/SCIF-211-t. #再执行 git push --force origin <分支名>，[如果你已经将分支推送到远程仓库，并且之后对该分支进行了 git rebase 操作，那么你必须使用 --force 标志来覆盖远程分支上的历史记录。这是因为 rebase 会修改提交历史，不允许通过普通推送来更新远程分支。如果这里不用 forece的话，通过普通的push,可能会报本地和远程对应的分支冲突，需要merge，所以直接forece最好了，因为就是想把本地的应用到对应的远程.] #注意事项:
在使用这个命令的过程中，我发现一个问题，有如下场景:
比如说我的代码分值为 tt, 修改了如下内容:
$a = "hello world",
然后我执行 git rebase origin/dev
然后提示冲突，对比文件发现
左边$a="say no",右边为$a="say yes",我希望看到的是 左边为我当前的修改 $a="hello world",但是现在不是，那就没办法直接进行比对操作 解决办法是：只能删除<<<<<<< HEAD和=======之间的行，以及>>>>>>> origin/dev之后的行，然后手动把 $a="hello world" 写到这个位置 针对这个问题，我通过Chat-GPT了解到如下内容:
问：
但是就是不明白为什么会出现这种情况，那不是我最新的修改在解决冲突的时候，有被覆盖的风险吗
答：
你的困惑是理解git rebase过程中的冲突解决方式的一个常见问题。在git rebase过程中，Git会将你的本地提交按顺序应用到目标分支（在你的情况下是origin/dev），因此冲突发生时，Git会尝试合并两个不同的更改。 问：
这句 在git rebase过程中，Git会将你的本地提交按顺序应用到目标分支 其中按顺序是什么意思，为什么不是最新提交呢
答：
在Git中，git rebase命令将会将你的本地提交按照它们的提交顺序（时间顺序）依次应用到目标分支上。这意味着git rebase会从你当前分支的最旧提交开始，然后逐个应用你的本地提交，直到最新的提交。因此，它会按照提交历史中的时间顺序应用这些提交，而不是按照它们在分支上的顺序。 这个行为的原因是为了确保在目标分支上的提交历史中，你的本地提交按照它们在时间上的顺序排列，以保持提交历史的一致性和可读性。这样，目标分支上的提交历史将会看起来好像你的更改是在最初的基础上按照顺序逐个应用的。 如果git rebase按照最新提交的顺序应用本地提交，可能会导致一些问题，因为这可能会破坏提交历史的顺序性，使提交历史变得混乱难以理解。 所以，虽然你的最新提交可能会在git rebase过程中被处理，但它会在其他提交之后。当有冲突时，Git会停下来等待你解决冲突，以确保在合并过程中不会丢失任何信息。 问：
也就是说 我上面的问题 :
$a = "hello world",
然后我执行 git rebase origin/dev
然后提示冲突，对比文件发现
左边$a="say no",右边为$a="say yes" 这个$a="say no" 是我之前的某一次旧的提交，和dev 冲突了吗，然后 我最新的提交 $a = "hello world", 还没有被应用 答：
是的，根据你的描述，$a="say no" 是你之前的某一次旧的提交，而$a = "hello world" 是你的最新提交。当你执行git rebase origin/dev时，Git 将尝试将你的本地提交按照它们的提交顺序应用到 origin/dev 分支上。 在这个过程中，Git 首先会尝试应用旧的提交$a="say no"，然后应用你的最新提交 $a = "hello world"。如果在这两个提交之间存在冲突，Git 会停止重播过程并提示你解决这些冲突。 所以，$a="say no" 与 origin/dev 分支上的某些提交冲突，导致了冲突的发生。在冲突解决之前，你的最新提交 $a = "hello world" 尚未被应用到 origin/dev 分支上。你需要手动解决冲突并继续重播过程，以确保你的最新修改被正确地应用到最终的分支状态中。 其实上面出现的旧代码，并不是我们需要的，实际上我们只需要把最新的版本和目标版本比较就可以了，可以通过下面的方法实现:
执行: $ git rebase -i origin/dev ， 加上-i参数，会发现如下信息:
pick ee14fc5fa scif-309
pick d53e200e1 scif-309
pick 00dd45cee scif-309
pick 44ba1cb64 scif-309
pick 794e04704 scif-309
pick c8e8284aa scif-309 //这个是最新一次提交的内容
...
... 我们要选择:pick c8e8284aa scif-309 进行rebase, 需要如下操作:
可以直接编辑,改为
drop ee14fc5fa scif-309
drop d53e200e1 scif-309
drop 00dd45cee scif-309
drop 44ba1cb64 scif-309
drop 794e04704 scif-309
pick c8e8284aa scif-309
...
... ^G Help ^O Write Out ^W Where Is ^K Cut ^T Execute ^C Location M-U Undo M-A Set Mark M-] To Bracket M-Q Previous ^B Back ^◂ Prev Word ^A Home
^X Exit ^R Read File ^\\ Replace ^U Paste ^J Justify ^/ Go To Line M-E Redo M-6 Copy ^Q Where Was M-W Next ^F Forward ^▸ Next Word ^E End 然后下面又有这么多命令，我要选择哪个保存呢，选择 ^O Write Out [ctrl+O]即可，当执行了ctrl+O以后，会出现下面的信息:
File Name to Write: /home/k8s/code/sciforum.net/.git/rebase-merge/git-rebase-todo //这里也是可以输入信息的，默认可以不输入，直接点击 Enter 键就可以了 [必须要敲enter] ^G Help M-D DOS Format M-A Append M-B Backup File
^C Cancel M-M Mac Format M-P Prepend ^T Browse 然后再ctrl+X 即可完成当前rebase. 大概率会出现如下信息, 下面的就是合并[最新的代码]的过程，以及冲突:
Auto-merging src/Controller/Admin/DashboardController.php
Auto-merging src/Entity/Submission.php
CONFLICT (content): Merge conflict in src/Entity/Submission.php
error: could not apply c8e8284aa... scif-309
hint: Resolve all conflicts manually, mark them as resolved with
hint: "git add/rm <conflicted_files>", then run "git rebase --continue".
hint: You can instead skip this commit: run "git rebase --skip".
hint: To abort and get back to the state before "git rebase", run "git rebase --abort".
Could not apply c8e8284aa... scif-309 然后就是手动解决冲突,然后提交，注意这里只用 commit，不要push 然后再执行:$ git rebase --continue
Successfully rebased and updated refs/heads/SCIF-309-t. //因为我们已经选择了最新的版本，所以这个 continue 不会再继续rebase了，直接给结果 这样整个冲突就解决完了，最后将当前分支直接覆盖到远程:
$ git push --force origin SCIF-309-t`},{header:"更新 feature 分支，使它基于最新 base 分支， 同时整理分支， 使用rebase -X 实现",slug:"更新-feature-分支-使它基于最新-base-分支-同时整理分支-使用rebase-x-实现",content:""},{header:"🔄 流程解释",slug:"🔄-流程解释",content:`git fetch origin
git rebase -X ours origin/base-branch
git push --force origin feature-branch git fetch origin 拉取远程仓库最新的提交到本地引用。
不改动你当前分支，只更新 origin/base-branch 等远程分支信息。 git rebase -X ours origin/base-branch 把当前分支（feature-branch）的提交 重新应用在 origin/base-branch 最新提交上。
-X ours：如果发生冲突，优先保留你的 feature-branch 改动。
最终结果：你的 feature 分支基于最新的 base 分支，同时保留你的修改。 git push --force origin feature-branch 因为 rebase 改写了提交历史，所以必须强制推送。 更新远程 feature-branch，远程 base-branch 不受影响。 更安全做法：
git push --force-with-lease origin feature-branch 避免意外覆盖别人提交。`},{header:"💡 场景总结",slug:"💡-场景总结",content:`用途：保持 feature 分支基于最新 base 分支开发，同时整理提交历史。
特点：不会产生 merge commit，提交历史整洁。
注意事项： 仅适用于个人的 feature 分支，如果多人共用，需要注意强推风险。`}]},{path:"/content/other/git/git%E4%B9%8Bsquash%E5%90%88%E5%B9%B6.html",title:"git之squash合并",pathLocale:"/",contents:[{header:"git 使用 squash merge",slug:"git-使用-squash-merge",content:""},{header:"🔹 1. 什么是 squash merge",slug:"🔹-1-什么是-squash-merge",content:`squash merge 是 Git 合并的一种方式： 将一个分支（通常是 feature branch）上的 多个提交 合并成 一个新的提交
新提交的作者默认是执行 merge 的人
合并完成后，master（或目标分支）上只会看到这一个 commit 命令示例：
git checkout master
git merge --squash feature-branch
git commit -m "Add new feature" // 如果需要保留原作者信息，可以 git commit --author="Original Dev <dev@example.com>" -m "Add new feature"`},{header:"🔹 2. 特点",slug:"🔹-2-特点",content:`特点
说明 提交数
feature-branch 的多个提交合并成一个新的 commit 作者信息
默认是执行 merge 的人；可用 --author="..." 保留原作者 历史整洁
master 上不会有很多小提交，提交历史更简洁 保留改动
所有 feature-branch 的改动都会包含在新 commit 中 feature-branch 不变
原分支的提交依然存在，不受影响`},{header:"🔹 3. 使用场景",slug:"🔹-3-使用场景",content:`提交历史需要整洁：例如 master 或 main 分支上不希望有每个小提交
功能完成后合并：把一整个功能模块作为一个 commit 提交到主分支
临时修复或小功能：多个零散提交合并成一个完整的逻辑提交 ⚠️ 注意：如果团队希望保留每个小提交的作者信息或历史，不适合使用 squash merge`},{header:"🔹 4. 和普通 merge 对比",slug:"🔹-4-和普通-merge-对比",content:`对比项
普通 merge
squash merge 提交数
保留 feature-branch 的每个提交
所有提交合并成一个新的 commit 历史完整性
历史完整，可追溯每个小提交
历史压缩，只保留一个 commit 作者信息
保留每个 commit 的原作者
默认是执行 merge 的人，可手动指定 author 生成 merge commit
会生成一个 merge commit
不生成 merge commit（除非手动） 适用场景
协作开发，保留完整历史
发布或整合功能，保持 master 历史干净`},{header:"🔹 5. 总结建议",slug:"🔹-5-总结建议",content:`保留原始提交历史 → 用普通 merge
希望 master 干净整洁 → 用 squash merge，并在需要时指定作者`}]},{path:"/content/other/git/git%E4%B9%8B%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"git之创建项目的几种方式",pathLocale:"/",contents:[{header:"",slug:"",content:`git之创建项目的几种方式:
Git global setup
git config --global user.name "shipeng guo"
git config --global user.email "shipeng.guo@qinhong.com" 1.Create a new repository
git clone ssh://git@gitlab.qinhong.com:9922/dev/sciforum-frontend-v2.git
cd sciforum-frontend-v2
git switch -c main //这个命令用于在Git版本控制系统中创建一个新的分支并切换到该分支
touch README.md
git add README.md
git commit -m "add README" 2.Push an existing folder
cd existing_folder
git init --initial-branch=main //在当前文件夹中初始化一个新的Git仓库，并指定初始分支为 "main"。这个命令将创建一个.git子文件夹，其中包含Git仓库的配置和历史信息。
git remote add origin ssh://git@gitlab.qinhong.com:9922/dev/sciforum-frontend-v2.git
git add .
git commit -m "Initial commit" 3.Push an existing Git repository
cd existing_repo
git remote rename origin old-origin // 将原始的远程仓库名称 "origin" 重命名为 "old-origin"。这是一种更改本地仓库关联的远程仓库名称的方式，以便你可以保留之前的配置，同时为新的远程仓库添加一个新的名称。这个命令不会对远程仓库本身产生影响，也不会改变其他用户的配置。它只是为了方便本地工作目录中的Git仓库更改远程仓库的别名，而不影响远程仓库的状态。
git remote add origin ssh://git@gitlab.qinhong.com:9922/dev/sciforum-frontend-v2.git // 添加一个新的远程仓库地址，并将其命名为 "origin"。这样，Git就会关联到新的远程仓库地址，而不再使用之前的 "old-origin"。`}]},{path:"/content/other/git/git%E4%B9%8B%E5%8F%96%E6%B6%88merge%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE.html",title:"git之取消merge后的数据",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候执行 git merge branch_name，但是执行以后 又想取消，可以按下面的命令执行
①$ git reflog ②git reset --hard commit-before-the-merge
$ git reset --hard f615238`}]},{path:"/content/other/git/git%E4%B9%8B%E5%8F%96%E6%B6%88merge%E7%8A%B6%E6%80%81.html",title:"git之取消merge状态",pathLocale:"/",contents:[{header:"",slug:"",content:`git之取消merge状态:
$ git merge --abort`}]},{path:"/content/other/git/git%E4%B9%8B%E5%8F%96%E6%B6%88%E8%BF%BD%E8%B8%AA.html",title:"git之取消追踪",pathLocale:"/",contents:[{header:"",slug:"",content:`做项目的时候，有时候不小心提交了私有的代码或者配置等信息，需要取消git代码追踪，操作如下:
1.如果是对所有文件都取消跟踪的话，就是 git rm -r --cached . //不删除本地文件 git rm -r --f . //删除本地文件 2.对某个文件取消追踪 git rm --cached readme.txt 删除readme.txt的跟踪，并保留在本地。 git rm --f readme.txt 删除readme.txt的跟踪，并且删除本地文件。 3.实际使用 git rm --cached ./resources/js/app.js`}]},{path:"/content/other/git/git%E4%B9%8B%E5%8F%96%E6%B6%88%E8%BF%BD%E8%B8%AA%E5%85%B3%E7%B3%BB.html",title:"git之取消追踪关系",pathLocale:"/",contents:[{header:"",slug:"",content:`git之取消追踪关系：
在开发过程中，我们可能有一些测试代码或者功能还在开发的代码，这时候并不想提交到代码仓库，但是又不小心添加到git记录里，一般都是 add操作，则会时候可以
通过下面的命令取消git 追踪关系： // 单个
vagrant@homestead:~/code/admin$ git rm -r -f --cached database/seeders/MenuTableSeeder.php //多个
vagrant@homestead:~/code/admin$ git rm -r -f --cached app/Console/Commands/*
rm 'app/Console/Commands/SyncCategory.php'
rm 'app/Console/Commands/SyncCompany.php'
rm 'app/Console/Commands/UpdateProduct.php'`}]},{path:"/content/other/git/git%E4%B9%8B%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF.html",title:"git之批量删除本地分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git之批量删除本地分支:
$ git branch | grep "feat/requrement-1206_" | xargs git branch -D
Deleted branch feat/requrement-1206_base-feature-event-settingss-registration (was df69cca0).
Deleted branch feat/requrement-1206_event-setting-registration-create-section (was 97919b7c).
Deleted branch feat/requrement-1206_event-setting-registration-create-ticket (was 344bb46c).
Deleted branch feat/requrement-1206_event-setting-registration-ticket-list (was 697babab).
Deleted branch feat/requrement-1206_event-settings-registration-tickets (was 85171474). 说明:
git branch：列出所有本地分支。
grep "your-pattern"：根据你提供的字符串（例如 "feature/"）来筛选分支。可以使用正则表达式来匹配更复杂的模式。
xargs git branch -D：将匹配到的分支名逐个传递给 git branch -D 命令来进行删除。`}]},{path:"/content/other/git/git%E4%B9%8B%E6%92%A4%E9%94%80merge%E7%9A%84%E6%AD%A5%E9%AA%A4.html",title:"git之撤销merge的步骤",pathLocale:"/",contents:[{header:"",slug:"",content:`git之撤销merge的步骤(也适用于普通的提交):
1>git status
这会显示当前的分支状态和是否有未推送的提交 2>如果合并已经提交，但还没有推送，可以使用 reset 命令来撤销最后一次提交： git reset --hard HEAD~1 或者 git reset --hard HEAD^
ex:
$ git reset --hard HEAD^
HEAD is now at 20312c8f fix(): create problems 这会将您的分支回退到合并之前的状态。注意，这将删除合并提交以及合并带来的所有更改 3>如果想保留您的工作目录中的更改，可以使用 --soft 选项替代 --hard
git reset --soft HEAD~1 这会撤销提交，但保留更改在工作目录中 4>如果合并还没有提交，只是在暂存区，您可以使用(只是add 但是没有 commit)
git reset --merge 这会取消合并操作，并将文件恢复到合并前的状态 5>操作完，执行 git status 查看分支状态`}]},{path:"/content/other/git/git%E4%B9%8B%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B.html",title:"git之日志查看",pathLocale:"/",contents:[{header:"",slug:"",content:`git之日志查看:
git log 这将显示所有提交历史(从最新提交 开始) git log <commit-hash>
这将显示指定提交及其祖先的提交历史(从commit-hash开始到过去的提交) git show <commit-hash>
这将显示指定提交的详细信息，包括提交的作者、日期、提交消息以及具体的修改内容`}]},{path:"/content/other/git/git%E4%B9%8B%E6%9C%AC%E5%9C%B0push%E5%A4%B1%E8%B4%A5%EF%BC%8C%E6%92%A4%E9%94%80commit.html",title:"git之本地push失败，撤销commit",pathLocale:"/",contents:[{header:"",slug:"",content:`当commit了，然后push，结果puash失败，就想撤销commit,但是保留代码,可以通过--soft参数实现:
$ git reset --soft HEAD^ HEAD^的意思是上一个版本，也可以写成HEAD~1
如果你进行了2次commit，想都撤回，可以使用HEAD~2 命令格式：git reset [--soft | --mixed | --hard] [<commit>]
至于这几个参数：
--mixed 意思是：不删除工作空间改动代码，撤销commit，并且撤销git add . 操作
这个为默认参数,git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 --soft 不删除工作空间改动代码，撤销commit，不撤销git add . --hard
删除工作空间改动代码，撤销commit，撤销git add .`}]},{path:"/content/other/git/git%E4%B9%8B%E6%9C%AC%E5%9C%B0%E7%89%88%E6%9C%AC%E5%9B%9E%E9%80%80%EF%BC%8C%E7%84%B6%E5%90%8E%E5%8F%91%E6%94%B9%E8%BF%9C%E7%A8%8B%E7%89%88%E6%9C%AC.html",title:"git之本地版本回退，然后发改远程版本",pathLocale:"/",contents:[{header:"",slug:"",content:`git之本地版本回退，然后发改远程版本:
回滚到指定提交版本:
$ git reset --hard a14201ce5a455c3ad0aff1043772a5f8822449bc 回退之后，可以直接用本地版本覆盖远程:
$ git push -f origin dev 还可以:
$ git push -f origin dev:dev`},{header:"两者的关系",slug:"两者的关系",content:`git push -f origin dev
省略了目标分支，等价于：
git push -f origin dev:dev 也就是：把本地的 dev 分支 推送到远程 origin 的 dev 分支，并且强制覆盖。 git push -f origin 本地分支:远程分支
这种写法更灵活，比如：
git push -f origin dev:feature-x 意思是：把本地的 dev 分支推到远程的 feature-x 分支（覆盖远程）。`},{header:"总结",slug:"总结",content:`git push -f origin dev 👉 本地 dev → 远程 dev（强制覆盖）
git push -f origin dev:dev 👉 完整写法，结果一样
git push -f origin dev:other-branch 👉 本地 dev → 远程 other-branch（强制覆盖）`}]},{path:"/content/other/git/git%E4%B9%8B%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E4%BB%93%E5%BA%93%E7%9A%84%E9%BB%98%E8%AE%A4%E5%88%86%E6%94%AF.html",title:"git之查看当前仓库的默认分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git之查看当前仓库的默认分支:
通过如下命令:git ls-remote --symref <远程仓库URL>，这将显示远程仓库的HEAD引用，即默认分支。 使用:
$ git ls-remote --symref ssh://git@gitlab.qinhong.com:9922/dev/test.net.git
ref: refs/heads/master HEAD
...
...`}]},{path:"/content/other/git/git%E4%B9%8B%E9%80%9A%E8%BF%87%E8%84%9A%E6%9C%AC%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E5%88%86%E6%94%AF%E5%90%8D.html",title:"git之通过脚本获取当前分支名",pathLocale:"/",contents:[{header:"",slug:"",content:'git之通过脚本获取当前分支名: git rev-parse --abbrev-ref HEAD\n分析:\n这段脚本使用了 Git 命令 `git rev-parse --abbrev-ref HEAD`，结合了 shell 变量定义，分析如下： - **`git rev-parse --abbrev-ref HEAD`**: 这个命令用于获取当前检出的分支的名称。`--abbrev-ref` 选项返回简短的引用名称，而不是完整的引用路径。`HEAD` 表示当前分支的引用，因此该命令输出的是当前分支的名称（例如 `main`、`feature/new-feature` 等）。 - **`LOCAL_BRANCH_NAME="$(git rev-parse --abbrev-ref HEAD)"`**: 这是 shell 脚本中的变量赋值语法，`$()` 用于执行括号内的命令，并将其输出作为结果。这里，执行 `git rev-parse --abbrev-ref HEAD` 命令，并将输出值赋给 `LOCAL_BRANCH_NAME` 变量。 总结：这个脚本片段的作用是通过 Git 命令获取当前分支的名称，并将其存储在名为 `LOCAL_BRANCH_NAME` 的变量中。'}]},{path:"/content/other/git/git%E4%B9%8B%E9%87%8D%E5%91%BD%E5%90%8D%E5%88%86%E6%94%AF.html",title:"git之重命名分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git重命名本地/远程分支
①先重命名当前本地分支
git branch -m <new_name> 重命名本地其他分支
git branch -m old-branch-name new-branch-name ②再删除远程分支，可以不用在本地切换到对应的分支，比如本地是dev, 可以删除远程的dev_feature_1分支
git push origin --delete <old_name> ③再将本地分支推到远程分支
git push origin -u <new_name> ④将本地和远程建立关系
git branch --set-upstream-to=origin/<new_name>`}]},{path:"/content/other/git/git%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E5%AF%B9commit-msg%E7%9A%84%E8%A7%84%E8%8C%83.html",title:"git代码提交对commit-msg的规范",pathLocale:"/",contents:[{header:"",slug:"",content:'git代码提交对commit-msg的规范:\n在 .husky 下配置 commit-msg脚本，内容如下:\nnpx --no -- commitlint --edit $1 分析:\nnpx --no -- commitlint --edit $1 让我们逐部分详细分析这个命令: 1. `npx`: - 这是Node.js生态系统中的一个工具,用于执行npm包中的二进制文件。 - 使用`npx`的好处是,它可以执行本地安装的包,而不需要全局安装或直接修改PATH。 - 在这个上下文中,它用来运行`commitlint`命令。 2. `--no --`: - 这是`npx`的一个特殊选项。 - `--no`告诉`npx`不要自动安装缺失的包。 - 双破折号(`--`)是一个shell约定,用来表示选项的结束。这确保后面的所有内容都被视为命令参数,而不是`npx`的选项。 3. `commitlint`: - 这是实际要执行的命令。 - `commitlint`是一个用于检查Git提交信息是否符合特定格式的工具。// 这里其实就是 @commitlint/cli 这个工具, 可以运行 npx commitlint --help 查看支持的参数 4. `--edit $1`: - `--edit`是`commitlint`的一个选项,指示它应该检查一个文件的内容。 - `$1`是一个shell变量,代表传递给脚本的第一个参数。 - 在Git hooks上下文中,`$1`通常是Git自动创建的临时文件的路径,该文件包含了提交信息。 这个命令的执行流程:\n1. 当开发者创建一个新的Git提交时,Husky会触发这个hook。\n2. Git会创建一个临时文件,包含提交信息,并将其路径作为第一个参数传递给hook脚本。\n3. Hook脚本使用`npx`来运行本地安装的`commitlint`。\n4. `commitlint`读取并检查Git提供的提交信息文件。\n5. 如果提交信息符合预定义的规则,`commitlint`会允许提交;否则,它会阻止提交并显示错误信息。 使用这种方式的优点:\n- 确保使用项目本地安装的`commitlint`版本,避免全局版本可能造成的不一致。\n- 不需要修改PATH或使用相对路径来执行`commitlint`。\n- `--no`选项防止`npx`在`commitlint`不存在时尝试安装它,这可能会导致意外行为。 这个设置帮助团队维护一致的提交信息格式,提高代码库的可维护性和可读性。如果你想了解如何自定义`commitlint`规则或整合到其他工作流程中,我可以提供更多信息。 commit-msg hook 给了我们一个机会在提交完成之前检查和potentially修改提交信息。\ncommit-msg hook 实际上是在 pre-commit hook 之后运行的。它的主要目的是检查提交信息的格式和内容，而不是检查代码本身。\n这种设计允许我们：\n首先检查代码质量（在 pre-commit 中）\n然后保证提交信息的质量（在 commit-msg 中）\n这样的顺序确保了both代码和提交信息都符合项目的标准before完成提交。\n相关配置：\n1>可以直接在package.json下配置\n"commitlint": { "rules": { // 更多规则参考: https://commitlint.js.org/reference/rules.html "subject-case": [ 0, // 提示级别 "always" // 本来还应该有第三个参数的，就是subject-case 支持的value, 因为配置了 0 ，所以就不用配置了 ] }, "extends": [ "@commitlint/config-conventional" // 关于 conventional 规则参考 https://www.conventionalcommits.org/en/v1.0.0/ ]\n} 2>可以生成一个配置文件commitlint.config.js\n{ "commitlint": { "rules": { "subject-case": [0, "always"] }, "extends": [ "@commitlint/config-conventional" ] }\n} 上面配置分析:\n这个配置定义了项目中commitlint的行为。让我解释一下这个配置的各个部分： "rules" 对象：\n这里定义了特定的commitlint规则。在这个例子中，只有一个规则被显式定义：\n"subject-case": [ 0, "always"\n] "subject-case" 是规则的名称，它控制提交消息主题（第一行）的大小写。\n[0, "always"] 是规则的配置： 0 表示这个规则被禁用（0 = off, 1 = warning, 2 = error）\n"always" 是规则的附加配置，但因为规则被禁用，所以这里没有实际效果 这个配置实际上是关闭了对主题行大小写的限制，允许开发者使用任何大小写格式。 "extends" 数组：\n"extends": [ "@commitlint/config-conventional"\n] 这表示项目的commitlint配置扩展了 @commitlint/config-conventional 包。这是一个常用的预设配置，它实施了Conventional Commits规范。\nConventional Commits是一种提交消息的格式约定，通常看起来像：\n<type>[optional scope]: <description> [optional body] [optional footer(s)] 综合分析：\n1. 这个项目使用了Conventional Commits规范作为基础。\n2. 但是，它关闭了对主题行大小写的限制，这可能是为了给开发者更多的灵活性。\n3. 除了 `subject-case` 规则，其他所有来自 `@commitlint/config-conventional` 的规则都会被应用。 官方文档: https://commitlint.js.org/ 总结:\ncommitlint 的核心功能和用途： 1. 主要功能： - commitlint 主要用于检查 Git 提交信息（commit messages）的格式和内容。 2. 目的： - 确保项目中所有的提交信息遵循一致的格式和约定。 - 提高代码库的可维护性和可读性。 - 便于自动化工具（如生成更新日志）处理提交历史。 3. 工作原理： - 通常通过 Git hooks（特别是 commit-msg hook）集成到工作流中。 - 在每次提交时自动运行，检查提交信息是否符合预定义的规则。 4. 常见用途： - 强制实施 Conventional Commits 规范。 - 确保提交信息包含必要的信息（如类型、范围、描述等）。 - 限制提交信息的长度、格式或使用的词语。 5. 可配置性： - 可以通过配置文件（如我们之前讨论的 package.json 或 commitlint.config.js）自定义规则。 - 可以扩展预设配置（如 @commitlint/config-conventional）并覆盖特定规则。 6. 与其他工具集成： - 经常与 Husky 等工具配合使用，以自动化执行检查。 - 可以集成到 CI/CD 流程中，确保所有提交（包括通过 UI 创建的）都符合规范。 7. 好处： - 帮助团队保持一致的提交风格。 - 使得理解项目历史和生成变更日志变得更容易。 - 促进更好的协作和代码审查流程。 总的来说，commitlint 是一个强大的工具，用于维护高质量、一致的 Git 提交历史。它不仅仅是简单的检查，而是帮助团队建立更好的沟通和协作实践。 参考官网: https://commitlint.js.org/reference/configuration.html (主要两种方式，本文采用的是第二种)'}]},{path:"/content/other/git/git%E4%BB%A5%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E4%B8%BA%E6%8C%87%E5%AE%9A%E5%88%86%E6%94%AF%E5%9C%A8%E6%9C%AC%E5%9C%B0%E5%88%9B%E5%BB%BA%E5%88%86%E6%94%AF.html",title:"git以远程分支为指定分支在本地创建分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git以远程分支为指定分支在本地创建分支:
$ git checkout -b b1 origin/dev $ git push origin b1:b1 $ git remote show origin $ git branch --set-upstream-to=origin/b1 $ git remote show origin`}]},{path:"/content/other/git/git%E4%BF%AE%E6%94%B9%E9%82%AE%E7%AE%B1.html",title:"git修改邮箱",pathLocale:"/",contents:[{header:"",slug:"",content:`git修改邮箱:
因为git全局设置用户名跟邮箱，基本操作一次以后很少再变化，所以记忆不是很深刻，但是更换电脑的时候又会用到，然后再去查，所以在这里记录一下，方便自己以后查看。 查看git配置信息：git config --list
查看用户名：git config user.name
查看邮箱：git config user.email
设置全局用户名：git config --global user.name "xxx"(输入你的用户名)
设置全局邮箱：git config --global user.email "xxx"(输入你的邮箱)`}]},{path:"/content/other/git/git%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C%E5%9C%BA%E6%99%AF.html",title:"git分支操作场景",pathLocale:"/",contents:[{header:"",slug:"",content:`1.查看远程分支
#] git remote -v origin https://gitee.com/xx/xx.git (fetch)
origin https://gitee.com/xx/xx.git (push) 2.移除远程分支关系
#] git remote rm origin 3.添加远程分支关系
#]git remote add origin https://gitee.com/xx/xx.git
#]git push -u origin master`}]},{path:"/content/other/git/git%E5%88%A0%E9%99%A4%E5%88%86%E6%94%AF%E6%98%AF%E5%90%A6%E4%BC%9A%E5%B0%86%E5%85%B6%E4%BB%8Egit%E7%9A%84%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95%E4%B8%AD%E5%AE%8C%E5%85%A8%E5%88%A0%E9%99%A4.html",title:"git删除分支是否会将其从git的历史记录中完全删除",pathLocale:"/",contents:[{header:"",slug:"",content:`git删除分支是否会将其从git的历史记录中完全删除? 不会
删除分支只是从分支列表中移除这个分支的引用，并不会删除实际的提交记录。
当我们在Git中进行提交时，会生成一个唯一的哈希值，该哈希值将这个提交与其他提交进行区分。分支实际上只是这些提交记录的引用，删除分支只会删除该引用，而不会删除提交记录本身。
所以，即使我们删除一个分支，之前在这个分支上进行的提交记录仍然存在于Git的历史记录中。
通过 git reflog 可以查看
有人说通过 --orphan 参数实现删除，我测试过了，不行
git reflog和 git log的区别:
git reflog:可以查看所有分支的所有操作记录（包括已经被删除的 commit 记录和 reset 的操作）
git log:只能查看所有提交过的版本信息(已经被删除的 commit 记录和 reset 的操作 看不到)
git reflog --pretty=oneline //通过--pretty=oneline参数简化输出，更清晰
git log --pretty=oneline //通过--pretty=oneline参数简化输出，更清晰`}]},{path:"/content/other/git/git%E5%88%A0%E9%99%A4%E6%9C%AC%E5%9C%B0%E4%BB%A5%E5%8F%8A%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF.html",title:"git删除本地以及远程分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git删除本地以及远程分支:
删除远程分支:
duo@k8s:~/code/test git push origin --delete m_guoshipeng #可以不用在本地切换到对应的分支，比如本地是dev, 可以删除远程的dev_feature_1分支
remote: Sending mail...
remote: ignoring branch delete
...
... 删除本地分支:
duo@k8s:~/code/test git branch -d m_guoshipeng
error: The branch 'm_guoshipeng' is not fully merged.
If you are sure you want to delete it, run 'git branch -D m_guoshipeng'.
duo@k8s:~/code/test git branch -D m_guoshipeng
Deleted branch m_guoshipeng (was c0db2e5).
...
... 两者的区别:
git branch -d 会在删除前检查merge状态（其与上游分支或者与head）。
git branch -D 是git branch --delete --force的简写，它会直接删除。`}]},{path:"/content/other/git/git%E5%9B%9E%E6%BB%9A%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95.html",title:"git回滚某个文件的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`git回滚某个文件的方法:
1.
$ git log ./components/app/form/inputNumber/AppFormInputNumber.vue
commit 006bbb98877ab03bfd024839a6db168300999fbb
Author: Jun Fu <jun.fu@mdpi.com>
Date: Tue Mar 11 06:30:04 2025 +0000 Resolve SCIF-1616 "Fix/ fix 0311" commit 905d0957ea4022d2266fabdce7465dc5b0adea4d
Author: guoshipeng <shipeng.guo@mdpi.com>
Date: Fri Feb 28 12:26:29 2025 +0800 fix: ticket problem 2.
$ git checkout 905d0957ea4022d2266fabdce7465dc5b0adea4d ./components/app/form/inputNumber/AppFormInputNumber.vue
Updated 1 path from abbc66fd 参考:
场景1：修改了文件/path/to/file，没有提交，但是觉得改的不好，想还原。
解决：
git checkout /path/to/file 场景2：修改了文件/path/to/file，已经提交，但是觉得改的不好，想还原到指定版本。
解决：
1. 首先查看文件的历史版本。git log /path/to/file
2. 找到你想要还原的版本。如
commit 052c0233bcaef35bbf6e6ebd43bfd6a648e3d93b
Author: panww <panww@gmail.com>
Date: Wed Nov 8 11:48:31 2017 +0800
commit modify/path/to/file
3. 将文件还原到你想要还原的版本。$ git checkout \${commit} /path/to/file。即$ git checkout 052c0233bcaef35bbf6e6ebd43bfd6a648e3d93b /path/to/file
4. 这时查看文件，会发现文件已经还原了。（如果没有还原，请刷新再看。）
5. commit、push。`}]},{path:"/content/other/git/git%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E5%88%86%E6%94%AF.html",title:"git恢复删除的分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git恢复删除的分支:
$ git remote show origin Remote branches: dev tracked docs tracked m_guoshipeng tracked master tracked refs/remotes/origin/guoshipeng stale (use 'git remote prune' to remove)
...
...
发现我的远程分支，处于上面这个状态，说明远程我的分支被删除了,但是记录还在，执行 git remote prune origin 就会把这个记录删除，但是本地还是有这个分支的代码，执行 git branch -d [分支名称] 就可以删除。
我的分支被删除，可能是因为之前merge 到 master的时候，选择了 merge 之后删除源代码的选项。
遇到这种情况，如果自己的分支还要继续使用，那么就不要执行git remote prune origin，而是在本地代码做一个小的改动，然后提交，那么会在远程自动创建一个新的 guoshipeng 分支。`}]},{path:"/content/other/git/git%E6%8A%A5%E9%94%99%E4%B9%8Bpull_refused.html",title:"git报错之pull_refused",pathLocale:"/",contents:[{header:"",slug:"",content:`git报错之pull_refused:
在pull 代码的时候可能会报下面的错误：
Failed to connect to github.com port 443 after 2117 ms: Connection refused 原因①当前分支版本和线上版本不一致，push 之前先pull一下即可 原因②github.com 网络问题
去这个网站： https://ipaddress.com/website/github.com 输入github，然后复制出IP 在本地的hosts文件里面配置： 140.82.113.4 github.com ，再操作即可`}]},{path:"/content/other/git/git%E6%8A%A5%E9%94%99%E4%B9%8Bpush_refused.html",title:"git报错之push_refused",pathLocale:"/",contents:[{header:"",slug:"",content:`git报错之push_refused:
在push 代码的时候可能会报下面的错误：
Failed to connect to github.com port 443 after 2117 ms: Connection refused 原因①当前分支版本和线上版本不一致，push 之前先pull一下即可 原因②github.com 网络问题
去这个网站： https://ipaddress.com/website/github.com 输入github，然后复制出IP 在本地的hosts文件里面配置： 140.82.113.4 github.com ，再操作即可`}]},{path:"/content/other/git/git%E6%8F%90%E4%BA%A4commit%E6%A0%BC%E5%BC%8F%E6%A0%87%E5%87%86.html",title:"git提交commit格式标准",pathLocale:"/",contents:[{header:"",slug:"",content:`git提交commit格式标准:
The commit message should be structured as follows: <type>(<scope>): <JIRA ticket number-subject> The “<type>” field must be chosen from the options listed below:
build : Changes related to building the code (e.g. adding external libraries). chore : Changes that do not affect the external user (e.g. updating the .gitignore file or .prettierrc file). feat : Introduces a new feature to the codebase. fix : A bug fix. docs : Any changes that specifically relate to documentation (e.g. update comments for better code readability, update configuration file with new settings description, update installation instructions in README). refactor : A code that neither fix bug nor adds a feature. (eg: This can used when there is semantic changes like renaming a variable/ function name). perf : A code that improves performance style: A code that is related to styling. test : Adding new test or making changes to existing test. The “scope” field is optional and should be a noun that represents the part of the codebase affected by the commit, for example if the commit changes the submissions dashboard page, the scope could be “dashboard submissions“. If the commit affects multiple areas of the codebase, “global” or “all” could be used as the scope. The “subject” field should be a brief description of the commit, written in the imperative present tense. It should not end with a period and the first letter should not be capitalized. For example, “add new event builder step” or “fix bug in search functionality” are both appropriate subjects. The introduction of the "subject" should always feature the Jira ticket number (SCIF-x).`}]},{path:"/content/other/git/git%E6%8F%90%E4%BA%A4%E7%9A%84OPEN_SSL%E5%92%8CTime_Out%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html",title:"git提交的OPEN_SSL和Time_Out问题以及解决办法",pathLocale:"/",contents:[{header:"",slug:"",content:`git提交的OPEN_SSL和Time_Out问题以及解决办法:
$ git push -u origin master fatal: unable to access 'https://github.com/gspgsp/vue-blog.git/': Failed to connect to github.com port 443 after 21045 ms: Timed out git config --global --unset https.proxy $ git push -u origin master fatal: unable to access 'https://github.com/gspgsp/vue-blog.git/': OpenSSL SSL_read: Connection was reset, errno 10054 git config --global http.sslVerify "false" //可能是因为本地开启了代理的缘故
直接恢复，使用代理：
git config --global http.proxy "http://127.0.0.1:7890"
git config --global https.proxy "https://127.0.0.1:7890" 再执行 $ git push -u origin master 就好了 host文件配置:
140.82.112.3 github.com
185.199.108.153	assets-cdn.github.com
185.199.109.153 assets-cdn.github.com
185.199.110.153 assets-cdn.github.com
185.199.111.153 assets-cdn.github.com`}]},{path:"/content/other/git/git%E6%9C%AC%E5%9C%B0fetch%E4%B9%8B%E5%90%8E%E5%88%87%E6%8D%A2%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C.html",title:"git本地fetch之后切换分支操作",pathLocale:"/",contents:[{header:"",slug:"",content:`git本地fetch之后切换分支操作:
1.一般会在本地执行git fetch, 会把远程最新的分支拉下来
2.本地想切换到想查看的远程新分支,可以有三种方式
1>直接通过编辑器， checkout 指定分支 2>git checkout -b feature-branch origin/feature-branch 3>git switch -c feature-branch origin/feature-branch
-c：是 git switch 命令的一个选项，用于创建新的本地分支。即使您指定了远程分支，-c 也会确保本地分支创建，并且您会自动切换到该分支。 git本地切换分支的几种方式
#q切换一存在的分支
git checkout feature-branch git switch feature-branch #新增并切换到分支
git checkout -b my-branch
git switch -c my-branch 注意，加 -b 或者 -c 到一个已经存在的分支，会报错`}]},{path:"/content/other/git/git%E6%9C%AC%E5%9C%B0%E5%B7%B2%E6%9C%89%E9%A1%B9%E7%9B%AE%E7%9B%B4%E6%8E%A5%E6%8E%A8%E5%88%B0%E8%BF%9C%E7%A8%8B(%E7%94%A8%E4%BA%8E%E6%9C%AC%E5%9C%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%B9%E7%9B%AE%E6%8E%A8%E5%88%B0%E8%BF%9C%E7%A8%8B).html",title:"git本地已有项目直接推到远程",pathLocale:"/",contents:[{header:"",slug:"",content:`git本地已有项目直接推到远程(用于本地初始化项目推到远程):
git config --global user.name "xxx"
git config --global user.email "123456@qq.com" cd duoxiao-www
git init
如果没有这个初始化，那么就会报下面的错误:
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set). git remote add origin https://gitee.com/qinhong_design/duoxiao-www.git git add . git commit -m 'init project' git push -u origin master`}]},{path:"/content/other/git/git%E6%9C%AC%E5%9C%B0%E6%8F%90%E4%BA%A4%E8%A6%86%E7%9B%96%E5%88%B0%E8%BF%9C%E7%A8%8B.html",title:"git本地提交覆盖到远程",pathLocale:"/",contents:[{header:"",slug:"",content:`git本地提交覆盖到远程:
使用以下命令将本地分支强制推送到远程仓库（例如，推送到 origin 的 master 分支）：
git push --force origin master
或者
git push -f origin master
其中： --force 或 -f 表示强制推送，覆盖远程仓库中的历史。
origin 是远程仓库的默认名称，master 是要推送的分支名称。请根据你的实际分支名称调整。`}]},{path:"/content/other/git/git%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E5%88%86%E6%94%AF%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF.html",title:"git查看当前分支的远程分支",pathLocale:"/",contents:[{header:"",slug:"",content:`git查看当前分支的远程分支的两种方法:
[root@k8smaster ~]# ~/code/shop$ git branch -vv
* local daf2bff [origin/local] 代码整理 master ba6408a [origin/master] init 还有就是：
git remote show origin`}]},{path:"/content/other/git/git%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8C%BA%E5%9F%9F.html",title:"git的几个区域",pathLocale:"/",contents:[{header:"",slug:"",content:`git的几个区域:
git中文件所在位置有四个，在工作区内、在索引区内、在本地仓库、在远程仓库。 处于四个位置中文件的状态分别为untracked、unmodified、modified、staged。 通过三个操作可以把文件进行状态转移： git add 把工作区文件添加到索引区； git commit 把索引区文件添加到本地仓库； git push 把本地仓库文件添加到远程仓库。`}]},{path:"/content/other/git/%E5%85%B3%E4%BA%8Egit%E7%9A%84reset%E6%97%A0%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF.html",title:"关于git的reset无效的场景",pathLocale:"/",contents:[{header:"",slug:"",content:'关于git的reset无效的场景:\n关于 git reset --hard HEAD^ 无效的一种场景:\ncommit a5e7e31afcef015ee0d26e714a9233e8a450a42b (HEAD -> feat/HUIYI-1156_base-feature-event-settings-registration, origin/feat/HUIYI-1156_base-feature-event-settings-registration)\nMerge: b9acf56a 2c3e3942\nAuthor: guoshipeng <shipeng.guo@qinhong.com>\nDate: Thu Nov 28 13:40:32 2024 +0800 fix(): merge conflict commit 2c3e394267c2a55c3aca2bdc87509d20ed1932a0 (origin/version_1_0_0, version_1_0_0)\nAuthor: Shipeng Guo <shipeng.guo@qinhong.com>\nDate: Thu Nov 28 03:34:14 2024 +0000 Resolve HUIYI-1494 "Feat/ update mui version" commit 3b678c619b9ce372a7ec4d944be6562144c96271\nAuthor: Yaqi Deng <yaqi.deng@qinhong.com>\nDate: Tue Nov 26 13:17:33 2024 +0800 feat: HUIYI-1288 add presentation video settings commit b9acf56a23962c2c7cc6baea003a8c5c021545d3\nAuthor: Shipeng Guo <shipeng.guo@qinhong.com>\nDate: Thu Nov 28 01:48:55 2024 +0000 Resolve HUIYI-1206 "Feat/ registration tickets" 分析:\ncommit a5e7e31afcef015ee0d26e714a9233e8a450a42b (HEAD -> feat/HUIYI-1156_base-feature-event-settings-registration, origin/feat/HUIYI-1156_base-feature-event-settings-registration)\nMerge: b9acf56a 2c3e3942 从提供的 Git 提交记录： commit a5e7e31afcef015ee0d26e714a9233e8a450a42b (HEAD -> feat/HUIYI-1156_base-feature-event-settings-registration, origin/feat/HUIYI-1156_base-feature-event-settings-registration)\nMerge: b9acf56a 2c3e3942\n我们可以解析出以下信息： ### 1. **当前的 `HEAD`**\n- `HEAD -> feat/HUIYI-1156_base-feature-event-settings-registration`： - `HEAD` 指向的是 `feat/HUIYI-1156_base-feature-event-settings-registration` 分支。 - 这个分支当前处于提交 `a5e7e31afcef015ee0d26e714a9233e8a450a42b`，并且是 `origin/feat/HUIYI-1156_base-feature-event-settings-registration`（即远程分支）的当前状态。 ### 2. **合并提交（Merge Commit）**\n- `Merge: b9acf56a 2c3e3942`： - 这表明 `a5e7e31afcef015ee0d26e714a9233e8a450a42b` 是一个 **合并提交**（merge commit），它有两个父提交： - 第一个父提交是 `b9acf56a23962c2c7cc6baea003a8c5c021545d3`，这是一个之前的提交，可能来自分支 `feat/HUIYI-1156_base-feature-event-settings-registration`。 - 第二个父提交是 `2c3e394267c2a55c3aca2bdc87509d20ed1932a0`，这可能来自另一分支（如 `version_1_0_0`）或是被合并的分支。 ### 3. **远程和本地分支**\n- `origin/feat/HUIYI-1156_base-feature-event-settings-registration` 表示远程仓库的 `feat/HUIYI-1156_base-feature-event-settings-registration` 分支，指向同一个提交（`a5e7e31afcef015ee0d26e714a9233e8a450a42b`）。\n- `HEAD` 指向本地分支 `feat/HUIYI-1156_base-feature-event-settings-registration`，这表明你正在该分支上工作。 ### 结论\n- 当前的 `HEAD` 指向 `feat/HUIYI-1156_base-feature-event-settings-registration` 分支的合并提交 `a5e7e31afcef015ee0d26e714a9233e8a450a42b`。\n- 合并提交有两个父提交：`b9acf56a23962c2c7cc6baea003a8c5c021545d3` 和 `2c3e394267c2a55c3aca2bdc87509d20ed1932a0`。 为什么 git reset --hard HEAD^ 可能无效\n合并提交有多个父提交：当你执行 git merge 时，它会生成一个合并提交，该提交通常有两个父提交。在这种情况下，HEAD^ 只会回退到合并提交的第一个父提交，而不是你希望回退到的版本。\n回退到更早的提交：如果你想回到合并操作之前的状态，并且合并提交的第一个父提交已经包含了许多更早的提交，HEAD^ 可能会把你带到一个意外的提交，而不是直接回到你预期的版本。 解决办法明确指定你希望回退到的提交哈希值，通过 git reset --hard <commit-hash> 来回退到正确的提交。git log --oneline 查看完整的hash值。'}]},{path:"/content/other/git/%E5%A6%82%E4%BD%95%E6%8A%8Agithub%E4%BB%93%E5%BA%93%E6%8E%A8%E5%88%B0npm.html",title:"如何把github仓库推到npm",pathLocale:"/",contents:[{header:"",slug:"",content:`如何把github仓库推到npm:
先确定当前npm的源为: https://registry.npmjs.org/ 然后:
npm login
// 输入npm账号名 // 输入npm密码 // 输入npm邮箱 // 输入一次验证code npm publish`}]},{path:"/content/other/spread/2022%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6.html",title:"2022年倒计时",pathLocale:"/",contents:[{header:"",slug:"",content:`现在是2022年的12月30号，离2023年还有两天的时间，遂想对2022年做一个总结。
之前一直在上海做开发，今年3月10几号从上海回武汉，准备回武汉发展，还好回来的及时，因为3月20几号，上海就开始封城了，想想都可怕。
回到武汉，投了一些简历，回应并不是特别的好，可能是期望值比较高吧，后来，就降低了一些标准，进了个小公司，负责项目的后台全部开发，
一直想转go开发，后来就用go做后端开发语言，再后来就来到了现在的公司，感觉2022年过的稀里糊涂，反正就是过了这一年。2023年的工作
计划是，继续在全栈开发的路上越走越远，继续完善自己的项目，希望可以做起来。`}]},{path:"/content/other/spread/2023%E5%80%92%E8%AE%A1%E6%97%B6.html",title:"2023倒计时",pathLocale:"/",contents:[{header:"",slug:"",content:`现在是2023年12月31日晚上22:41分，即将进入2024年，在即将跨年之际，相对过去一年做一个总结.
1.工作
2023年的计划是往全栈技术靠拢，开发一套在线教育平台，目前，全栈开发这一块儿基本上没什么问题了，前端也算是熟悉了一些，至少可以单独
排页面了，后端技术，之前一直用的是laravel，目前整个公司的项目都是symfony，我也从一个小白，掌握了这个框架的大部分知识，也灭杀问题，
但是目前项目用的技术栈还是有些贫乏，除了有一些新的框架，比如: nuxt tailwindcss typescript 这些前端的东西，后端基本上没有什么新
的东西，就是很普通的业务逻辑，甚至都没有使用redis这些，唯一使用的可能是一个企业级搜索引擎:solr，这个配置还是挺简单的，其它的就没有
什么了，我感觉很单一，所以我计划2024继续我的在线教育平台的开发，把过去学到的东西，都应用进来，不同端使用不同的语言框架，我认为这很
有必要，毕竟在武汉这样的城市，只会一门语言实在是太难生存了，还有就是自己马上也就34了，开发这个在线教育平台，也是给自己一次创业的机会
，毕竟以后的路会越来越难，但凡能够自给自足，才能放松，否则一直得不断的学习，充实自己。 2.生活
我感觉目前生活的很单一，没有花很多时间在其它方面，可能大部分时间都在陪家人度过，可能我觉得这世上除了家人，好像没什么值得自己再花时间
去维系的吧，这是30岁以后的我的感受，如果在30岁之前大概不会这样，我是2017年结婚的，那年27，不知道为什么，现在感觉家庭在我心目中是
非常重要的，其它的都是浮云。话说今年想买个自行车，没事骑一骑的，但是一直没有付诸行动，夏天的时候还搞了一次肾结石，当时给我疼的，我还
是想还好锻炼身体，肌肉还是要有的，毕竟曾经的自己还是很strong的，也是暴脾气，不服就干。 3.未来
其实这个年纪的我算是目标比较清晰的了，马上回武汉就两年了，感觉上班真的很难挣到钱，所以2024还是需要一些行动的，我想注册自己的公司，将
知识变现，这个是我过去10年的工作总结，知识真的是有价值的，也是最轻松也是最容易实现的，所以我要尝试。我打算在后台功能模块都开发的差不
多了，就行动，不过实现这个目标，还是以有很多细节需要处理，一个是美工，二个是运营，看似简单，其实很难，当然如果花钱的话可能会容易一些吧。
还有就是希望给自己的孩子一个高的起点吧，我不想把希望都寄托在下一代身上，能实现多少就实现多少吧。这个世界很大，应该努力出去看看。 4.结语
2024向着目标继续努力 上进 奋斗 加油!`}]},{path:"/content/other/spread/2024%E5%80%92%E8%AE%A1%E6%97%B6.html",title:"2024倒计时",pathLocale:"/",contents:[{header:"",slug:"",content:`现在是2024年12月31日21:56分，即将进入2025年，其实之前感觉有很多话想说，可是打开电脑突然不知道从哪里说起。 1.工作上:
回顾过去一年，工作基本上就是围绕公司的项目在开发，目前的技术栈是 mysql8 + symfony7 + nuxt3 + tailwindcss3 + vue3 + typescript，之前第一个项目其实感觉tailwindcss3很有局限性，但是用久了感觉也
挺好的，整个项目是前后端分离的，后端基于docker搭建的开发环境，感觉还可以，适用于laravel11项目。vue3的话，目前主要是组合式API开发，彻底摒弃了vue2的语法，感觉很舒服。并且ts和vue3的结合使用，效率真
的很高。其实很想使用ts开发一个插件的，但是一直没有时间去弄，不过中间花时间重新完善了一个老版本的vuepress2搜索插件，感觉也不错。个人项目上，本来自己计划的在线教育平台已经开发完了，但是我发现一个问题
，现在AI工具实在是太强大了，我需要把大模型搜索也加进来，基本上也实现了，现在一直有个疑问，搞了这个平台，没流量，怎么办? 所以计划2025还是从在大平台打造自己的个人IP开始，而不是有个孤零零的产品，这个很
重要。至于怎么开始，还得好好考虑下。或许会从B站开始吧。 2.生活上:
感觉没有特别的，还是一如既往，一步一个脚印，有时间就多陪陪孩子，好吃好喝。 3.未来:
话说告别2024，迎来2025，那么自己也就35了，时间过的真的很快，从2014年大学毕业，一晃就十年了，仿佛一切就像昨天发生的一样，这是一个非常关键的分界岭。无论如何都需要稳定自己的收入，但是年龄越来越大的问题
也是很焦虑的，还是那个目标，知识变现的问题，总会有突破口。回想起自己曾经踏上新疆的沙漠，走进油田的日子，我感觉大部分大学毕业生都会会像我当初那样，迷茫的，路在哪里，不知道。但是我还是认为知识是最有价值
的，还是这个方向。 4.结语
2024在平淡中度过，2025继续加油!`}]},{path:"/content/other/spread/AppImage%E5%92%8CDeb%E5%8C%85%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"AppImage和Deb包的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`AppImage和Deb包的区别:
AppImage 是一种通用的软件打包格式,它可以在大多数 Linux 发行版上直接运行而无需安装。这种格式允许开发者将整个应用程序及其所有依赖项打包到单个文件中,使应用程序更易于分发和使用。 使用 AppImage 具有以下一些优点: 无需安装 - 只需下载 AppImage 文件,标记为可执行,然后直接运行它。
无依赖地狱 - AppImage 中已经包含了应用程序所需的所有依赖库,避免了传统软件包之间相互依赖的问题。
与发行版无关 - 理论上,AppImage 可以在所有 Linux 发行版上运行,而无需针对特定版本进行打包或编译。
沙箱化 - AppImage 在沙箱环境中运行,避免与系统其他部分产生冲突。
易于删除 - 只需删除 AppImage 文件即可完全卸载应用程序。
在 Ubuntu 上使用 AppImage 非常简单,请按照以下步骤操作: 下载所需的 AppImage 文件。
在终端中导航到下载目录。
使用 chmod a+x 命令赋予 AppImage 文件可执行权限。例如: chmod a+x ApplicationName.AppImage
运行该文件,例如: ./ApplicationName.AppImage
就是这样,应用程序就会启动了!很多开源软件和一些商业软件现在都提供了 AppImage 格式的下载。它为 Linux 用户提供了一种额外的灵活安装选择。 Debian软件包(deb格式)是Ubuntu等基于Debian的Linux发行版使用的传统软件包格式。deb格式和AppImage有一些显著区别: deb软件包:
需要通过包管理器(如apt)安装,会将文件解包并部署到系统相应的位置。
会自动处理依赖关系,从软件仓库下载所需的依赖库。
与系统的软件包管理深度集成,可以方便地升级、卸载。
被安装到系统后,多个程序可共享同一个库文件。
安装时可能会修改系统配置(如修改环境变量等)。
特定于不同的Linux发行版和架构。
相比之下,AppImage: 是单个可执行文件,不需安装过程。
所有依赖已打包在内,不依赖系统库。
与系统基本隔离,不会影响其它程序,更新时完全覆盖。
可以在不同Linux发行版和架构间移植使用。
方便分发和备份,只需复制AppImage文件。
总的来说,deb更适合常规需要深度系统集成的应用程序,而AppImage则更加灵活、无缝,尤其适合在不同环境间使用、测试或临时运行某些程序。两者在使用场景和设计理念上有所不同,兼有利弊,开发者或用户可根据实际需求选择使用。`}]},{path:"/content/other/spread/CIDR%E7%9A%84%E5%90%AB%E4%B9%89.html",title:"CIDR的含义",pathLocale:"/",contents:[{header:"",slug:"",content:`CIDR的含义:
英文缩写: CIDR (Classless InterDomain Routing)
中文译名: 无类别域间路由
分 类: 网络与交换
解 释: 现行的IPv4（网际协议第4版）的地址将耗尽，这是一种为解决地址耗尽而提出的一种措施。它是将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，可以减少由核心路由器运载的路由选择信息的数量。
CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给服务提供商（ISP），再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，从而减轻Internet路由器的负担。所有发送到这些地址的信息包都被送到如MCI或Sprint等ISP。1990年，Internet上约有2000个路由。五年后，Internet上有3万多个路由。如果没有CIDR，路由器就不能支持Internet网站的增多。 CIDR采用13～27位可变网络ID，而不是A-B-C类网络ID所用的固定的7、14和21位。 CIDR 如何工作: CIDR 对原来用于分配A类、B类和C类地址的有类别路由选择进程进行了重新构建。CIDR用 13-27位长的前缀取代了原来地址结构对地址网络部分的限制（3类地址的网络部分分别被限制为8位、16位和24位）。在管理员能分配的地址块中，主机数量范围是32-500,000，从而能更好地满足机构对地址的特殊需求。 CIDR 地址中包含标准的32位IP地址和有关网络前缀位数的信息。以CIDR地址222.80.18.18/25为例，其中“/25”表示其前面的之中的前25位代表网络部分，其余位代表主机部分。 CIDR建立于“超级组网”的基础上，“超级组网”是“子网划分”的派生词，可看作子网划分的逆过程。子网划分时，从地址主机部分借位，将其合并进网络部分；而在超级组网中，则是将网络部分的某些位合并进主机部分。这种无类别超级组网技术通过将一组较小的无类别网络汇聚为一个较大的单一路由表项，减少了Internet路由域中路由表条目的数量。`}]},{path:"/content/other/spread/CORS%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.html",title:"CORS的工作流程",pathLocale:"/",contents:[{header:"",slug:"",content:`CORS的工作流程:
浏览器发起请求，当检测到跨域请求时，浏览器会自动发送一个预检请求（OPTIONS 请求），询问目标服务器是否允许跨域。
服务器响应：如果服务器在响应中包含了正确的 CORS 头（如 Access-Control-Allow-Origin: * 或指定的域名），浏览器才会允许跨域请求的实际数据交互。 关键点：
1>CORS 是浏览器层的限制，用于保护用户免受潜在的恶意跨域请求攻击。
2>服务器端通信不受 CORS 限制：如果客户端不是浏览器（如服务器端代码、Postman、curl），跨域限制不适用。
3>服务器配置 CORS 响应头：通过服务器设置正确的 Access-Control-Allow-Origin 头，浏览器就能允许合法的跨域请求。 如何解决跨域问题？
1>服务器设置 CORS 头：通过在服务器响应中添加 Access-Control-Allow-Origin，可以允许特定源或所有源访问资源。
2>使用代理服务器：在开发环境中，本地代理服务可以转发请求，绕过浏览器的同源策略。
3>开发时禁用 CORS：可以启动浏览器时禁用 CORS 安全检查，或者使用浏览器插件来临时关闭跨域限制。// google 使用 CORS Unblock`}]},{path:"/content/other/spread/CPU_GPU_%E5%86%85%E5%AD%98_%E6%98%BE%E5%AD%98%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"CPU、GPU、内存、显存之间的关系",pathLocale:"/",contents:[{header:"CPU、GPU、内存、显存之间的关系",slug:"cpu、gpu、内存、显存之间的关系",content:""},{header:"🖥️ 计算机核心硬件关系",slug:"🖥️-计算机核心硬件关系",content:""},{header:"1️⃣ CPU（中央处理器）",slug:"_1️⃣-cpu-中央处理器",content:`作用：通用计算（操作系统、程序运行、逻辑控制） 和内存关系： 需要数据时 → 向 内存（RAM）取数据
计算完成 → 再写回内存 局限：并行能力弱，不适合大规模矩阵计算（比如深度学习）。`},{header:"2️⃣ 内存（RAM）",slug:"_2️⃣-内存-ram",content:`作用：临时存储程序运行时的数据 特征： 容量大（几 GB ～ 几十 GB）
速度比硬盘快，但比 CPU/GPU 缓存慢 关系： CPU 和 GPU 都要从 内存里取数据
相当于一个“工作台”，越大越能同时放更多东西。`},{header:"3️⃣ GPU（图形处理器）",slug:"_3️⃣-gpu-图形处理器",content:`作用：擅长并行计算（图形渲染、AI 训练/推理） 和内存关系： 需要数据时，通常要从 内存复制数据到显存，才能计算 特点： 核心数多（上千个），擅长矩阵运算
适合深度学习、图像识别`},{header:"4️⃣ 显存（VRAM）",slug:"_4️⃣-显存-vram",content:`作用：GPU 的“专用内存” 特征： 容量比内存小（常见 4GB ～ 24GB）
速度比普通内存快很多（带宽大） 关系： GPU 计算前，要把数据从 RAM 传到 VRAM
模型和中间结果都要放在 VRAM，显存不够就会报错（Out of Memory, OOM）`},{header:"🔄 数据流关系总结",slug:"🔄-数据流关系总结",content:`硬盘（SSD/HDD） ↓ （加载程序/数据）
内存（RAM） ↓ （CPU 取数据）
CPU（逻辑控制/通用计算） 或：
内存（RAM） ↓ （复制到显存 VRAM）
显存（VRAM） ↓
GPU（并行计算）`},{header:"📌 总结一句话",slug:"📌-总结一句话",content:`CPU：大脑，做通用计算，和内存直接交互
内存（RAM）：工作台，存运行时数据，CPU/GPU都要用
GPU：计算工厂，擅长并行运算，需要数据放进显存
显存（VRAM）：GPU的专属小工作台，存放模型和图像数据`}]},{path:"/content/other/spread/DNS%E5%92%8CNS%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"DNS和NS的关系",pathLocale:"/",contents:[{header:"DNS和NS的关系",slug:"dns和ns的关系",content:""},{header:"✅ 先解释：",slug:"✅-先解释",content:"DNS 服务器 和 DNS 是什么关系？"},{header:"一句话总结：",slug:"一句话总结",content:"DNS 是一个系统（协议 + 架构 + 工作流程），而 DNS 服务器 是这个系统中的具体“执行者”或“节点”。"},{header:"🔍 更清楚地说：",slug:"🔍-更清楚地说",content:`概念
解释 DNS
全称是 Domain Name System，是一个分布式的域名解析系统/协议 DNS 服务器
实现 DNS 协议的服务器，负责接收、处理域名查询请求，返回 IP 或其他记录`},{header:"🔁 举个生活中的类比：",slug:"🔁-举个生活中的类比",content:`概念
类比 DNS
像是“全国身份证查询系统”（一套规则+分层管理） DNS 服务器
像是“你所在城市的公安局户籍查询窗口”（提供查询服务的执行点） 所以： DNS 是系统和协议的总称
DNS 服务器 是实际提供服务的电脑/节点`},{header:"📚 常见的几种 DNS 服务器类型：",slug:"📚-常见的几种-dns-服务器类型",content:`类型
作用 根 DNS 服务器
全球最上层的 13 个服务器，负责告诉你 .com、.org 等的服务器在哪 顶级域服务器（TLD）
管理 .com、.net、.cn 等域的解析 权威 DNS 服务器
最终提供某个具体域名的记录（如 example.com 的 A 记录），通常由 NS 平台提供 递归 DNS 服务器
你本地网络使用的 DNS（比如 114.114.114.114），它会帮你“找到底”再返回结果`},{header:"🧠 举个真实查询过程来对照：",slug:"🧠-举个真实查询过程来对照",content:`你访问：www.example.com 你电脑访问的是「本地 DNS 服务器」（114.114.114.114） → 递归服务器 它再访问： 根 DNS 服务器
.com 顶级域服务器
example.com 的权威 DNS 服务器（由 NS 提供） 最终返回：A 记录 → 93.184.216.34`},{header:"✅ 小结：",slug:"✅-小结",content:`概念
核心理解 DNS
一种分布式系统 + 通信协议 DNS 服务器
实现和运行 DNS 协议的服务器节点 关系
DNS 是整个机制，DNS 服务器是参与者`},{header:"NS（Name Server）是什么？",slug:"ns-name-server-是什么",content:`NS 是 DNS 系统中的一个重要部分，指的是域名服务器（Name Server），它负责存储和提供一个域名的 DNS 记录。 一个域名的 NS 记录 指向了谁负责解析该域名。
NS 是 DNS 的具体执行者，它告诉别人你的域名解析记录在哪里查。`},{header:"DNS 和 NS 的关系",slug:"dns-和-ns-的关系",content:`方面
DNS
NS 全称
Domain Name System
Name Server（名称服务器） 作用
整个域名解析系统
负责提供域名解析记录的服务器 举例
把 example.com 转成 IP 地址
提供 example.com 的 A、MX、CNAME 等记录的服务器 类型
是一个系统
是 DNS 系统中的服务器角色 记录类型
包含 A、CNAME、MX、TXT、NS 等
NS 是其中的一种记录类型，告诉谁负责域名的解析`},{header:"常见 DNS 记录类型",slug:"常见-dns-记录类型",content:`类型
说明
示例 A
把域名解析为 IPv4 地址
example.com → 1.2.3.4 AAAA
把域名解析为 IPv6 地址 CNAME
别名记录，将一个域名指向另一个域名
www.example.com → example.com MX
邮件服务器记录 TXT
文本记录，用于验证、SPF、DKIM 等 NS
指定该域名使用哪些 Name Server
example.com → ns1.dns.com`},{header:"实际场景举例",slug:"实际场景举例",content:`假设你注册了一个域名 myapp.com，并使用了某 DNS 服务商（比如 Cloudflare 或 阿里云）： 在域名注册商处配置 NS 记录： 设置为：ns1.cloudflare.com、ns2.cloudflare.com 这些 NS 会在 Cloudflare 端提供 DNS 记录： A 记录：myapp.com → 123.123.123.123
CNAME 记录：www.myapp.com → myapp.com`},{header:"小结",slug:"小结",content:`DNS 是整个域名解析的体系。
NS 是负责「提供解析记录」的服务器。
配置 NS 是把域名解析的权力交给某个 DNS 服务商。
NS 记录在域名注册商处设置，A、CNAME 等记录在 DNS 服务商管理后台设置。
之前容易混淆是因为 之前的 域名服务 IP NS 都是阿里云，所以感觉不出差别，但是NS是是可以配置为其它的服务商的，那么对应的A 等记录也需要在其它服务商平台配置
一般不要混合使用多个不同的NS, 但是可以使用多个同平台的NS， 比如ns1.google.com ns2.google.com 如果不同平台的 NS 配置内容不一致，就会出现结果不一致，导致解析“有时对，有时错”。
各平台的 TTL、同步机制也不同，容易产生冲突或循环解析。
有些平台还会检测域名是否真的使用它们的 NS，如果只是挂着不管理，可能导致 NXDOMAIN。`}]},{path:"/content/other/spread/FFMpeg%E5%A4%84%E7%90%86%E8%A7%86%E9%A2%91.html",title:"FFMpeg处理视频",pathLocale:"/",contents:[{header:"",slug:"",content:`最近在做视频上传的时候，有个需求是，当视频上传玩以后，需要获取视频时长，所以想到用这个工具
1.ubuntu22安装FFMpeg sudo apt update
sudo apt install ffmpeg
ffmpeg -version 2. 使用
$ffprobe = FFProbe::create();
$ffprobe->format($fileUrl)->get('duration'); 直接这样使用会报错：Unable to load FFProbe的问题，需要添加配置文件 $config = [ 'ffmpeg.binaries' => '/usr/bin/ffmpeg', 'ffprobe.binaries' => '/usr/bin/ffprobe' ];
$ffprobe = FFProbe::create($config);
$videoDuration = $ffprobe->format($fileUrl)->get('duration'); 这样就可以获取视频的时长`}]},{path:"/content/other/spread/Google_Search_Console%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"Google_Search_Console的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`Google_Search_Console的使用:
seo在Google Search Console提交下网页，可以加速更新搜索内容 说明:
Google Search Console 是由 Google 提供的一款免费工具，主要用于帮助网站所有者和管理员监控、维护和优化他们网站在 Google 搜索结果中的表现。以下是 Google Search Console 的一些主要功能和用途： 网站索引状态：查看您的网站页面是否已被 Google 收录和索引。
搜索分析：了解用户如何通过 Google 搜索找到您的网站，包括搜索查询、点击率、排名位置等数据。
移动设备友好性：检查您的网站是否适合在移动设备上浏览。
网站错误报告：发现并修复网站中的技术问题，如 404 错误页面或服务器错误。
安全问题通知：如果 Google 检测到您的网站存在安全问题（如恶意软件或网络钓鱼），会通过 Search Console 通知您。
结构化数据：测试和监控您网站的结构化数据标记。
站点地图提交：向 Google 提交您网站的站点地图，帮助搜索引擎更好地理解您的网站结构。
外部链接：查看哪些网站链接到了您的网站。
核心网页指标：了解您网站的用户体验表现，如加载速度、交互性和视觉稳定性。
URL 检查工具：检查特定 URL 在 Google 搜索中的索引状态。 使用 Google Search Console 可以帮助网站管理员优化他们的网站，提高在搜索结果中的可见性，并解决可能影响搜索排名的问题。 手册:
https://developers.google.com/search/docs/monitor-debug/search-console-start?hl=zh-cn`}]},{path:"/content/other/spread/IP%E5%9C%B0%E5%9D%80.html",title:"IP地址",pathLocale:"/",contents:[{header:"",slug:"",content:`经常会使用到这些概念，记录一下
IP地址分类/IP地址10开头和172开头和192开头的区别/判断是否同一网段 简单来说在公司或企业内部看到的就基本都是内网IP，ABC三类IP地址里的常见IP段。 每个IP地址都包含两部分，即网络号和主机号。 InterNIC将IP地址分为五类:
A类保留给ZF或大型企业，
B类分配给中等规模的公司，
C类分配给小公司或个人，
D类用于组播，
E类用于实验，
注：各类可容纳的地址数目不同。 A、B、C三类IP地址的特征：当将IP地址写成二进制形式时，
A类地址的第一位总是O，如，10.0.0.1==00001010-00000000-00000000-00000001
==》1.0.0.0-127.255.255.255，默认子网掩码为255.0.0.0，最多可容纳16777215台计算机
B类地址的前两位总是10，如，172.16.0.1==10101100-00010000-00000000-00000001
==》128.0.0.0-191.255.255.255，默认子网掩码为255.255.0.0，最多可容纳65535台计算机
C类地址的前三位总是110。如，192.168.0.1==11000000-10101000-00000000-00000001
==》192.0.0.0-223.255.255.255，默认子网掩码是255.255.255.0，最多可容纳254台计算机 IP地址中保留地址：主机部分全为0的IP地址保留用于网络地址，主机部分全为1的IP地址保留为广播地址，224--255部分保留作为组播和实验目的。 同时注意IP地址分配时不能使用最末位为0和255的地址，因为这是广播地址，普通计算机上不能使用，但可用于网关和路由器上。 专用IP地址： 就是我们在3类地址中常见到内网的IP段。 10.0.0.0--10.255.255.255
172.16.0.0--172.31.255.255 192.168.0.0--192.168.255.255 内网的计算机以NAT（网络地址转换）协议，通过一个公共的网关访问Internet。内网的计算机可向Internet上的其他计算机发送连接请求，但Internet上其他的计算机无法向内网的计算机发送连接请求。`}]},{path:"/content/other/spread/Mnesia%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F.html",title:"Mnesia数据库管理系统",pathLocale:"/",contents:[{header:"",slug:"",content:`简介: Mnesia，是使用Erlang编程语言编写的分布式、软实时数据库管理系统。它也是作为开放电信平台的一部分发布的。 优势: 适用于电信应用的关系/对象混合数据模型。
DBMS 查询语言，查询列表理解 (QLC) 作为附加库。
坚持。表可以连贯地保存在磁盘和主存储器中。
复制。表可以在多个节点上复制。
原子交易。一系列的表操作操作可以组合成一个原子事务。
位置透明度。可以在不知道实际数据位置的情况下编写程序。
极快的实时数据搜索。
模式操作例程。DBMS 可以在运行时重新配置，而无需停止系统。 所属公司: Mnesia 与 Erlang 都是爱立信公司为与电信相关的软实时分布式高可用的计算工作而开发的。 在rabbitMq里的延迟队列插件会用到这个数据库，将消息在交换机处暂存储在mnesia(一个分布式数据系统)表中。`}]},{path:"/content/other/spread/N-A%E7%9A%84%E5%90%AB%E4%B9%89.html",title:"N/A的含义",pathLocale:"/",contents:[{header:"",slug:"",content:`N/A的含义：
N/A，是英语“不适用”（Not applicable）等类似单词的缩写，常可在各种表格中看到，在英文文档中尤其看到的比较多.`}]},{path:"/content/other/spread/SSL%E5%92%8CTLS%E5%8C%BA%E5%88%AB.html",title:"SSL和TLS区别",pathLocale:"/",contents:[{header:"SSL和TLS区别",slug:"ssl和tls区别",content:"SSL 和 TLS 经常被混用，但它们其实有区别，而且 TLS 可以看作是 SSL 的升级版。我们可以从几个方面来理解它们的区别："},{header:"1. 定义",slug:"_1-定义",content:`SSL (Secure Sockets Layer)：由 Netscape 开发的加密协议，用于在客户端和服务器之间建立安全连接。历史版本有 SSL 2.0、SSL 3.0。
TLS (Transport Layer Security)：SSL 的继任者，由 IETF 标准化，更安全、更高效。TLS 1.0~1.3 版本中，1.2 和 1.3 最常用。`},{header:"2. 安全性",slug:"_2-安全性",content:`SSL 已经被认为不安全： SSL 2.0 有多种漏洞，已经废弃。
SSL 3.0 存在 POODLE 攻击漏洞。 TLS 修复了 SSL 的很多问题，并且支持更强的加密算法。`},{header:"3. 协议版本",slug:"_3-协议版本",content:`协议
发布年份
特点 SSL 2.0
1995
弱加密，不推荐使用 SSL 3.0
1996
修复部分漏洞，但仍有安全隐患 TLS 1.0
1999
SSL 3.0 升级版，支持更强算法 TLS 1.1
2006
弱加密改进，支持更安全模式 TLS 1.2
2008
常用版本，支持 AEAD 加密和 SHA-2 TLS 1.3
2018
连接握手更快、更安全，去掉不安全算法`},{header:"4. 握手方式",slug:"_4-握手方式",content:`SSL： 允许多种加密套件，但某些套件不安全。
握手过程较复杂，通信加密过程较慢。 TLS： 改进握手流程（TLS 1.3 更简化，只需一次 RTT）。
强制使用更安全的加密算法，防止降级攻击。`},{header:"5. 协议兼容性",slug:"_5-协议兼容性",content:`TLS 向下兼容 SSL，但通常现代浏览器和服务器只支持 TLS。
所以你现在在浏览器看到的 https://，实际上用的是 TLS，而不是传统 SSL。`},{header:"总结一句话",slug:"总结一句话",content:"TLS 是 SSL 的安全升级版，支持更强加密算法和更高效的握手，SSL 已经过时。"},{header:"案例:",slug:"案例",content:"在 现代 Nginx 配置中，ssl 这个标记 在某些情况下仍然需要，但其意义已经和以前略有不同："},{header:"1. 作用",slug:"_1-作用",content:`listen 443 ssl; 告诉 Nginx 该端口是 HTTPS，需要使用证书进行加密。
如果不加 ssl，Nginx 会把这个端口当作普通 HTTP（明文）端口，即使你配置了证书，也不会启用 TLS。 所以它主要是端口绑定和加密开关，而不是说“使用 SSL 协议”。`},{header:"2. 现代 Nginx 的变化",slug:"_2-现代-nginx-的变化",content:`在 Nginx 1.15.0 之后，你可以使用 listen 443 http2; 并且配合 ssl_certificate 和 ssl_certificate_key 自动启用 TLS。
也就是说，如果你已经配置了证书，现代 Nginx 会自动启用 TLS，即使没有显式写 ssl。
但是为了兼容老配置或明确标识，这个 ssl 仍然常用。`},{header:"3. 推荐做法",slug:"_3-推荐做法",content:`# 推荐明确写 ssl
listen 443 ssl http2;
ssl_certificate /etc/nginx/certs/example.com.crt;
ssl_certificate_key /etc/nginx/certs/example.com.key;
ssl_protocols TLSv1.2 TLSv1.3; 明确写 ssl 可以： 保证向下兼容老版本 Nginx。
让配置语义更清晰：这个端口是 HTTPS/TLS。`},{header:"总结一句话：",slug:"总结一句话-1",content:"不写 ssl 也可能生效（现代 Nginx），但写上 ssl 更安全、明确、兼容。"}]},{path:"/content/other/spread/SVG%E4%B8%8EPNG%E6%9C%89%E4%BD%95%E5%8C%BA%E5%88%AB.html",title:"SVG与PNG有何区别",pathLocale:"/",contents:[{header:"",slug:"",content:`SVG与PNG有何区别:
1.什么是SVG
SVG代表可缩放矢量图形，它是网络上使用最广泛的矢量文件格式 2.SVG的特性
可扩展： SVG可以在不损害图像质量的情况下向上或向下调整大小。无论大小，它都会非常清晰和清晰。
矢量：大多数图像文件类型都包含像素。矢量本质上是实时渲染图像的代码片段，将其转换为您在屏幕上看到的像素。虽然它们显示相同的图像，但背景中发生的事情却大不相同。
图形：虽然可能不太为人所知，但SVG是一种图像文件类型，如PNG、JPEG或GIF。它只是处理事情有点不同。`}]},{path:"/content/other/spread/TCP%E5%92%8CUDP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF.html",title:"TCP和UDP协议使用场景",pathLocale:"/",contents:[{header:"TCP和UDP协议使用场景",slug:"tcp和udp协议使用场景",content:""},{header:"TCP 的典型使用场景，结合它的特性来看。",slug:"tcp-的典型使用场景-结合它的特性来看。",content:""},{header:"🔹 先看 TCP 的特点",slug:"🔹-先看-tcp-的特点",content:`面向连接：三次握手建立连接，保证通信可靠。
可靠传输：有序、无丢失、无重复（靠序列号、确认应答、重传）。
流量控制 & 拥塞控制：保证传输不会把对方或网络压垮。
面向字节流：数据是连续的字节流，适合大块数据传输。 因此：TCP 适合对数据完整性和可靠性要求高的场景。`},{header:"🔹 TCP 使用场景",slug:"🔹-tcp-使用场景",content:""},{header:"1. 网页访问（HTTP/HTTPS）",slug:"_1-网页访问-http-https",content:`绝大多数网页加载基于 HTTP/1.1 和 HTTP/2 → TCP（HTTP/3 除外，它基于 QUIC/UDP）。
要求：数据必须完整，HTML/CSS/JS 少一个字节都可能出错。`},{header:"2. 文件传输",slug:"_2-文件传输",content:`FTP、SFTP、FTPS、SMB、NFS 等。
要求：文件必须 100% 完整，不能丢数据。`},{header:"3. 电子邮件",slug:"_3-电子邮件",content:`SMTP、IMAP、POP3 都基于 TCP。
要求：邮件必须完整送达，不能缺失。`},{header:"4. 数据库访问",slug:"_4-数据库访问",content:`MySQL、PostgreSQL、Oracle、SQL Server 等。
要求：SQL 查询结果必须可靠返回，事务数据绝不能丢。`},{header:"5. 远程登录",slug:"_5-远程登录",content:`SSH、Telnet。
要求：命令和输出必须可靠有序，不能乱序。`},{header:"6. 即时通讯（文字为主）",slug:"_6-即时通讯-文字为主",content:`微信文字聊天、Slack、WhatsApp 消息（消息层用 TCP 或基于 TCP 的协议）。
要求：文字消息不能丢，必须按顺序送达。
（语音/视频实时通话则更多走 UDP）`},{header:"7. 大多数 API 调用",slug:"_7-大多数-api-调用",content:`REST API（基于 HTTP/HTTPS）
gRPC（默认基于 HTTP/2 → TCP）
要求：请求和响应必须可靠。`},{header:"8. 大部分区块链网络",slug:"_8-大部分区块链网络",content:"例如 比特币、以太坊 P2P 节点，常用 TCP 传输区块数据。"},{header:"🔹 UDP 的使用场景",slug:"🔹-udp-的使用场景",content:""},{header:"🔹 先回顾 UDP 特点",slug:"🔹-先回顾-udp-特点",content:`无连接：不需要三次握手，直接发包。
不可靠：不保证包一定送达，也不保证顺序。
轻量级：头部开销小（8字节，对比 TCP 的 20+ 字节）。
实时性强：延迟低，不需要等待确认。 所以：UDP 适合对速度要求高、但能容忍部分丢包的场景。`},{header:"🔹 典型使用场景",slug:"🔹-典型使用场景",content:""},{header:"1. 实时音视频/语音通话",slug:"_1-实时音视频-语音通话",content:`场景：Zoom、微信语音、腾讯会议、直播推流
原因：语音/视频是实时流，偶尔丢几个包只会造成瞬时马赛克，比延迟要好得多。
协议：很多基于 RTP/RTCP (Real-time Transport Protocol)，底层是 UDP。`},{header:"2. 在线游戏",slug:"_2-在线游戏",content:`场景：LOL、王者荣耀、CS:GO 等
原因：游戏对实时性要求高，玩家移动/攻击数据必须快速同步，丢个包就算了，下一个包会更新位置。
协议：常见的游戏引擎（如 Unity、Unreal）提供 UDP 网络模块。`},{header:"3. DNS (域名解析)",slug:"_3-dns-域名解析",content:`场景：解析 www.example.com -> IP
原因：DNS 查询通常只有一个请求+一个响应，短小快速，不必建立 TCP 连接。
说明：大部分 DNS 用 UDP，只有在响应过长或需要可靠性时才会切 TCP。`},{header:"4. DHCP (动态主机配置协议)",slug:"_4-dhcp-动态主机配置协议",content:`场景：电脑开机自动获取 IP 地址
原因：刚开机时还没有 IP，无法建立 TCP 连接；用 UDP 广播发送发现包更合适。`},{header:"5. 流媒体传输",slug:"_5-流媒体传输",content:`场景：视频直播（RTSP、QUIC 之前的 RTP/UDP 流）、IPTV
原因：对实时性要求高，允许一定丢包，UDP 更适合。`},{header:"6. 物联网（IoT）和轻量协议",slug:"_6-物联网-iot-和轻量协议",content:`场景：传感器上报数据、MQTT-SN 等
原因：设备算力有限，UDP 更节省资源。`},{header:"7. 新一代协议（基于 UDP 封装可靠性）",slug:"_7-新一代协议-基于-udp-封装可靠性",content:`QUIC（HTTP/3 使用） Google 开发，跑在 UDP 上，但自己实现了可靠传输、加密、多路复用。
好处：比 TCP+TLS+HTTP/2 快，尤其适合移动网络。 所以，HTTP/3 = QUIC = 基于 UDP，但表现出类似 TCP 的可靠性。`},{header:"TCP和UDP对比",slug:"tcp和udp对比",content:`TCP vs UDP 对比表 + 场景举例 特性
TCP
UDP 类型
面向连接
无连接 可靠性
可靠传输，保证数据完整、有序
不保证可靠性，可能丢包或乱序 数据传输
面向字节流
面向报文（Message） 连接建立
三次握手
无需握手，直接发包 连接关闭
四次挥手
不需要关闭 流量控制
有（避免拥塞）
无 传输延迟
较高（可靠性开销）
低（轻量、实时） 头部开销
20 字节
8 字节 适合场景
文件传输、网页访问、邮件、数据库、远程登录
实时语音/视频、在线游戏、DNS 查询、直播、IoT 上报 典型应用协议
HTTP/HTTPS、FTP/SFTP、SMTP/IMAP/POP3、MySQL/PostgreSQL、SSH
DNS、DHCP、RTP/RTCP（音视频）、QUIC（HTTP/3）、游戏自定义协议 使用特点
数据完整性优先，允许延迟
速度和实时性优先，可容忍丢包`},{header:"🔹 总结对比",slug:"🔹-总结对比",content:`TCP → 数据必须完整，能等，适合文件、网页、数据库、邮件、API。
UDP → 要快、实时，丢一点没关系，适合语音视频、游戏、DNS、直播。`}]},{path:"/content/other/spread/ab%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95.html",title:"ab压力测试",pathLocale:"/",contents:[{header:"",slug:"",content:`搭建服务以后，会对其做压力测试，这里选择ab压力测试 ab的概念:
ab是ApacheBench命令的缩写。 ab的原理:
ab命令会创建多个并发访问线程，模拟多个访问者同时对某一URL地址进行访问。它的测试目标是基于URL的，因此，它既可以用来测试apache的负载压力，也可以测试nginx等其它Web服务器的压力。 ab的安装:
[root@k8smaster k8s-cluster]# yum install httpd-tools ab参数说明:
[root@k8smaster ~]# ab --help
ab: wrong number of arguments
Usage: ab [options] [http[s]://]hostname[:port]/path
Options are: -n requests Number of requests to perform -c concurrency Number of multiple requests to make at a time -t timelimit Seconds to max. to spend on benchmarking This implies -n 50000 -s timeout Seconds to max. wait for each response Default is 30 seconds -b windowsize Size of TCP send/receive buffer, in bytes -B address Address to bind to when making outgoing connections -p postfile File containing data to POST. Remember also to set -T -u putfile File containing data to PUT. Remember also to set -T -T content-type Content-type header to use for POST/PUT data, eg. 'application/x-www-form-urlencoded' Default is 'text/plain' -v verbosity How much troubleshooting info to print -w Print out results in HTML tables -i Use HEAD instead of GET -x attributes String to insert as table attributes -y attributes String to insert as tr attributes -z attributes String to insert as td or th attributes -C attribute Add cookie, eg. 'Apache=1234'. (repeatable) -H attribute Add Arbitrary header line, eg. 'Accept-Encoding: gzip' Inserted after all normal header lines. (repeatable) -A attribute Add Basic WWW Authentication, the attributes are a colon separated username and password. -P attribute Add Basic Proxy Authentication, the attributes are a colon separated username and password. -X proxy:port Proxyserver and port number to use -V Print version number and exit -k Use HTTP KeepAlive feature -d Do not show percentiles served table. -S Do not show confidence estimators and warnings. -q Do not show progress when doing more than 150 requests -g filename Output collected data to gnuplot format file. -e filename Output CSV file with percentages served -r Don't exit on socket receive errors. -h Display usage information (this message) -Z ciphersuite Specify SSL/TLS cipher suite (See openssl ciphers) -f protocol Specify SSL/TLS protocol (SSL3, TLS1, TLS1.1, TLS1.2 or ALL) -n：在测试会话中所执行的请求个数。默认时，仅执行一个请求。 -c：一次产生的请求个数。默认是一次一个。 ab -c 100 -n 200 http://192.168.123.142/
上面的语句表示有100个并发访问，每秒总共有200个请求，在此情况下进行压力测试。 ab性能指标:
1、吞吐率（Requests per second）
服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。 记住：吞吐率是基于并发用户数的。这句话代表了两个含义：
a、吞吐率和并发用户数相关
b、不同的并发用户数下，吞吐率一般是不同的 计算公式：总请求数/处理完成这些请求数所花费的时间，即
Request per second=Complete requests/Time taken for tests 必须要说明的是，这个数值表示当前机器的整体性能，值越大越好。 2、并发连接数（The number of concurrent connections）
并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。 3、并发用户数（Concurrency Level）
要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数就得除以这个基数。 4、用户平均请求等待时间（Time per request） 计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即：
Time per request=Time taken for tests/（Complete requests/Concurrency Level） 5、服务器平均请求等待时间（Time per request:across all concurrent requests） 计算公式：处理完成所有请求数所花费的时间/总请求数，即：
Time taken for/testsComplete requests
可以看到，它是吞吐率的倒数。 同时，它也等于用户平均请求等待时间/并发用户数，即
Time per request/Concurrency Level ad压力测试案例:
[root@k8smaster k8s-cluster]# ab -n 1000 -c 10 https://test.abc.com/v1/test/helloword
This is ApacheBench, Version 2.3 <$Revision: 1430300 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking test.abc.com (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Completed 600 requests
Completed 700 requests
Completed 800 requests
Completed 900 requests
Completed 1000 requests
Finished 1000 requests Server Software: Server Hostname: test.abc.com
Server Port: 443
SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128 Document Path: /v1/test/helloword
Document Length: 21 bytes Concurrency Level: 10
Time taken for tests: 13.639 seconds
Complete requests: 1000
Failed requests: 0
Write errors: 0
Total transferred: 221000 bytes
HTML transferred: 21000 bytes
Requests per second: 73.32 [#/sec] (mean)
Time per request: 136.389 [ms] (mean)
Time per request: 13.639 [ms] (mean, across all concurrent requests)
Transfer rate: 15.82 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max
Connect: 12 117 286.8 22 1674
Processing: 4 13 36.8 5 619
Waiting: 4 13 36.8 5 619
Total: 16 130 290.3 30 1680 Percentage of the requests served within a certain time (ms) 50% 30 66% 61 75% 68 80% 73 90% 288 95% 840 98% 1655 99% 1661 100% 1680 (longest request)`}]},{path:"/content/other/spread/apt-get_install%E5%92%8Capt_install%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"apt-get install 和 apt install的区别",pathLocale:"/",contents:[{header:"apt-get install 和 apt install的区别",slug:"apt-get-install-和-apt-install的区别",content:"简单来说，apt-get 和 apt 都是 Debian / Ubuntu 系统下的包管理命令，但是它们有一些历史和使用上的区别："},{header:"1. apt-get",slug:"_1-apt-get",content:`历史更久，用于脚本和后台操作。
命令和选项更多、更稳定，向后兼容性好。
常用命令： sudo apt-get update # 更新索引
sudo apt-get upgrade # 升级所有已安装软件包
sudo apt-get install vim # 安装软件包
sudo apt-get remove vim # 卸载软件包
sudo apt-get autoremove # 自动删除不需要的依赖 特点： 面向系统管理员和脚本，稳定可靠。
输出信息比较详细，适合自动化脚本。`},{header:"2. apt",slug:"_2-apt",content:`相对较新（Ubuntu 16.04+ 提供）。
其实是对 apt-get 和 apt-cache 的 高层封装，提供更简洁、用户友好的命令。
常用命令： sudo apt update # 更新索引
sudo apt upgrade # 升级已安装软件
sudo apt install vim # 安装软件包
sudo apt remove vim # 卸载软件包
sudo apt autoremove # 自动删除不需要的依赖 特点： 输出更简洁、带进度条。
面向终端用户和日常操作。
不推荐在脚本里用 apt，因为未来可能会改变输出格式。`},{header:"⚡ 总结",slug:"⚡-总结",content:`命令
适用场景
输出/体验
稳定性 apt-get
脚本、后台操作
详细、稳定
高 apt
终端交互、手动操作
简洁、带进度条
稳定，但面向用户 ✅ 结论： 日常手动安装软件 → 用 apt，更简洁。
脚本或自动化 → 用 apt-get，更安全稳定。`}]},{path:"/content/other/spread/dnsmasq%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"dnsmasq的使用",pathLocale:"/",contents:[{header:"dnsmasq的使用",slug:"dnsmasq的使用",content:"dnsmasq 是一个轻量级的 DNS 转发器和 DHCP 服务器，广泛用于小型网络、开发环境或嵌入式设备中。它配置简单、占用资源少，非常适合以下用途："},{header:"📌 常见用途",slug:"📌-常见用途",content:`DNS 缓存与转发
提高域名解析速度，将请求转发给上游 DNS（如 8.8.8.8）。 本地域名解析
比如将 myapp.local 指向某个本地 IP（适合本地开发环境）。 DHCP 服务器
给局域网内设备自动分配 IP 地址。 PXE 网络启动、TFTP 支持
常用于自动化部署或嵌入式系统。`},{header:"✅ 示例：配置本地域名解析和 DNS 缓存",slug:"✅-示例-配置本地域名解析和-dns-缓存",content:"假设你希望将 myapp.local 解析到本地服务器 IP 192.168.1.100，并启用 DNS 缓存："},{header:"/etc/dnsmasq.conf 示例：",slug:"etc-dnsmasq-conf-示例",content:`# 指定上游 DNS 服务器
server=8.8.8.8 # 启用缓存
cache-size=1000 # 自定义域名解析
address=/myapp.local/192.168.1.100`},{header:"✅ 示例：同时启用 DHCP",slug:"✅-示例-同时启用-dhcp",content:`# 设置 DHCP 范围
dhcp-range=192.168.1.50,192.168.1.150,12h 同时启用 DHCP 的作用，可以为局域网内的设备分配IP，要让这个配置生效，可以通过如下步骤实现:
1.用网线（或热点）把其他设备连接到你电脑（桥接或共享网络）
2.禁用局域网中其他 DHCP（如路由器 DHCP）
3.动你电脑的 dnsmasq，分配 IP（如 192.168.1.50~150）
4.其他设备会自动获得 IP 并使用你的电脑作为 DNS / 网关 如果只是想测试一下 dnsmasq 的 DHCP 功能，可以这样：
使用笔记本 → 开热点 → 运行 dnsmasq → 其他设备连接这个热点
1.用 Linux 笔记本开 Wi-Fi 热点（或者 USB 网络共享）
2.设置热点子网为如 192.168.8.1
3.在热点网卡上启用 dnsmasq，配置为：
interface=wlp3s0 # ← 你开启热点的那个网卡
dhcp-range=192.168.8.50,192.168.8.150,12h
dhcp-option=3,192.168.8.1 # 默认网关
dhcp-option=6,192.168.8.1 # DNS
4.手机、电脑连上你的热点后，会自动分配 IP，并能通过你电脑访问自建服务。`},{header:"启动服务（在 Linux 上）",slug:"启动服务-在-linux-上",content:"sudo systemctl start dnsmasq\nsudo systemctl enable dnsmasq 或者使用 Docker 启动（如果不想改本机配置）：\ndocker run --rm -p 53:53/udp --cap-add=NET_ADMIN \\ -v $(pwd)/dnsmasq.conf:/etc/dnsmasq.conf \\ # 可以现在本地定义好`dnsmasq`的配置文件, 然后挂载 andyshinn/dnsmasq"}]},{path:"/content/other/spread/event_stream%E6%A0%BC%E5%BC%8F.html",title:"关于 text/event-stream",pathLocale:"/",contents:[{header:"",slug:"",content:`关于 text/event-stream:
text/event-stream 是一种特殊的 MIME 类型,用于服务器向客户端发送事件流。这种技术主要用于实现服务器发送事件(Server-Sent Events, SSE)。以下是对 text/event-stream 的几个关键理解点: 1. 单向通信：与 WebSocket 不同,SSE 是单向的,只能从服务器向客户端发送数据。 2. 基于 HTTP：它使用标准的 HTTP 协议,不需要特殊的协议支持。 3. 自动重连：客户端会自动尝试重新连接,如果连接断开。 4. 数据格式：事件流的数据格式简单,由文本行组成,每个事件之间用空行分隔。 5. 事件类型：可以指定不同的事件类型,允许客户端针对不同类型的事件进行不同的处理。 6. 实时更新：适用于需要服务器主动推送数据的场景,如实时通知、股票行情更新等。 7. 浏览器支持：大多数现代浏览器都支持 SSE。 8. 轻量级：相比 WebSocket,SSE 更加轻量,适用于单向数据流的场景。 以下是一个使用 Go 实现的简单服务器,它每秒向客户端发送一次当前时间:
package main import ( "fmt" "log" "net/http" "time"
) func main() { http.HandleFunc("/events", eventsHandler) log.Println("Server is running on http://localhost:8080") log.Fatal(http.ListenAndServe(":8080", nil))
} func eventsHandler(w http.ResponseWriter, r *http.Request) { // 设置响应头 w.Header().Set("Content-Type", "text/event-stream") w.Header().Set("Cache-Control", "no-cache") w.Header().Set("Connection", "keep-alive") // 创建一个通道来发送信号,以便在客户端断开连接时停止发送事件 clientClosed := r.Context().Done() for { select { case <-clientClosed: return // 客户端断开连接,退出函数 default: // 发送事件 fmt.Fprintf(w, "data: The server time is: %v\\n\\n", time.Now().Format(time.RFC3339)) w.(http.Flusher).Flush() time.Sleep(time.Second) // 每秒发送一次 } }
} //
这个 Go 示例的工作原理如下: 我们创建了一个 HTTP 服务器,监听在 8080 端口。
/events 路径被映射到 eventsHandler 函数。
在 eventsHandler 函数中: 我们设置了适当的响应头,包括 Content-Type: text/event-stream。
我们使用一个无限循环来持续发送事件。
每次循环,我们发送当前时间作为事件数据。
我们使用 Flush() 来确保数据立即发送给客户端。
我们使用 time.Sleep() 来控制发送频率。 我们使用 r.Context().Done() 来检测客户端是否断开连接,如果断开则停止发送事件。 要使用这个服务器,客户端(如 Web 浏览器)可以使用 EventSource API 来连接和接收事件:
const eventSource = new EventSource('http://localhost:8080/events'); eventSource.onmessage = function(event) { console.log(event.data);
};`}]},{path:"/content/other/spread/firebase%E6%8E%A8%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"firebase推送消息的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`firebase推送消息的使用:
https://www.gstatic.com/firebasejs/9.1.3/firebase-app-compat.js https://console.firebase.google.com //firebase控制台 https://firebase.google.com/docs/cloud-messaging/js/client?hl=zh-cn //在web站点推送 https://blog.csdn.net/weixin_42861028/article/details/105510528 //使用 https://firebase.google.cn/docs/cloud-messaging/js/receive?hl=zh-cn#web-namespaced-api //js调用`}]},{path:"/content/other/spread/google%E6%90%9C%E7%B4%A2%E4%B9%8Brobots%E6%96%87%E4%BB%B6.html",title:"google搜索之robots文件",pathLocale:"/",contents:[{header:"",slug:"",content:`经常在项目的根目录会看到一个robots.txt文件，今天就来普及一下它的作用 介绍 robots.txt 文件规定了搜索引擎抓取工具可以访问您网站上的哪些网址。 此文件
主要用于避免您的网站收到过多请求；它并不是一种阻止 Google 抓取某个网页的
机制。若想阻止 Google 访问某个网页，请使用 noindex 禁止将其编入索引，或
使用密码保护该网页。 用途 robots.txt 文件主要用于管理流向您网站的抓取工具流量 编写 robots.txt 文件应位于网站的根目录下。因此，对于网站 www.example.com，robots.txt 文件
的路径应为 www.example.com/robots.txt 下面是一个包含两条规则的简单 robots.txt 文件：
User-agent: Googlebot
Disallow: /nogooglebot/ User-agent: *
Allow: / Sitemap: https://www.example.com/sitemap.xml 实际使用:
User-agent: *
Allow: /
Sitemap: https://www.example.com/sitemap.xml 更新 robots.txt 文件 实际使用的时候，站点内容可能会不停的更新，所以可以通过定时任务，定期修改文件内容 参考(https://developers.google.com/search/docs/crawling-indexing/robots/create-robots-txt?hl=zh-cn)`}]},{path:"/content/other/spread/hash%E5%8A%A0%E5%AF%86%E4%B9%8Bbcrypt.html",title:"hash加密之bcrypt",pathLocale:"/",contents:[{header:"",slug:"",content:`hash加密之bcrypt:
bcrypt cost
When BCrypt was first published, in 1999, they listed their implementation's default cost factors: normal user: 6
super user: 8
A bcrypt cost of 6 means 64 rounds (26 = 64) 当BCrypt在1999年首次发布时，他们列出了他们实施的默认成本因素： 普通用户：6
超级用户：8
bcrypt成本为6意味着64轮（26=64）。 在线工具:https://bcrypt.online/`}]},{path:"/content/other/spread/http%E5%92%8Ctcp%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"http和tcp网络的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`首先看一下OSI(Open Systems Interconnection)网络体系结构: TCP 按层次分，TCP处于传输层，提供可靠的字节流服务，主要解决数据如何在网络中传输。
字节流服务（Byte Stream Service）：为了方便运输，将大块数据分割成报文段（segment）为单位的数据包进行管理。可靠的传输服务是指能够把数据准确可靠地传给对方。
TCP协议为了更容易传送大数据才把数据分割，而且TCP协议能够确认数据最终是否送达给对方。
TCP采用了三次握手（three-way handshaking）策略和四次挥手策略 来确认数据是否送达给对方。 HTTP
按层次分，HTTP处于应用层，用于客户端和服务端之间的通信，主要是解决如何包装数据。
HTTP协议能够明确区分哪端是客户端，哪端是服务端。
HTTP是不保存状态的协议，即无状态协议。
HTTP协议是建立在TCP之上的。`}]},{path:"/content/other/spread/jwt%E7%9F%A5%E8%AF%86%E6%99%AE%E5%8F%8A.html",title:"jwt知识普及",pathLocale:"/",contents:[{header:"",slug:"",content:`jwt知识普及: 构成
一个JWT由三部分组成，头部、载荷与签名。 名词解释
sub: 该JWT所面向的用户
iss: 该JWT的签发者
iat(issued at): 在什么时候签发的
exp(expires):token什么时候过期
nbf(not before)：token在此时间之前不能被接收处理
jti：JWT ID为web token提供唯一标识 官方文档
https://www.rfc-editor.org/rfc/rfc7519#page-9`}]},{path:"/content/other/spread/makefile%E7%9A%84%E7%9B%B8%E5%85%B3%E4%BB%8B%E7%BB%8D.html",title:"makefile的相关介绍",pathLocale:"/",contents:[{header:"",slug:"",content:`makefile的相关介绍: Makefile 是用于自动化构建过程的文件，通过它可以定义各种编译规则、文件依赖和操作指令。Makefile 主要由构建工具 make 使用，通常用于编译程序，但也可以被用来处理任何其他任务，比如测试、打包、文档生成等。
一个典型的 Makefile 的结构包括目标（target）、依赖（dependencies）和命令（command），它们一般长这样：
target: dependencies command 以下是 Makefile 的主要功能： 自动化构建：通过 Makefile 可以自动化地进行代码编译，避免手动输入复杂的编译命令。 管理依赖：Makefile 可以检查源文件是否发生更改，并仅重新编译那些受影响的文件，提高构建效率。 执行自定义任务：Makefile 可以用于构建、清理、测试、部署等任务，通过 make clean、make test 等命令执行。 跨平台支持：虽然具体的 Makefile 可能需要针对不同平台做调整，但它提供了一个基础的跨平台构建方案，特别适用于 UNIX 系统。 使用参考手册: https://makefiletutorial.com/ //非官方
定义一个makefile:
Makefile 文件通常直接命名为 Makefile（首字母大写，没有文件扩展名），这是约定俗成的命名方式。这样命名后，只需在项目根目录下执行 make 命令即可自动找到并执行 Makefile 文件中的默认任务（即第一个定义的目标）。
如果 Makefile 文件的名称不同于默认的 Makefile，可以使用 -f 选项指定文件名：make -f Makefile.dev
使用案例:
下面是一个典型的 Go 项目 Makefile，包括构建、运行、测试和清理等命令：`},{header:"定义变量",slug:"定义变量",content:`APP_NAME = myapp
VERSION = 1.0.0
BUILD_DIR = build`},{header:"默认目标",slug:"默认目标",content:`.PHONY: all
all: build`},{header:"编译项目",slug:"编译项目",content:`.PHONY: build
build:
go build -o $(BUILD_DIR)/$(APP_NAME) main.go`},{header:"运行项目",slug:"运行项目",content:`.PHONY: run
run:
go run main.go`},{header:"执行测试",slug:"执行测试",content:`.PHONY: test
test:
go test ./...`},{header:"清理构建文件",slug:"清理构建文件",content:`.PHONY: clean
clean:
rm -rf $(BUILD_DIR)`},{header:"代码检查和格式化",slug:"代码检查和格式化",content:`.PHONY: lint
lint:
go vet ./...
golint ./...
在此例中，make 会根据 Makefile 自动化地编译程序，make clean 则可以清理生成的文件。
在这个 Makefile 中，你可以使用以下命令：
make build：编译项目，生成二进制文件。
make run：直接运行项目。
make test：执行测试。
make clean：清理构建文件。
make lint：执行代码检查和格式化。
当然在项目根目录中打开终端，运行以下命令来执行 Makefile 中的默认目标： make //不加任何额外命令, 如果想执行特定目标，例如 build 或 test，可以在 make 命令后指定目标名称, 如上所展示的内容.
关于默认目标的定义:
在 Makefile 中，默认目标通常是第一个定义的目标。这个目标会在直接运行 make 时自动执行，所以通常将最常用或核心的任务作为第一个目标，例如 all、build 或 default。`},{header:"常见的默认目标",slug:"常见的默认目标",content:`all：最常见的默认目标，通常用于执行一系列任务（如构建、测试、代码检查等）。
.PHONY: all
all: build test lint build：直接将构建任务作为默认目标，如果构建是项目的核心操作。
.PHONY: build
build: go build -o myapp main.go default：有些开发者会使用 default 作为默认目标的名称，效果与 all 类似，但这不是一种通用惯例。
.PHONY: default
default: build`},{header:"如何选择默认目标",slug:"如何选择默认目标",content:`小型项目：一般选择 build 或 run 作为默认目标。
中大型项目：使用 all 作为默认目标，并在其中包含多个任务，例如构建、测试、代码检查等。 例如：
.PHONY: all
all: build test lint .PHONY: build
build: go build -o myapp main.go .PHONY: test
test: go test ./... .PHONY: lint
lint: go vet ./... golint ./... 直接执行 make 时，默认会先运行 all 目标，然后依次执行 build、test 和 lint。
.PHONY 用于声明伪目标（phony targets），即标识某些目标不是实际文件，而是任务名称。这样可以避免 make 把目标名称当作文件来处理，提高任务执行的可靠性和性能。`}]},{path:"/content/other/spread/node%E7%9A%84DEB%E7%89%88%E6%9C%AC.html",title:"node的DEB版本",pathLocale:"/",contents:[{header:"",slug:"",content:`node的DEB版本:
站点:https://deb.nodesource.com/ 对于 setup_20.x 中的 x 不需要更改。让我解释一下原因：
NodeSource 的脚本命名约定:
NodeSource（Node.js 的一个主要分发渠道）使用 setup_XX.x 的格式来指代 Node.js 的主要版本。这里的 x 是一个通配符，代表该主要版本下的所有次要版本和补丁版本。
自动更新到最新次要版本:
使用 setup_20.x 可以确保您总是安装 Node.js 20 系列的最新稳定版本。这包括所有的次要版本更新和安全补丁。
灵活性和维护性:
保持 x 可以让您的 Dockerfile 更加灵活。当 Node.js 发布新的 20.x 版本时（比如从 20.1 到 20.2），您不需要更新 Dockerfile。 官方推荐:
这是 NodeSource 官方推荐的安装方法，用于获取特定主要版本的最新稳定版。
因此，您应该保持 setup_20.x 不变。这样的设置意味着：
当您第一次构建 Docker 镜像时，它会安装当时 Node.js 20 系列的最新版本。
如果您之后重新构建镜像，它会安装那时 Node.js 20 系列的最新版本。`}]},{path:"/content/other/spread/npm-fund%E6%8F%90%E7%A4%BA.html",title:"npm fund 提示",pathLocale:"/",contents:[{header:"",slug:"",content:`npm fund 提示:
经常在通过npm install之后，会有 npm fund 提示，如下，查了一下，原来是有项目需要捐赠, 如下:
root@HPDEV-31:~/code/qinhong-frontend-v2$ npm install > postinstall
> nuxt prepare ✔ Types generated in .nuxt 3:05:06 PM > prepare
> husky install husky - Git hooks installed added 1120 packages in 5m 151 packages are looking for funding run \`npm fund\` for details`}]},{path:"/content/other/spread/npm%E5%8C%85%E5%89%8D%E9%9D%A2%E5%8A%A0@%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D.html",title:"npm包前面加@是什么意思",pathLocale:"/",contents:[{header:"",slug:"",content:`今天看vue-cli文档，发现了下面的这段话 vue-cli 改为了 @vue/cli，这两个npm有什么区别呢？npm包前面加@是什么意思呢？ Vue CLI 的包名称由 vue-cli 改成了 @vue/cli。 如果你已经全局安装了旧版本的 vue-cli (1.x 或 2.x)，你需要先通过 npm uninstall vue-cli -g 或 yarn global remove vue-cli 卸载它。 查了下官网，npm包前面加@，代表scopes相关的包，可以理解为作用域(范围)包，作用域使我们可以创建与其他用户或组织创建的包同名，而不会发生冲突。 A scope allows you to create a package with the same name as a package created by another user or Org without conflict. 作用域名称是介于@和斜线之间的所有内容： The scope name is everything between the @ and the slash: // “npm” scope:
@npm/package-name
// “npmcorp” scope:
@npmcorp/package-name
为什么需要有作用域包
npm包一个诟病就是包名很容易被占用的问题，占用后用其他人就不能用了。而作用域包类似于创建了一个命名空间，不同的命名空间，可以使用相同的包名 作用域的命名不是谁便就能用的，只有两种可以使用：自己的用户名、自己创建的组织名 注意：必须先注册一个npm用户帐户，然后才能发布用户作用域的npm软件包。此外，要发布组织作用域的软件包，您必须创建一个npm用户帐户，然后创建一个npm Org(组织)。`}]},{path:"/content/other/spread/npm%E5%8C%85%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B.html",title:"npm包发布流程",pathLocale:"/",contents:[{header:"npm包发布流程",slug:"npm包发布流程",content:'$ npm login $ npm run build $ npm publish 注意每次发布都需要修改 "version": "1.0.3", 下的版本，否则会失败'}]},{path:"/content/other/spread/npm%E7%89%88%E6%9C%AC%E5%8F%B7%E8%A7%84%E5%88%99.html",title:"npm版本号规则",pathLocale:"/",contents:[{header:"",slug:"",content:`通过执行以下命令能够查看某个依赖包的最新版本:
# 查看某个 package 的注册信息
npm view <package-name> # 查看某个 package 的最新版本
npm view <package-name> version # 查看某个 package 在 npm 服务器上所发布过的版本
npm view <package-name> versions # 查看仓库依赖树上所有包的版本信息
npm ls npm 中的包模块版本都需要遵循 SemVer（Semantic Version，语义化版本）规范，这是由 Github 起草的一个具有指导意义的，统一的版本号表示规则.
SemVer 规范的标准版本号采用 X.Y.Z 的格式，其中 X、Y 和 Z 为非负的整数，且禁止在数字前方补零。X 是主版本号、Y 是次版本号、而 Z 为修订号。每个元素必须以数值来递增。 主版本号（major）：当你做了不兼容的 API 修改
次版本号（minor）：当你做了向下兼容的功能性新增
修订号（patch）：当你做了向下兼容的问题修正。 版本号标签:
版本号标签	语义	说明
latest	默认	不指定版本情况下默认安装的最新版本
alpha	内测	内部测试版，一般不向外部发布，会有很多 BUG，一般只有测试人员使用
beta	公测	也是测试版本，这个阶段的版本会一直加入新的功能，在 Alpha 版之后推出
next	下一个 rc	候选	Release Candidate 系统平台上就是发行候选版本。RC 版不会再加入新的功能了，主要着重于除错
experimental	实验
给版本号添加标签的方式有两种:
# 第一种方式：在发布时指定标签
# 1. version-tag 替换为版本号标签的名称
npm publish --tag <version-tag> # 示例
npm publish --tag next react@18.0.0
npm publish --tag experimental vue@3.2.0 # 第二种方式：发布后执行以下命令
# 1. package-name 替换为 npm 包名字
# 2. version 替换为 npm 包的指定版本
# 3. version-tag 替换为版本号标签的名称
npm dist-tag add <package-name>@<version> <version-tag> # 示例
npm dist-tag add react@18.0.0 alpha
npm dist-tag add vue@3.2.0 next 版本号操作工具:semver，可以通过 npm 安装，npm install semver
版本号特殊字符:
版本号包可能包含 ~ 和 ^ 符号：
~：当安装依赖时获取到有最新版本时，安装到 x.y.z 中 z 的最新版本。即保持主版本号、次版本号不变的情况下，保持修订号的最新版本
^：当安装依赖时获取到由最新版本时，安装到 x.y.z 中 y 和 z 都为最新版本。即保持主版本号不变的情况下，保持次版本号、修订版本号为最新版本。 除此以外，还包含以下规则：
>：接受高于指定版本的任何版本
>= 接受等于或高于指定版本的任何版本
<=：接受等于或低于指定版本的任何版本
<：接受低于指定版本的任何版本
=：接受确切的版本
-：接受一定范围的版本，例如 2.1.0 - 2.4.1
||：组合集合，例如 < 2.2 || > 2.4`}]},{path:"/content/other/spread/php%E5%86%85%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E9%80%9A%E8%BF%87nginx%E4%BB%A3%E7%90%86%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB.html",title:"php内置服务器和通过nginx代理有什么区别",pathLocale:"/",contents:[{header:"php内置服务器和通过nginx代理有什么区别",slug:"php内置服务器和通过nginx代理有什么区别",content:"Laravel 的 内置服务器（php artisan serve）和 通过 Nginx 代理运行 Laravel，主要区别在于 用途 和 性能："},{header:"1. Laravel 内置服务器 (php artisan serve)",slug:"_1-laravel-内置服务器-php-artisan-serve",content:`本质：PHP 自带的 php -S 内置 Web 服务器，单进程、同步阻塞。 用途：开发测试用。 特点： 启动简单，不需要配置 Nginx/Apache。
支持基本的路由转发，满足调试需求。
单进程，并发能力极差（一个请求没处理完，下一个就得等）。
不适合生产环境（官方也明确写了：php artisan serve 仅供开发）。`},{header:"2. Nginx + PHP-FPM",slug:"_2-nginx-php-fpm",content:`本质：Nginx 作为前端 Web 服务器，接收请求并交给 PHP-FPM（FastCGI）处理。 用途：生产环境的标准部署方式。 特点： 高性能（支持成千上万并发）。
可以做 负载均衡、缓存、静态文件处理、反向代理 等。
PHP-FPM 可以开多个 worker 进程，提高并发。
配置稍复杂，需要维护 Nginx 和 PHP-FPM 两部分。`},{header:"简单对比",slug:"简单对比",content:`特点
内置服务器 (artisan serve)
Nginx + PHP-FPM 部署难度
简单，一条命令启动
需要配置 Nginx 与 PHP-FPM 并发性能
极差（单进程）
高（支持多进程 + 负载均衡） 静态文件
PHP 内置服务器处理（慢）
Nginx 原生处理（快） 可扩展性
无法扩展
支持缓存、SSL、负载均衡等 使用场景
开发测试
生产环境 ✅ 结论： 开发调试 → 用 php artisan serve 就够了。
上线/压测 → 必须用 Nginx + PHP-FPM（或 Apache）。 要不要我给你写一个 Nginx 配置示例，让你本地也可以用 Nginx 代理跑 Laravel 项目？这样你就能体验到生产环境的效果。
区别主要在于 用途 和 性能：`},{header:"php artisan serve 内置服务器",slug:"php-artisan-serve-内置服务器",content:`本质：php -S，PHP 自带的单进程内置 Web 服务器。 优点：一条命令就能跑起来，零配置，方便开发调试。 缺点： 单进程，并发性能差（一个请求没结束，其他请求得等）。
静态文件（CSS/JS/图片）也要经过 PHP 处理，效率低。
没有反向代理、负载均衡、缓存等功能。
只适合本地开发测试，不能用于生产环境。`},{header:"Nginx + PHP-FPM",slug:"nginx-php-fpm",content:`本质：Nginx 处理 HTTP 请求，静态资源自己直接返回；动态请求转给 PHP-FPM（FastCGI）。 优点： 高性能（Nginx 可以处理成千上万并发，PHP-FPM 有多个 worker 进程）。
静态文件直接由 Nginx 处理，速度快。
支持 HTTPS、反向代理、负载均衡、缓存等高级功能。
生产环境标准做法。 缺点：需要配置和维护（Nginx 配置文件 + PHP-FPM 参数）。`},{header:"对比表",slug:"对比表",content:`特点
php artisan serve
Nginx + PHP-FPM 部署难度
超简单，一条命令
需要配置 并发性能
差（单进程）
高（多进程 + 高并发） 静态文件
PHP 处理（慢）
Nginx 原生处理（快） 功能扩展
无
缓存、SSL、负载均衡等 使用场景
开发调试
生产环境 ✅ 总结： 开发环境：直接用 php artisan serve，方便快捷。
生产环境：必须用 Nginx + PHP-FPM，否则性能和稳定性都不够。`}]},{path:"/content/other/spread/solr%E6%90%9C%E7%B4%A2%E6%9C%8D%E5%8A%A1%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"solr搜索服务的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`solr9.6搜索服务的使用:
官网下载solr-9.6.0.tgz
1>解压
tar zxvf ./solr-9.6.0.tgz 2>运行自带的example项目
k8s@HPDEV-31:/usr/local/solr-9.6.0$ sudo bin/solr start -e techproducts -p 8985 -force 这里使用 -force:
WARNING: Starting Solr as the root user is a security risk and not considered best practice. Exiting. Please consult the Reference Guide. To override this check, start with argument '-force' ERROR: Failed to start Solr using command: "bin/solr" start -p 8985 -s "example/techproducts/solr" Exception : org.apache.commons.exec.ExecuteException: Process exited with an error: 1 (Exit value: 1) 3>停止之前的
k8s@HPDEV-31:/usr/local/solr-9.6.0$ sudo bin/solr stop -p 8985 -force 4>再次启动
k8s@HPDEV-31:/usr/local/solr-9.6.0$ sudo bin/solr start -p 8985 -force
*** [WARN] *** Your open file limit is currently 1024. It should be set to 65000 to avoid operational disruption. If you no longer wish to see this warning, set SOLR_ULIMIT_CHECKS to false in your profile or solr.in.sh
Java 17 detected. Enabled workaround for SOLR-16463
Waiting up to 180 seconds to see Solr running on port 8985 [|] Started Solr server on port 8985 (pid=35159). Happy searching! 5>创建core(必须先启动solr)
k8s@HPDEV-31:/usr/local/solr-9.6.0$ sudo bin/solr create -c conferences_core -p 8985 -force
WARNING: Using _default configset with data driven schema functionality. NOT RECOMMENDED for production use. To turn off: bin/solr config -c conferences_core -p 8985 -action set-user-property -property update.autoCreateFields -value false Created new core 'conferences_core' 默认创建路径如下：
/usr/local/solr-9.6.0/server/solr/conferences_core 参考:https://solr.apache.org/guide/solr/latest/deployment-guide/installing-solr.html 6>修改core的 schema, 添加字段
k8s@HPDEV-31:/usr/local/solr-9.6.0/server/solr/conferences_core/conf$ sudo vim managed-schema.xml <field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" />
<!-- docValues are enabled by default for long type so we don't need to index the version field -->
<field name="age" type="pint" indexed="true" stored="true" />
<field name="description" type="text_ik" indexed="true" stored="true" /> // 注意我第一次没有安装ik分词器，默认好像没有 type为 text_ik，但是我安装完ik分词器之后就有了，所以下次使用的时候，还是先安装ik,然后再倒数据，同时如果后来重新改了这个记得relaod core
<field name="create_time" type="pdate" indexed="true" stored="true" />
<field name="update_time" type="pdate" indexed="true" stored="true" /> 然后 reload，结果一直报错，于是把 create_time 改为 createTime， update_time 改为 updateTime 就好了(xml格式的文件问题很多坑...)
当然官网还有schema api: https://solr.apache.org/guide/solr/latest/indexing-guide/schema-api.html
我通过api给schema添加了一个新的字段，第一次添加的时候没有选择 indexed="true", 结果导致 description 不能插入，一直报: from index options=docs to inconsistent index options=docs_and_freqs_and_positions 问题，但是后来加上了indexed="true" 就没问题了,这个属性必须要有，即使是设置为indexed="false"； 同时还注意到当新增 filed 之后，之前查询的数据是不包含这 field的，只有后面新增的数据中包含了这个field, 那么查询的数据才会包含这个新增的field. 7>添加数据(选择Documents操作 /update)
目前添加的机制是，如果添加的数据的 id 不存在，那么就会新增，否则更新数据，比如： {"id": "11","age": 40,"description": "创造了古代浪漫主义文学高峰、歌行体和七绝达到后人难及的高度"},
{"id": "12","age": 31,"description": "唐代伟大的现实主义文学作家，唐诗思想艺术的集大成者"}
{"id": "13","age": 31,"description": "头孢不叫阿莫西林。头孢和阿莫西林属于两种不同的抗菌药物，患者需要在医生指导下服用。若是出现身体不适，要及时就医治疗"}
{"id": "14","age": 68,"description": "阿莫西林属于广谱青霉素类抗生素，对肺炎链球菌、溶血性链球菌、不产青霉素酶葡萄球菌、粪肠球菌、大肠埃希菌等均具有良好的抗菌活性。有片剂、颗粒剂等多种剂型，临床上适用于敏感菌所致的皮肤及软组织感染、呼吸道感染、胃肠道感染、尿路感染、败血症等"}
{"id": "15","age": 52,"description": "如果患者无甲状腺疾病相关症状，且其他检查指标均正常，则说明甲状腺功能正常。如果患者出现甲状腺功能亢进症或甲状腺功能减退症的相关症状，且伴有促甲状腺激素（TSH）、甲状腺抗体等其他甲状腺指标异常，则说明甲状腺功能异常，需要查明原因后进行相应的治疗"} 报错，需要 _vesion_ 字段(我猜测是每个document都必须有一个版本字段的原因是，为了记录最近操作)，直接客户端选择schema,然后添加这个字段(string类型即可)即可，再执行添加json数据，不报错.
我发现插入完数据之后，再 sudo vim managed-schema.xml，里面的内容也变了. 官网 update document api: https://solr.apache.org/guide/solr/latest/indexing-guide/indexing-with-update-handlers.html
关于各个 field 属性的介绍: https://solr.apache.org/guide/solr/latest/indexing-guide/fields.html 8>条件查询报错:Undefined field _text_
解决方法:https://opensolr.com/faq/view/opensolr-wiki-q-a/104/undefined-field-_text_
但是执行之后又会报其它错误,又恢复了,最好直接添加一个 _text_ 字段，这样不会报错，主要是添加这个_text_以后，对于查询参数 q, 可以直接写任何东西,不用指定某个字段，那么会走默认字段，就是这里的_text_，其实上面的链接里有，打开配置会发现.但是一般 _text_字段又没有数据,所以什么也查不到. 参考这个初始化配置:https://solr.apache.org/guide/solr/latest/configuration-guide/initparams.html 我发现查询应该这么用:
比如查询 description的q参数
description:*古代*
这样就不会报错了,需要指定查询的字段 参考:https://blog.csdn.net/zhouzhiwengang/article/details/111028596 如果查询所有数据,那么q参数如下(默认值)
*:* 还可以多条件:
description:*因为* && age:42 官网query api: https://solr.apache.org/guide/solr/latest/query-guide/json-request-api.html
这个是我的一个复合查询语句: http://localhost:8985/solr/conferences_core/select?fl=* score&indent=true&q.op=OR&q=description:*文*&rows=2&sort=id desc&start=0&useParams= 9>删除数据
documents的Request-Handler /update
documents type 选择 XML documents 输入下面语句
<delete><query>*:*</query></delete>
<commit/> 但是上面的删除，会删除所有的数据. 删除指定id的数据:
<delete>
<id>11</id>
</delete> 删除指定筛选条件的数据:
<delete>
<query>description:*唐代*</query>
</delete> 10>更新数据(选择Documents操作 /update)
目前更新的机制是，添加 id 相同的数据，会自动更新为最新数据，比如下面会更新id为11的数据：
{"id": "11","age": 36,"description": "秋季破鼻子可能是空气干燥、不良习惯导致的，还可能与鼻腔异物、外伤、过敏性鼻炎等情况有关，具体可以前往医院就诊，明确诊断后，在医生指导下进行针对性治疗。"}, 11>ik分词器:
https://mvnrepository.com/artifact/com.github.magese/ik-analyzer
选择合适的版本，在 Files 找到jar下载 目前最高的是8.x版本，但是对于solr9.x 也是可以用的,就选择最新的 8.5版本就可以了 将这个jar包放到如下目录(里面全是jar包):
/usr/local/solr-9.6.0/server/solr-webapp/webapp/WEB-INF/lib 进入下面这个目录:
/usr/local/solr-9.6.0/server/solr/conferences_core/conf sudo vim managed-schema.xml 我直接在最后一个 fieldType 添加如下代码:
<!-- ik分词器 --> <fieldType name="text_ik" class="solr.TextField"> <analyzer type="index" useSmart="false" class="org.wltea.analyzer.lucene.IKAnalyzer"/> <analyzer type="query" useSmart="true" class="org.wltea.analyzer.lucene.IKAnalyzer"/> </fieldType> 然后重新启动solr服务:
k8s@HPDEV-31:/usr/local/solr-9.6.0$ sudo bin/solr restart -p 8985 -force 测试ik是否可用:
选择对应的core, 然后点击 Analysis, Field Value: 输入一串中文 Analyse Fieldname / FieldType 中找到 text_ik, 点击右侧的 Analyse values 即可看到分词结果 也可以在 Analyse Fieldname / FieldType 中找到 设置了 text_ik 的 filed，比如这里的 description, 然后点击右侧的 Analyse values 即可看到分词结果. 分词查询:
将 q 字段给值 description:多种机制， 不要加 ** 号, 不然分词不起作用. 12>关于高亮部分
如果想使用 highlighting 功能，需要配置 hl参数和hl.fl参数,一个是控制是否高亮，一个是控制需要高亮的字段(可以有多个),至少需要这两个参数，否则查询不生效
这里设置为: hl=true, 以及 hl.fl=description
http://localhost:8985/solr/conferences_core/select?hl.fl=description&hl=true&indent=true&q.op=OR&q=description:两种人&useParams= 如果想重新配置包裹高亮的标签，可以通过下面两个参数实现, 默认是 <em> </em> 标签:
hl.simple.pre
hl.simple.post 比如设置为: hl.simple.pre=<strong>, hl.simple.post=</strong>, 最实用的是配置color为红色样式. 以下是highlighting的查询结果:
"highlighting":{ "16":{ "description":["创造了古代浪漫主义<em>文学</em>高峰、歌行体和七绝达到后人难及的高度"] }, "11":{ "description":["创造了古代浪漫主义<em>文学</em>高峰、歌行体和七绝达到后人难及的高度"] } } 官网参考: https://solr.apache.org/guide/solr/latest/query-guide/highlighting.html 13>solr安全配置
参考: https://solr.apache.org/guide/solr/latest/deployment-guide/authentication-and-authorization-plugins.html
基本授权: https://solr.apache.org/guide/solr/latest/deployment-guide/basic-authentication-plugin.html 这里配置 /usr/local/solr-9.6.0/server/solr/security.json, 然后重启solr:
{
"authentication":{ "blockUnknown": true, "class":"solr.BasicAuthPlugin", "credentials":{"solr":"IV0EHq1OnNrj6gvRCwvFwTrZ1+z1oBbnQdiVC3otuq0= Ndd7LKvVBAaZIF0QAVi1ekCfAJXr1GGfLtRUXhgrF8c="}, "realm":"My Solr users", "forwardCredentials": false }
} 默认用户名: solr 密码: SolrRocks 总参考：
https://blog.csdn.net/hejiahao_/article/details/133698865`}]},{path:"/content/other/spread/vagrant%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99.html",title:"vagrant启动报错",pathLocale:"/",contents:[{header:"",slug:"",content:`vagrant up 报错了。报错信息:process_builder.rb:44:in \`encode!': "\\\\xE5" to UTF-8 in conversion from ASCII-8BIT to UTF-8 to UTF-16LE (Encoding::UndefinedConversionError) 解决方案： 找到报错信息的process_builder.rb 44行，编码位置换成一下： #newstr.encode!('UTF-16LE')
newstr.encode!('UTF-16LE', invalid: :replace, undef: :replace, replace: '?') 2.修改了上面的还是报错
VBoxManage.exe error: VT-x is not available (VERR_VMX_NO_VMX) code E_FAIL (0x80004005) gui headless [closed] 解决办法(我这里是执行 off 命令, 重启电脑, 再次 vagrant up 就好了):
To turn Hypervisor off, run this from Command Prompt (Admin) (Windows+X): bcdedit /set hypervisorlaunchtype off
and reboot your computer. To turn it back on again, run: bcdedit /set hypervisorlaunchtype on
If you receive "The integer data is not valid as specified", try: bcdedit /set hypervisorlaunchtype auto [参考链接]https://stackoverflow.com/questions/37955942/vagrant-up-vboxmanage-exe-error-vt-x-is-not-available-verr-vmx-no-vmx-code`}]},{path:"/content/other/spread/webstorm%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E4%B8%80%E7%9B%B4%E6%8A%A5%E7%9B%91%E5%90%AC%E6%95%B0%E9%87%8F%E8%BE%BE%E5%88%B0%E4%B8%8A%E9%99%90%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"webstorm开发工具一直报监听数量达到上限的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`webstorm开发工具一直报监听数量达到上限的问题:
经常在webstorm下运行 npm run watch 或者 yarn dev 会报：System limit for number of file watchers reached
解决办法如下:
root@k8s:~$ cat /proc/sys/fs/inotify/max_user_watches
65536
root@k8s:~$ sudo sysctl fs.inotify.max_user_watches=131070
[sudo] password for root: fs.inotify.max_user_watches = 131070
root@k8s:~$ root@k8s:~$ cat /proc/sys/fs/inotify/max_user_watches
131070
root@k8s:~$ sudo sysctl -p 按照上面的命令执行一遍就好了`}]},{path:"/content/other/spread/%E4%B8%80%E4%B8%AA%E6%A0%87%E5%87%86%E7%9A%8436%E5%AD%97%E7%AC%A6UUIDv4%E5%AD%97%E7%AC%A6%E4%B8%B2.html",title:"一个标准的36字符UUIDv4字符串",pathLocale:"/",contents:[{header:"",slug:"",content:`一个标准的36字符UUIDv4字符串:
123e4567-e89b-12d3-a456-426655440000 它包含32个十六进制数字和4个连字符(-)。具体格式是: 8个数字
1个连字符
4个数字
1个连字符
4个数字
1个连字符
4个数字
1个连字符
12个数字
以下是一个随机生成的UUIDv4示例: 550e8400-e29b-41d4-a716-446655440000`}]},{path:"/content/other/spread/%E4%B8%96%E7%95%8C%E6%A0%87%E5%87%86%E6%97%B6%E9%97%B4UTC.html",title:"世界标准时间UTC",pathLocale:"/",contents:[{header:"",slug:"",content:`世界标准时间UTC（Universal Time Coordinated），又称世界统一时间、国际时间、全球时钟、协调世界时，简称UTC，由原子钟提供，非常精确。
从19 世纪中叶起，世界上以英国皇家格林尼治天文台公布的时间为标准时间，即“格林尼治标准时间（Greenwich Mean Time）”，简称GMT。但由于
与UTC存在秒差，因此从1972 年1 月1日起，改以UTC为世界标准时间。
当前
欧洲 英国 UTC+0
亚洲 中国 UTC+8
各国时间速查:https://time.24436.com/`}]},{path:"/content/other/spread/%E4%BA%8C%E7%BB%B4%E7%A0%81%E5%AE%B9%E9%94%99%E7%8E%87%E5%B9%B2%E5%98%9B%E7%9A%84.html",title:"二维码容错率干嘛的",pathLocale:"/",contents:[{header:"二维码容错率干嘛的",slug:"二维码容错率干嘛的",content:"容错率（Error Correction Level）是二维码的一项非常重要的参数，它决定了二维码 在部分损坏或被遮挡时仍然可以被识别 的能力。"},{header:"1️⃣ 容错率的级别",slug:"_1️⃣-容错率的级别",content:`二维码通常有四个标准级别： 缩写
容错率
描述 L
7%
低容错率，可修复大约 7% 的二维码损坏区域 M
15%
中等容错率，可修复大约 15% 的损坏 Q
25%
高容错率，可修复大约 25% 的损坏 H
30%
最高容错率，可修复大约 30% 的损坏 换句话说，如果你设置 H，即使二维码的 30% 被污损、遮挡或者印刷失误，扫码器仍然能读取出正确内容。`},{header:"2️⃣ 容错率的影响",slug:"_2️⃣-容错率的影响",content:`二维码大小 容错率越高，二维码会增加更多“纠错码块”，二维码会显得更复杂，占用更多空间。 可读性 高容错率 → 可耐受破损，但二维码图案更密集
低容错率 → 图案简单，占用空间小，但容易损坏时无法识别 应用场景 L / M：二维码贴在屏幕、名片等小型物件，环境干净
Q / H：二维码贴在户外、包装、杂物上，容易被刮擦、遮挡`},{header:"3️⃣ 举例",slug:"_3️⃣-举例",content:`L (7%)：二维码一小块污损，可能无法扫描
H (30%)：二维码即使有大面积遮挡，也能正常识别 简单总结： 容错率就是二维码的“自我修复能力”，越高越抗损坏，但二维码图案越复杂。`}]},{path:"/content/other/spread/%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B%E5%B9%B3%E5%8F%B0Sonar.html",title:"代码检测平台Sonar",pathLocale:"/",contents:[{header:"",slug:"",content:`代码检测平台Sonar:
1>官网
https://www.sonarsource.com/ 2>主要使用sonarqube(可以本地部署)
https://docs.sonarsource.com/sonarqube/latest/ 3>配置
webstorm插件: SonarLint`}]},{path:"/content/other/spread/%E4%BC%98%E7%A7%80%E7%AB%99%E7%82%B9.html",title:"优秀站点",pathLocale:"/",contents:[{header:"",slug:"",content:`记录几个优秀站点，就当是工具吧 symfony学习网站: https://symfonycasts.com/ 各种语言学习: https://pjchender.dev/，我主要关注的是golang,比如:https://pjchender.dev/golang/maps/ 各种语言博客: https://www.sitepoint.com 好用的vue裁剪/剪裁插件: https://advanced-cropper.github.io/vue-advanced-cropper VUE相关知识整理: https://vue3js.cn/ 各语言知识讨论社区: https://www.pixelstech.net/ 网路安全的社区: https://www.freebuf.com/ LayUi新文档(v2.8,基于vuepress，但是其它页面做的非常舒服) https://layui.dev/ 社区出的LayUi的vue版本 http://www.layui-vue.com/ 国外工具类网站 https://www.flightpedia.org/ PHP各个版本差别 https://php.watch/ IP地址查看 https://whatismyipaddress.com/ 优秀国外博客 https://blog.logrocket.com/ 在线AI画图 https://ideogram.ai/ 旅游网站(兼容了m站，可以用来参考) https://tw.trip.com/ Jquery下的toolTip工具 https://www.heteroclito.fr/modules/tooltipster/ http://calebjacob.github.io/tooltipster/ 在线裁剪图片(处理图片-google) https://www.iloveimg.com/ PHP优秀博客(国外) https://www.strangebuzz.com/ 各语言免费在线代码库 https://www.freecodecamp.org/ Ai学习框架sklearn https://scikit-learn.org/stable/ 生活 资讯 创业分享平台(tw) https://blog.yuyansoftware.com.tw/ https://www.yuyansoftware.com.tw/ 前后端框架(小众和bootstrap有一拼) https://get.foundation/sites/docs/index.html 优秀的技术博客(git自动化部署) https://hlog.cc/archives/49/ chatGpt社区 https://community.openai.com/ 论文查重网站 https://www.ithenticate.com/ https://www.turnitin.com/ 优秀博客，专注于优秀的项目(个体) https://baiyue.one/ 前端技术文档 https://ezdoc.cn/ 优秀后台项目:
https://github.com/shoppingzh/vue-relaxed-admin
https://github.com/lin-xin/vue-manage-system IP地址查看: https://sites.ipaddress.com/ Jan 是一个帮助你在本地运行开源大模型的程序，支持Windows、Mac和Linux多平台: https://github.com/janhq/jan 国产AI优秀问答 https://devv.ai/ OpenAI Watch 这个网站有意思，每个小时让 GPT 用 TikZ （一种 LaTeX 下画图的文本格式）画一张独角兽，然后记录下来 https://openaiwatch.com/ 邮件管理工具和 foxmail 差不多 https://www.thunderbird.net/ vuejs文章推送 https://vuejsdevelopers.com/newsletter/ vue3表单验证 https://vee-validate.logaretm.com/v3/ nuxt3文章 https://masteringnuxt.com/blog/protecting-routes-in-nuxt-3 科技信息网站 https://www.engadget.com/ tailwindcss再次使用文档
https://tailwindcss.com/docs/margin //tailwindcss各元素样式
https://play.tailwindcss.com/ // 在线运行环境 国外亲段课程网站 https://www.vuemastery.com/holiday/ 在线生成3D模型工具 https://monstermash.zone/ 各种工具网站 https://www.toolfk.com/ 各种css动画样式 https://css-loaders.com/ 随机生成人物头像 https://peepslab.com/ 好用的录屏工具-loom https://www.loom.com/looms/videos 在线编辑markdown文本，推送到微信 https://github.com/doocs/md 办公套件
邮箱: https://www.thunderbird.net/
沟通: teams / skype 在线颜色转换(包括很多工具)
https://www.pcsetc.com/hexrgb/
https://www.pcsetc.com/ 单词音标提取工具
https://pt.hongliang.fun/ //国内提供
https://dictionaryapi.dev/ // 国外免费API 站点主题色网站
https://colorhunt.co/
https://picular.co/
https://jeanhwea.github.io/article/color-theme-sites.html
https://github.com/Jeanhwea/jeanhwea.github.io //可以关注下这个人的博客 markdown编辑器-marktext
https://github.com/marktext/marktext apache项目提问题需要jira账号
https://issues.apache.org/jira/login.jsp
username:gmail
pwd: 常用 优秀博客
https://www.hangge.com/
https://dev.to/naxrohan/laravel-sail-ngrok-2kk4
https://www.coding10.com/
https://www.tubring.cn/
https://www.ziruchu.com/ 设计素材
https://www.behance.net/
https://www.freepik.com/ 前端框架h3
https://h3.unjs.io/ 优秀博客
https://medium.com/ 富文本编辑器(所见既所得)
https://github.com/Vanessa219/vditor
https://github.com/codemirror/codemirror5 laravel 命令文档
https://artisan.page/ 关于php拓展
http://ppa.launchpadcontent.net/ondrej/php/ubuntu/ 图片上传尺寸标准
https://help.oxfordabstracts.com/knowledge/picture-dimensions-for-upload laravel中文文档
https://laravel.net.cn/ 优秀博客
https://wyz.xyz
https://www.iyuu.cn/ 使用showDoc管理API文档:
https://www.showdoc.com.cn/ pina文档
https://pinia.web3doc.top/ vpn网站
站点1: (poxiaoyun.com)
魔戒.net (mojie.me) 学术平台
http://www.imeta.science/
http://www.imeta.science/meeting/2024/ 优秀博客
https://nickdesaulniers.github.io/
https://docs.deno.com/
https://www.cnblogs.com/lori 在线代码运行平台
https://codapi.org/ 数学公式
https://cortexjs.io/mathlive/ 前端组件库，好像专门用于tooltip的
https://floating-ui.com/docs/vue js在线环境
https://developer.mozilla.org/zh-CN/play
https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web //web网站文档(html + css + js) Typescript书籍:
https://gibbok.github.io/typescript-book/zh-cn/book/the-concise-typescript-book/
ECMAScript书籍:
https://es6.ruanyifeng.com/ docker镜像代理地址查询
https://www.cnblogs.com/alex-oos/p/18417200 ScreenToGif(将截屏转化为动画)
https://www.screentogif.com/ UI框架headlessui(可以拿来重新封装)
https://headlessui.com/ 仿真运行
https://github.com/frangoteam/FUXA markdown文档
https://markdown.com.cn/basic-syntax/emphasis.html vue3资源库
https://hu-snail.github.io/vue3-resource/ 工具API(专注于各种数据 API，涵盖金融、天气、货币汇率、身份验证等领域)
https://apilayer.com/ Yoda 条件判断 规范
https://en.wikipedia.org/wiki/Yoda_conditions 富文本编辑器框架 prosemirror
https://prosemirror.net/ 小工具站点
https://www.iamwawa.cn/daxiaoxie.html 我的restful标准:
https://note.youdao.com/s/CEuORpbG 谷歌字体
https://fonts.google.com/icons
https://iconify.design/ 2D游戏开发平台
https://phaser.io/
https://docs.phaser.io/phaser/getting-started/installation big.js 前端高精度计算包
https://github.com/MikeMcl/big.js 强大的错误追踪系统Sentry
http://sinhub.cn/2019/07/getting-started-guide-of-sentry/ 在线创建 mock 数据
https://mockapi.io/ (我创建的一个接口 https://687725f3dba809d901ee128c.mockapi.io/api/v1/articles) 人民教育出版
https://jc.pep.com.cn/ 优秀博客
https://linux.do/
https://geektutu.com/ (主要是课程写的比较好) 远程桌面
https://rustdesk.com/ 验证域名设置是否合规的在线工具
https://mxtoolbox.com
https://mailtester.com 在线日历工具
https://calendly.com/ 图片(图床)平台
https://imgur.com/ 机器学习框架: PyTorch
相关书籍: https://tingsongyu.github.io/PyTorch-Tutorial-2nd/
代码: https://github.com/TingsongYu/PyTorch-Tutorial-2nd 还能用的docker镜像加速服务
https://1ms.run/ docker 自建代理
https://github.com/whyun-pages/docker-registry 独立开发者项目
https://github.com/xorpay/chinese-independent-developer 查看 npm 包的graph站点
https://npmgraph.js.org`}]},{path:"/content/other/spread/%E5%85%B3%E4%BA%8Ebcrypt.html",title:"关于bcrypt",pathLocale:"/",contents:[{header:"",slug:"",content:`关于bcrypt加密: 上图是一个 bcrypt 哈希的示例图，其由四部分组成：
Prefix 说明了使用的 bcrypt 的版本
Cost 是进行哈希的次数 - 数字越大生成 bcrypt 的速度越慢，成本越大。同样也意味着如果密码库被盗，攻击者想通过暴力破解的方法猜测出用户密码的成本变得越昂贵。
Salt 是添加到要进行哈希的字符串中的随机字符，所以使用 bcrypt 时不需要我们在表里单独存储 Salt。
Hashed Text 是明文字符串最终被 bcrypt 应用这些设置哈希后的哈希文本。`}]},{path:"/content/other/spread/%E5%85%B3%E4%BA%8EopenAPI%E6%B3%A8%E5%86%8C%E4%BB%A5%E5%8F%8A%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8%E7%9A%84%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.html",title:"关于openAPI注册以及接口调用的说明文档",pathLocale:"/",contents:[{header:"",slug:"",content:`最近chat-gpt很火，于是花了点时间也注册了账号，下面是我的操作步骤：
1.访问openapi官网：https://platform.openai.com/ 2.google账号登录 3.第一次注册需要手机号验证，必须为国外手机号，所以通过 sms-active 生成手机号：60+(113)9314146 发送验证码 注意 使用 sms-active 服务的时候，最好选择主流国家，不要选择不入流的国家，因为可能收不到验证码，或者收到验证码，但是前面的地区号 不一致 导致没法使用
这个是报的错误：We've detected suspicious behavior from phone numbers similar to yours. Please try again later or contact us through our help center at help.openai.com 4.注册成功以后，就可有 登陆了，会在个人中心生成一个API Key，用来调用接口，保存好这个Key，只会生成一次 5.直接访问 https://platform.openai.com/playground 可以看到一个对话框，直接体验 6.也可以访问下面这个链接，但是一般会报错： 访问：https://chat.openai.com/ Access denied You do not have access to chat.openai.com. The site owner may have set restrictions that prevent you from accessing the 7.还可以通过PostMan 调用接口
接口调用一定要配合 Key 使用：
header头需要这个认证参数:Authorization:Bearer sk-dfasfasdfdgdfdsfgdgfdhgfhgfjhgjhgj
比如我调用了获取模型的接口： url: get https://api.openai.com/v1/models 返回:
{ "object": "list", "data": [ { "id": "babbage", "object": "model", "created": 1649358449, "owned_by": "openai", "permission": [ { "id": "modelperm-49FUp5v084tBB49tC4z8LPH5", "object": "model_permission", "created": 1669085501, "allow_create_engine": false, "allow_sampling": true, "allow_logprobs": true, "allow_search_indices": false, "allow_view": true, "allow_fine_tuning": false, "organization": "*", "group": null, "is_blocking": false } ], "root": "babbage", "parent": null }, { "id": "davinci", "object": "model", "created": 1649359874, "owned_by": "openai", "permission": [ { "id": "modelperm-U6ZwlyAd0LyMk4rcMdz33Yc3", "object": "model_permission", "created": 1669066355, "allow_create_engine": false, "allow_sampling": true, "allow_logprobs": true, "allow_search_indices": false, "allow_view": true, "allow_fine_tuning": false, "organization": "*", "group": null, "is_blocking": false } ], "root": "davinci", "parent": null }, { "id": "gpt-3.5-turbo-0301", "object": "model", "created": 1677649963, "owned_by": "openai", "permission": [ { "id": "modelperm-ms2DpLH5OCOZpUikJ4sRQNkh", "object": "model_permission", "created": 1677691853, "allow_create_engine": false, "allow_sampling": true, "allow_logprobs": true, "allow_search_indices": false, "allow_view": true, "allow_fine_tuning": false, "organization": "*", "group": null, "is_blocking": false } ], "root": "gpt-3.5-turbo-0301", "parent": null }, { "id": "text-davinci-003", "object": "model", "created": 1669599635, "owned_by": "openai-internal", "permission": [ { "id": "modelperm-6CAfTW5IbFpnlziQKoDilahq", "object": "model_permission", "created": 1677793558, "allow_create_engine": false, "allow_sampling": true, "allow_logprobs": true, "allow_search_indices": false, "allow_view": true, "allow_fine_tuning": false, "organization": "*", "group": null, "is_blocking": false } ], "root": "text-davinci-003", "parent": null } ]
}`}]},{path:"/content/other/spread/%E5%85%B3%E4%BA%8Esocket.html",title:"关于socket",pathLocale:"/",contents:[{header:"关于socket",slug:"关于socket",content:""},{header:"1. Socket 本身是什么？",slug:"_1-socket-本身是什么",content:`Socket 不是协议，而是一种 编程接口（API），提供应用程序和网络协议栈交互的接口。 作用：让应用程序可以发送/接收数据，而不用关心底层的传输细节。 常用类型： TCP Socket → 面向连接、可靠传输
UDP Socket → 无连接、快速传输`},{header:"2. Socket 与应用层协议的关系",slug:"_2-socket-与应用层协议的关系",content:`Socket 是载体，可以承载不同应用层协议： HTTP（浏览器请求）
WebSocket（实时消息）
MySQL 协议（数据库访问）
自定义二进制协议（游戏、IoT） 所以 Socket 本身不是应用层协议，只是应用层协议和传输层之间的桥梁。`},{header:"3. Socket 的传输层依赖",slug:"_3-socket-的传输层依赖",content:`TCP Socket → 基于 TCP 传输层 保证数据可靠、有序、完整
三次握手、四次挥手 UDP Socket → 基于 UDP 传输层 无连接、不保证可靠性
适合实时性高、允许丢包的场景 也就是说，Socket 的“底层”就是 TCP 或 UDP，而应用程序通过 Socket 使用它们。`},{header:"4. 举例说明",slug:"_4-举例说明",content:`应用层协议 / 场景
Socket 类型
传输层协议 HTTP/HTTPS
TCP Socket
TCP WebSocket
TCP Socket
TCP MySQL 客户端
TCP Socket
TCP 游戏实时数据
UDP Socket
UDP DNS 查询
UDP Socket
UDP`},{header:"✅ 总结",slug:"✅-总结",content:`Socket 不是协议，是应用程序访问网络的接口。它不管底层是 TCP 还是 UDP，都是应用程序和网络协议栈之间的桥梁。
Socket 可以承载不同应用层协议（HTTP、WebSocket、MySQL、自定义协议等）。
底层传输依赖 TCP 或 UDP，决定数据可靠性和实时性。`},{header:"之所以有这个 socket 问题是因为，过去总是说socket协议，其实不对，应该是WebSocket协议",slug:"之所以有这个-socket-问题是因为-过去总是说socket协议-其实不对-应该是websocket协议",content:"很多人把 WebSocket 当成“Socket”，或者说“TCP 连接”，其实要区分清楚："},{header:"1. WebSocket 是应用层协议",slug:"_1-websocket-是应用层协议",content:`WebSocket 定义了浏览器/客户端和服务器之间 双向通信的应用层协议 它规定了： 握手过程（HTTP Upgrade 请求）
数据帧格式（文本帧、二进制帧、Ping/Pong）
心跳和关闭流程 也就是说，WebSocket 的语义、数据解析、帧边界 都属于应用层的东西。`},{header:"2. WebSocket 和 TCP 的关系",slug:"_2-websocket-和-tcp-的关系",content:`WebSocket 并不是独立的传输协议，它是 运行在 TCP 之上的应用层协议 TCP 提供： 可靠传输
有序、完整、重传 WebSocket 只关心 消息的格式、双向通信语义，不关心数据包是否丢失或乱序`},{header:"3. 连接示意",slug:"_3-连接示意",content:`客户端应用（浏览器/JS） │ WebSocket 协议（应用层） │ TCP Socket（传输层） │ IP/网络层 │ 数据链路/物理层 TCP Socket = 应用程序调用接口
TCP = 传输层协议，保证可靠传输
WebSocket = 应用层协议，定义消息格式和通信语义`},{header:"✅ 总结",slug:"✅-总结-1",content:`WebSocket ≠ TCP
WebSocket 是应用层协议，依赖 TCP 提供底层可靠传输
“WebSocket 连接”这个说法，只是习惯说法，本质上是 TCP 连接 + WebSocket 协议握手 + 双向数据流`},{header:"案例:基于Socket.js的实时监听响应",slug:"案例-基于socket-js的实时监听响应",content:"实时监听响应，就是客户端和服务器 建立一个长连接，然后服务器可以主动推送数据给客户端，这正是 Socket.js/WebSocket 的用途。"},{header:"1. 核心原理",slug:"_1-核心原理",content:`传统 HTTP 客户端发请求 → 服务器响应 → 连接关闭
不适合实时通知，因为每次都要建立 TCP 连接，延迟高 Socket.js / WebSocket 客户端发一次握手请求（HTTP Upgrade） → 建立 TCP 长连接
服务器可以随时向客户端推送消息
双向通信、实时性高
底层仍然是 TCP Socket，WebSocket 协议在上面定义了消息格式`},{header:"2. 实时监听流程示意",slug:"_2-实时监听流程示意",content:`客户端用 socket.js 发起连接请求
服务端接收，完成 WebSocket 握手
TCP 长连接建立
服务端可以 随时向客户端发送消息（例如聊天、通知、数据更新）
客户端监听 onmessage 回调，实时获取数据`},{header:"3. 总结",slug:"_3-总结",content:`socket.js / WebSocket = 应用层协议和 API
TCP Socket = 底层传输保证可靠
实时监听响应 = 利用 WebSocket 在 TCP 长连接上实现的双向实时通信`}]},{path:"/content/other/spread/%E5%85%B3%E4%BA%8Ewebstorm%E5%85%A8%E5%B1%80%E6%9B%BF%E6%8D%A2%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"关于webstorm全局替换的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`关于webstorm全局替换的问题:
使用phpstorm的时候，可能会执行 ctrl + r 进行全局替换操作，但是注意当文件比较多的时候，比如草果一百个，可能会替换不测底，
解决办法:
https://intellij-support.jetbrains.com/hc/en-us/community/posts/360002679840-Find-in-Path-shows-max-100-results`}]},{path:"/content/other/spread/%E5%85%B3%E4%BA%8E%E5%90%84%E4%B8%AA%E8%BF%9B%E5%88%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E6%8D%A2%E7%AE%97.html",title:"关于各个进制之间的换算",pathLocale:"/",contents:[{header:"关于各个进制之间的换算",slug:"关于各个进制之间的换算",content:"当然可以！我们一步步来回顾这个："},{header:"🧮 十六进制字符串长度与字节数的关系",slug:"🧮-十六进制字符串长度与字节数的关系",content:""},{header:"1️⃣ 一个字节（byte）是多少位（bit）？",slug:"_1️⃣-一个字节-byte-是多少位-bit",content:"1 byte = 8 bits"},{header:"2️⃣ 十六进制的一个字符表示多少位？",slug:"_2️⃣-十六进制的一个字符表示多少位",content:`1 个十六进制字符（如 a 或 f） = 4 bits
因为十六进制 = 基数为 16 = $2^4$`},{header:"3️⃣ 两个十六进制字符（如 fa）= 1 个字节",slug:"_3️⃣-两个十六进制字符-如-fa-1-个字节",content:`所以：
字节数 = 十六进制字符数 ÷ 2`},{header:"🔢 举例：64 个十六进制字符怎么算",slug:"🔢-举例-64-个十六进制字符怎么算",content:`64 hex 字符 × 4 bits = 256 bits
64 hex 字符 ÷ 2 = 32 bytes ✅ 所以： a3a674a11af75cc3ab6e91c8f1f12d246f4132f0fdbed4977214d11070862fa9
共 64 个字符
对应 32 字节（256 bits）`},{header:"✅ 总结",slug:"✅-总结",content:`十六进制字符数
字节数（bytes）
位数（bits） 16
8
64 32
16
128 64
32
256 128
64
512 一个十六进制（Hex）字符表示 4 位（bits）。`},{header:"📌 原因解释：",slug:"📌-原因解释",content:`十六进制是以 16 为基数的进制系统，对应的每个字符可以表示的值是：
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, a, b, c, d, e, f 这 16 个符号，刚好等于 $2^4 = 16$，所以： ✅ 1 个十六进制字符 = 4 位（bit）`},{header:"🔢 举个例子：",slug:"🔢-举个例子",content:`十六进制 A = 十进制 10 = 二进制 1010
十六进制 F = 十进制 15 = 二进制 1111`},{header:"🔄 对照参考表：",slug:"🔄-对照参考表",content:`十六进制
二进制
位数 0
0000
4 位 1
0001
4 位 2
0010
4 位 9
1001
4 位 a
1010
4 位 f
1111
4 位 所以当你看到一个 64 位的十六进制字符串，比如：
a3a674a11af75cc3ab6e91c8f1f12d246f4132f0fdbed4977214d11070862fa9 它表示的是： 64 个十六进制字符 × 4 bits = 256 bits
或者说 256 ÷ 8 = 32 字节（bytes）`}]},{path:"/content/other/spread/%E5%8A%A0%E5%AF%86%E4%B9%8BX.509.html",title:"加密之X.509",pathLocale:"/",contents:[{header:"",slug:"",content:`项目开发过程中，看到这个属性，就记录一下:
X.509是密码学里公钥证书的格式标准。X.509证书已应用在包括TLS/SSL在内的众多网络协议里，同时它也用在很多非在线应用场景里，
比如电子签名服务。X.509证书里含有公钥、身份信息（比如网络主机名，组织的名称或个体名称等）和签名信息（可以是证书签发机构CA的签名，也可以是自签名）。 在X.509里，组织机构通过发起证书签名请求（CSR）来得到一份签名的证书。首先需要生成一对密钥对，然后用其中的私钥对CSR进行数字签署（签名），并安全地保存私钥。
CSR进而包含有请求发起者的身份信息、用来对此请求进行验真的的公钥以及所请求证书专有名称。CSR里还可能带有CA要求的
其它有关身份证明的信息。然后CA对这个CSR进行签名。 组织机构可以把受信的根证书分发给所有的成员，这样就可以使用公
司的PKI系统了。浏览器（如Firefox）或操作系统预装有可信任的根证书列表，所以主流CA发布的TLS证书都直接可以正常使
用。浏览器的开发者直接影响着它的用户对CA的信任。X.509也定义了CRL实现标准。另一种检查合法性的方式是OCSP。`}]},{path:"/content/other/spread/%E5%90%84%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"各个网络层之间的关系",pathLocale:"/",contents:[{header:"各个网络层之间的关系",slug:"各个网络层之间的关系",content:"从 OSI 七层模型 和 TCP/IP 四层模型 两个视角对比，再结合 HTTP / MySQL / TCP 来理解。"},{header:"1. OSI 七层模型",slug:"_1-osi-七层模型",content:`理论模型，分为 7 层，每层只和相邻层交互： 应用层 直接面对用户，定义应用协议。
例子：HTTP、FTP、SMTP、MySQL 协议。 表示层 数据表示、加密解密、压缩。
例子：TLS/SSL（HTTPS 就用它）。 会话层 建立、管理、终止会话。
例子：RPC、SQL 会话管理。 传输层 端到端传输、错误检测、流量控制。
例子：TCP（可靠）、UDP（不可靠）。 网络层 负责寻址和路由。
例子：IP 协议。 数据链路层 在同一个局域网（直连节点）传输帧。
例子：以太网、Wi-Fi、PPP。 物理层 真实比特流传输。
例子：光纤、电缆、无线电波。`},{header:"2. TCP/IP 四层模型（工程实践）",slug:"_2-tcp-ip-四层模型-工程实践",content:"实际使用时，常简化为四层： 应用层（对应 OSI 应用+表示+会话层） HTTP、MySQL、DNS、SSH … 传输层 TCP、UDP 网络层 IP 网络接口层（对应 OSI 数据链路+物理层） 以太网、Wi-Fi、光纤、电缆"},{header:"3. 各层关系（以 PHP 访问 MySQL 举例）",slug:"_3-各层关系-以-php-访问-mysql-举例",content:`应用层 协议：MySQL 协议（定义握手、认证、SQL 命令格式）
参与者：PHP mysqli / PDO 驱动，MySQL Server 传输层 协议：TCP
功能：提供可靠的数据流，让 MySQL 协议的报文不丢失、不乱序 网络层 协议：IP
功能：把数据从客户端主机路由到服务器主机 链路/物理层 协议：以太网帧、光纤、Wi-Fi
功能：真正传输 0 和 1`},{header:"4. 层与层的协作关系",slug:"_4-层与层的协作关系",content:`上层依赖下层 HTTP/MySQL 不需要关心数据怎么走，只要 TCP 能保证可靠性就行。
TCP 不需要关心数据怎么到对方，只要 IP 能正确路由就行。 封装（Encapsulation） 每一层的数据都会被下一层“打包”。 例子： 应用层报文 → 加 TCP 头 → TCP 段
TCP 段 → 加 IP 头 → IP 包
IP 包 → 加以太网头 → 数据帧 解封装（Decapsulation） 服务器收到数据后，反向剥开：物理层 → 数据链路层 → 网络层 → 传输层 → 应用层。`},{header:"5. 总结",slug:"_5-总结",content:`TCP/IP 是分层设计的，各层只需关注本职工作。
应用层决定了数据“长什么样”（HTTP、MySQL、游戏协议）。
传输层决定了数据“怎么传”（可靠 TCP / 不可靠 UDP）。
网络层决定了数据“去哪”（IP 地址、路由）。
链路/物理层决定了数据“怎么送到下一跳”（网卡、电缆、无线）。`},{header:"6. 对应用层 HTTP、FTP、SMTP、MySQL 协议 使用方式分析",slug:"_6-对应用层-http、ftp、smtp、mysql-协议-使用方式分析",content:"应用层协议（HTTP、FTP、SMTP、MySQL 等）与“协议://”写法的关系："},{header:"1. 应用层协议和 URI (统一资源标识符)",slug:"_1-应用层协议和-uri-统一资源标识符",content:`在日常开发中，我们经常写 协议://地址:端口/...，这是 URI/URL 的一种语法格式。
但要注意：并不是所有的应用层协议都必须以这种方式书写，是否使用 协议:// 取决于这个协议有没有 统一的资源定位方式。`},{header:"2. 常见协议的 协议:// 形式",slug:"_2-常见协议的-协议-形式",content:`✅ HTTP/HTTPS 使用统一的 URL 语法：
http://example.com:80/path
https://example.com:443/path HTTP 是万维网的核心协议，天然适合用 URL。 ✅ FTP 也支持 URI 形式：
ftp://user:password@ftp.example.com:21/path/file.txt ✅ SMTP（邮件传输协议） 一般不直接用 URL，而是邮件地址形式：
user@example.com 但理论上也存在 URI 规范：
mailto:user@example.com ✅ MySQL 协议 MySQL 有自己的 连接字符串格式，不同语言/驱动可能差异：
// 参数方式
mysqli_connect("127.0.0.1", "user", "pass", "db"); // URI 方式（某些驱动支持）
mysql://user:pass@127.0.0.1:3306/db 这是参考 URL 习惯写的，方便表示，但它本质上不是 HTTP 那样的通用 URL，而是 MySQL 驱动库自己解析的字符串。`},{header:"3. 总结关系",slug:"_3-总结关系",content:`协议://... 是 URI 语法，主要用于资源定位（尤其是 HTTP/FTP）。
有些协议（HTTP/FTP）标准化了 URI 语法，所以大家都用。
有些协议（MySQL、Redis、MongoDB）借鉴了 URI 语法，作为连接字符串。
有些协议（SMTP、POP3）主要用在程序交互，不常见 URI，但标准也定义过。`}]},{path:"/content/other/spread/%E5%9C%A8ubuntu22%E4%B8%8B%E9%85%8D%E7%BD%AEminio%E6%9C%8D%E5%8A%A1.html",title:"在ubuntu22下配置minio服务",pathLocale:"/",contents:[{header:"在ubuntu22下配置minio服务",slug:"在ubuntu22下配置minio服务",content:`vim docker-compose.yml (这里不需要加 version信息，不然启动会报 docker-compose.yml: \`version\` is obsolete) 添加如下内容:
services:
minio:
image: minio/minio:latest
container_name: minio
ports:
- "9002:9000" # API 端口 (宿主机访问需要的话保留)
- "9003:9001" # 控制台端口
environment:
MINIO_ROOT_USER: admin
MINIO_ROOT_PASSWORD: secret123
volumes:
- minio_data:/data
command: server /data --console-address ":9001"
restart: unless-stopped
networks:
- docker_network-internal # ✅ 和 symfony 一样的网络 volumes:
minio_data: networks:
docker_network-internal: # ✅ 定义内部网络
external: true # ⚠️ 如果这个网络已经在 Symfony 的 compose 文件里定义过，就加 external 执行:
docker-compose up -d 查看容器运行状态:
$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
d4ee821f0460 minio/minio:latest "/usr/bin/docker-ent…" 51 seconds ago Up 50 seconds 0.0.0.0:9002->9000/tcp, :::9002->9000/tcp, 0.0.0.0:9003->9001/tcp, :::9003->9001/tcp minio 资源访问，默认访问会报如下错误 AccessDenied Access Denied. Artificial_Intelligence_(AI)_and_AI-assisted_technology_in_publishing.mp4 media /media/Artificial_Intelligence_(AI)_and_AI-assisted_technology_in_publishing.mp4 1866451F7FF248B7 dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8 需要设置内容为public，默认是不能对外访问的
# Mac / Linux
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/ 添加别名
mc alias set localminio http://localhost:9002 admin secret123 将 Bucket 设置为公开（匿名访问）
mc anonymous set download localminio/media 设置为私有
mc anonymous set none localminio/media 参数说明:
download → 允许匿名下载（公开读取）
media → 你的 Bucket 名称 验证:
$ mc anonymous list localminio/media
media/* => readonly 返回 Bucket 对象列表 访问 URL 就不再报 Access Denied`},{header:"使用问题",slug:"使用问题",content:"发现第一次上传图片的size一直为0,然后我手动上传一张图片"},{header:"上传图片并设置 MIME",slug:"上传图片并设置-mime",content:'mc cp --attr "Content-Type=image/jpeg" ./image.jpg localminio/media/ 然后再通过控制面板上传就可以了，不知道为什么. 但是通过控制面板上传视频的时候是可以的.'},{header:"在项目中使用,使用S3上传",slug:"在项目中使用-使用s3上传",content:`symfony7下使用, 安装包:
composer require aws/aws-sdk-php 环境变量:
MINIO_ENDPOINT=http://minio:9000
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=secret123
MINIO_BUCKET=media 测试路由:
#[Route('/test', name: 'test', methods: ['GET'])]
public function test()
{
$s3 = new S3Client([
'version' => 'latest',
'region' => 'us-east-1', // 只需填写任意字符串
'endpoint' => $_ENV['MINIO_ENDPOINT'],
'use_path_style_endpoint' => true, // MinIO 必须开启 path style
'credentials' => [
'key' => $_ENV['MINIO_ACCESS_KEY'],
'secret' => $_ENV['MINIO_SECRET_KEY'],
],
]); //$filePath = $this->getParameter('kernel.project_dir') . '/public/images/logo_test.png'; $filePath = $this->getParameter('kernel.project_dir') . '/public/images/publishing.mp4'; $bucket = $_ENV['MINIO_BUCKET']; //$key = 'uploads/example.jpg'; $key = 'uploads/wuhan.mp4'; $s3->putObject([ 'Bucket' => $bucket, 'Key' => $key, 'SourceFile' => $filePath, 'ACL' => 'public-read', // 公开访问 ]); echo "File uploaded: {$key}";
} 访问上传图片: http://localhost:9002/media/uploads/example.jpg`},{header:"相关拓展",slug:"相关拓展",content:`视频播放配置 <video
src="http://localhost:9002/media/Artificial_Intelligence_(AI)_and_AI-assisted_technology_in_publishing.mp4"
autoplay muted playsinline controls>
</video> 其中:
controls
必须要有，不然啥都没有`},{header:"什么是s3",slug:"什么是s3",content:"S3 是什么，以及为什么 MinIO / Laravel / Symfony 里老是提到它。"},{header:"1. S3 的本质",slug:"_1-s3-的本质",content:`S3 全称：Amazon Simple Storage Service
是 亚马逊云（AWS） 提供的一种 对象存储服务
类似网盘，但专门为程序和服务器使用，而不是人手动上传/下载 特点： 以 Bucket（桶） 组织文件
文件叫 Object（对象），有 Key（路径+文件名）
访问通过 HTTP(S) API
可以存放不限大小、数量的文件
提供权限控制、临时签名 URL、版本管理等`},{header:"2. S3 API",slug:"_2-s3-api",content:`S3 API 是 Amazon 定义的一套 HTTP 接口规范
全世界几乎所有对象存储（阿里 OSS、腾讯 COS、七牛云 Kodo、MinIO…）都 兼容 S3 API
这样一来，开发者只需要学会 S3 的 SDK 或 API，就能无缝切换存储服务 例子：上传一个文件 (HTTP PUT 请求)
PUT /mybucket/uploads/photo.jpg HTTP/1.1
Host: s3.amazonaws.com
Authorization: AWS4-HMAC-SHA256 Credential=xxxx
Content-Length: 1234
Content-Type: image/jpeg`},{header:"3. MinIO 与 S3 的关系",slug:"_3-minio-与-s3-的关系",content:`MinIO 并不是 AWS 的一部分
它是一个开源项目，目标就是 100% 兼容 S3 API
这样，你用 AWS SDK / S3 SDK 写的代码，不改动就能用 MinIO 换句话说：
👉 MinIO = 自己搭建一个小型的 AWS S3`},{header:"4. 在 Laravel / Symfony 里为什么用 s3 驱动",slug:"_4-在-laravel-symfony-里为什么用-s3-驱动",content:`Laravel 的 filesystem 是基于 Flysystem Flysystem 内置很多适配器：local、ftp、sftp、s3… s3 驱动的意思是：通过 S3 API 访问对象存储 所以： 配 AWS → s3
配 MinIO → s3
配七牛云（兼容 S3）→ 也用 s3`},{header:"5. 举个例子",slug:"_5-举个例子",content:`Storage::disk('s3')->put('hello.txt', 'Hello world'); 如果你配置了 AWS S3 → 存到 AWS
配了 MinIO → 存到 MinIO
配了七牛云（兼容 S3）→ 存到七牛云 因为大家都兼容 S3 API，所以 Laravel/Flysystem 只需要一个 s3 驱动即可。 ✅ 总结： S3 = Amazon 的对象存储服务
S3 API = 一套事实上的对象存储行业标准
MinIO 兼容 S3 API，所以 Laravel/Symfony 里配置 s3 驱动就能直接用 MinIO`}]},{path:"/content/other/spread/%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7.html",title:"在线工具",pathLocale:"/",contents:[{header:"",slug:"",content:`1.在线图片格式转换工具
[链接]
https://www.aconvert.com/cn/image/png-to-svg/
2.在线颜色反转工具
[链接]
https://fontmeme.com/zh/invert-colors/
3.在线bcrypt加密数据
[链接]
https://bcrypt.online/
4.在线贝塞尔曲线计算( cubic-bezier )
[链接]
https://cubic-bezier.com/
5.好用的富文本编辑器 TinyMCE
[链接]
https://www.tiny.cloud/
补充：
https://www.tiny.cloud/docs/tinymce/6/creating-a-plugin/?_ga=2.45605092.1100574337.1686531043-87378848.1686272359#example-using-external_plugins //用户自定义plugins或者收费plugins的配置
https://www.tiny.cloud/docs/tinymce/6/vue-ref/#form-input-bindings-v-model //vue绑定不生效问题，主要是vue版本的问题 vue2和vue3不通用
https://www.tiny.cloud/docs/tinymce/6/toolbar-configuration-options/ //toolbar设置
自定义图片上传:
上传图片完成以后报：Error: Errors: Failed path: (data > src) Could not find valid 错误: 主要是tinyMCE版本的问题 6/5不一样
v6:https://www.tiny.cloud/docs/tinymce/6/upload-images/#example-using-images_upload_handler
images_upload_handler: async (blobInfo, success) => new Promise(async (resolve, reject) => { const file = blobInfo.blob() const {url} = await this.uploadFile(file, 'image') console.log(url) resolve(url);
}) v5:https://www.tiny.cloud/docs/configure/file-image-upload/#images_upload_handler
images_upload_handler: async (blobInfo, success) => {
const file = blobInfo.blob()
const { url } = await this.uploadFile(file, 'image')
console.log(url)
success(url)
} 自定义图片上传的时候，图片路径会被转换为相对路径的问题 ，这个问题只需要在初始化是添加一个参数即可解决 convert_urls: false 6.在线颜色定义
[链接]
https://convertingcolors.com/rgb-color-0_0_0.html?search=RGB(0,%200,%200)
7.谷歌站点验证
[链接]
https://www.google.com/recaptcha/about/
8.在线生成 ics 日历文件
[链接]
https://ical.marudot.com/
各平台对应日历格式参数:
https://github.com/InteractionDesignFoundation/add-event-to-calendar-docs/tree/main/services
9.icon设计
[链接]
https://www.iconfinder.com/
10.php自动发布工具deployer
[链接]
https://deployer.org/`}]},{path:"/content/other/spread/%E5%9C%A8%E7%BA%BF%E7%94%9F%E6%88%90SHA%E5%AF%86%E9%92%A5.html",title:"在线生成SHA密钥",pathLocale:"/",contents:[{header:"",slug:"",content:`在线生成SHA密钥:
https://emn178.github.io/online-tools/sha256.html $ openssl rand -base64 12 | tr -dc 'a-zA-Z0-9' | fold -w 16 | head -n 1 //linux生成16位
HszFDPMA3uFZphPW 签名方式:
RSA: 公钥和私钥
SHA256: 16位字符串即可`}]},{path:"/content/other/spread/%E5%9F%BA%E4%BA%8Estorybook%E6%90%AD%E5%BB%BAUI%E5%B9%B3%E5%8F%B0.html",title:"基于storybook搭建UI平台",pathLocale:"/",contents:[{header:"",slug:"",content:`基于storybook搭建UI平台:
https://www.letswrite.tw/storybook-init/`}]},{path:"/content/other/spread/%E5%B8%A6%E5%AE%BD%E7%9A%84%E8%AE%A1%E7%AE%97.html",title:"带宽的计算",pathLocale:"/",contents:[{header:"带宽的计算",slug:"带宽的计算",content:"500mbps约等于62.5兆（MB）的宽带理论下载速度，但实际使用中，由于各种因素的影响，实际速度通常会低于这个理论值。 首先，明确概念：500mbps中的“mbps”是Million bit per second的缩写，即兆比特每秒，表示的是数据传输速率，单位是比特每秒(bps)。具体来说，500mbps意味着每秒可以传输500兆比特的数据。 其次，进行单位换算：在计算实际下载速度时，我们通常使用的是字节(Byte)而不是比特(bit)。1字节等于8比特，因此，要将比特率转换为字节率，需要将比特率除以8。所以，500mbps除以8等于62.5MB/s，这是理论上的最大下载速度。"}]},{path:"/content/other/spread/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%96%87%E4%BB%B6mime%E7%B1%BB%E5%9E%8B.html",title:"常见的文件mime类型",pathLocale:"/",contents:[{header:"",slug:"",content:`常见的文件mime类型: text/plain 表示文本文件的默认值。一个文本文件应当是人类可读的，并且不包含二进制数据
application/octet-stream 表示所有其他情况的默认值。一种未知的文件类型应当使用此类型。浏览器在处理这些文件时会特别小心，试图防止、避免用户的危险行为 扩展名 文档类型 MIME 类型
.aac AAC 音频	audio/aac
.abw AbiWord 文档	application/x-abiword
.apng 动态可移植网络图形（APNG）图像 image/apng
.arc 归档文件（嵌入多个文件） application/x-freearc
.avif AVIF 图像 image/avif
.avi AVI：音频视频交织文件格式（Audio Video Interleave） video/x-msvideo
.azw Amazon Kindle 电子书格式 application/vnd.amazon.ebook
.bin 任何二进制数据类型 application/octet-stream
.bmp Windows OS/2 位图 image/bmp
.bz BZip 归档 application/x-bzip
.bz2 BZip2 归档 application/x-bzip2
.cda CD 音频 application/x-cdf
.csh C-Shell 脚本 application/x-csh
.css 层叠样式表（CSS） text/css
.csv 逗号分隔值（CSV） text/csv
.doc Microsoft Word application/msword
.docx Microsoft Word（OpenXML） application/vnd.openxmlformats-officedocument.wordprocessingml.document
.eot MS 嵌入式 OpenType 字体 application/vnd.ms-fontobject
.epub	电子出版（EPUB）	application/epub+zip
.gz GZip 压缩归档 application/gzip
.gif 图像互换格式（GIF） image/gif
.htm, .html 超文本标记语言（HTML） text/html
.ico 图标（Icon）格式 image/vnd.microsoft.icon
.ics iCalendar 格式 text/calendar
.jar Java 归档（JAR） application/java-archive
.jpeg, .jpg JPEG 图像 image/jpeg
.js JavaScript text/javascript （规范：HTML 和 RFC 9239）
.json JSON 格式 application/json
.jsonld JSON-LD 格式 application/ld+json
.mid, .midi 音乐数字接口（MIDI） audio/midi、audio/x-midi
.mjs JavaScript 模块 text/javascript
.mp3 MP3 音频 audio/mpeg
.mp4 MP4 视频 video/mp4
.mpeg MPEG 视频 video/mpeg
.mpkg Apple 安装包 application/vnd.apple.installer+xml
.odp 开放文档演示稿文档 application/vnd.oasis.opendocument.presentation
.ods 开放文档表格文档 application/vnd.oasis.opendocument.spreadsheet
.odt 开放文档文本文档 application/vnd.oasis.opendocument.text
.oga OGG 音频 audio/ogg
.ogv OGG 视频 video/ogg
.ogx OGG application/ogg
.opus Opus 音频 audio/opus
.otf OpenType 字体 font/otf
.png 便携式网络图形 image/png
.pdf Adobe 便携式文档格式（PDF） application/pdf
.php 超文本预处理器（Personal Home Page） application/x-httpd-php
.ppt Microsoft PowerPoint application/vnd.ms-powerpoint
.pptx Microsoft PowerPoint（OpenXML） application/vnd.openxmlformats-officedocument.presentationml.presentation
.rar RAR 归档 application/vnd.rar
.rtf 富文本格式（RTF） application/rtf
.sh 伯恩 shell 脚本 application/x-sh
.svg 可缩放矢量图形（SVG） image/svg+xml
.tar 磁带归档（TAR） application/x-tar
.tif, .tiff 标签图像文件格式（TIFF） image/tiff
.ts MPEG 传输流 video/mp2t
.ttf TrueType 字体 font/ttf
.txt 文本（通常是 ASCII 或 ISO 8859-n） text/plain
.vsd Microsoft Visio application/vnd.visio
.wav 波形音频格式 audio/wav
.weba WEBM 音频 audio/webm
.webm WEBM 视频 video/webm
.webp WEBP 图像 image/webp
.woff Web 开放字体格式（WOFF） font/woff
.woff2 Web 开放字体格式（WOFF） font/woff2
.xhtml XHTML application/xhtml+xml
.xls Microsoft Excel application/vnd.ms-excel
.xlsx Microsoft Excel（OpenXML） application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
.xml XML RFC 7303（section 4.1）推荐使用 application/xml，但有时仍会使用 text/xml。你可以将特定的 MIME 类型分配给具有 .xml 扩展名的文件，这取决于其内容的解释方式。例如，Atom 消息来源是 application/atom+xml，而 application/xml 是默认的有效值。
.xul XUL application/vnd.mozilla.xul+xml
.zip ZIP归档 application/zip
.3gp 3GPP音视频容器 video/3gpp；如果不包含视频则为 audio/3gpp
.3g2 3GPP2音视频容器 video/3gpp2；如果不包含视频则为 audio/3gpp2
.7z 7-zip 归档	application/x-7z-compressed`}]},{path:"/content/other/spread/%E5%BD%93ping%E5%9F%9F%E5%90%8D%E6%97%B6_%E5%AE%9E%E9%99%85%E4%B8%8A%E6%98%AF%E5%9C%A8ping_CDN%E7%9A%84%E6%9F%90%E4%B8%AA%E8%BE%B9%E7%BC%98%E8%8A%82%E7%82%B9_%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3.html",title:"当ping域名时_实际上是在ping_CDN的某个边缘节点_怎么理解",pathLocale:"/",contents:[{header:"",slug:"",content:`ping域名时，实际上是在ping CDN的某个边缘节点，怎么理解?
1. Ping 的基本原理： - Ping 是一个网络工具，用于测试到达特定 IP 地址的网络连通性和响应时间。 - 当您 ping 一个域名时，系统首先需要将域名解析为 IP 地址。 2. CDN 的介入： - 在使用 CDN 的情况下，域名解析不会直接指向原始服务器，而是指向 CDN 的基础设施。 3. CDN 边缘节点： - CDN 在全球各地部署了大量的服务器，这些服务器被称为"边缘节点"或"边缘服务器"。 - 这些节点分布在不同的地理位置，目的是离用户更近，提供更快的访问速度。 4. 智能 DNS 解析： - 当您 ping 域名时，CDN 的 DNS 服务器会根据您的位置选择一个最近或最优的边缘节点。 - 返回给您的 IP 地址实际上是这个被选中的边缘节点的 IP，而不是原始服务器的 IP。 5. 实际 ping 过程： - 系统使用 CDN 提供的 IP 地址（边缘节点的 IP）进行 ping。 - 您发送的 ping 请求实际上是到达了 CDN 的边缘节点，而不是原始服务器。 6. 响应来源： - 对 ping 的响应来自 CDN 的边缘节点。 - 这个节点可能已经缓存了网站的内容，或者在需要时会从原始服务器获取内容。 7. 动态性： - 不同地理位置的用户 ping 相同的域名可能会得到不同的 IP 地址。 - 这是因为 CDN 会为不同区域的用户选择不同的最优边缘节点。 8. 优势： - 降低延迟：用户与较近的边缘节点通信，而不是直接与可能远距离的原始服务器通信。 - 负载分散：流量分布在多个边缘节点上，而不是集中在单一服务器。 - 安全性：原始服务器的 IP 被隐藏，增加了安全性。 9. 实际应用： - 这就是为什么有时候 ping 一个知名网站会得到看似不相关的 IP 地址。 - 这个 IP 实际上属于 CDN 提供商的网络，而不是网站自己的服务器。 理解这一点很重要，因为它解释了为什么使用 CDN 的网站在进行网络诊断时可能会表现得与传统托管不同。这种机制是 CDN 提高性能和安全性的核心策略之一。`}]},{path:"/content/other/spread/%E5%BD%93ping%E5%9F%9F%E5%90%8D%E6%97%B6_%E5%BE%97%E5%88%B0%E7%9A%84%E6%98%AFCDN%E7%9A%84IP%E5%9C%B0%E5%9D%80_%E8%BF%99%E6%98%AF%E5%9B%A0%E4%B8%BACDN%E9%80%9A%E5%B8%B8%E4%BC%9A%E6%8E%A5%E7%AE%A1%E5%9F%9F%E5%90%8D%E7%9A%84DNS%E8%A7%A3%E6%9E%90_%E8%BF%99%E4%B8%AA%E4%BB%80%E4%B9%88%E5%8E%9F%E7%90%86.html",title:"当ping域名时_得到的是CDN的IP地址_这是因为CDN通常会接管域名的DNS解析_这个什么原理",pathLocale:"/",contents:[{header:"",slug:"",content:`当ping域名时，得到的是CDN的IP地址。这是因为CDN通常会接管域名的DNS解析。这个什么原理?
CDN（内容分发网络）接管域名DNS解析的原理：
1. DNS解析基本原理： - 当您ping一个域名时，首先需要将域名转换为IP地址。 - 这个过程叫做DNS解析。 2. CDN的DNS接管： - 当网站使用CDN服务时，网站所有者会将其域名的DNS控制权交给CDN提供商（如Cloudflare）。 3. CDN的DNS服务器： - CDN提供商运营自己的DNS服务器。 - 这些服务器被设置为该域名的权威DNS服务器。 4. 智能DNS解析： - 当用户尝试解析域名时，CDN的DNS服务器会根据多种因素选择最佳的CDN节点IP来响应。 - 这些因素包括：用户地理位置、CDN节点负载、网络状况等。 5. 返回CDN节点IP： - DNS查询返回的不是源服务器的IP，而是最近或最优的CDN节点的IP。 6. 动态性： - 不同地区、不同时间的用户可能会得到不同的IP地址。 - 这使得CDN可以实现负载均衡和就近访问。 7. ping的结果： - 当您ping域名时，您实际上是在ping CDN的某个边缘节点。 - 这就是为什么您看到的是CDN的IP（如104.18.24.151），而不是源服务器的IP。 8. 安全性提升： - 这种方式也隐藏了源服务器的真实IP，增加了安全性。 9. 实现方法： - 技术上，这通常通过修改域名的NS（Name Server）记录来实现。 - 域名的NS记录会指向CDN提供商的DNS服务器。 10. 灵活性： - CDN可以快速更改IP映射，无需修改客户的DNS设置。 - 这允许CDN提供商快速响应网络变化或安全威胁。 这种DNS接管机制是CDN发挥作用的关键。它允许CDN在全球范围内分发内容，优化访问速度，同时提供额外的安全层。`}]},{path:"/content/other/spread/%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E4%BB%98%E6%AC%BE%E5%88%B0%E9%9B%B6%E9%92%B1.html",title:"微信企业付款到零钱",pathLocale:"/",contents:[{header:"",slug:"",content:`微信企业付款到零钱:
企业付款到零钱提供由商户付款至微信用户零钱的能力，支持平台操作及接口调用两种方式。
特点：
免费：不收取付款手续费，节省企业成本。
快速：在发起后，及时到账用户零钱。通过微信消息触达，用户及时获知入账详情。
灵活：可通过页面或接口发起付款，灵活满足企业不同场景的付款需求。
友好：通过openid即可实现付款，无需获取用户敏感隐私信息。
安全：提供多种安全工具，满足不同场景安全需求。如：按需调整付款额度；支持收款账户限制；支持安全防刷，拦截恶意用户、小号、机器号码；支持自定义大额通知等。
应用场景：
费用报销，保险理赔，员工福利，用户奖励等；
开通条件必须同时满足以下3个条件方可开通：
1，商户入驻90天
2，截至今日回推30天连续交易流水
3，保持健康交易。`}]},{path:"/content/other/spread/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E4%B9%8B%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF.html",title:"微信开发之获取用户信息",pathLocale:"/",contents:[{header:"",slug:"",content:`在做项目的时候，经常会涉及到获取微信用户信息，主要有如下两种方法实现:
①通过网页授权的方式获取，步骤如下:
1 第一步：用户同意授权，获取code
请求链接为：
在确保微信公众账号拥有授权作用域（scope参数）的权限的前提下（已认证服务号，默认拥有 scope 参数中的snsapi_base和snsapi_userinfo 权限），引导关注者打开如下页面：
https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&redirect_uri=REDIRECT_URI&response_type=code&scope=SCOPE&state=STATE#wechat_redirect 2 第二步：通过 code 换取网页授权access_token 和openid(不管 scope为snsapi_base和snsapi_userinfo中的哪种方式，都会有值，只是为snsapi_base的时候，没有了第四步操作)
获取 code 后，请求以下链接获取access_token：
https://api.weixin.qq.com/sns/oauth2/access_token?appid=APPID&secret=SECRET&code=CODE&grant_type=authorization_code 3 第三步：刷新access_token（如果需要）
获取第二步的refresh_token后，请求以下链接获取access_token：
https://api.weixin.qq.com/sns/oauth2/refresh_token?appid=APPID&grant_type=refresh_token&refresh_token=REFRESH_TOKEN 4 第四步：拉取用户信息(需 scope 为 snsapi_userinfo)，通过access_token 和openid
http：GET（请使用 https 协议）：
https://api.weixin.qq.com/sns/userinfo?access_token=ACCESS_TOKEN&openid=OPENID&lang=zh_CN 5 附：检验授权凭证（access_token）是否有效
http：GET（请使用 https 协议）：
https://api.weixin.qq.com/sns/auth?access_token=ACCESS_TOKEN&openid=OPENID ②通过UnionID机制
这个机制的原理是：在关注者与公众号产生消息交互后，公众号可获得关注者的OpenID（加密后的微信号，每个用户对每个公众号的 OpenID 是唯一的。对于不同公众号，同一用户的 openid 不同）。
公众号可通过本接口来根据 OpenID 获取用户基本信息，包括语言和关注时间。 开发者可通过 OpenID 来获取用户基本信息。请使用 https 协议。
接口调用请求说明 http请求方式: GET https://api.weixin.qq.com/cgi-bin/user/info?access_token=ACCESS_TOKEN&openid=OPENID&lang=zh_CN 这里的 access_token 是 调用接口凭证(和网页授权的那个不一样，就是全局唯一的那个access_token，通过https请求方式: GET https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&appid=APPID&secret=APPSECRET 获取) ，
openid 是 普通用户的标识，对当前公众号唯一 但是种方式，2021年12月27日之后，不再输出头像、昵称信息。如果要获取 必须经过用户网页授权才能拿到。 所有文档见：
https://developers.weixin.qq.com/doc/offiaccount/OA_Web_Apps/Wechat_webpage_authorization.html
https://developers.weixin.qq.com/doc/offiaccount/User_Management/Get_users_basic_information_UnionID.html#UinonId //在开发过程中经常会有下面的用法，来验证获取用户信息的方式 public function rules() { return [ 'code' => 'required_without:access_token|string', //第一种 'access_token' => 'required_without:code|string', //第二种 'openid' => 'required_with:access_token|string', //第二种 ]; }`}]},{path:"/content/other/spread/%E6%95%B0%E6%8D%AE%E5%BA%93DDL%E5%92%8CDML.html",title:"数据库DDL和DML",pathLocale:"/",contents:[{header:"",slug:"",content:`数据库DDL和DML:
在 MySQL 中，DDL（Data Definition Language，数据定义语言）和 DML（Data Manipulation Language，数据操作语言）是两种不同类型的 SQL 语句，各自用于不同的操作：`},{header:"1. DDL（数据定义语言）",slug:"_1-ddl-数据定义语言",content:`作用：用于定义或更改数据库对象的结构，比如数据库、表、索引等。
主要特点：DDL 语句会影响数据库的结构，一般不涉及具体的数据。
常用语句： CREATE：创建数据库、表、视图、索引等。例如，CREATE TABLE users (id INT, name VARCHAR(50));。
ALTER：修改数据库对象的结构，例如修改表结构、增加/删除字段等。例如，ALTER TABLE users ADD age INT;。
DROP：删除数据库对象，例如删除表或数据库。例如，DROP TABLE users;。
TRUNCATE：清空表中所有数据，但保留表结构。例如，TRUNCATE TABLE users;。 事务特性：DDL 操作一般是自动提交的，不能回滚。`},{header:"2. DML（数据操作语言）",slug:"_2-dml-数据操作语言",content:`作用：用于对数据库中的数据进行增删改查。
主要特点：DML 语句直接操作数据，并不会改变数据库结构。
常用语句： SELECT：查询数据。例如，SELECT * FROM users;。
INSERT：插入数据。例如，INSERT INTO users (id, name) VALUES (1, 'Alice');。
UPDATE：更新数据。例如，UPDATE users SET name = 'Bob' WHERE id = 1;。
DELETE：删除数据。例如，DELETE FROM users WHERE id = 1;。 事务特性：DML 操作通常在事务中使用，可以回滚。`},{header:"区别总结",slug:"区别总结",content:`作用不同：DDL 用于定义数据库结构，DML 用于操作数据。
是否影响结构：DDL 改变表结构或数据库对象；DML 只改变数据内容。
事务特性：DDL 语句一般自动提交，不支持回滚；DML 语句支持回滚和提交。`}]},{path:"/content/other/spread/%E6%97%A5%E6%9C%9F%E5%90%8E%E9%9D%A2st-nd-rd-th%E7%9A%84%E5%8C%BA%E5%88%86%E5%92%8C%E7%94%A8%E6%B3%95.html",title:"日期后面st-nd-rd-th的区分和用法",pathLocale:"/",contents:[{header:"",slug:"",content:`日期后面st/nd/rd/th的区分和用法：
（1）结尾是1的：1，21，31后面加st（first的缩写）； （2）结尾是2的：2，22，32后面加nd（second的缩写）; （3）结尾是3的：3，23，33后面加rd（third的缩写）; （4）其他结尾都加th。 PHP可以通过 date('jS F Y'， time())，实现：22nd September 2023 date('jS M Y')，实现： 22nd Sep 2023`}]},{path:"/content/other/spread/%E6%97%B6%E5%8C%BAGMT-CST-UTC.html",title:"时区GMT-CST-UTC",pathLocale:"/",contents:[{header:"",slug:"",content:`UTC(世界标准时间) 协调世界时，又称世界标准时间或世界协调时间，简称UTC（从英文“Coordinated Universal Time”／法文“Temps Universel Coordonné”而来），是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林尼治标准时间。 GMT(格林尼治平时) 格林尼治平时（又称格林尼治平均时间或格林尼治标准时间，旧译格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 理论上来说，格林尼治标准时间的正午是指当太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。由于地球在它的椭圆轨道里的运动速度不均匀，这个时刻可能与实际的太阳时有误差，最大误差达16分钟。 由于地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治时间已经不再被作为标准时间使用。现在的标准时间，是由原子钟报时的协调世界时（UTC）。 CST(北京时间) 北京时间，China Standard Time，中国标准时间。在时区划分上，属东八区，比协调世界时早8小时，记为UTC+8。 不过这个CST这个缩写比较纠结的是它可以同时代表四个不同的时间： Central Standard Time (USA) UT-6:00
Central Standard Time (Australia) UT+9:30 China Standard Time UT+8:00
Cuba Standard Time UT-4:00`}]},{path:"/content/other/spread/%E6%97%B6%E9%97%B4%E5%8D%95%E4%BD%8D.html",title:"时间单位",pathLocale:"/",contents:[{header:"",slug:"",content:"常用时间单位 1.Seconds /秒 2.Milliseconds /毫秒 3.Microseconds/µs /微秒 4.Nanoseconds /纳秒"}]},{path:"/content/other/spread/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.html",title:"时间复杂度",pathLocale:"/",contents:[{header:"时间复杂度-关于 O(n) 和 O(log n)的定义",slug:"时间复杂度-关于-o-n-和-o-log-n-的定义",content:"“O(n)” 和 “O(log n)” 是算法分析中的时间复杂度（Time Complexity）表示方式，用来衡量算法随着输入规模增大时，运行时间的增长趋势。我们来详细对比这两者："},{header:"🔢 O(n)（线性时间复杂度）",slug:"🔢-o-n-线性时间复杂度",content:`含义：随着输入数据量 n 的增加，算法的运行时间也线性增加。 举例：
function sum(arr) { let total = 0; for (let i = 0; i < arr.length; i++) { total += arr[i]; } return total;
} 这个函数会对每个元素做一次操作，所以时间复杂度是 O(n)。 特点： 效率中等；
适用于遍历型操作；
如果 n = 1000，就需要大约 1000 次操作。`},{header:"🪜 O(log n)（对数时间复杂度）",slug:"🪜-o-log-n-对数时间复杂度",content:`含义：随着 n 的增加，运行时间只增加对数倍数，增长非常慢。 举例：二分查找：
function binarySearch(arr, target) { let left = 0; let right = arr.length - 1; while (left <= right) { let mid = Math.floor((left + right) / 2); if (arr[mid] === target) return mid; if (arr[mid] < target) left = mid + 1; else right = mid - 1; } return -1;
} 每次都将搜索区间减半，所以是 O(log n)。 特点： 效率非常高；
常见于排序数组上的查找、树结构操作（如平衡二叉树）；
如果 n = 1024，最多只需要大约 log₂(1024) = 10 次操作！`},{header:"⛳ 比较总结",slug:"⛳-比较总结",content:`时间复杂度
操作数增长
举例
效率 O(n)
成正比
遍历数组
中等 O(log n)
成对数增长
二分查找
非常高效`},{header:"可视化对比（大致数量）：",slug:"可视化对比-大致数量",content:`n 值
O(n) 操作次数
O(log n) 操作次数 10
10
4 100
100
7 1000
1000
10 1,000,000
1,000,000
20`}]},{path:"/content/other/spread/%E6%B5%8F%E8%A7%88%E5%99%A8CSP%E9%97%AE%E9%A2%98.html",title:"浏览器CSP问题",pathLocale:"/",contents:[{header:"",slug:"",content:`浏览器CSP(Content Security Policy)问题:
https://www.hakatemia.fi/en/courses/browser-security/content-security-policy`}]},{path:"/content/other/spread/%E7%89%88%E6%9C%AC%E5%90%91%E4%B8%8B%E5%85%BC%E5%AE%B9%E5%92%8C%E5%90%91%E4%B8%8A%E5%85%BC%E5%AE%B9%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"版本向下兼容和向上兼容的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`版本向下兼容和向上兼容的区别:
向下兼容 (Backward Compatibility)：
向下兼容是指新版本的软件能够与旧版本的软件或数据进行兼容。这意味着更新后的软件可以无缝地与之前的版本进行互操作，而不会破坏现有的功能或数据。旧版本的软件或数据可以在新版本中正常工作，而不需要进行修改或适配。向下兼容性是确保用户升级到新版本时不会出现问题的重要因素。 向上兼容 (Forward Compatibility)：
向上兼容是指旧版本的软件能够与新版本的软件或数据进行兼容。这意味着现有的软件或数据可以在更新的版本中正常工作，而不需要进行修改或适配。向上兼容性在设计时要考虑到未来可能的改变，以确保新的功能或数据结构不会影响到现有的系统。 总结来说，向下兼容性确保新版本的软件可以与旧版本的软件和数据协同工作，而向上兼容性则确保旧版本的软件可以与新版本的软件和数据协同工作。这两者都是确保软件的演进和升级过程中不会破坏现有功能或数据的关键因素。在软件开发和维护中，平衡好向下兼容性和向上兼容性对于用户体验和系统的稳定性都是至关重要的。`}]},{path:"/content/other/spread/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A1%86%E6%9E%B6YOLO.html",title:"目标检测框架YOLO",pathLocale:"/",contents:[{header:"目标检测框架YOLO",slug:"目标检测框架yolo",content:`YOLO 框架一般指 You Only Look Once，是一个目标检测（Object Detection）框架。它的主要用途是：
✅ 识别和定位图像或视频中的物体 —— 不仅能识别“这是猫/狗/人”，还会给出物体在画面中的位置（用边框标注）。`},{header:"YOLO 的特点",slug:"yolo-的特点",content:`速度快 YOLO 的名字就是 “You Only Look Once”——只需要看一遍图像，就能同时完成分类和定位。
比传统的 R-CNN 系列快得多，适合实时场景。 端到端训练 输入一张图片，输出就是物体的类别和边框。
不需要复杂的中间处理步骤。 实时检测 比如在监控视频里，YOLO 能实时框出人、车等目标。`},{header:"YOLO 可以用来做什么？",slug:"yolo-可以用来做什么",content:`安防监控：识别人、车、危险物体
自动驾驶：检测行人、交通标志、车辆
工业质检：识别瑕疵品
医疗影像：检测肿瘤、病灶
无人机航拍：识别地物、目标跟踪 👉 总结一下：
YOLO 是一个 实时目标检测框架，用来识别并标注图像/视频里的物体及其位置，既快又准确。`}]},{path:"/content/other/spread/%E7%A0%B4%E8%A7%A3jetbrains%E8%BD%AF%E4%BB%B6.html",title:"破解jetbrains软件",pathLocale:"/",contents:[{header:"",slug:"",content:`在实际开发过程中，需要各种开发工具，现在主要使用jetbrains全家桶，下面以 webstorm 的破解过程进行讲解: 安装java环境 下载工具jetbra 网站:https://3.jetbra.in/ 下载好了解压到指定盘，里面有一些脚本文件，其中: install-current-user.vbs - 适用于当前 Windows 用户。 install-all-user.vbs - 适用于所有 Windows 用户。 install.sh - 适用于 Linux 和 Mac // ./scripts/install.sh，linux下的脚本执行完了，需要重新启动电脑，我这里用的是ubuntu22 接下来，您需要将jetbra文件夹下的配置添加到 webstorm64.vmoptions文件中 -javaagent:~/Downloads/jetbra/ja-netfilter.jar=jetbrains 在 linux 上，webstorm64.vmoptions 文件位于 ~/Downloads/WebStorm-223.7571.168/bin下 还是到这个网站:https://3.jetbra.in/ 下载各个工具对应版本的激活码 为应用添加图标，方便启动(这里以pycharm为例) 1>进入appications目录，新建xxx.desktop文件
guoshipeng@tianyi510s:~$ cd /usr/share/applications/
guoshipeng@tianyi510s:/usr/share/applications$ sudo vim py-charm.desktop
2>在xxx.desktop文件写入下面内容
[Desktop Entry]
Name=PyCharm
Exec=sh /home/guoshipeng/Downloads/pycharm-professional-2022.2.5/pycharm-2022.2.5/bin/pycharm.sh
Terminal=false
Type=Application
Icon=/home/guoshipeng/Downloads/pycharm-professional-2022.2.5/pycharm-2022.2.5/bin/pycharm.svg
Comment=PyCharm
Categories=Application; 注意上面Exec和Icon属性后面要修改为自己的WebStorm的安装目录对应的路径。
在上面配置完成后，打开右下角的应用显示里便能看到webstorm的启动图标了。 启动应用，然后输入刚才负复制出来的激活码就可以了，目前2022.2版本的可以激活到2025年，估计2023.2的可以激活到2026年吧 这里放几个激活码吧，都是2022.2.x的 goland: JZFLGE21ND-eyJsaWNlbnNlSWQiOiJKWkZMR0UyMU5EIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBHTyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFdTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJHTyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6ZmFsc2V9LHsiY29kZSI6IlBDV01QIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDkwMlBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6LTE1NTI3NDEyNzIiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-cQoXljKE7uBjoI23ZBPd84P89vQAaprVvVhxj1/nSOABUZKPZMCs6p2id5WKBP1n0EoPHykvzd0y7QcdcO2hxNwbaBRZxpPFuuMigGazrrt+zSd9+UlFXmtcseFTXlWn7Jw2qqp7WSVQlj+o3gf2Gic9/Vp2pAmIajMGdFDsXcHbYUrLwTRVtFkNtggtsqh0AVS8xhzLuXMzGXJsqEEWPZCKMEjy0bURm/FQvrRC/gIptJzuybSb/neqKmvxZefX1lhe98igS3tZsL/E+hsQK7ueXVSP2AuuVEz/6qHYknPS7K4UluWpd+ktIxTcHjIykK1tlWlwTsupZTxnvXFWQA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD webstorm: 8R927DG13X-eyJsaWNlbnNlSWQiOiI4UjkyN0RHMTNYIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IldTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFdTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQQ1dNUCIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX1dLCJtZXRhZGF0YSI6IjAxMjAyMjA5MDJQU0FOMDAwMDA1IiwiaGFzaCI6IlRSSUFMOjIwMTEzMjMwMjYiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-Jev3eIT6wPDh59rzeBG67oHD8GcYHifz9+OkIePP3Qo49dGX1DqLTGJgOxSClHrshRzjOktdBYwkwpeTrDMwgeGu+cy0OhzvtQMeh7R3HrEQkhGbNBjfpbW6nq6Mhv8k6Duoiw3XiU434V5iM6DgRN3Yzo8VKxU7Kb4u/SQnPTd+PR64hYJjblVXUzGHZUX4w8RBej3T0EREccs36bfnnPC2X91K/qbvr9C0uY/feHAMpuekMks0v4qApbInpw5O+elLE3l8txlNWhWSC8m/O/S7iydf27hV5mgePM5422Rpvm4dmA2DIQcq7xxdt4X67DmVGMC2yIFiH4hfkqySWg==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD phpstorm: DXHN0R5Z4F-eyJsaWNlbnNlSWQiOiJEWEhOMFI1WjRGIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFdTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQUFMiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDV01QIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDkwMlBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6LTE2MDY1NjU0NzQiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-PXxjbi2g20tUcfzptAnY/ZIKQbXW3FwXJ3P5scBMkXrya0Wg0YviqciwEWJe5laYfWevv8RzEEwrAcxz5ug1RYrg4bjZ7mJiQoOatsKahqGT1TDfU5YGpZPfbtjlKHAlYSszioJ0pka6go2qBa5AaPj4HmKfB4jkeGX4inRxPrIxc8PyAo0wyWWEaZ7R4pLC4ZDqIAYJ/IzXIf1V84+p5hGYd6QD6ze1BCEGxI/E8LjloaIvv0oNdkV2qTyDCH9IF3E42iheOwazyrlOWYivYyn/ew0kvjGwwSdbrbIJH7SSbaz2nxlBWnR04yJaI4txnnS1eUbiUNQtEhKJ3uD6oQ==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD pycharm:
EUWT4EE9X2-eyJsaWNlbnNlSWQiOiJFVVdUNEVFOVgyIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFBDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDV01QIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDkwMlBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6MzUzOTQ0NTE3IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-FT9l1nyyF9EyNmlelrLP9rGtugZ6sEs3CkYIKqGgSi608LIamge623nLLjI8f6O4EdbCfjJcPXLxklUe1O/5ASO3JnbPFUBYUEebCWZPgPfIdjw7hfA1PsGUdw1SBvh4BEWCMVVJWVtc9ktE+gQ8ldugYjXs0s34xaWjjfolJn2V4f4lnnCv0pikF7Ig/Bsyd/8bsySBJ54Uy9dkEsBUFJzqYSfR7Z/xsrACGFgq96ZsifnAnnOvfGbRX8Q8IIu0zDbNh7smxOwrz2odmL72UaU51A5YaOcPSXRM9uyqCnSp/ENLzkQa/B9RNO+VA7kCsj3MlJWJp5Sotn5spyV+gA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD intelij:
6G5NXCPJZB-eyJsaWNlbnNlSWQiOiI2RzVOWENQSlpCIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBEQiIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQUEMiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBHTyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFNXIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBQUyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFJCIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQQ1dNUCIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX1dLCJtZXRhZGF0YSI6IjAxMjAyMjA5MDJQU0FOMDAwMDA1IiwiaGFzaCI6IlRSSUFMOi0xMDc4MzkwNTY4IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-SnRVlQQR1/9nxZ2AXsQ0seYwU5OjaiUMXrnQIIdNRvykzqQ0Q+vjXlmO7iAUwhwlsyfoMrLuvmLYwoD7fV8Mpz9Gs2gsTR8DfSHuAdvZlFENlIuFoIqyO8BneM9paD0yLxiqxy/WWuOqW6c1v9ubbfdT6z9UnzSUjPKlsjXfq9J2gcDALrv9E0RPTOZqKfnsg7PF0wNQ0/d00dy1k3zI+zJyTRpDxkCaGgijlY/LZ/wqd/kRfcbQuRzdJ/JXa3nj26rACqykKXaBH5thuvkTyySOpZwZMJVJyW7B7ro/hkFCljZug3K+bTw5VwySzJtDcQ9tDYuu0zSAeXrcv2qrOg==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD`}]},{path:"/content/other/spread/%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B.html",title:"网络请求流程",pathLocale:"/",contents:[{header:"网络请求流程:",slug:"网络请求流程",content:`资源信息:
本机IP:192.168.5.17 默认网关:192.168.5.1(这个一般也是路由器的地址) 流程说明： 1>发起请求：
当你的计算机向外部服务器发起请求时，假设请求的目标 IP 地址是 203.0.113.5（一个网站的 IP 地址），而你的计算机的本地 IP 地址是 192.168.5.17。
计算机会将数据包的源地址设置为 192.168.5.17，目标地址设置为 203.0.113.5，然后将数据包通过 wlp2s0（无线网卡）发送到路由器。 2>路由器的处理：
路由器收到这个数据包后，会看到源地址是 192.168.5.17（本地计算机的 IP 地址），并将数据包的源地址替换为路由器的 IP 地址（比如 192.168.5.1）。然后，路由器会把数据包转发到外部网络（即 203.0.113.5）并等待响应。 3>外部服务器响应：
当外部服务器（例如网站服务器）收到请求并处理后，会生成响应并将其返回给请求的源 IP 地址，即路由器的 公网 IP（例如 203.0.113.1）。服务器会把响应数据包的目标地址设置为路由器的公网 IP。 4>路由器将响应转发回本地设备：
外部网络响应回到路由器的公网 IP 后，路由器会根据 网络地址转换（NAT） 技术，将响应数据包转发给正确的本地设备。
路由器会检查数据包，并发现它是响应从 本地 IP 192.168.5.17 发出的请求的。
路由器将数据包的目标地址修改为本地 IP 地址 192.168.5.17，然后通过 wlp2s0 将数据包发送回你的计算机。 5>最终到达计算机：
最终，计算机收到外部服务器的响应数据包，并根据内容进行处理。你看到网页加载完成，或者其他请求的结果。 总结：
外部网络的响应数据包通过 路由器的公网 IP 地址 返回到路由器。
路由器使用 NAT 功能，检查这个数据包，确认它是哪个本地设备发出的请求。
路由器将数据包转发给正确的本地设备（例如 192.168.5.17），确保响应到达正确的计算机。
因此，路由器不仅仅负责将数据包从本地网络转发到外部网络，也负责确保外部响应能够正确地送回到发起请求的本地设备。 这个过程的关键点：
源 IP 地址 和 目标 IP 地址 的作用：发起请求时，源 IP 是本地设备的 IP 地址，目标 IP 是外部服务器的 IP 地址；而响应时，外部服务器的目标 IP 是路由器的公网 IP，最终路由器通过 NAT 把数据转发到本地设备。
网络地址转换（NAT）：路由器通过 NAT 功能，把从本地设备发出的请求的源地址和端口号与外部服务器进行匹配，确保响应可以准确返回到正确的设备。
这个流程就是我们日常网络通信背后的基础，确保了设备可以和外部服务器进行正常的请求与响应交换。`},{header:"下面是我本地ip route 输出",slug:"下面是我本地ip-route-输出",content:`$ ip r
default via 192.168.5.1 dev wlp2s0 proto dhcp metric 600 169.254.0.0/16 dev wlp2s0 scope link metric 1000 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 dev br-7cbb16a986d6 proto kernel scope link src 172.18.0.1 172.19.0.0/16 dev br-fab0b27bf071 proto kernel scope link src 172.19.0.1 172.20.0.0/16 dev br-e6742f9d2eb1 proto kernel scope link src 172.20.0.1 192.168.5.0/24 dev wlp2s0 proto kernel scope link src 192.168.5.17 metric 600 192.168.49.0/24 dev br-331156baf737 proto kernel scope link src 192.168.49.1 linkdown`},{header:"重点解释 default via 192.168.5.1 dev wlp2s0 proto dhcp metric 600",slug:"重点解释-default-via-192-168-5-1-dev-wlp2s0-proto-dhcp-metric-600",content:`default：表示默认网关，意味着所有无法匹配具体路由的流量都会走这个路径。
via 192.168.5.1：表示流量通过 192.168.5.1 这个网关发送。
dev wlp2s0：流量通过 wlp2s0（你的无线网卡）发送。(需要无限网卡和路由器通信,这个192.168.5.1其实是路由器的IP，只有这样才能找到路由器)
proto dhcp：表示这条路由是通过 DHCP 服务器获取的。
metric 600：路由优先级，较小的 metric 优先级更高。`},{header:"Docker 和桥接网络",slug:"docker-和桥接网络",content:"172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 dev br-7cbb16a986d6 proto kernel scope link src 172.18.0.1 172.19.0.0/16 dev br-fab0b27bf071 proto kernel scope link src 172.19.0.1 172.20.0.0/16 dev br-e6742f9d2eb1 proto kernel scope link src 172.20.0.1"}]},{path:"/content/other/spread/%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E8%B7%A8%E5%9F%9F%E7%9A%84%E6%A6%82%E5%BF%B5.html",title:"网络请求跨域的概念",pathLocale:"/",contents:[{header:"",slug:"",content:`网络请求跨域的概念:
跨域：要注意的是，虽然不同子域名之间的访问被认为是跨域，但同一主域名下不同端口之间的访问也被视为跨域。 因为同源策略，所谓同源策略包括:协议、域名和端口 都要相同`}]},{path:"/content/other/spread/%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90https%E8%AF%81%E4%B9%A6.html",title:"自动生成https证书",pathLocale:"/",contents:[{header:"自动生成https证书",slug:"自动生成https证书",content:`可以通过 Certbot 包生成证书，可以自动配置nginx证书
Certbot / Let’s Encrypt`}]},{path:"/content/other/spread/%E8%87%AA%E5%AE%9A%E4%B9%89npm%E7%9A%84%E6%BA%90%E5%9C%B0%E5%9D%80.html",title:"自定义npm的源地址",pathLocale:"/",contents:[{header:"",slug:"",content:`自定义npm的源地址:
当我们的前端项目npm仓库有多个源，想在某个单独的项目中使用特定的npm源，则可以通过.npmrc文件或者package.json来进行配置
.npmrc文件配置
1.在项目根目录下创建.npmrc文件
2.编辑文件，输入registry="目标源地址"
registry="https://registry.npmjs.org/"
3.通过命令npm config ls查看当前项目下的registry是否发生了变化
配置完成后，npm源地址只在此项目中生效，并不会对全局npm的配置影响，可以在别的终端上通过命令npm config ls进行验证
package.json文件配置
在package.json文件中，添加publishConfig属性，这样可以指定npm源发布仓库（可以用于公司的npm私库）需要提前登录
"publishConfig": {
"registry": "http://xxxxx/"
}
总结:
package.json 一般用于自己定义npm包的时候，指定将这个包发布到哪个仓库去，可以是自己公司的私有仓库也可以是共有的。
.npmrc 文件，一般指定当前项目可以单独从哪些源(仓库)加载依赖，这个也很有用，一般大家默认都会配置taobao的源，但是会发现，有些包在taobao上找不到，就需要单独在则合理配置特殊的源地址了`}]},{path:"/content/other/spread/%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E6%8F%92%E4%BB%B6.html",title:"视频播放插件",pathLocale:"/",contents:[{header:"",slug:"",content:`视频播放插件:
https://videojs.com/ 视频格式转换工具:
https://handbrake.fr/`}]},{path:"/content/other/spread/%E8%BD%AF%E4%BB%B6%E6%88%96%E8%80%85%E9%A1%B9%E7%9B%AE%E5%90%84%E4%B8%AA%E7%89%88%E6%9C%AC%E4%BB%A3%E5%8F%B7%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"软件或者项目各个版本代号的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`软件或者项目各个版本代号的区别: Alpha
内部测试版本 (Alpha Releases) ，会引入新的功能和改进。Alpha 版是当前系列版本的最初版本。Alpha 版可能存在一些 bug，提供给尝鲜用户，可以用于测试最新的功能。 示例：
1.1 Alpha Beta
公开测试版本 (Beta Releases) ，会引入新的功能和改进，相对于内部测试版本已有了很大的改进，消除了严重的错误，但还是存在着一些 bug，提供给尝鲜用户，可以用于测试最新的功能。 示例：
1.1 Beta RC
候选发布版本 (Release Candidate Releases, RC) ，会引入新的功能和改进。RC 版本可用于早期测试，较公开测试版本的稳定性有较大改善，其稳定性足以开始测试，但不适合用于生产部署。 示例：
RC1
2.0-RC1 GA
正式发布版本 (General Availability Releases, GA) ，是当前系列版本的稳定版本，在候选发布版本 (Release Candidate Releases, RC) 之后发布，能够用于生产部署。 示例：
1.0 GA 纯数字版本号
无代号的纯数字版本号，通常理解为正式版本，同GA 示例：
1.0.0
2.0 DMR
开发里程碑版本 (Development Milestone Releases, DMR) ，通常理解为开发版，新功能尝鲜版本 示例：
TiDB 6.3.0-DMR LTS
长期支持版本 (Long-Term Support Releases, LTS) ，通常理解为稳定版，可长期使用，不会有大功能变更，只修复bug和漏洞。大多数商业软件都提供长期支持版本，如Windows、Ubuntu、Node Js等 示例：
Node 18.12.0 LTS
Ubuntu 22.04.1 LTS`}]},{path:"/content/php/laravel/laravel10%E7%9B%B8%E5%85%B3.html",title:"laravel10相关",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel10相关:
1.node升级(最好打开vpn,不然下载失败):
# installs nvm (Node Version Manager)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash # download and install Node.js (you may need to restart the terminal)
nvm install 20 # verifies the right Node.js version is in the environment
node -v # should print \`v20.15.0\` # verifies the right NPM version is in the environment
npm -v # should print \`10.7.0\` 官方链接：https://nodejs.org/zh-cn/download/package-manager 可以通过:$ nvm ls-remote 查看当前支持的node版本
不要使用网上其它方法，比如使用 n 升级，都是垃圾 2.composer install 报: phpoffice/phpspreadsheet 1.29.0 requires ext-dom * -> it is missing from your system. Install or enable PHP's dom extension
requires ext-curl * -> it is missing from your system. Install or enable PHP's curl extension. $ sudo apt-get install php8.3-curl 执行迁移文件的时候报:
$ php artisan migrate Illuminate\\Database\\QueryException could not find driver (Connection: mysql, SQL: select table_name as \`name\`, (data_length + index_length) as \`size\`, table_comment as \`comment\`, engine as \`engine\`, table_collation as \`collation\` from information_schema.tables where table_schema = 'mmailer' and table_type in ('BASE TABLE', 'SYSTEM VERSIONED') order by table_name) 原因:缺少mysql依赖驱动
$ sudo apt-get install php8.3-mysql 3.ubuntu22下有很多service,可以通过下面的命令找到指定的服务，比如php相关的
$ systemctl status php* 发现没有php8.3-fpm.servie, 但是执行php -v 却展示了，原因是我只安装了php8.3的cli，没有安装fpm
PHP 8.3.8 (cli) (built: Jun 8 2024 21:34:22) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.8, Copyright (c) Zend Technologies with Zend OPcache v8.3.8, Copyright (c), by Zend Technologies 手动改安装: sudo apt install php8.3-fpm 4.访问站点报 502, 查看error.log 如下:
2024/06/28 11:04:34 [crit] 55294#55294: *1 connect() to unix:/run/php/php8.3-fpm.sock failed (13: Permission denied) while connecting to upstream, client: 127.0.0.1, server: www.mmail.test, request: "GET / HTTP/1.1", upstream: "fastcgi://unix:/run/php/php8.3-fpm.sock:", host: "www.mmail.test" 可以确定这是一个对 /run/php/php8.3-fpm.sock 访问权限的问题
1>cd /etc/php/8.3/fpm/pool.d
vim www.conf, 将里面的 user = www-data
group = www-data
改为(因为我的nginx 的 user 是 yizhi):
user = yizhi
group = yizhi
再访问，还是报错，那还需要修改 sock文件的 user:group信息 2>
$ cd /run/php
$ ll
total 16
drwxr-xr-x 2 www-data www-data 220 6月 28 11:12 ./
drwxr-xr-x 41 root root 1120 6月 28 11:03 ../
-rw-r--r-- 1 root root 3 6月 28 08:37 php7.4-fpm.pid
srw-rw---- 1 yizhi yizhi 0 6月 28 08:37 php7.4-fpm.sock=
-rw-r--r-- 1 root root 3 6月 28 08:37 php8.1-fpm.pid
srw-rw---- 1 yizhi yizhi 0 6月 28 08:37 php8.1-fpm.sock=
-rw-r--r-- 1 root root 3 6月 28 08:37 php8.2-fpm.pid
srw-rw---- 1 www-data www-data 0 6月 28 08:37 php8.2-fpm.sock=
-rw-r--r-- 1 root root 5 6月 28 11:12 php8.3-fpm.pid
srw-rw---- 1 www-data www-data 0 6月 28 11:12 php8.3-fpm.sock=
lrwxrwxrwx 1 root root 30 6月 28 08:37 php-fpm.sock -> /etc/alternatives/php-fpm.sock= 发现 php8.2-fpm.sock 的 user:group 都为www-data,修改为yizhi
sudo chown yizhi:yizhi php8.3-fpm.sock 3>重启php8.3-fpm(也可以不用重启)
$ sudo systemctl restart php8.3-fpm 4>再次访问，没有报错 相关命令:
sudo chown 新用户名:新用户组名 文件名
sudo chown -R 新用户名:新用户组名 目录名 5.查看 Laravel 项目的版本:
php artisan --version 6.迁移数据库之后，初始化一个用户的另一种方式(通过 factory，而不是直接run创建,但是还是run方式要好一些)
//factories/UserFactory
class UserFactory extends Factory
{ protected $model = User::class; public function definition() { return [ 'id' => 1, 'name' => $this->faker->name,
// 'email' => $this->faker->unique()->safeEmail, 'email' => "shipeng.guo23@yizhi.com", 'email_verified_at' => now(), 'password' => bcrypt('Wuhan2019'), // password 'remember_token' => Str::random(10), 'role' => 'Publisher' ]; }
} //seeds下
class DatabaseSeeder extends Seeder
{ /** * Seed the application's database. * * @return void */ public function run() { \\App\\User::factory()->create(); }
} 执行:$ php artisan db:seed 即可新增一个用户`}]},{path:"/content/php/laravel/laravel11%E4%B8%AD%E4%BD%BF%E7%94%A8vite%E8%BF%9B%E8%A1%8C%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86.html",title:"laravel11中使用vite进行资源管理",pathLocale:"/",contents:[{header:"",slug:"",content:"laravel11中使用vite进行资源管理:\n@vite('resources/css/welcome.css')\n对于不同的打包方式， npm run dev 和 npm run build, 那么资源访问是不一样的: 1. 开发环境 (`npm run dev`): 当你运行`npm run dev`时，Vite启动一个开发服务器。这个服务器会: - 监听你的源文件变化 - 提供热模块替换(HMR) - 按需编译文件 在这种模式下，`@vite()`指令会: - 注入Vite的客户端脚本 - 创建一个`<script>`标签，指向Vite开发服务器上的入口文件 - 创建一个`<link>`标签，指向CSS文件(如果是独立的CSS文件) 这样，浏览器可以从Vite开发服务器请求并加载资源，实现快速的开发体验。 2. 生产环境 (`npm run build`): 当你运行`npm run build`时，Vite会: - 编译、压缩、优化所有资源 - 生成带有哈希的文件名，用于缓存破坏 - 创建一个manifest.json文件，映射原始文件名到编译后的文件名 在这种模式下，`@vite()`指令会: - 读取manifest.json文件 - 根据manifest中的映射，输出正确的`<script>`和`<link>`标签，指向编译后的文件 这种方法允许Laravel在开发和生产环境中都能正确地引用和加载资源，而不需要更改你的代码。\n值得注意的是，Laravel的`vite.php`配置文件和`Vite`facade处理了大部分复杂性，使得开发者可以轻松地在Laravel项目中集成和使用Vite。"}]},{path:"/content/php/laravel/laravel11%E4%BD%BF%E7%94%A8jquery.html",title:"laravel11使用jquery",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel11使用jquery:
1>首先 npm install jquery, 会安装最新版本v3.7 2>在bootstrap.js下配置jquery
import $ from 'jquery'; window.$ = window.jQuery = $; 3>在user.blade.php页面使用(这里继承自layout/app.balde.php)
@section('script')
<script> $(function (){ $('.user-log').click(function (){ console.log("11111") }) })
<\/script>
@endsection 4>运行 npm run dev 5>访问user页面， 报:ReferenceError: $ is not defined, Jquery Import with vite 6> 原因分析
刚开始我还以为这是因为 引入了vue的缘故，后来我把vue相关的部分全部注释了，发现还是报这个问题
①发现使用document.addEventListener 可以解决这个问题，但是写法太丑了，这个其实是等整个页面加载完再使用 jquery
document.addEventListener('DOMContentLoaded', function() { $('.user-log').click(function (){ console.log("11111") })
}); ②直接通过引入 <script src="https://code.jquery.com/jquery-3.7.1.min.js"><\/script> ， 也可以解决问题，但是这样很不友好 ③最终发现在 script 标签里添加 type="module" 问题解决，可以正常使用 $ 了
<script type="module"> $(function (){ $('.user-log').click(function (){ console.log("11111") }) })
<\/script> 根本原因是：
Vite is loading scripts as modules. And module scripts are always deferred. So if your jQuery script is placed after Vite directive, jQuery code is executed first, before loading jQuery to window - this triggers $ is undefined error. In best practise, you should move the jQuery code to app.js file, so it stays in it's own module. The other way to handle this is to mark your script tag as a module, then it'll follow the loading order of the document. 关于module scripts are always deferred: https://javascript.info/modules-intro#module-scripts-are-deferred // 以前不知道这个知识点，介绍的很详细，很有用 参考：https://stackoverflow.com/questions/73010251/referenceerror-is-not-defined-jquery-import-with-vite // 真的很有用的帖子 7>总结
laravel11使用vite编译js资源和之前的webpack还是有很大的区别的，但是使用vite更简洁，现在已经解决了使用 laravel11 + vite5 + vue3 + tailwindcss3 + jquery3 混合开发的所有问题`}]},{path:"/content/php/laravel/laravel11%E4%BD%BF%E7%94%A8vue3%E4%BD%9C%E4%B8%BA%E7%BB%84%E4%BB%B6%E5%88%9B%E5%BB%BA%E9%9D%9E%E5%8D%95%E9%A1%B5%E9%9D%A2%E5%BA%94%E7%94%A8.html",title:"laravel11使用vue3作为组件创建非单页面应用",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel11使用vue3作为组件创建非单页面应用:
// laravel11默认使用vite打包，相关配置在vite.config.js下 import { defineConfig } from 'vite';
import laravel from 'laravel-vite-plugin';
import vue from '@vitejs/plugin-vue' export default defineConfig({ plugins: [ laravel({ input: ['resources/css/app.css', 'resources/css/welcome.css' , 'resources/js/app.js'], // 除了app.css 也可以配置多个css入口文件(比如这里的welcome.css)，以前都是习惯在一个app.css,其实可以多个相当于对css分组打包了 refresh: true, }), vue({ template: { transformAssetUrls: { // Vue 插件会重写 Single File Components 中引用的资产 URL， // 指向 Laravel web 服务器。设置此值为 \`null\` 允许 Laravel 插件 // 重新指向 Vite 服务器。 base: null, // Vue 插件会解析绝对 URL 并将它们视为磁盘上文件的绝对路径。 // 设置此值为 \`false\` 将不处理绝对 URL，所以它们可以如预期 // 那样引用公共目录中的资产。 includeAbsolute: false } } }), ],
}); 默认是没有 vue 相关的配置的，但是可以通过 @vitejs/plugin-vue 插件添加，但是发现 vue 组件不生效, 下面是我的 app.js
import './bootstrap'; // 非单页面应用
import { createApp } from 'vue'; import ExampleComponent from './components/ExampleComponent.vue' const app = createApp({})
app.component('example-component', ExampleComponent) app.mount('#app') console.log('Vue app mounted') 没有任何问题，最后发现控制台有个警告:
Component provided template option but runtime compilation is not supported in this build of Vue. Configure your bundler to alias "vue" to "vue/dist/vue.esm-bundler.js". 开始没有注意，以为只是一个警告，但是后台添加到 vite.config.js下，问题解决了:
import { defineConfig } from 'vite';
import laravel from 'laravel-vite-plugin';
import vue from '@vitejs/plugin-vue' export default defineConfig({ plugins: [ laravel({ input: ['resources/css/app.css', 'resources/css/welcome.css' , 'resources/js/app.js'], // 除了app.css 也可以配置多个css入口文件(比如这里的welcome.css)，以前都是习惯在一个app.css,其实可以多个相当于对css分组打包了 refresh: true, }), vue({ template: { transformAssetUrls: { // Vue 插件会重写 Single File Components 中引用的资产 URL， // 指向 Laravel web 服务器。设置此值为 \`null\` 允许 Laravel 插件 // 重新指向 Vite 服务器。 base: null, // Vue 插件会解析绝对 URL 并将它们视为磁盘上文件的绝对路径。 // 设置此值为 \`false\` 将不处理绝对 URL，所以它们可以如预期 // 那样引用公共目录中的资产。 includeAbsolute: false } } }), ], resolve: { alias: { 'vue': 'vue/dist/vue.esm-bundler.js', }, },
}); 这行配置确保 Vite 使用了包含模板编译器的 Vue 版本，这对于在运行时编译模板是必要的.`}]},{path:"/content/php/laravel/laravel11%E7%9B%B8%E5%85%B3.html",title:"laravel11相关",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel11相关:
由于laravel11的版本更新和之前都不太一样，变化比较多,所以花时间创建一个对应版本 $ composer create-project laravel/laravel laravel11-project 报：
laravel/framework[v11.9.0, ..., v11.9.2] require fruitcake/php-cors ^1.3 -> found fruitcake/php-cors[dev-feat-setOptions, dev-master, dev-main, dev-test-8.2, v0.1.0, v0.1.1, v0.1.2, v1.0-alpha1, ..., 1.2.x-dev (alias of dev-master)] but it does not match the constraint 原因:
composer 源没有即使更新，替换为原来的源就可以了. composer create-project: 这是Composer的命令，用于从一个已存在的包创建新项目。
laravel/laravel: 这是Laravel框架的包名。
laravel11-project: 这是您要创建的新项目的目录名称。您可以根据需要更改这个名称。 执行这个命令后，Composer会下载最新版本的Laravel，并在指定的目录中设置一个新的Laravel项目。 其它作者的laravel11翻译的文档: https://laravel-docs.catchadmin.com/docs/11/prologue/release`}]},{path:"/content/php/laravel/laravel12%E4%B8%8B%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8E%9F%E7%90%86%E5%9B%9E%E9%A1%BE.html",title:"laravel12下基于redis的消息队列原理回顾",pathLocale:"/",contents:[{header:"laravel12下基于redis的消息队列原理回顾",slug:"laravel12下基于redis的消息队列原理回顾",content:""},{header:"1. 命令参数含义",slug:"_1-命令参数含义",content:`queue:work 👉 启动一个 队列 Worker 进程
redis 👉 不是 queue 名称，而是 队列连接（connection）名称 Laravel 的队列配置在 config/queue.php，里面有 connections：
'connections' => [ 'sync' => [...], 'database' => [...], 'redis' => [ // ← 这里就是 connection 名字 'driver' => 'redis', 'connection' => 'default', 'queue' => env('REDIS_QUEUE', 'default'), // 默认队列名叫 "default" 'retry_after' => 90, 'block_for' => null, ],
], 所以你运行：
php artisan queue:work redis 表示：用 redis 这个 connection 去取任务。
如果你要指定队列名字（queue name），要额外传：
php artisan queue:work redis --queue=emails 这样就会消费 emails 队列，而不是默认的 default。`},{header:"2. Worker 的运行原理",slug:"_2-worker-的运行原理",content:`queue:work 会启动一个常驻 PHP 进程，内部大致流程是： 进入循环 → 不断向 Redis 里 BLPOP（阻塞式 pop） 队列 默认队列 key 格式：queues:default
如果指定 --queue=emails → key 就是 queues:emails 拿到队列消息（就是被 dispatch() 序列化过的 Job 数据）
反序列化 Job → 调用 Job 的 handle() 方法
如果失败 → 重新入队（延迟），或者进入 failed_jobs 表
本质上就是一个常驻消费者进程，用 Redis 列表实现消息队列。`},{header:"3. Redis 中的存储形式",slug:"_3-redis-中的存储形式",content:`当你派发 Job：
SendEmailJob::dispatch('test@example.com'); Redis 里会多一条数据：
LPUSH queues:default "序列化后的 Job" Worker 消费时就是：
BRPOP queues:default 然后执行 Job。
✅ 总结： php artisan queue:work redis 里的 redis = connection 名，不是 queue 名。
真正的 队列名（queue name） 默认是 default，可以用 --queue= 参数指定。如： php artisan queue:work redis --queue=emails
Worker 内部就是不断 BRPOP Redis 列表，取出 Job，执行 handle()。`},{header:"config/queue.php下关于 after_commit配置的使用，这个特性很有必要，貌似从larael9.x 就有了，实际上有时候确实需要数据库操作完成，才回去触发异步任务，这样的需求很多",slug:"config-queue-php下关于-after-commit配置的使用-这个特性很有必要-貌似从larael9-x-就有了-实际上有时候确实需要数据库操作完成-才回去触发异步任务-这样的需求很多",content:"在 Laravel 12 的 queue.php 配置中，after_commit 是一个比较新的选项，用来控制 Job 是否在数据库事务提交后再入队。"},{header:"1. 默认配置示例",slug:"_1-默认配置示例",content:`'connections' => [ 'database' => [ 'driver' => 'database', 'table' => 'jobs', 'queue' => 'default', 'retry_after' => 90, 'after_commit' => false, ], 'redis' => [ 'driver' => 'redis', 'connection' => 'default', 'queue' => env('REDIS_QUEUE', 'default'), 'retry_after' => 90, 'block_for' => null, 'after_commit' => false, ],
],`},{header:"2. after_commit 的作用",slug:"_2-after-commit-的作用",content:`after_commit = false（默认） Job 会立即入队，即使当前数据库事务尚未提交
如果事务回滚，Job 依然会被消费 → 可能导致业务逻辑异常 after_commit = true Job 会 等到数据库事务提交成功后 再入队
保证 Job 消费时，相关数据库操作已经生效
常用于依赖数据库状态的异步任务，例如发送邮件、延迟计算统计等`},{header:"3. 使用示例",slug:"_3-使用示例",content:`use App\\Jobs\\MyJob;
use Illuminate\\Support\\Facades\\DB; DB::transaction(function () use ($user) { $user->update(['status' => 'active']); // Job 只有在事务提交成功后才会入队 MyJob::dispatch($user)->afterCommit();
}); afterCommit() 方法可以在 dispatch 时单独控制
配置文件 after_commit 选项是全局默认值`},{header:"4. 总结",slug:"_4-总结",content:`配置 / 方法
行为 after_commit = false
Job 立即入队，不依赖事务提交 after_commit = true
Job 只有在事务提交成功后入队 ->afterCommit() 方法
单次 dispatch 时覆盖全局配置 ✅ 小结： 如果 Job 依赖数据库状态，推荐开启 after_commit 或使用 ->afterCommit()
如果 Job 与事务无关，可以保持默认 false`},{header:"使用延迟队列",slug:"使用延迟队列",content:"在 Laravel 12 下，如果你想让某个 Job 延迟执行，可以用 delay() 方法 或 onQueue + delay 的组合。这里详细讲一下："},{header:"1. 在 Dispatch 时指定延迟",slug:"_1-在-dispatch-时指定延迟",content:`use App\\Jobs\\MyJob;
use Illuminate\\Support\\Facades\\Bus; // 延迟 10 秒执行
MyJob::dispatch($param1, $param2)->delay(now()->addSeconds(10)); now() → 当前时间
addSeconds(10) → 延迟 10 秒
也可以用 addMinutes(), addHours() 等`},{header:"例子：",slug:"例子",content:`MyJob::dispatch($user)->delay(now()->addMinutes(5)); Job 会被推到队列，但 不会立即被 worker 执行
Worker 取到任务时会检查 available_at 时间，未到时会跳过`},{header:"2. 在 Job 类里使用 ShouldQueue",slug:"_2-在-job-类里使用-shouldqueue",content:`确保你的 Job 类实现了 ShouldQueue：
use Illuminate\\Bus\\Queueable;
use Illuminate\\Contracts\\Queue\\ShouldQueue;
use Illuminate\\Foundation\\Bus\\Dispatchable; class MyJob implements ShouldQueue
{ use Dispatchable, Queueable; public function handle() { // 任务逻辑 }
} Queueable trait 提供了 delay() 方法的支持
ShouldQueue 告诉 Laravel 这是一个异步任务`},{header:"3. 结合队列名",slug:"_3-结合队列名",content:`如果你有多个队列，也可以指定队列：
MyJob::dispatch($user) ->onQueue('emails') ->delay(now()->addMinutes(5)); Job 会被推到 emails 队列
Worker 可以专门监听 emails 队列`},{header:"4. 延迟实现原理（Redis 队列）",slug:"_4-延迟实现原理-redis-队列",content:`Laravel 会把 Job 推到 Redis 的 delayed 队列
Worker 会周期性检查任务的 available_at 时间
只有到达时间的 Job 才会从 delayed 队列移动到正常队列，等待消费 所以延迟执行是通过 Redis 队列 + 时间戳 控制的，不依赖 PHP sleep 或阻塞`},{header:"5.关于 延迟原理的详细分析",slug:"_5-关于-延迟原理的详细分析",content:`在 Laravel 队列 + Redis 的场景下，Worker 确实同时扮演了 两个角色： 消费者（Consumer） 从主队列（ready queue）取任务执行
核心行为： 监听队列（BLPOP 或轮询）
拿到任务 → 调用 Job 的 handle() 执行 类似“真正的工人”，负责处理业务逻辑 延迟任务搬运者（Delayed Job Scheduler） 周期性检查 Redis delayed 队列
核心行为： 取出到达 available_at 时间的 Job
把它移动到主队列（ready queue） 类似“调度员”，保证延迟任务在到期时进入可执行队列 图示理解（逻辑流程） Delayed Queue (Redis zset) | | Worker 检查 available_at v
Ready Queue (Redis list) | | Worker 消费任务 v
Job handle() 执行 表格解析: 概念
说明 Worker
运行 php artisan queue:work 的 CLI 进程 Delayed 队列
Redis 的 zset，score = available_at 周期检查
Worker 循环中调用 migrateExpiredJobs() 检查到期任务 Ready 队列
Job 到时间后被移入这个队列，等待执行 Worker 是 单个常驻进程，同时做 调度 和 消费
所以即使延迟任务很多，也不需要额外的 Cron，Worker 自己就能处理 ✅ 总结 Worker = 消费者 + 延迟任务搬运者
延迟任务逻辑是 Worker 内部循环的一部分
你可以通过启动多个 Worker 或指定队列，灵活管理消费策略 ✅ 总结： Job 类要 implements ShouldQueue
Dispatch 时调用 ->delay(now()->addMinutes(...))
可选 onQueue() 指定队列
Worker 会自动处理延迟逻辑 参考文档: https://laravel.com/docs/12.x/queues#delayed-dispatching`},{header:"关于 多个不同的queue name 的使用以及消费",slug:"关于-多个不同的queue-name-的使用以及消费",content:""},{header:"1. 多队列共享一个 Redis 连接",slug:"_1-多队列共享一个-redis-连接",content:`connection 决定的是 Redis 实例/数据库 queue name 决定的是 逻辑队列分组 所以你可以在同一个 Redis 里，有多个逻辑队列： default
emails
notifications`},{header:"2. Worker 消费方式",slug:"_2-worker-消费方式",content:""},{header:"(a) 消费所有队列",slug:"a-消费所有队列",content:`php artisan queue:work redis 不指定 --queue → 默认会消费 default 队列
如果想消费多个队列，可以： php artisan queue:work redis --queue=default,emails,notifications Worker 会按顺序轮询这些队列的任务`},{header:"(b) 为特定队列指定 Supervisor",slug:"b-为特定队列指定-supervisor",content:`假设你只想消费 emails 队列： php artisan queue:work redis --queue=emails 然后配置 Supervisor 管理这个 worker： [program:laravel-emails]
command=php /var/www/html/artisan queue:work redis --queue=emails --sleep=3 --tries=3
process_name=%(program_name)s_%(process_num)02d
numprocs=1
autostart=true
autorestart=true 这样就专门为 emails 队列单独管理 worker，避免其他队列任务影响它的消费速度`},{header:"3. 总结",slug:"_3-总结",content:`概念
作用 connection
Redis 实例/队列驱动，底层存储 queue name
逻辑队列分组，用于区分不同任务类型 Worker 不指定队列
默认消费默认队列，也可通过 --queue=a,b,c 轮询多个队列 Worker 指定队列
可以专门消费某个队列，用 Supervisor 单独管理性能/资源 简单理解： connection = Redis 后台仓库
queue name = Redis 仓库里的不同抽屉
Worker = 打开抽屉取任务的人 这样你就可以灵活地按业务拆分队列、单独管理资源。`},{header:"关于redis的BLPOP",slug:"关于redis的blpop",content:`BLPOP 的名字就是 Blocking Left POP： L = Left 👉 从列表（list）的左边（头部）取数据
POP 👉 取出并删除该元素`},{header:"举例：",slug:"举例",content:`LPUSH myqueue "task1"
LPUSH myqueue "task2" 现在队列内容是（左边是头部）：
["task2", "task1"] 执行：
BLPOP myqueue 0 返回：
1) "myqueue"
2) "task2" 队列变为：
["task1"] 再执行一次：
1) "myqueue"
2) "task1" 队列变空。`},{header:"对比命令：",slug:"对比命令",content:`BLPOP → 从左边取
BRPOP → 从右边取`},{header:"queue:work 会启动一个常驻 PHP 进程 这个和php-fpm有关吗",slug:"queue-work-会启动一个常驻-php-进程-这个和php-fpm有关吗",content:""},{header:"1. php artisan queue:work",slug:"_1-php-artisan-queue-work",content:`启动的是一个 常驻的 PHP CLI 进程。
它直接跑在命令行（php 二进制）里，不依赖 Nginx/Apache。
原理是一个死循环：不断用 BLPOP 从 Redis 拉任务，然后执行 Job 的 handle()。
你可以用 ps -ef | grep queue:work 看到它就是一个普通的 php 进程。`},{header:"2. php-fpm",slug:"_2-php-fpm",content:`php-fpm（FastCGI Process Manager）是 Web 请求的 PHP 进程池，通常由 Nginx/Apache 调用。
用来处理 HTTP 请求（比如你访问一个 Laravel 页面，Nginx 转发给 php-fpm）。
php-fpm 的进程是短生命周期的：一个请求 → 执行 → 返回 → 等待下一个请求。`},{header:"3. 两者的区别",slug:"_3-两者的区别",content:`特性
queue:work
php-fpm 启动方式
命令行 php artisan queue:work
系统服务（php-fpm） 生命周期
常驻进程（死循环）
短请求生命周期 触发来源
Redis 队列任务
Nginx/Apache 发来的 HTTP 请求 场景
异步任务消费（发邮件、导出、通知等）
Web 页面请求处理`},{header:"4. 有没有关系？",slug:"_4-有没有关系",content:`运行环境：它们都用同一个 PHP 解释器（php 二进制 + PHP 扩展）。
进程独立：queue:work 跟 php-fpm 没有直接关系，它们互不干扰。
间接联系：Web 请求（php-fpm 执行）里 dispatch() 了一个 Job → Job 被推到 Redis → queue:work 消费并执行。 所以可以理解为： php-fpm 负责请求入口
queue:work 负责后台异步任务
它们是配套而不是相互依赖的。 ✅ 总结：
queue:work 启动的常驻 PHP 进程 和 php-fpm 没关系，它就是一个独立的 PHP CLI worker。
唯一的联系是：Web 请求（php-fpm）可能会产生任务，交给 queue:work 去处理。`},{header:"php cli 和 php fpm 在当前php docker环境下的对比",slug:"php-cli-和-php-fpm-在当前php-docker环境下的对比",content:"本质上这两个都是 php 的 SAPI(Server API)"},{header:"$ php -v / -i",slug:"php-v-i",content:`PHP 8.3.0alpha1 (cli) (built: Jun 13 2023 11:11:54) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.0-dev, Copyright (c) Zend Technologies
完美 ✅
这个输出说明你的 PHP CLI 已经可用： (cli) → 告诉你这是 命令行接口（CLI）版本
(NTS) → 表示 非线程安全（Non Thread Safe）
版本信息和 Zend Engine 都正常显示 结合你之前的 php-fpm -v 输出： 组件
状态
作用 php-cli
已安装
命令行运行 Artisan 命令、队列 Worker、Cron 等 php-fpm
已安装
Web 请求处理（通过 Nginx/Apache）`},{header:"✅ 总结：",slug:"✅-总结",content:`你的系统环境 完全可以： 运行 php artisan queue:work（依赖 CLI）
处理 HTTP 请求（依赖 php-fpm） 两者是独立的，互不影响，但可以配合使用：Web 请求产生任务 → CLI Worker 异步执行`},{header:"$ php-fpm -v / -i",slug:"php-fpm-v-i",content:`PHP 8.3.0alpha1 (fpm-fcgi) (built: Jun 13 2023 11:11:57)
Copyright (c) The PHP Group
Zend Engine v4.3.0-dev, Copyright (c) Zend Technologies
完美 ✅
你的输出说明了几件事： PHP-FPM 已安装 (fpm-fcgi) 明确标识这是 FastCGI Process Manager 版本
可以被 Nginx/Apache 用来处理 Web 请求 PHP 版本 你安装的是 PHP 8.3.0 alpha1，属于开发版/测试版
注意生产环境最好用稳定版本 Zend Engine 版本 用于解释执行 PHP 代码的核心引擎信息 所以结论： php-fpm 可用 → 可以处理 Web 请求
php-cli 依然独立，你的 php -v 输出 CLI 信息的话，也能跑命令行脚本和 queue:work 简单理解： php-fpm → Web 请求入口
php-cli → 命令行脚本、队列 Worker、Cron`},{header:"查看不同Server API 加载的模块",slug:"查看不同server-api-加载的模块",content:`$ php -m
$ php-fpm -m
这两个命令输出的内容是一样的，为什么呢，按道理讲这是两个不同的SAPI环境，为什么会一样呢?`},{header:"1. Docker 镜像里的 PHP 结构",slug:"_1-docker-镜像里的-php-结构",content:`大多数官方 PHP 镜像（如 php:8.3-fpm 或 php:8.3-cli）本身包含 相同的核心和扩展目录
Docker 安装扩展（docker-php-ext-install 或 pecl install）会把扩展统一安装到 PHP 的 extension_dir 下
无论你是 CLI 还是 FPM，都共享同一套扩展路径`},{header:"2. SAPI 独立，但扩展共享",slug:"_2-sapi-独立-但扩展共享",content:`SAPI：CLI 和 FPM 是不同的接口，行为不同
扩展：安装在同一目录 → 都能被加载
所以即便 FPM 和 CLI 各自有自己的 php.ini，只要都启用相同扩展，就会看到几乎一样的 php -m / php-fpm -m`},{header:"3. 实际效果",slug:"_3-实际效果",content:`CLI → 可以跑 artisan queue:work、Cron、命令行脚本
FPM → 处理 Web 请求
都能用 Redis、PDO、curl 等扩展
开发时不必担心扩展缺失 ✅ 总结： Docker 安装的 PHP 扩展默认对 CLI 和 FPM 都可用
CLI / FPM 的行为和配置仍然独立，只是扩展共享
所以看到 php -m 和 php-fpm -m 输出一致是正常现象`}]},{path:"/content/php/laravel/laravel_IDE_%E8%BE%85%E5%8A%A9%E6%96%87%E4%BB%B6.html",title:"laravel_IDE_辅助文件",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel_IDE_辅助文件:
Laravel 还提供了一个名为 "IDE Helper" 的第三方包，可以极大地改善 IDE 支持： 安装：composer require --dev barryvdh/laravel-ide-helper
使用：运行 php artisan ide-helper:generate 生成辅助文件
git: 在gitignore下忽略 /_ide_helper.php 这个包会为所有 Facade 生成虚拟的 PHP 类定义，包含所有可用的方法，从而提供完整的代码提示`}]},{path:"/content/php/laravel/laravel%E4%B9%8Bexcel%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA.html",title:"laravel之excel批量导入导出",pathLocale:"/",contents:[{header:"",slug:"",content:`在开发过程中经常会用到 excel导入导出数据，以下是几个场景以及对应的解决方案，操作之前先安装依赖: composer require maatwebsite/excel (最好3.1+版本)：
1.excel批量导入
在控制器里添加如下方法: public function import(Request $request, ProductImport $productImport) { try { $productImport->import($request->file('excel')); //Excel::import(new ProductImport(), $request->file('excel')); //也可以这样使用 } catch (\\Throwable $throwable) { return $this->_error($throwable->getMessage()); } return $this->_success("导入成功"); } 在 namespace App\\Imports; 下定义 ProductImport:
<?php namespace App\\Imports; use Illuminate\\Support\\Collection;
use Illuminate\\Support\\Facades\\DB;
use Illuminate\\Support\\Facades\\Log;
use Maatwebsite\\Excel\\Concerns\\ToCollection;
use Maatwebsite\\Excel\\Concerns\\WithChunkReading;
use Maatwebsite\\Excel\\Concerns\\Importable; class ProductImport implements ToCollection, WithChunkReading
{ use Importable; public function chunkSize(): int { //控制数据读取大小，防止一次导入太多数据 return 500; } public function collection(Collection $rows) { //如果需要去除表头 unset($rows[0]); foreach ($rows as $key => $row) { $this->_saveData($row->toArray()); } } private function _saveData($data) { try { DB::transaction(function () use ($data) { $product['name'] = $data[0] ?? ''; $product['cover_image'] = $data[1] ?? ''; $product['price'] = $data[2] ?? 0; $product['description'] = $data[3] ?? ''; $product['detail'] = $data[4] ?? ''; $exist = Product::query()->where(['name' => $data[0]])->first(); if (!$exist) { Product::query()->create($product); } }); } catch (\\Throwable $exception) { Log::info("create error is:" . $exception->getMessage()); } }
} 2.批量导出
①数据量不大的时候可以有下面几种方法 1.基于数组的导出
在控制器下添加如下方法
public function exports(Request $request) { $data = ProductService::index($request->all()); //可以传递 $request->input('page', 1) 分页参数 return (new ProductExport($data))->download(); } 在 namespace App\\Imports;下添加如下 ProductExport 类 use Illuminate\\Contracts\\Support\\Responsable;
use Maatwebsite\\Excel\\Concerns\\Exportable;
use Maatwebsite\\Excel\\Concerns\\FromArray;
use Maatwebsite\\Excel\\Concerns\\ShouldAutoSize;
use Maatwebsite\\Excel\\Concerns\\WithEvents;
use Maatwebsite\\Excel\\Concerns\\WithHeadings;
use Maatwebsite\\Excel\\Concerns\\WithMapping;
use Maatwebsite\\Excel\\Events\\AfterSheet; class ProductExport implements FromArray, Responsable, WithMapping, WithHeadings, ShouldAutoSize, WithEvents
{ use Exportable; protected $data; protected $fileName = '.xlsx'; public function __construct(array $data) { $this->data = $data; $title = '产品数据-' . date('Y-m-d'); $this->fileName = $title . '.xlsx'; return $this; } public function array(): array { return $this->data; } public function map($product): array { return [ $product['name'], $product['cover_image'], $product['price'], $product['description'], $product['detail'] ]; } public function headings(): array { return [ '名称', '产品图片', '产品价格', '产品描述', '产品详情' ]; } public function registerEvents(): array { return [ AfterSheet::class => function (AfterSheet $event) { $event->sheet->getColumnDimension('A')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('B')->setAutoSize(false)->setWidth(50); $event->sheet->getColumnDimension('C')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('D')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('E')->setAutoSize(false)->setWidth(10); } ]; }
} //当需要导出图片的时候可以按下面的方法操作
<?php
/** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/20 * Time: 15:25 */ namespace App\\Imports; use Illuminate\\Contracts\\Support\\Responsable;
use Maatwebsite\\Excel\\Concerns\\Exportable;
use Maatwebsite\\Excel\\Concerns\\FromArray;
use Maatwebsite\\Excel\\Concerns\\ShouldAutoSize;
use Maatwebsite\\Excel\\Concerns\\WithEvents;
use Maatwebsite\\Excel\\Concerns\\WithHeadings;
use Maatwebsite\\Excel\\Concerns\\WithMapping;
use Maatwebsite\\Excel\\Events\\AfterSheet;
use PhpOffice\\PhpSpreadsheet\\Worksheet\\Drawing; class ProductExport implements FromArray, Responsable, WithMapping, WithHeadings, ShouldAutoSize, WithEvents
{ use Exportable; protected $data; protected $fileName = '.xlsx'; public function __construct(array $data, $page = 1) { $this->data = $data; $title = '用户数据-' . '第' . $page . '页-' . date('Y-m-d');//这个是导出当前页的写法 $this->fileName = $title . '.xlsx'; return $this; } public function array(): array { return $this->data; } public function map($user): array { return [ $user->id, $user->name, $user->description, //$user->cover_image, //这个图片链接可以不用了 ，因为后面会通过 Drawing 将链接渲染为图片 ]; } public function headings(): array { return [ '产品ID', '产品名称', '产品详情', '产品图片', ]; } public function registerEvents(): array { return [ AfterSheet::class => function (AfterSheet $event) { $event->sheet->getColumnDimension('A')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('B')->setAutoSize(false)->setWidth(50); $event->sheet->getColumnDimension('C')->setAutoSize(false)->setWidth(30); $event->sheet->getColumnDimension('D')->setAutoSize(false)->setWidth(10); //导出图片部分，官网：https://docs.laravel-excel.com/3.1/exports/drawings.html 中通过实现 implements WithDrawings 里的方法实现也可以，但是具体到逻辑，不用 implements WithDrawings，直接使用Drawing类实例化对象即可，我认为下面的写法更合理一些 $data = $this->array(); foreach ($data as $key => $val) { $temp = $val->toArray(); $event->sheet->getRowDimension($key + 2)->setRowHeight(30); //直接用var_dump($temp['id'])，没有任何效果，但是通过Log打印日志，就可以取到值，说明是有值的 //Log::info("id is:".$temp['id']); //Log::info("cover_image is:".$temp['cover_image']); if ($temp['cover_image']) { $base_name = pathinfo($temp['cover_image'])['basename']; if (!file_exists('/img/' . $base_name)) {//防止重复存储图片 $get_file = @file_get_contents($temp['cover_image']);//需要通过 file_get_contents 而不是 file_put_contents if ($get_file) { $fp = @fopen(storage_path('/img/' . $base_name), "w"); @fwrite($fp, $get_file); @fclose($fp); } } $drawing = new Drawing(); // 给每个图片链接一个 Drawing 对象处理 $drawing->setResizeProportional(true);// 这个还没搞懂怎么使用，感觉是要重置属性 //在导出图片的时候不能设置width，一设置就会有展示问题，比如这里设置为10，实际上展示的根本就不是10，而是很大的一个值 //$drawing->setWidth(10); $drawing->setPath(storage_path('/img/' . $base_name)); // 这个必须为本地图片，需要先将外网图片下载存储到本地，我这里存储到storage/img下，将来这个文件夹肯定会很大，尽管我做了不重复存储的判断 $drawing->setHeight(30);// 这里要设置 一个宽度，不然显示也会有问题，但是 尽管这里设置了30 $drawing->setCoordinates('D' . ($key + 2));// 这个主要用来设置 图片展示在哪行哪列 $drawing->setWorksheet($event->sheet->getDelegate());// 当前 $drawing 作用在哪里 } } } ]; }
} 2.普通查询导出
在控制器下添加如下方法:
public function export() { return (new ProductExport())->download(); }
在 namespace App\\Imports; 下添加如下代码:
<?php
/** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/30 * Time: 10:09 */ namespace App\\Imports; use App\\Models\\Product\\Product;
use Illuminate\\Contracts\\Queue\\ShouldQueue;
use Maatwebsite\\Excel\\Concerns\\Exportable;
use Maatwebsite\\Excel\\Concerns\\FromQuery;
use Maatwebsite\\Excel\\Concerns\\WithCustomQuerySize;
use Maatwebsite\\Excel\\Concerns\\WithMapping; /** * * Class ProductExport * @package App\\Imports */
class ProductExport implements FromQuery, WithMapping
{ use Exportable; protected $where; protected $fileName = '产品数据测试.xlsx'; public function query() { return Product::query()->where('id', '<', 100); // 使用 where 查询，这里只用查询，不用get；这个where 条件可以在控制器里实例化 ProductExport 的时候通过自定义set/get方法传递，或者在构造方法里传递 } public function map($product): array { return [ $product->id, $product->name, $product->description, ]; }
} 3.分多个excel sheet的导出
在控制器下添加如下方法: public function export(Request $request) { $sheetData = []; Product::query()->chunkById(1000, function ($items) use (&$sheetData) { $data = []; $sheetName = '产品列表数据';//每一个sheet的名称，多个的话 excel 会自动在后面追加阿拉伯数字 $columnFormats = [];//根据需求添加 $temp = []; if ($items->isNotEmpty()) { $items->each(function ($item) use (&$temp) { $temp[] = ['id' => $item->id, 'name' => $item->name, 'cover_image' => $item->cover_image, 'price' => $item->price, 'description' => $item->description, 'created_at' => $item->created_at]; }); } //对列进行特殊处理，use PhpOffice\\PhpSpreadsheet\\Style\\NumberFormat; $columnFormats['D'] = NumberFormat::FORMAT_NUMBER_0; //格式化数字 $columnFormats['F'] = NumberFormat::FORMAT_DATE_YYYYMMDD2; //格式化时间 $data['sheet'] = $sheetName; $data['data'] = $temp; $data['columnFormats'] = $columnFormats; $sheetData[] = $data; }); // 标题 $headings = ['ID', '名称', '封面图', '价格', '描述', '创建时间']; $sheet = []; foreach ($sheetData as &$item) { $sheet[] = new ProductMultiSheet($item['data'], $headings, $item['sheet'], $item['columnFormats']); } return (new MultiTest())->download($sheet); } 在 namespace App\\Imports;下添加如下代码，由于是分多个sheet导出，需要两个类来操作，一个做导出操作，还有一个做单个excel表数据处理： <?php
/** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/30 * Time: 11:48 */ namespace App\\Imports; use Maatwebsite\\Excel\\Concerns\\FromArray;
use Maatwebsite\\Excel\\Concerns\\WithEvents;
use Maatwebsite\\Excel\\Concerns\\WithHeadings;
use Maatwebsite\\Excel\\Concerns\\WithTitle;
use Maatwebsite\\Excel\\Concerns\\WithColumnFormatting;
use Maatwebsite\\Excel\\Events\\AfterSheet; class ProductMultiSheet implements FromArray, WithTitle, WithHeadings, WithColumnFormatting, WithEvents
{ private $data; private $headings; private $title; private $columnFormats; /** * @param array $data 数据 * @param array $headings 头部 * @param string $title sheet名称 * @param array $columnFormats 格式化列 */ public function __construct(array $data, array $headings, string $title, array $columnFormats = []) { $this->data = $data; $this->headings = $headings; $this->title = $title; $this->columnFormats = $columnFormats; } /** * 数据 * @return array */ public function array() : array { return $this->data ? : []; } /** * 表头 * @return array */ public function headings() : array { return $this->headings ? : []; } /** * sheet名称 * @return string */ public function title() : string { return $this->title ? : ''; } /** * 列格式列 * @return array */ public function columnFormats() : array { return $this->columnFormats ? : []; } public function registerEvents(): array { return [ AfterSheet::class => function (AfterSheet $event) { $event->sheet->getColumnDimension('A')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('B')->setAutoSize(false)->setWidth(50); $event->sheet->getColumnDimension('C')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('D')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('E')->setAutoSize(false)->setWidth(10); $event->sheet->getColumnDimension('F')->setAutoSize(false)->setWidth(10); } ]; }
} <?php
/** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/30 * Time: 13:55 */ namespace App\\Imports; use Maatwebsite\\Excel\\Concerns\\WithMultipleSheets; class MultiTest implements WithMultipleSheets
{ private $sheets; /** * @param array $data * @param array $registerEvents * @param string $filename * @return \\Symfony\\Component\\HttpFoundation\\BinaryFileResponse */ public function download(array $sheets, string $filename = '产品数据.xlsx') { $this->sheets = $sheets; return \\Maatwebsite\\Excel\\Facades\\Excel::download($this, $filename); } /** * @return array */ public function sheets(): array { return $this->sheets ?: []; }
} 本来还想在多个sheet导出，通过异步队列实现，但是没有成功，这个以后再弄 ②数据量很大的时候需要用到异步队列(redis)操作
在控制器下添加如下方法：
public function export() { //注意，通过队列导出 需要先创建 store 里的 filePath 文件地址(完整地址) //注意，这个异步执行可能需要很久，所以 打开时间太快的话 产品数据测试2.xlsx 可能没有数据 //注意，这个 chain 里的job 必须要通过队列执行(implements ShouldQueue)，不能同步执行，我感觉是 store 走了队列，然后 job 也要走队列 (new ProductMultiExport())->store(storage_path('logs').'/产品数据测试2.xlsx')->chain([new SendEmail()]); return $this->_success("操作完成"); } 在 namespace App\\Imports; 下添加如下代码：
<?php
/** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/30 * Time: 10:09 */ namespace App\\Imports; use App\\Models\\Product\\Product;
use Illuminate\\Contracts\\Queue\\ShouldQueue;
use Maatwebsite\\Excel\\Concerns\\Exportable;
use Maatwebsite\\Excel\\Concerns\\FromQuery;
use Maatwebsite\\Excel\\Concerns\\WithCustomQuerySize;
use Maatwebsite\\Excel\\Concerns\\WithMapping; /** * 可以通过 implements ShouldQueue 实现通过队列导出 * * Class CompanyMultiExport * @package App\\Imports */
class ProductMultiExport implements FromQuery, WithMapping, WithCustomQuerySize, ShouldQueue
{ use Exportable; protected $where; protected $fileName = '产品数据测试.xlsx'; //注意：当使用队列异步导出的时候，好像只能用query()获取数据，array()一直获取不到数据 public function query() { return Product::query()->where('id', '<', 10000); // 使用 where 查询，这里只用查询，不用get } public function map($product): array { return [ $product->id, $product->name, $product->description, ]; } //必须要有这个，默认队列只会导出 1000 条数据，需要指定导出总数，不然数据不完整 public function querySize(): int { return Product::query()->where('id', '<', 10000)->count();//和query的条件要一样 }
} 在 namespace App\\Jobs; 下添加下面代码：
<?php /** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/30 * Time: 16:10 */ namespace App\\Jobs; use Illuminate\\Bus\\Queueable;
use Illuminate\\Contracts\\Queue\\ShouldQueue;
use Illuminate\\Queue\\SerializesModels;
use Illuminate\\Queue\\InteractsWithQueue;
use Illuminate\\Foundation\\Bus\\Dispatchable;
use Illuminate\\Support\\Facades\\Log; class SendEmail implements ShouldQueue
{ use Queueable, Dispatchable, InteractsWithQueue, SerializesModels; public function handle() { Log::info("下载完成，可以发邮件了通知下载了"); }
}`}]},{path:"/content/php/laravel/laravel%E4%B9%8BforPageAfterId%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"laravel之forPageAfterId的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`偶然看到这个函数，觉得在特殊场景下可能会有用:
laravel forPageAfterId 查询的用法，将上一次分页查询的结果的最后一条，作为下一次分页查询的开始
$res = Product::query()->forPageAfterId(10,1000)->get();
dd($res);`}]},{path:"/content/php/laravel/laravel%E4%B9%8BgetConnectionName%E9%94%99%E8%AF%AF.html",title:"laravel之getConnectionName错误",pathLocale:"/",contents:[{header:"",slug:"",content:`记录一个小问题，在模型关联查询的时候报了:
[2022-09-02 11:00:50] local.ERROR: Call to undefined method App\\Models\\Product\\UserProduct::getConnectionName() {"userId":1,"exception":"[object] (Error(code: 0): Call to undefined method App\\\\Models\\\\Product\\\\UserProduct::getConnectionName() at /home/vagrant/code/...)
[stacktrace] 原因是：UserProduct 忘了 继承 基础Model类`}]},{path:"/content/php/laravel/laravel%E4%B9%8Bhomestead%E4%B8%8Belasticsearch%E5%AE%89%E8%A3%85.html",title:"laravel之homestead下elasticsearch安装",pathLocale:"/",contents:[{header:"",slug:"",content:`homestead下配置elasticsearch
1.homestead.yaml文件修改，我这里使用 7.10.0，这是之前项目一直使用的版本，也是云服务器上的版本，注意后面安装ik分词器的时候也需要对应版本
features: - mysql: true - redis: true - memecached: true - mariadb: false - postgresql: true - ohmyzsh: false - webdriver: false - elasticsearch: version: 7.10.0 services: - enabled: - "mysql" - "postgresql" - "redis" - "memecached" - "elasticsearch"
# - disabled:
# - "postgresql@11-main" ports: - send: 33060 # MySQL/MariaDB to: 3306 - send: 54320 to: 5432 - send: 6379 to: 6379 - send: 11211 to: 11211 - send: 9200 to: 9200 2.重新启动vagrant加载配置
$ vagrant.exe reload --provision 3.安装ik分词器插件
#]cd /usr/share/elasticsearch/plugins
#]mkdir ik
#]chmod -R 777 ./ik
#]cd ik
#]wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.0/elasticsearch-analysis-ik-7.10.0.zip
#]unzip elasticsearch-analysis-ik-7.10.0.zip 4.重启es服务
#]service elasticsearch restart 5.本地测试
#] curl 127.0.0.1:9200
{ "name" : "homestead", "cluster_name" : "homestead", "cluster_uuid" : "aoCViOY0ScGvX9AXldGbRQ", "version" : { "number" : "7.10.0", "build_flavor" : "default", "build_type" : "deb", "build_hash" : "51e9d6f22758d0374a0f3f5c6e8f3a7997850f96", "build_date" : "2020-11-09T21:30:33.964949Z", "build_snapshot" : false, "lucene_version" : "8.7.0", "minimum_wire_compatibility_version" : "6.8.0", "minimum_index_compatibility_version" : "6.0.0-beta1" }, "tagline" : "You Know, for Search"
} 6.配置除本机以外的客户端访问
我记得自己搭建es会创建 elasticsearch:elasticsearch 用户名:用户组
所以 修改 /etc/elasticsearch/elasticsearch.yml 需要 elasticsearch 用户 或者 root 用户
我就直接使用 root用户：
vagrant@homestead:/etc$ sudo su root root@homestead:/etc/elasticsearch# vim elasticsearch.yml cluster.name: homestead
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
#node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /var/lib/elasticsearch
#
# Path to log files:
#
path.logs: /var/log/elasticsearch
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
#
network.host: 0.0.0.0
#
# Set a custom port for HTTP:
#
#http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
#discovery.seed_hosts: ["host1", "host2"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
cluster.initial_master_nodes: ["node-1"]
#
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Gateway -----------------------------------
#
# Block initial recovery after a full cluster restart until N nodes are started:
#
#gateway.recover_after_nodes: 3
#
# For more information, consult the gateway module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Require explicit names when deleting indices:
#
#action.destructive_requires_name: true 再次重启报错：
[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 原因是: 如果配置了network.host 0.0.0.0 ，就是允许除了本机以外的其它客户端访问，那么就需要配置一个主节点的名字才行，所以 在上面的 yml 文件里配置了： cluster.initial_master_nodes: ["node-1"]`}]},{path:"/content/php/laravel/laravel%E4%B9%8Bhomestead%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html",title:"larave之homestead配置文件",pathLocale:"/",contents:[{header:"",slug:"",content:`larave之homestead配置文件:
---
ip: "192.168.56.56"
memory: 2048
cpus: 2
provider: virtualbox authorize: ~/.ssh/id_rsa.pub keys: - ~/.ssh/id_rsa folders: - map: D:/code to: /home/vagrant/code sites: - map: admin.design.test to: /home/vagrant/code/design-admin/public php: "7.3" databases: - homestead features: - mysql: true - redis: true - memecached: true - mariadb: false - postgresql: true - ohmyzsh: false - webdriver: false services: - enabled: - "mysql" - "postgresql" - "redis" - "memecached"
# - disabled:
# - "postgresql@11-main" ports: - send: 33060 # MySQL/MariaDB to: 3306 - send: 54320 to: 5432 - send: 6379 to: 6379 - send: 11211 to: 11211
# - send: 4040
# to: 4040
# - send: 54320 # PostgreSQL
# to: 5432
# - send: 8025 # Mailhog
# to: 8025
# - send: 9600
# to: 9600
# - send: 27017
# to: 27017 配置完以后执行 vagrant up/halt，vagrant reload --provision 正常情况下会启动所有的服务，但是通过netstat -tnlp 发现 5432 服务(postgresql)没有启起来 vagrant@homestead:~$ service postgresql status
● postgresql.service - PostgreSQL RDBMS Loaded: loaded (/lib/systemd/system/postgresql.service; disabled; vendor preset: enabled) Active: inactive (dead)
vagrant@homestead:~$ service postgresql start
==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===
Authentication is required to start 'postgresql.service'.
Authenticating as: vagrant //需要输入密码，密码默认为 vagrant
Password:
==== AUTHENTICATION COMPLETE ===
vagrant@homestead:~$ service postgresql status
● postgresql.service - PostgreSQL RDBMS Loaded: loaded (/lib/systemd/system/postgresql.service; disabled; vendor preset: enabled) Active: active (exited) since Mon 2022-10-17 05:17:28 UTC; 9s ago Process: 4725 ExecStart=/bin/true (code=exited, status=0/SUCCESS) Main PID: 4725 (code=exited, status=0/SUCCESS) Oct 17 05:17:28 homestead systemd[1]: Starting PostgreSQL RDBMS...
Oct 17 05:17:28 homestead systemd[1]: Finished PostgreSQL RDBMS. 这样就好了`}]},{path:"/content/php/laravel/laravel%E4%B9%8Blaravel_server%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"laravel之laravel_server的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel之laravel server的使用:
直接通过下面命令启动larave server：
php artisan serve
来源： https://wyz.xyz/d/763-laravel-11-servbayqiang-qiang-lian-he-da-zao-gao-xiao-wei-fu-wu-jia-gou 相关介绍:
php artisan serve 是 Laravel 提供的一个命令行工具，用于启动内置的 PHP 开发服务器。这在开发和测试阶段非常有用，因为它可以快速启动一个简单的 HTTP 服务器来运行你的 Laravel 应用，而不需要配置更复杂的 Web 服务器（如 Apache 或 Nginx）。 主要功能
启动开发服务器:
php artisan serve 启动一个内置的 PHP 开发服务器，使你能够在本地计算机上访问你的 Laravel 应用。默认情况下，它会监听在 http://localhost:8000 上。 指定主机和端口:
你可以通过命令行选项指定主机和端口。例如，使用 php artisan serve --host=127.0.0.1 --port=8080 将服务器绑定到 http://127.0.0.1:8080。 开发测试:
这个服务器适用于开发和测试阶段，但不建议在生产环境中使用，因为它没有像 Apache 或 Nginx 那样的生产级别的性能和安全性。 使用:
启动开发服务器（默认端口 8000）:
php artisan serve 指定端口（例如端口 8080）:
php artisan serve --port=8080 指定主机（例如 127.0.0.1）:
php artisan serve --host=127.0.0.1 同时指定主机和端口:
php artisan serve --host=127.0.0.1 --port=8080 注意事项
开发环境: 这个服务器是为了开发环境而设计，不适合用于生产环境。生产环境中应该使用像 Apache、Nginx 或其他专业的 Web 服务器来提供服务。
性能: 内置服务器适用于测试和开发，但对于生产环境，使用专门的 Web 服务器可以提供更好的性能和安全性。
CLI: 运行 php artisan serve 命令时，你通常需要在 Laravel 项目的根目录中执行，确保可以找到 artisan 脚本和正确的项目设置。`}]},{path:"/content/php/laravel/laravel%E4%B9%8Bmiddleware.html",title:"laravel之middleware",pathLocale:"/",contents:[{header:"",slug:"",content:`/** * 直接在控制器的构造函数里调用 * * ProductController constructor. */
public function __construct()
{ //由于Get 请求没法使用 FormRequest 做参数验证，因为请求的Body 没有参数，所以想到可以使用中间件对指定的Get方法做参数验证 //控制器里使用中间件的几个场景如下: //通过 param 中间件控制
// $this->middleware('param')->only('getTag');
// $this->middleware('auth');
// $this->middleware('param')->except('edit'); //直接写一个闭包的middleware，不用全局定义，就不用单独写一个Middleware类了，这样就只用于当前控制器 $this->middleware(function ($request, $next) { if (empty($request->input('tag'))) { return response()->json(['message' => 'tag参数必须', 'data' => [], 'code' => 4012]); } return $next($request); })->only('getTag');
} /** * 在routes/api.php里定义路由 */
Route::group([ 'prefix' => 'test', 'middleware' => ['auth'],//给组添加中间件 'as' => 'test.',
], function () { Route::get('sort', [TestController::class, 'index'])->name('test.index')->withoutMiddleware(['auth']);//组中的某些路由不想要中间件，可以通过withoutMiddleware指定
}
);`}]},{path:"/content/php/laravel/laravel%E4%B9%8BpostgresSql%E8%BF%9E%E6%8E%A5.html",title:"laravel之postgresSql连接",pathLocale:"/",contents:[{header:"",slug:"",content:`larave之postgresSql连接:
xshell登录homested,然后执行如下操作即可登录psql：
psql -U homestead -h localhost -W 密码输入 secret 通过navicate登录：
地址：127.0.0.1 / localhost
端口：54320
用户名：homestead
密码：secret
默认数据库：homestead / postgres，这两个库默认都会有 laravel在env中的配置：
DB_CONNECTION=pgsql
DB_HOST=127.0.0.1
DB_PORT=5432
DB_DATABASE=homestead
DB_USERNAME=homestead
DB_PASSWORD=secret`}]},{path:"/content/php/laravel/laravel%E4%B9%8B%E5%A4%9A%E6%9D%A1%E4%BB%B6%E7%9A%84or%E6%88%96and%E7%9A%84like%E6%9F%A5%E8%AF%A2.html",title:"laravel之多条件的or或and的like查询",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel之多条件的or或and的like查询:
场景：有时候我们需要对同一个字段做多个值的like查询，这个字段的多个值是由逗号隔开的字符串，对于前端页面可能会把这个字符串拆开
以标签的形式展开，然后做条件筛选
一般都是 or like 查询，有如下两种方式:
①直接在 where 条件里使用
if (isset($params['tags'])){ $conditions = explode(',', $params['tags']); $query = $query->where(function ($query) use($conditions){ foreach ($conditions as $k=> $val){ if ($k == 0){ $query->where('tags', 'like', '%'.$val.'%'); }else{ $query->orWhere('tags', 'like', '%'.$val.'%'); } } }); } ②在model里通过scope实现
首先在model里定义: public function scopeOrWhereLike($query, $conditions) { return $query->where(function ($query) use($conditions){ foreach ($conditions as $k=> $val){ if ($k == 0){ $query->where('tags', 'like', '%'.$val.'%'); }else{ $query->orWhere('tags', 'like', '%'.$val.'%'); } } }); //也可以直接返回 $query
// return $query; } // 然后在查询的时候调用这个scope if (isset($params['tags'])){ $query = $query->orWhereLike(explode(',', $params['tags'])); } 再写一个 and like，这个在同字段肯定是查不出结果的，除非正好是一个值:
①直接在 where 条件里使用 if (isset($params['tags'])){ $conditions = []; foreach (explode(',', $params['tags']) as $val){ $conditions[] = ['tags', 'like', '%'.$val.'%']; } $query = $query->where($conditions); } ②在model里通过scope实现
首先在scope里面定义: public function scopeAndWhereLike($query, $conditions) { $where = []; foreach ($conditions as $val){ $where[] = ['tags', 'like', '%'.$val.'%']; } return $query->where($where); //下面这个写法也是可以的
// $query->where(function ($query) use($conditions){
// foreach ($conditions as $val){
// $query->where('tags', 'like', '%'.$val.'%');
// }
// }); //也可以直接返回 $query
// return $query; } // 然后在查询的时候调用这个scope if (isset($params['tags'])){ $query = $query->andWhereLike(explode(',', $params['tags'])); } 上面两种情形，当 $conditions 包括多个字段的时候，直接取 $key 就可以实现多字段的 or/and like 查询了`}]},{path:"/content/php/laravel/laravel%E4%B9%8B%E6%89%93%E5%8D%B0sql.html",title:"laravel之打印sql",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel之打印sql:
在laravel执行查询的时候，有时候需要打印sql，可以使用下面的方式实现:
在AppServiceProvider.php的boot 方法里面加入如下的方法：
public function boot() { // \\DB::listen( function ($sql) { foreach ($sql->bindings as $i => $binding) { if ($binding instanceof \\DateTime) { $sql->bindings[$i] = $binding->format('\\'Y-m-d H:i:s\\''); } else { if (is_string($binding)) { $sql->bindings[$i] = "'$binding'"; } } } // 解析查询参数 $query = str_replace(array('%', '?'), array('%%', '%s'), $sql->sql); $query = vsprintf($query, $sql->bindings); // 输出到 storage日志下 $logFile = fopen( storage_path('logs' . DIRECTORY_SEPARATOR . date('Y-m-d') . '_query.log'), 'a+' ); fwrite($logFile, date('Y-m-d H:i:s') . ': ' . $query . PHP_EOL); fclose($logFile); } ); }`}]},{path:"/content/php/laravel/laravel%E4%B9%8B%E6%9B%B4%E6%96%B0%E6%8C%87%E5%AE%9A%E7%9A%84%E5%8C%85.html",title:"laravel之更新指定的包",pathLocale:"/",contents:[{header:"",slug:"",content:`在laravel开发项目的时候，有时候需要更新指定的包的版本，尤其是自定义的composer 包的内容发生了变化，那么就需要更新才能使用新的属性或者方法,
有如下集中使用场景: composer更新指定的依赖包 compoesr 的require/update都可以更新指定的依赖包(升级/降级)。
require更为灵活些，未安装则进行安装，已安装则根据传入的版本号进行升级或降级。
update则无法在命令行传入新的版本号，需要先手动在composer.json中指定新的版本号，然后执行更新命令。 require 命令 // 安装包
composer require census/sql:1.3.3 // 已安装 升级
composer require census/sql:1.3.4 // 已安装 降级
composer require census/sql:1.3.2 update 命令 update命令无法在命令行中指定包版本号，需要手动修改composer.json文件 错误用法composer update census/sql:1.3.4 正确用法示例vim composer.json "require": { "census/sql": "1.3.4" }, :wq #升级到1.3.4 同时，如果我们编辑更新了多个包的版本号，则无法使用
composer update package1
composer update package2
composer update package3 的方式去依次的更新，因为composer会校验配置文件的完整性json vs lock，你指定要我更新A，但你B的version在json和lock中不一致，你却不要我更新它，这是有问题的。 这时只能使用composer update全局更新依赖，注意是全局包的更新操作，一些你未更改但使用了版本号范围的包也有可能被更新升级，请慎用！ install 命令 install可以用于项目初始化后，初次安装依赖，且会优先读取composer.lock中的版本号，以尽可能的保证协作开发中包版本的一致性。 composer.lock中存有的包版本记录相当于执行 composer require packageName:versionNo，不存有的相当于执行composer update packageName with versionRule in composer.json。 当我们协同开发时，A 在本地安装了新的依赖包，或者更新了依赖包，会写入 composer.lock/composer.json,A 上传至仓库，B 拉取至本地后，应执行一次 composer install来同步团队的版本变更。 所以协作开发中，我们建议要同时将composer.lock/composer.json上传至远端仓库。 版本号管理:
版本号范围大于/大于等于：>1.2.3 >=1.2.3
小于/小于等于：<1.2.3 <=1.2.3
确切的版本号：1.2.3
~1.2.3: 1.2.3 <= version < 1.3 //小版本
^1.2.3: 1.2.3 <= version < 2.0 //大版本`}]},{path:"/content/php/laravel/laravel%E4%B9%8B%E7%94%9F%E6%88%90%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6%E4%BB%A5%E5%8F%8A%E4%BF%AE%E6%94%B9%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6.html",title:"laravel之生成迁移文件以及修改迁移文件",pathLocale:"/",contents:[{header:"",slug:"",content:`laravel开发过程中，总是要执行迁移文件，创建或修改数据，还是把几个常用的命令记下来:
1.通过迁移文件生成数据库
php artisan migrate #生成数据库
php artisan migrate --seed生成数据表同时初始化数据 2.seeder创建
php artisan make:seeder AdminTableSeeder #新建一个seeder 3.给数据库初始化数据
php artisan db:seed --class=UsersTableSeeder 如果在执行:php artisan db:seed --class=UsersTableSeeder的时候报类似下面的错误，可以通过composer dump-autoload命令解决 4.创建生成表的迁移文件
php artisan make:migration create_{$table_name}_table --create={$table_name} #注意 {$table_name} 就是table_name 实际不用加 {$}符号 php artisan make:migration create_users_table --create=users #同上，用于创建users表 5.修改迁移文件
php artisan make:migration add_votes_to_users_table --table=users #用于修改users表，给votes加个字段 6.注意点: 通过指定migrate的path来选择性生成数据库，避免重复 导致报错
php artisan migrate --path=/database/migrations/2018_12_13_082054_create_coupon_category_table.php (up) php artisan migrate:rollback --path=/database/migrations/2020_03_25_104544_add_repair_type_to_edu_chapters_table.php (down) 7.数据库回滚操作
php artisan migrate:reset // 这个命令会将之前所有的迁移文件全部删除，就像格式化一样(回滚所有)
php artisan migrate:rollback // 这个命令会回滚最新的一次迁移操作，有一种场景很奇怪，很危险，就是我迁移文件里有的执行失败了，有的成功了，结果我想重新执行，自然会报 表已经存在的错误，于是乎 就想回滚一下，我没有指定任何迁移文件，结果我之前的迁移表全部没有了，而不是把我当前执行有错的回滚了，相当于 1 2 3(有错误) ， 就剩1了，2 没了 3 也没了
php artisan migrate:refresh //这个命令会回滚所有操作，然后再执行migrate 8.个人建议，如果一个迁移文件下有多个表操作，可以按照下面的方式执行
class CreateUsersTable extends Migration
{ /** * Run the migrations. * * @return void */ public function up() { //通过 try catch 捕获异常，然后drop，算是回滚了，这个是 mysql的 DDL 操作，自然不能用 transaction 操作，这个对 DML 有效 try{ // 用户表 Schema::create('users', function (Blueprint $table) { $table->bigIncrements('id')->comment('ID'); $table->string('avatar')->nullable()->comment('头像'); $table->string('nickname', 100)->comment('昵称'); $table->timestamp('created_at')->nullable()->comment('创建时间'); $table->timestamp('updated_at')->nullable()->comment('修改时间'); }); DB::statement('alter table ' . config('database.connections.mysql.prefix', '') . 'users comment "用户表"'); // 用户日志表 Schema::create('user_logs', function (Blueprint $table) { $table->bigIncrements('id')->comment('ID'); $table->timestamp('created_at')->nullable()->comment('创建时间'); $table->timestamp('updated_at')->nullable()->comment('修改时间'); $table->unsignedBigInteger('user_id')->comment('用户ID'); $table->foreign('user_id')->references('id')->on('users')->onDelete('cascade'); }); DB::statement('alter table ' . config('database.connections.mysql.prefix', '') . 'user_logs comment "用户日志表"'); }catch(PDOException $ex){ $this->down(); throw $ex; } } /** * Reverse the migrations. * * @return void */ public function down() { Schema::dropIfExists('users'); Schema::dropIfExists('user_logs'); }
}`}]},{path:"/content/php/laravel/laravel%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%8A%80%E5%B7%A7.html",title:"laravel模型中的几个小技巧",pathLocale:"/",contents:[{header:"",slug:"",content:`larave模型中的几个小技巧:
①模型中关于 $dates 和 $dateFormat
//将 [] 中自定的字段，转为 Carbon 类的时间对象，可以使用 Carbon 的方法，比如：$data->deleted_at->getTimestamp()；默认 created_at 和 updated_at 都已经转过了，就不用在 [] 里 写了
protected $dates = ['deleted_at'];
//定义时间存储到数据的格式，默认 'Y-m-d H:i:s'
protected $dateFormat = 'Y-m-d H:i';
②模型中关于scope的使用，主要有两种使用方式: //局部使用Scope，这个status scope 还带了参数，更加灵活， 使用的时候直接 Produt::query()->->status(1)->get();就可以了
public function scopeStatus($query, $status = 0)
{ return $query->where('status', $status);
} //全局使用Scope，这个不许用显示的调用
protected static function boot()
{ parent::boot(); //通过给scope 定义一个名称 filter，定义名称的好处是，可以通过 withoutGlobalScope()，取消指定名称的 scope；或者 withoutGlobalScopes(),不带参数可以取消所有scope static::addGlobalScope('filter', function (Builder $builder) { $builder->where('status', 0); }); //匿名 scope static::addGlobalScope(function (Builder $builder) { $builder->where('status', 0); }); //定义一个 Scope 实例，一定要new 一个对象 static::addGlobalScope(new StatusScope()); } //StatusScope 类如下，实现了Scope的一个apply接口 <?php /** * Created by PhpStorm. * User: guoshipeng * Date: 2022/9/23 * Time: 11:26 */ namespace App\\Scopes; use Illuminate\\Database\\Eloquent\\Builder; use Illuminate\\Database\\Eloquent\\Model; use Illuminate\\Database\\Eloquent\\Scope; class StatusScope implements Scope { public function apply(Builder $builder, Model $model) { return $builder->where('status', 1); } } ③自动维 护创建时间 或 更新时间 直接在模型里面加 public $timestamps = true; 即可实现自动维护<br> 有时候我们只想维护其中一个，怎么弄，比如不需要自动更新时间，可以在模型里加： const UPDATED_AT = null;<br> 或者我们不想要 updated_at，想要改为其它的，我们可以在模型里加：const UPDATED_AT = 'update_time';`}]},{path:"/content/php/base/PHP%E4%B9%8Breadfile%E5%92%8Cfile_get_contents%E5%8C%BA%E5%88%AB.html",title:"PHP之readfile和file_get_contents区别",pathLocale:"/",contents:[{header:"",slug:"",content:`readfile和file_get_contents都是用于读取文件内容的PHP函数，但它们之间有一些关键的区别。
返回值：
readfile: 将文件内容直接输出到输出缓冲区，并返回读取的字节数。通常用于直接输出文件内容到浏览器，例如用于下载文件。
file_get_contents: 将文件内容读取到一个字符串中，并返回该字符串。通常用于在脚本中处理文件内容，而不是直接输出到浏览器。 用途：
readfile: 主要用于将文件内容直接输出到浏览器，通常用于文件下载或显示图像等二进制文件。
file_get_contents: 主要用于将文件内容读取到字符串中，以便在脚本中进一步处理，例如进行字符串操作、解析JSON等。 性能： readfile: 适合处理大文件，因为它在输出时逐块读取文件，不会将整个文件加载到内存中。
file_get_contents: 将整个文件内容加载到内存中，对于大文件可能导致内存占用较高。 总体来说，如果你只是希望将文件内容输出到浏览器，而不需要在脚本中进一步处理，可以使用readfile。如果你需要在脚本中对文件内容进行操作，那么使用file_get_contents更为合适。 示例代码:待补充...`}]},{path:"/content/php/base/PHP%E4%B9%8B%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"PHP之代码静态分析工具的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`多人同时开发同一个项目的时候，为了同意编码的风格，可以通过 phpstan 和 php-cs-fixer 对代码进行静态分析，使用命令如下:
php7.4 ./vendor/bin/phpstan
php7.4 ./vendor/bin/php-cs-fixer fix --config=.php-cs-fixer.dist.php --verbose --dry-run --using-cache=no --diff //这个会展示具体的哪些行有问题 也可以是:
$ php ./vendor/bin/phpstan
$ php ./vendor/friendsofphp/php-cs-fixer/php-cs-fixer.php fix --verbose --dry-run --using-cache=no //这个只会展示哪些有问题，但是不会展示哪些行 如果需要单元测试，可以通过下面的命令实现:
php7.4 ./vendor/bin/simple-phpunit
php ./vendor/bin/phpunit 注意上面的php7.4只是当前环境下php的版本，可以配置为 全局php软连接，上面的命令执行都是在项目的根目录下.`}]},{path:"/content/php/base/PHP%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BC%A0%E9%80%92%E9%97%AE%E9%A2%98.html",title:"PHP之对象传递问题",pathLocale:"/",contents:[{header:"PHP之对象传递问题",slug:"php之对象传递问题",content:`本来以为对象作为参数传递或者赋值是引用传递的，但是不是这样的，其实是对象标识符（即对象句柄）传递，这个句柄允许访问实际的对象。但是有引用传递的效果。 示例:
class Test { public $value = 1;
} function modify(Test $obj) { $obj->value = 99;
} $a = new Test();
modify($a); echo $a->value; // 输出 99，说明 modify 中的修改影响了原始对象 class Person { public string $name = 'Alice';
} $a = new Person();
$b = $a; $b->name = 'Bob'; echo $a->name; // 输出 Bob ✅ 如果想创建一个新的独立对象，必须使用 clone：
$c = clone $a;
$c->name = 'Charlie'; echo $a->name; // 仍然是 Bob ✅
echo $c->name; // 是 Charlie ✅ 官方文档说明: https://www.php.net/manual/en/language.oop5.references.php 对象句柄和&引用传递的区别:
对于 $b = $a 来说， $b 和 $a 是两个变量，分别有自己的内存地址，但是指向的内容是一样的， $b 如果再次被赋值为$c，那就和$a 没关系了
对于 $b = &$a 来说， $b就是$a的alias(别名)， 它们是同一个变量的两个名字， b 如果再次被赋值为$c, 那么$a 也要变`},{header:"通过zval的角度分析:",slug:"通过zval的角度分析",content:`我们现在来深入底层探讨： 当执行 $a = new StdClass(); $b = $a; 时，$a 的 zval 到底是什么结构，$b 的 zval 和 $a 的有什么不同？ 我们将分两步： 先理解 zval 是什么（PHP 内部结构）
具体讲 $a = new StdClass(); $b = $a; 时发生了什么`},{header:"🧠 第一步：什么是 zval？",slug:"🧠-第一步-什么是-zval",content:`zval 是 PHP 用来存储变量的内部结构。
一个 zval 包括这些核心部分： 字段
含义 value
存储实际值（int、string、object 句柄等） refcount
引用计数（这个值被几个变量引用） is_ref
是否是显式引用（通过 & 赋值） type
类型信息，如 IS_STRING、IS_OBJECT 等`},{header:"🧪 第二步：执行 $a = new StdClass(); 后发生了什么？",slug:"🧪-第二步-执行-a-new-stdclass-后发生了什么",content:"$a = new StdClass(); 这一步会创建："},{header:"🔹 一个对象结构（heap 上）：",slug:"🔹-一个对象结构-heap-上",content:"对象实例（如地址 0xABC123）： class_name => StdClass properties => []"},{header:"🔹 一个 zval 给 $a：",slug:"🔹-一个-zval-给-a",content:"zval_a: type => IS_OBJECT value => handle 指向 0xABC123 refcount => 1 is_ref => 0 变量 $a 指向这个 zval_a。"},{header:"然后 $b = $a; 又做了什么？",slug:"然后-b-a-又做了什么",content:`这一步不是复制对象，也不是复制 zval，而是： 复制 zval 的指针（zval_b 指向和 zval_a 同一块内存）
zval 的引用计数 refcount++ 所以现在：
$a 和 $b 都指向同一个 zval： zval_shared: type => IS_OBJECT value => handle → 0xABC123 refcount => 2 is_ref => 0 注意：$a 和 $b 是两个变量名，但它们指向同一个 zval（zval 本身在内存中只有一份）`},{header:"✅ 修改对象属性时的行为",slug:"✅-修改对象属性时的行为",content:"$b->x = 123; 你是在操作对象句柄（0xABC123）指向的内存，所以 $a->x 也变了。"},{header:"❗但再举一个反例，看看不一样的地方：",slug:"❗但再举一个反例-看看不一样的地方",content:`$a = new StdClass();
$b = $a;
$b = new StdClass(); // 此时 b 不再指向原对象 现在 $b 会指向新的 zval：
$b → zval_b_new value => handle → 0xDEF456 refcount => 1 $a → 原 zval_a value => handle → 0xABC123 refcount => 1（原来是 2，现在 -1）`},{header:"🔁 如果你用了引用 &：",slug:"🔁-如果你用了引用",content:`$a = new StdClass();
$b = &$a; 此时会合并 $a 和 $b 的符号表变量名，让它们指向同一个 zval，并把 is_ref 设置为 1：
zval_ref: type => IS_OBJECT value => handle → 0xABC123 refcount => 2 is_ref => 1 现在，无论你对 $a 还是 $b 赋新值、改指向，都完全等价了（引用语义）。`},{header:"🧪 如何验证这些行为？",slug:"🧪-如何验证这些行为",content:`可以用 PHP 的 debug_zval_dump()：
$a = new StdClass();
$b = $a; debug_zval_dump($a); 输出类似：
object(stdClass)#1 (0) refcount(2) 说明 $a 的 zval 被引用了 2 次（$a 和 $b）。`},{header:"✅ 总结",slug:"✅-总结",content:`操作
行为 $a = new StdClass();
创建 zval，refcount = 1，is_ref = 0 $b = $a;
指向同一 zval，refcount++ $b = &$a;
真正引用，两个变量名绑定同一个 zval，is_ref = 1 修改对象属性
改的是对象实例本身，两个变量看到的结果都变 重新赋新对象给 $b
$b 指向新 zval，$a 不受影响 可以发现，refcount 都为2，但是 is_ref 一个是0 一个是1
官方文档说明: https://www.php.net/manual/zh/function.debug-zval-dump.php`},{header:"关于写时复制:",slug:"关于写时复制",content:"我们现在来深入讲解："},{header:"🧠 PHP 的 Copy-On-Write（COW，写时复制）机制 + zval 管理图解",slug:"🧠-php-的-copy-on-write-cow-写时复制-机制-zval-管理图解",content:""},{header:"一、背景：PHP 的变量实现方式",slug:"一、背景-php-的变量实现方式",content:"PHP 每个变量都不是直接保存值，而是通过一个叫 zval 的结构来管理值和引用关系。"},{header:"一个 zval 结构包含：",slug:"一个-zval-结构包含",content:`value: 变量的值（string/int/object/array...）
refcount: 有多少个变量共享这个 zval（引用计数）
is_ref: 是否为“引用模式”（即通过 & 建立 alias）`},{header:"二、赋值行为图解",slug:"二、赋值行为图解",content:""},{header:"情况 1：普通赋值（非引用）",slug:"情况-1-普通赋值-非引用",content:`$a = 'hello';
$b = $a; 🔍 发生了什么：
+------+ +-----------------------+
| $a | -----> | zval: |
| | | value: "hello" |
| $b | -----> | refcount: 2 |
| | | is_ref: 0 |
+------+ +-----------------------+ $a 和 $b 指向同一个 zval
refcount = 2
但 is_ref = 0，表示它们不是绑定 alias
改 $a = 'world' 会发生 写时复制（Copy-On-Write）`},{header:"写时复制触发（COW）",slug:"写时复制触发-cow",content:`$a = 'hello';
$b = $a;
$a = 'world'; 🔍 发生了什么：
Step 1:
$a, $b --> "hello" (refcount = 2, is_ref = 0) Step 2:
$a = 'world'; // 修改触发 Copy-On-Write： -> PHP 创建一个新的 zval 给 $a -> 原 zval 的 refcount--（变 1） -> 新 zval 的 refcount = 1 结果：
$a ---> "world" (refcount = 1)
$b ---> "hello" (refcount = 1) 👉 这样就节省了内存，直到你真的需要修改才复制。`},{header:"情况 2：引用赋值（使用 &）",slug:"情况-2-引用赋值-使用",content:`$a = 'hello';
$b = &$a; 🔍 发生了什么：
+------+ +------------------------+
| $a | -----> | zval: |
| $b | -----> | value: "hello" |
| | | refcount: 2 |
| | | is_ref: 1 <--------- 绑定 alias
+------+ +------------------------+ $a 和 $b 完全绑定，是 同一个变量的两个名字
改任意一方，另一方立即变
赋值也影响彼此（不是写时复制） $b = 'world'; // $a 也变成 'world'`},{header:"三、对象赋值与 COW 的不同",slug:"三、对象赋值与-cow-的不同",content:`$obj1 = new stdClass();
$obj2 = $obj1; 在对象赋值中： 变量指向的是一个对象句柄（handle）
PHP 不会复制对象，默认行为就是“引用共享对象” $obj2->x = 123; // $obj1->x 也变 但重要的是：
$obj2 = new stdClass(); // ❌ $obj1 保持原对象 对象赋值 不会触发 COW，因为对象内部不是简单值，而是指向堆上对象内存。`},{header:"四、变量表、zval、内存图",slug:"四、变量表、zval、内存图",content:""},{header:"PHP 的变量机制可视化如下：",slug:"php-的变量机制可视化如下",content:`Symbol Table (符号表)
+------+ +-----------+
| $a | --> | zval A |
| $b | --> | zval A |
+------+ +-----------+ 当赋值或引用时： 变量表指向同一个 zval
修改时，根据 refcount 和 is_ref 判断是否需要 copy
refcount > 1 && is_ref == 0 → 会触发 COW
is_ref == 1 → 强制引用，绝不复制`},{header:"五、最佳口诀记忆：",slug:"五、最佳口诀记忆",content:`类型
refcount
is_ref
是否复制 普通赋值
✅ 增加
❌ 否
✅ 修改时复制 引用赋值（&）
✅ 增加
✅ 是
❌ 不复制 对象赋值
✅ 共享
❌ 否
❌ 不复制，操作引用`},{header:"🧪 推荐调试方法",slug:"🧪-推荐调试方法",content:`使用 debug_zval_dump($var) 查看：
$a = 'abc';
$b = $a; debug_zval_dump($a);
/*
string(3) "abc"
refcount(2)
is_ref=0
*/ 再用 $b = &$a; 试试看区别。`}]},{path:"/content/php/base/PHP%E4%B9%8B%E6%89%A7%E8%A1%8C%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.html",title:"PHP之执行测试用例",pathLocale:"/",contents:[{header:"",slug:"",content:`执行测试用例，只展示执行报错的用例，可以考虑使用PHPUnit的 --testdox 选项，该选项会生成测试文档，其中包含每个测试的名称和结果。你可以使用grep来筛选出包含 "Error" 的行:
./vendor/bin/simple-phpunit --testdox | grep "Error"`}]},{path:"/content/php/base/composer_install%E6%8A%A5%E9%94%99.html",title:"composer install 报错",pathLocale:"/",contents:[{header:"",slug:"",content:`composer install 报错:
执行: composer install 报： Your lock file does not contain a compatible set of packages. Please run composer update. 执行: compsoer update 报： require composer-runtime-api ^2.2 -> found composer-runtime-api[2.0.0] but it does not match the constraint
执行： composer self-update 即可解决
参考：https://stackoverflow.com/questions/65495849/laravel-composer-install-giving-error-your-lock-file-does-not-contain-a-compati 然后再执行 composer install`}]},{path:"/content/php/base/composer%E5%AE%89%E8%A3%85%E6%8A%A5php%E4%BE%9D%E8%B5%96%E9%94%99%E8%AF%AF.html",title:"composer安装报php依赖错误",pathLocale:"/",contents:[{header:"",slug:"",content:`composer安装报php依赖错误:
执行 composer install 报:
Problem 1
- Root composer.json requires PHP extension ext-redis * but it is missing from your system. Install or enable PHP's redis extension. 解决，
安装redis拓展: $ sudo apt-get install php8.3-redis`}]},{path:"/content/php/base/composer%E6%BA%90%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4.html",title:"composer源相关命令",pathLocale:"/",contents:[{header:"",slug:"",content:`composer源相关命令:
1>composer 查看源信息:
composer config -gl 2>使用阿里云源码:
composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ 3>恢复到默认源:
composer config -g --unset repos.packagist 4>清理缓存
composer clearcache`}]},{path:"/content/php/base/docker%E4%B8%8B%E5%AE%89%E8%A3%85php%E7%9A%84imagick%E6%8B%93%E5%B1%95.html",title:"docker下安装php的imagick拓展",pathLocale:"/",contents:[{header:"docker下安装php的imagick拓展",slug:"docker下安装php的imagick拓展",content:""},{header:"1.刚开始是这么安装的",slug:"_1-刚开始是这么安装的",content:"RUN apt-get install -y \\ libxslt1-dev \\ imagick \\ && docker-php-ext-install xsl \\ && docker-php-ext-install bcmath \\ && docker-php-ext-install imagick"},{header:"2.这个写法分析",slug:"_2-这个写法分析",content:""},{header:"这个写法的问题在于：",slug:"这个写法的问题在于",content:`docker-php-ext-install imagick 是无效的，因为 imagick 并不是 PHP 自带的扩展，而是一个通过 PECL 安装的扩展。
docker-php-ext-install 只能安装 PHP 官方内置的扩展（比如 xsl、bcmath、pdo_mysql 等）。`},{header:"正确写法应该是",slug:"正确写法应该是",content:`（基于 Debian 系的官方 PHP 镜像）
RUN apt-get update && apt-get install -y \\ libxslt1-dev \\ libmagickwand-dev --no-install-recommends \\ && docker-php-ext-install xsl \\ && docker-php-ext-install bcmath \\ && pecl install imagick \\ && docker-php-ext-enable imagick \\ && rm -rf /var/lib/apt/lists/*`},{header:"关键点",slug:"关键点",content:`系统库安装 libmagickwand-dev 是 Imagick 必需的头文件和库。
不要直接装 imagick 这个 apt 包，因为那是系统的 CLI 工具或旧版扩展，不一定适配 PHP 版本。 PECL 安装 pecl install imagick 会从官方源下载编译 PHP Imagick 扩展。 启用扩展 docker-php-ext-enable imagick 会在 php.ini 里注册它。 对于 PHP 自带的内置扩展，如果它需要依赖，就先 apt-get install 对应的系统库，然后 docker-php-ext-install xxx`},{header:"3.apt-get install 和 docker-php-ext-install 关系",slug:"_3-apt-get-install-和-docker-php-ext-install-关系",content:"它们的关系其实可以这么理解："},{header:"1️⃣ 角色不同",slug:"_1️⃣-角色不同",content:`apt-get install
安装的是系统级软件包（包括编译 PHP 扩展时需要的头文件和库文件）。 来源：Debian/Ubuntu 系统的 APT 软件仓库
作用：提供 PHP 扩展编译时的依赖环境（例如 .h 头文件、.so 动态库等） docker-php-ext-install
安装的是 PHP 自带的内置扩展（ext/ 目录里的源码），它会调用 docker-php-source + docker-php-ext-configure + docker-php-ext-install 的组合脚本去编译这些扩展。 来源：PHP 官方 Docker 镜像自带的源码
作用：在已有的系统依赖支持下，把扩展编译成 .so 并在 PHP 里启用`},{header:"2️⃣ 依赖关系",slug:"_2️⃣-依赖关系",content:`很多内置扩展并不是“裸装”就能编译成功，它们会用到系统级的库。
这时： apt-get install 装好依赖
docker-php-ext-install 编译安装扩展 举个例子：
RUN apt-get update && apt-get install -y \\ libxslt1-dev \\ libzip-dev \\ && docker-php-ext-install xsl zip 流程是： apt-get install libxslt1-dev libzip-dev → 安装系统库和头文件
docker-php-ext-install xsl zip → 编译 xsl 和 zip 扩展（依赖上一步装的库）`},{header:"3️⃣ 什么时候不需要 apt-get install",slug:"_3️⃣-什么时候不需要-apt-get-install",content:`扩展完全不依赖系统库（例如 bcmath、mysqli）：
RUN docker-php-ext-install bcmath mysqli`},{header:"4️⃣ 什么时候用不到 docker-php-ext-install",slug:"_4️⃣-什么时候用不到-docker-php-ext-install",content:`如果是 PECL 扩展（imagick、redis、xdebug 等），它们不在 PHP 内置源码里，需要用：
RUN apt-get install -y libmagickwand-dev \\ && pecl install imagick \\ && docker-php-ext-enable imagick 这里就不走 docker-php-ext-install 了。 ✅ 总结一句：
apt-get install 是“买原材料”，docker-php-ext-install 是“用这些材料把 PHP 扩展做出来并装进 PHP 里”。
没有材料就做不出来，有材料但不去做，PHP 里也不会有这个扩展。`},{header:"4.上面的配置好了，但是实际运行中会有如下报错",slug:"_4-上面的配置好了-但是实际运行中会有如下报错",content:`> [php 2/11] RUN apt-get update && apt-get install -y libxslt1-dev libmagickwand-dev --no-install-recommends && docker-php-ext-install xsl && docker-php-ext-install bcmath && pecl install imagick && docker-php-ext-enable imagick: 0.524 Ign:1 http://deb.debian.org/debian buster InRelease 0.589 Ign:2 http://deb.debian.org/debian-security buster/updates InRelease 0.661 Ign:3 http://deb.debian.org/debian buster-updates InRelease 0.724 Err:4 http://deb.debian.org/debian buster Release
0.724 404 Not Found [IP: 151.101.90.132 80]
0.787 Err:5 http://deb.debian.org/debian-security buster/updates Release
0.787 404 Not Found [IP: 151.101.90.132 80]
0.852 Err:6 http://deb.debian.org/debian buster-updates Release
0.852 404 Not Found [IP: 151.101.90.132 80]
0.860 Reading package lists...
1.425 E: The repository 'http://deb.debian.org/debian buster Release' no longer has a Release file.
1.425 E: The repository 'http://deb.debian.org/debian-security buster/updates Release' no longer has a Release file.
1.425 E: The repository 'http://deb.debian.org/debian buster-updates Release' no longer has a Release file.
------
failed to solve: process "/bin/sh -c apt-get update && apt-get install -y libxslt1-dev libmagickwand-dev --no-install-recommends && docker-php-ext-install xsl && docker-php-ext-install bcmath && pecl install imagick && docker-php-ext-enable imagick" did not complete successfully: exit code: 100 出现问题原因分析 和imagick 安装无关，根本原因是你的 PHP Docker 镜像基于 Debian buster，而 buster 已经 停止维护（EOL）， 官方的 APT 仓库被移到了归档站，所以 apt-get update 会直接 404。
对于我这里的原因是: 我使用了自建的php镜像源，但是这个镜像里对于php景象的依赖是Debian buster, 所以现在有如下解决方案 1.改成归档源RUN sed -i 's|deb.debian.org|archive.debian.org|g' /etc/apt/sources.list \\
&& sed -i '/security.debian.org/d' /etc/apt/sources.list \\
&& apt-get update \\
&& apt-get install -y \\
libxslt1-dev \\
libmagickwand-dev --no-install-recommends \\
&& docker-php-ext-install xsl \\
&& docker-php-ext-install bcmath \\
&& pecl install imagick \\
&& docker-php-ext-enable imagick \\
&& rm -rf /var/lib/apt/lists/* 部分配置分析: sed -i 's|deb.debian.org|archive.debian.org|g' /etc/apt/sources.list sed -i '/security.debian.org/d' /etc/apt/sources.list apt-get update 这三条命令的作用是修改 Debian 系统的 APT 软件源配置，让系统从归档（archive）服务器下载旧版本的软件包，解决官方源因为版本停止维护而导致的 404 错误。具体解释如下： sed -i 's|deb.debian.org|archive.debian.org|g' /etc/apt/sources.list sed 是文本替换命令，-i 表示直接修改文件。 作用：把 /etc/apt/sources.list 文件中所有 deb.debian.org 的字符串替换成 archive.debian.org。 为什么要替换？ deb.debian.org 是 Debian 正常的软件仓库地址，但对于停止维护的旧版本，它会被移除包，访问会 404。 archive.debian.org 是 Debian 的归档仓库，保留了旧版本的完整包。 sed -i '/security.debian.org/d' /etc/apt/sources.list作用：删除 /etc/apt/sources.list 文件中包含 security.debian.org 的所有行。
为什么要删除？ Debian 的安全更新源 security.debian.org 对旧版本（比如 buster）已经停止服务，访问会 404。 删除后防止 apt-get update 报错。 apt-get update执行更新软件包索引，重新加载修改后的源列表。
这一步能成功，说明之前的替换和删除操作正确，APT 能够从归档服务器正常拉取软件包索引。 2.从镜像源头升级 如果能改这个私有镜像的构建方式，建议让它基于
php:8.3-fpm-bullseye 或 php:8.3-fpm-bookworm，
这样 apt 源是活的，不需要 archive 站。这个是最好的方式，这样所有使用这个自定义源的都可以生效`}]},{path:"/content/php/base/php-fpm%E9%85%8D%E7%BD%AE%E4%B8%8D%E5%BD%93%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"php-fpm配置不当引发的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`最近在配置 php 环境的时候，遇到一个问题，明明配置了 nginx 的user和group，也配置了 php-fpm的 user和group，为什么还是会
报 502 错误呢 分析原因如下 当我们在 配置php-fm的配置文件的时候，如果listen 配置了tcp连接 如：listen = 127.0.0.1:9000 ，按上面的配置
运行不会有什么问题，但是如果配置了socket连接，那么就会有问题，需要配置 listen.owner和listen.group = nobody这两个参数，
这两个参数的解释如下： ; Set permissions for unix socket, if one is used. In Linux, read/write
; permissions must be set in order to allow connections from a web server.
; Default Values: user and group are set as the running user
; mode is set to 0660
;listen.owner = nobody
;listen.group = nobody
;listen.mode = 0660 翻译过来就是：sock文件的读写用户 都必须和 web服务器的一致，这里就是要和nginx的用户一致，所以把这里配置一下，重启fpm和nginx
就可以了 那么 user/group 和 listen.owner/listen.group的区别是啥，前者是php-fpm启动的用户和用户组，后者是sock连接的用户和用户组，当
为 TCP 连接的时候 ，这个就不会有影响了。`}]},{path:"/content/php/base/php74%E4%B8%8B%E8%AF%B7%E6%B1%82%E9%94%99%E8%AF%AF%E9%9B%86%E5%90%88.html",title:"php74下请求错误集合",pathLocale:"/",contents:[{header:"",slug:"",content:`php74下请求错误集合： php7.4 提交post请求，结果报下面的错误 2023/09/20 15:51:48 [error] 1044#1044: *1194 FastCGI sent in stderr: "PHP message: PHP Fatal error: Allowed memory size of 134217728 bytes exhausted (tried to allocate 20480 bytes) in /home/k8s/code/test.com/vendor/doctrine/orm/lib/Doctrine/ORM/Internal/Hydration/AbstractHydrator.php on line 447PHP message: PHP Fatal error: Allowed memory size of 134217728 bytes exhausted (tried to allocate 65536 bytes) in /home/k8s/code/test.com/vendor/symfony/error-handler/DebugClassLoader.php on line 349" while reading response header from upstream, client: 127.0.0.1, server: test.local, request: "POST /event/proposal/create/04d4a042b713404738d190ce39875f7f HTTP/1.1", upstream: "fastcgi://unix:/run/php/php7.4-fpm.sock:", host: "test.local", referrer: "http://test.local/event/proposal/create/04d4a042b713404738d190ce39875f7f" 肯定是要修改memory_limit的值，有两个地方有php.ini
一个是: /etc/php/7.4/fpm下的php.ini,还有一个是:/etc/php/7.4/cli 下的php.ini，我么应该修改fpm下的php.ini的memory_limit=1024M,而不是cli的那个，否则不生效。 还是那个问题: cli用于命令行，fpm 用户web请求.
如下命令行可以以体现:
k8s@HPDEV-31:/etc/php/7.4$ php --ini
Configuration File (php.ini) Path: /etc/php/7.4/cli
Loaded Configuration File: /etc/php/7.4/cli/php.ini
Scan for additional .ini files in: /etc/php/7.4/cli/conf.d
Additional .ini files parsed: /etc/php/7.4/cli/conf.d/10-mysqlnd.ini,
/etc/php/7.4/cli/conf.d/10-opcache.ini,
/etc/php/7.4/cli/conf.d/10-pdo.ini,
...
...`}]},{path:"/content/php/base/php8%E4%B9%8BAttributes%E6%B3%A8%E8%A7%A3.html",title:"php8之Attributes注解",pathLocale:"/",contents:[{header:"",slug:"",content:`php8之Attributes注解:
现在php8经常可以看到这种写法
#[Params("Foo", "argument")]
#[See("https://xxxxxxxx/xxxx/xxx.html")]
function dummy($argument) {} #[ Params("Foo", "argument"), See("https://xxxxxxxx/xxxx/xxx.html")
]
function dummy($argument) {} $ref = new ReflectionFunction("dummy"); var_dump($ref->getAttributes("See")[0]->getName());
var_dump($ref->getAttributes("See")[0]->getArguments()); 参考:https://www.laruence.com/2020/06/12/5902.html`}]},{path:"/content/php/base/php8%E4%B9%8Benum%E9%85%8D%E5%90%88match%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php8之enum配合match的使用",pathLocale:"/",contents:[{header:"php8之enum配合match的使用:",slug:"php8之enum配合match的使用",content:`// 定义了如下enum类，用于获取 suffix
enum RegistrationSuffix: string
{ case Early = 'early'; case Late = 'late'; case Regular = 'regular'; public static function getSuffix(?string $suffix): self { return match ($suffix) {//使用 match 表达式（PHP 8.0+）来实现选择逻辑 'Early bird' => self::Early, 'Late' => self::Late, default => self::Regular, }; }
} // 使用
$suffix = RegistrationSuffix::getSuffix('Early bird');
var_dump($suffix); // enum(RegistrationSuffix::Early) $suffixValue = RegistrationSuffix::getSuffix('Early bird')->value;
echo $suffixValue; // 输出 "early"`}]},{path:"/content/php/base/php8%E4%B9%8Bmatch%E5%87%BD%E6%95%B0.html",title:"php8之match函数",pathLocale:"/",contents:[{header:"",slug:"",content:`概念：
match 表达式基于值的一致性进行分支计算。 match表达式和 switch 语句类似， 都有一个表达式主体，可以和多个可选项进行比较。 与 switch 不同点是，它会像三元表达式一样求值。 与 switch 另一个不同点，它的比较是严格比较（ ===）而不是松散比较（==）。 Match 表达式从 PHP 8.0.0 起可用。
语法:
<?php
$return_value = match (subject_expression) { single_conditional_expression => return_expression, conditional_expression1, conditional_expression2 => return_expression,
};
?> 使用:
//php switch 替换为 match:
return match ($type) { 'course' => $this->_em->getRepository(UserCourse::class)->getUserCourseList($params), 'certification' => $this->_em->getRepository(UserCourse::class)->getUserCertificationList(), 'favorite' => $this->_em->getRepository(UserFavorite::class)->getUserFavoriteList(), default => [], }; switch ($type) { case 'course': return $this->_em->getRepository(UserCourse::class)->getUserCourseList($params); case 'certification': return $this->_em->getRepository(UserCourse::class)->getUserCertificationList(); case 'favorite': return $this->_em->getRepository(UserFavorite::class)->getUserFavoriteList(); }`}]},{path:"/content/php/base/php8%E5%91%BD%E5%90%8D%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php8命名参数的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`php8命名参数的使用: 在 PHP 8 中，你可以通过命名参数来显式传递特定的参数，而跳过其他默认值的参数。这使得代码更加灵活、可读，尤其是在有多个可选参数的场景中。
在你的示例中，如果方法定义如下：
public function normalizeData(ResponsibleInterface|array $data, ?string $format = JsonEncoder::FORMAT, array $context = []): mixed { // 方法体
} 你可以在调用 normalizeData 时显式传递 context 参数，而不需要传递 format 参数，因为 format 已有默认值。调用方式如下：
$normalizedData = $this->serializerService->normalizeData($responsible, context: $context); 在这里，context 被显式赋值，而 format 保持默认值。这种用法在 PHP 8 中被称为命名参数，让你可以根据需求跳过或更改特定参数，同时提高了代码的可读性和灵活性。
这样做的好处是，可以跳过中间的参数，而在php7及以前，需要按顺序传递参数`}]},{path:"/content/php/base/php8%E6%B3%9B%E5%9E%8B%E7%9A%84%E4%BD%93%E7%8E%B0.html",title:"php8泛型的体现",pathLocale:"/",contents:[{header:"",slug:"",content:'php8泛型的体现:\n<?php namespace App\\Model\\Dto\\Mapper; use App\\Model\\Dto\\Interface\\ResponsibleInterface; /** * @template TResponsibleInterface of ResponsibleInterface * @template TMapperDtoInterface of MapperDtoInterface */\ninterface MapperInterface\n{ /** * @param TMapperDtoInterface $data * * @return TResponsibleInterface */ public function toDto(MapperDtoInterface $data): ResponsibleInterface; /** * @param array<TMapperDtoInterface> $data * * @return array<TResponsibleInterface> */ public function toListDto(array $data): array;\n} 关于 `@template` 标签： 1. 这是 PHP 文档注解（Docblock）中的特性，不完全属于 PHP 8 的语法特性 2. 作用是为泛型提供类型注解和文档说明 - 帮助开发者理解接口或类的泛型约束 - 为 IDE 和静态分析工具提供类型提示 - 增强代码的类型安全性和可读性 3. 示例中的 `@template` 声明了两个泛型类型： - `TResponsibleInterface`：受限于必须实现 `ResponsibleInterface` - `TMapperDtoInterface`：受限于必须实现 `MapperDtoInterface` 4. 语法格式：`@template 泛型名称 [of 约束类型]` 这是一种文档和类型注解，提高代码的类型安全性和可读性。 /** * @implements MapperDtoInterface<Country> */\n#[ORM\\Entity]\n#[ORM\\Table(name: "country")]\nclass Country implements MapperDtoInterface\n{ } 怎么理解 @implements MapperDtoInterface<Country> `@implements MapperDtoInterface<Country>` 是一种泛型注解，表示 `Country` 类实现了 `MapperDtoInterface` 接口，并且具体的泛型类型是 `Country` 本身。 这意味着：\n1. `Country` 类遵守 `MapperDtoInterface` 的契约\n2. 在接口的泛型定义中，`Country` 同时作为输入和输出类型\n3. 提供给 IDE 和静态分析工具的类型信息\n4. 增强代码的类型安全性和可读性 这是 PHP 中通过注解模拟泛型的一种方式。 解释:\n在这个场景中，"同时作为输入和输出类型"意味着： 1. 输入：`Country` 可以作为数据传输对象（DTO）的类型\n2. 输出：`Country` 也可以是最终返回的对象类型 例如，在映射器中，你可以：\n- 将 `Country` 作为输入 DTO\n- 经过转换后，仍然返回 `Country` 对象 这种注解提供了类型一致性的保证和更清晰的接口定义。'}]},{path:"/content/php/base/phpstorm%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%B0%8F%E6%8A%80%E5%B7%A7.html",title:"phpstorm快捷键小技巧",pathLocale:"/",contents:[{header:"",slug:"",content:`phpstorm快捷键小技巧:
1.选中构造函数的参数 点击 alt + enter，可以直接初始化参数`}]},{path:"/content/php/base/phpstorm%E6%8F%92%E4%BB%B6%E4%B9%8BCamelCase.html",title:"phpstorm插件之CamelCase",pathLocale:"/",contents:[{header:"",slug:"",content:`主要解决代码下划线转小驼峰的问题:
装好插件，使用快捷键为：shit+alt+u`}]},{path:"/content/php/base/php%E4%B9%8BbindTo%E5%87%BD%E6%95%B0.html",title:"php之bindTo函数",pathLocale:"/",contents:[{header:"",slug:"",content:`php的匿名函数的bindTo()方法
简单来说这个方法主要是修改匿名函数的作用于范围的
比如:
<?php class A { private $val; function __construct($val) { $this->val = $val; } function getClosure() { //returns closure bound to this object and scope return function() { return $this->val; }; }
} $ob1 = new A(1);
$ob2 = new A(2); $cl = $ob1->getClosure();
echo $cl(), "\\n";
$cl = $cl->bindTo($ob2);
echo $cl(), "\\n";
?> 会输出:
1
2`}]},{path:"/content/php/base/php%E4%B9%8Bbreak%E5%87%BD%E6%95%B0.html",title:"php之break函数",pathLocale:"/",contents:[{header:"",slug:"",content:`break结束当前for, foreach, while, do-while或switch结构的执行。
break接受一个可选的数字参数，告诉它有多少个嵌套的封闭结构要被断开。默认值是1，
只有直接的包围结构被断开。但是数值不能大于嵌套的层数，否则会报错.
<?php
$arr = array('one', 'two', 'three', 'four', 'stop', 'five');
foreach ($arr as $val) { if ($val == 'stop') { break; /* You could also write 'break 1;' here. */ } echo "$val<br />\\n";
} /* Using the optional argument. */ $i = 0;
while (++$i) { switch ($i) { case 5: echo "At 5<br />\\n"; break 1; /* Exit only the switch. */ case 10: echo "At 10; quitting<br />\\n"; break 2; /* Exit the switch and the while. */ default: break; }
}
?> 关键是 break 后面的参数比较牛逼!`}]},{path:"/content/php/base/php%E4%B9%8Bfirst_class_callable_syntax%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php之first_class_callable_syntax的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`php之first_class_callable_syntax的使用: 声明一个Test类 <?php namespace App\\Controller\\Admin; use Closure; /** * 声明一个Test类 */
class Test { public function getPrivateMethod(): Closure { return Closure::fromCallable([$this, 'privateMethod']); //8.1之前 //return $this->privateMethod(...);//8.1之后 } private function privateMethod(): void { file_put_contents('./3.txt', __METHOD__.time()); }
} 在这个控制器里 调用 Test类 <?php namespace App\\Controller\\Admin; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route; /** * 在这个控制器里 调用 Test类 */
class IndexController extends AbstractController
{ #[Route('/admin', name: 'admin')] public function index(Request $request): Response { // 初始化类 $test = new Test; // 调用类里的私有化方法,得到一个Closure $privateMethod = $test->getPrivateMethod(); // 执行这个 Closure $privateMethod(); return $this->renderForm('admin/index.html.twig'); }
} 参考(https://wiki.php.net/rfc/first_class_callable_syntax)
各个版本的PHP的wiki(https://wiki.php.net/rfc#php_83)
RFC解释:request for comments(征求意见)，应该是php的社区版`}]},{path:"/content/php/base/php%E4%B9%8BfromCallable%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php之fromCallable的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目，遇到将函数转为闭包的场景，所以记录一下: 将当前类下的 writeLog 方法，转化为闭包函数 $fn = Closure::fromCallable([$this, 'writeLog']);
$fn('hello'); 将php自带的函数转为闭包函数 $fnStr = Closure::fromCallable('strlen');
var_dump($fnStr('hello')); 将另一个类的静态方法转化为闭包函数 $fnRead = Closure::fromCallable([TopicRepository::class, 'readLog']);
var_dump($fnRead());`}]},{path:"/content/php/base/php%E4%B9%8Bphpseclib%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php之phpseclib的使用",pathLocale:"/",contents:[{header:"php之phpseclib的使用",slug:"php之phpseclib的使用",content:"在php项目开发过程中，有时候我们需要deploy某些项目，但是需要SSH登陆远程服务器，我发现这个包特别好用 composer require phpseclib/phpseclib:~3.0 官网： http://phpseclib.com/ 当然这个包不仅可以使用SSH 还有 SFTP 等，非常好用"}]},{path:"/content/php/base/php%E4%B9%8Bunlink%E5%88%A0%E9%99%A4%E6%9C%AC%E5%9C%B0%E8%B5%84%E6%BA%90.html",title:"php之unlink删除本地资源",pathLocale:"/",contents:[{header:"",slug:"",content:`php之unlink删除本地资源，主要是删除数据库图片资源，一般只是删除的资源链接，没有删除本地文件
可以通过unlink删除连接下对应的资源
$filePath = $publicDir.userPicture->getPath();
$imgCacheManager->remove(userPicture->getPath());
@unlink($filePath);`}]},{path:"/content/php/base/php%E4%B9%8Bunlink%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"php之unlink的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`php之unlink的使用:
unlink filename 只会删除 filename，但不会影响 filename 所在的目录结构。
只适用于文件，不适用于目录（尝试 unlink 目录会报错）。
只是解除目录对该文件的引用，如果该文件仍然被其他进程打开，它的内容不会立即被删除，直到最后一个引用关闭。 例子:
$ mkdir -p testdir/subdir
$ touch testdir/subdir/file.txt
$ unlink testdir/subdir/file.txt # 仅删除 file.txt，不影响 testdir/subdir
$ ls testdir/subdir
# 输出为空，表示文件删除了，但 subdir 仍然存在 实际项目使用:
public function removeFile(string $filePath): void
{ $filePath = $this->dmsDir . $filePath; if (file_exists($filePath)) { if (!unlink($filePath)) { throw new \\Exception("Failed to delete file '$filePath'."); } }
} 上面代码优化:
public function removeFile(string $filePath): void
{ $filePath = $this->dmsDir . $filePath; if (is_file($filePath)) { // 确保它是一个文件, file_exists 对于目录也会返回true, 可以避免误删目录, 虽然这里unlink删除不了目录，但是减少了异常抛出次数 if (!@unlink($filePath)) { //unlink 只能对文件生效 throw new \\RuntimeException("Failed to delete file '$filePath'."); } }
} 关于
file_exists:
https://www.php.net/manual/en/function.file-exists.php is_file:
https://www.php.net/manual/en/function.is-file.php`}]},{path:"/content/php/base/php%E4%B9%8Busort%E5%AF%B9%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E6%8E%92%E5%BA%8F.html",title:"php之usort对二维数组排序",pathLocale:"/",contents:[{header:"",slug:"",content:`php之usort对二维数组排序，其中用到__invoke，感觉很巧妙 <?php
class Sort
{ private $key; public function __construct(string $key) { $this->key = $key; } public function __invoke(array $a, array $b): int { return $a[$this->key] <=> $b[$this->key]; }
}
$customers = [ ['id' => 1, 'first_name' => 'John', 'last_name' => 'Do'], ['id' => 3, 'first_name' => 'Alice', 'last_name' => 'Gustav'], ['id' => 2, 'first_name' => 'Bob', 'last_name' => 'Filipe']
];
// sort customers by first name
usort($customers, new Sort('first_name'));
print_r($customers);
// sort customers by last name
usort($customers, new Sort('last_name'));
print_r($customers);
?> 输出: Array
( [0] => Array ( [id] => 3 [first_name] => Alice [last_name] => Gustav ) [1] => Array ( [id] => 2 [first_name] => Bob [last_name] => Filipe ) [2] => Array ( [id] => 1 [first_name] => John [last_name] => Do )
)
Array
( [0] => Array ( [id] => 1 [first_name] => John [last_name] => Do ) [1] => Array ( [id] => 2 [first_name] => Bob [last_name] => Filipe ) [2] => Array ( [id] => 3 [first_name] => Alice [last_name] => Gustav )
)`}]},{path:"/content/php/base/php%E4%B9%8Byield%E5%85%B3%E9%94%AE%E5%AD%97.html",title:"php之yield关键字",pathLocale:"/",contents:[{header:"",slug:"",content:`php之yield关键字:
这个关键字的学名是 生成器，任何包含 yield 的函数都是一个生成器函数。 生成器函数看起来像普通函数——不同的是普通函数返回一个值，而生成器可以 yield 生成多个想要的值。 当一个生成器被调用的时候，它返回一个可以被遍历的对象.当你遍历这个对象的时候(例如通过一个foreach循环)，PHP 将会在每次需要值的时候调用对象的遍历方法，并在产生一个值之后保存生成器的状态，这样它就可以在需要产生下一个值的时候恢复调用状态。 一旦不再需要产生更多的值，生成器可以简单退出，而调用生成器的代码还可以继续执行，就像一个数组已经被遍历完了。 生成器函数的核心是yield关键字。它最简单的调用形式看起来像一个return申明，不同之处在于普通return会返回值并终止函数的执行，而yield会返回一个值给循环调用此生成器的代码并且只是暂停执行生成器函数。
一个简单的例子:
<?php
function gen_one_to_three() { for ($i = 1; $i <= 3; $i++) { //注意变量$i的值在不同的yield之间是保持传递的。 yield $i; }
} $generator = gen_one_to_three();
foreach ($generator as $value) { echo "$value\\n";
}
?> 输出:
1
2
3 注意:
在内部会为生成的值配对连续的整型索引，就像一个非关联的数组。 生成器能够返回多个值，通过 Generator::getReturn() 可以获取到
一个简单的例子:
<?php $gen = (function() { yield 1; yield 2; return 3;
})(); foreach ($gen as $val) { echo $val, PHP_EOL;
} echo $gen->getReturn(), PHP_EOL; 输出:
1
2
3`}]},{path:"/content/php/base/php%E4%B9%8B%E4%BD%BF%E7%94%A8gd%E5%BA%93%E7%BB%99%E5%9B%BE%E7%89%87%E6%B7%BB%E5%8A%A0%E6%96%87%E5%AD%97%E4%BB%A5%E5%8F%8A%E5%9B%BE%E7%89%87.html",title:"php之使用gd库给图片添加文字以及图片",pathLocale:"/",contents:[{header:"",slug:"",content:`php之使用gd库给图片添加文字以及图片:
这个功能其实很简单，设计出图片模板，然后再指定的位置替换上 指定的内容即可，代码如下:
<?php namespace App\\Service; use Symfony\\Component\\Validator\\Constraints\\Date; class CertificationService
{ public static string $signatureName = 'John Doe'; public static string $prefix = 'certification'; /** * @throws \\Exception */ public static function generateCertification($name, $course, $createdAt): string { $imgPath = './statics/img/certificationTemplate.png'; $fontPathB = './statics/img/suisse/SuisseIntl-SemiBold.otf'; // 600 字体文件 $fontPathM = './statics/img/suisse/SuisseIntl-Medium.otf'; // 500 字体文件 $signaturePath = './statics/img/signature.png'; $img = imagecreatefrompng($imgPath); $font_size = 18; $color = imagecolorallocate($img, 0, 0, 0); if ($name) { $x = 1080; $y = 301 + 20; // 404.6 - (10 + ( 28 - 20 ) / 2) //将$name 方法模板的水平中间位置，这个要先通过 imagettfbbox 将文字格式化为文字盒子，再计算出这个文字盒子的宽高，用 (总宽度 - 盒子宽度)/2，得到中间位置 $nameBox = imagettfbbox($font_size, 0, $fontPathB, $name); self::imageToText($img, $font_size, ceil(($x - $nameBox[2]) / 2), $y, $color, $fontPathB, $name); } $x = 581; $y = 344 + 14 + 8; // 489.6 - (10 + (28 - 20) / 2) self::imageToText($img, $font_size, $x, $y, $color, $fontPathB, $course); //sig 将signature 图片添加到模板的指定位置 $overlayImage = imagecreatefrompng($signaturePath); list($overlayWidth, $overlayHeight) = getimagesize($signaturePath); imagecopy($img, $overlayImage, 656, 456, 0, 0, $overlayWidth, $overlayHeight); if ($name) { $number = ''; array_map(function ($item) use (&$number) { $number .= substr($item, 0, 1); }, explode(" ", ucwords($course))); $number .= ' ' . random_int(10000, 99999); $x = 357; $yNumber = 503 + 24; // 554.6 + 20 + (28 - 20) / 2 self::imageToText($img, 16, $x, $yNumber, $color, $fontPathM, $number); $time = \\date('Y.m.d', time()); $yTime = 537 + 24; self::imageToText($img, 16, $x, $yTime, $color, $fontPathM, $time); } $date = (new \\DateTime())->format('Y-m-d'); $ext = substr($imgPath, strripos($imgPath, '.')); $destDir = 'upload' . '/' . self::$prefix . '/' . $date . '/'; $filename = md5(microtime()) . $ext; if (!is_dir($destDir)) { @mkdir($destDir, 0777, true); } imagepng($img, './' . $destDir . $filename); imagedestroy($img); return $destDir . $filename; } public static function imageToText($img, $font_size, $x, $y, $color, $fontPath, $text): void { imagettftext($img, $font_size, 0, $x, $y, $color, $fontPath, $text); }
}`}]},{path:"/content/php/base/php%E4%B9%8B%E5%8E%BB%E6%8E%89%E5%AF%8C%E6%96%87%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%A0%87%E7%AD%BE.html",title:"php之去掉富文本中的标签",pathLocale:"/",contents:[{header:"",slug:"",content:`在实际使用中，有时候需要计算富文本字数，一估算阅读速度，所以就有必要剥去字符串中的 HTML、XML 以及 PHP 的标签,获取纯文本内容
function contentFormat($content = ''){ $data = $content; $formatData_01 = htmlspecialchars_decode($data);//把一些预定义的 HTML 实体转换为字符 $formatData_02 = strip_tags($formatData_01);//函数剥去字符串中的 HTML、XML 以及 PHP 的标签,获取纯文本内容 return $formatData_02; } //但是在前端使用的时候，还要再 htmlspecialchars_encode 字符串。比如 vue 渲染页面的时候`}]},{path:"/content/php/base/php%E4%B9%8B%E5%8F%8C%E9%87%8Dfor%E5%BE%AA%E5%BA%8F%E4%B8%8Breturn%E5%92%8Cbreak%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"php之双重for循序下return和break的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`php之双重for循序下return和break的区别: /** * @return int * * 下面的方法调用 如果是 return $val, 那么执行 test 方法，会得到 2； 如果是 break ,那么执行 test 方法，会得到 0； */ public function test(): int { $a1 = [1,2,3,4]; $a2 = [2,3]; foreach ($a2 as $val){ foreach ($a1 as $v){ if ($val == $v){ return $val;
// break; } } } return 0; } 总结: return 会结束所有的循环，而 break 只会结束当前循环`}]},{path:"/content/php/base/php%E4%B9%8B%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%B1%9E%E6%80%A7%E6%8F%90%E5%8D%87.html",title:"php之构造函数属性提升",pathLocale:"/",contents:[{header:"php之构造函数属性提升",slug:"php之构造函数属性提升",content:`public function __construct( public readonly ?EmailDto $email,
) {
} 这段代码等效为:
public readonly ?EmailDto $email; public function __construct(?EmailDto $email)
{ $this->email = $email;
} 其中 readonly 是php8.1引入的, 使用的是 constructor property promotion（构造函数属性提升）语法`}]},{path:"/content/php/base/php%E4%B9%8B%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E8%BD%AC%E4%B9%89addslashes.html",title:"php之特殊字符转义addslashes",pathLocale:"/",contents:[{header:"php之特殊字符转义addslashes",slug:"php之特殊字符转义addslashes",content:"addslashes() 的作用就是 在字符串中自动给某些特殊字符前加上反斜杠（\\）进行转义，这样它们在 SQL、PHP 字符串、或其他需要转义的场景中不会被直接当作特殊字符处理。"},{header:"会转义哪些字符？",slug:"会转义哪些字符",content:`addslashes() 会在下面这些字符前加上反斜杠： 单引号 ' → \\'
双引号 " → \\"
反斜杠 \\ → \\\\
NUL（ASCII 0，空字符） → \\0`},{header:"例子",slug:"例子",content:`$str = "O'Reilly";
echo addslashes($str); 输出：
O\\'Reilly 在 SQL 中，如果不转义，O'Reilly 会因为 ' 号破坏语句结构：
SELECT * FROM users WHERE name = 'O'Reilly'; -- ❌ SQL 语法错误 加了 addslashes() 后：
SELECT * FROM users WHERE name = 'O\\'Reilly'; -- ✅ 安全`},{header:"注意",slug:"注意",content:`addslashes() 是最基础的转义方法，并不针对某个特定数据库优化。
在数据库场景里更推荐使用 PDO 或 Doctrine 的参数绑定（Prepared Statements），这样不需要手动转义。
如果必须手动转义，MySQL 其实还有更安全的 mysqli_real_escape_string()（会根据数据库连接的字符集处理转义）。`}]},{path:"/content/php/base/php%E5%9C%A8%E5%9B%BE%E7%89%87%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE%E6%B7%BB%E5%8A%A0%E6%96%87%E5%AD%97%E5%92%8C%E6%B0%B4%E5%8D%B0.html",title:"php在图片指定位置添加文字和水印",pathLocale:"/",contents:[{header:"",slug:"",content:`// 设置图片路径和字体路径
$imgPath = 'image.jpg';
$fontPath = 'arial.ttf'; // 创建图像对象
$img = imagecreatefromjpeg($imgPath); // 设置颜色
$white = imagecolorallocate($img, 255, 255, 255); // 添加文字
$text = 'Hello World!';
$font_size = 20;
$x = 10;
$y = 50;
imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $text); // 添加水印
$watermark = imagecreatefrompng('watermark.png');
$watermark_width = imagesx($watermark);
$watermark_height = imagesy($watermark);
$dest_x = imagesx($img) - $watermark_width - 10;
$dest_y = imagesy($img) - $watermark_height - 10;
imagecopy($img, $watermark, $dest_x, $dest_y, 0, 0, $watermark_width, $watermark_height); // 输出图像
header('Content-Type: image/jpeg');
imagejpeg($img); // 释放内存
imagedestroy($img);
imagedestroy($watermark); 代码解释： 首先，我们需要设置要操作的图像路径和字体路径。
使用 imagecreatefromjpeg() 函数创建一个图像对象。
使用 imagecolorallocate() 函数设置颜色。
使用 imagettftext() 函数在指定位置添加文本。
使用 imagecreatefrompng() 函数创建水印图像对象。
使用 imagesx() 和 imagesy() 函数获取水印图像的宽度和高度。
使用 imagecopy() 函数将水印添加到图像的指定位置。
使用 header() 函数设置图像的 MIME 类型，并使用 imagejpeg() 函数输出图像。
最后，使用 imagedestroy() 函数释放内存。
请注意，此示例中的水印图像是一个 PNG 图像，但可以使用任何支持的图像格式，如 GIF 或 JPEG。 实际项目中使用:
项目使用:
<?php namespace App\\Service; class CertificationService
{ public static function generateCertification(): void {
// 设置图片路径和字体路径 $imgPath = './statics/img/certificationTemplate.png'; $fontPath = './stsong.ttf'; // 创建图像对象 $img = imagecreatefrompng($imgPath); // 设置颜色 $white = imagecolorallocate($img, 255, 255, 255); // 添加文字 $name = 'Ryan Gislong'; $font_size = 20; $x = 100; $y = 496-19; // 496 - (10 + ( 38 - 20 ) / 2) imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $name);
// 添加文字 $course = 'Information for Editors'; $font_size = 20; $x = 100; $y = 587 - 14; // 587 - (10 + (28 - 20) / 2) imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $course);
// 添加文字 $number = 'JTT 108'; $font_size = 20; $x = 292; $y = 692 + 24; // 692 + 20 + (28 - 20) / 2 imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $number); // 添加文字 $createdAt = '08.08.2023'; $font_size = 20; $right_margin = 54; // 右侧边距 $bbox = imagettfbbox($font_size, 0, $fontPath, $createdAt); $text_width = $bbox[2] - $bbox[0]; $x = imagesx($img) - $text_width - $right_margin; $y = 443 + 24; // 692 + 20 + (28 - 20) / 2 imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $createdAt); // 添加文字 $signatureName = 'John Doe'; $font_size = 20; $right_margin = 54; // 右侧边距 $bbox = imagettfbbox($font_size, 0, $fontPath, $signatureName); $text_width = $bbox[2] - $bbox[0]; $x = imagesx($img) - $text_width - $right_margin; $y = 471 + 24; // 692 + 20 + (28 - 20) / 2 imagettftext($img, $font_size, 0, $x, $y, $white, $fontPath, $signatureName); // 添加水印 $watermark = imagecreatefrompng('./statics/img/signature.png'); $watermark_width = imagesx($watermark); $watermark_height = imagesy($watermark); $dest_x = imagesx($img) - $watermark_width - 56; $dest_y = 507; imagecopy($img, $watermark, $dest_x, $dest_y, 0, 0, $watermark_width, $watermark_height);
// 输出图像
// header('Content-Type: image/jpeg');
// imagepng($img); imagewebp($img, './statics/img/new.png'); // 释放内存 imagedestroy($img); imagedestroy($watermark); }
}`}]},{path:"/content/php/base/php%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0.html",title:"php在线运行平台",pathLocale:"/",contents:[{header:"",slug:"",content:`php在线运行平台:
php在线项目(包括代码+域名):
https://phpsandbox.io/ //google账号 php代码片段在线测试(很好用):
https://codapi.org/
https://codapi.org/php/ //选择php的
https://codapi.org/vs/ //关于这个项目
https://antonz.org/ //作者博客,很有用
https://github.com/nalgeon/codapi //项目源码，有必要看一看`}]},{path:"/content/php/base/php%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%89%E7%A7%8D%E5%9C%BA%E6%99%AF.html",title:"php字符串转数组的三种场景",pathLocale:"/",contents:[{header:"",slug:"",content:`1.按照特殊字符分割字符串
$str = 'a,b,c';
$arr = explode(',',$str); 2.按照长度分割字符串
$str = 'abc';
$arr = str_split($str);// 这个在答题系统用的多，用于分割答案 3.利用正则分割字符串
$str = 'a b,c';
$arr = preg_split("/[\\s,]+/",$str); 以上的三种方式，涵盖了PHP字符串切割成数组的常见的应用场景。每一个场景PHP都提供了相应的函数解决，我们要根据具体场景来选择适合的函数，即使preg_split也能够解决所有的字符串分割，但是能够避免正则切割的尽量去避免，相比explode、str_split而言效率低很多，因为需要调用正则引擎这是比较耗费资源的。`}]},{path:"/content/php/base/php%E5%AE%9E%E7%8E%B0%E6%96%90%E6%B3%A2%E6%8B%89%E5%88%87.html",title:"php实现斐波拉切",pathLocale:"/",contents:[{header:"",slug:"",content:`<?php /** * 测试类 * * Created by PhpStorm. * User: guoshipeng * Date: 2022/10/20 * Time: 10:43 */
namespace App\\Http\\Controllers\\Test; use App\\Http\\Controllers\\Controller; class TestController extends Controller
{ /** * 获取斐波拉且 */ public function fb(){ dd($this->getFb(10));
// dd($this->other(5));
// dd($this->getDieDai(5)); } /** * 递归调用实现-斐波拉且 * * @param $n * @return int */ private function getFb($n){ if ($n <= 0){ return 0; } if ($n == 1 || $n == 2){ return 1; } return $this->getFb($n - 1) + $this->getFb($n -2); } /** * 迭代实现-斐波拉且 * * @param $n * @return int */ private function getDieDai($n){ if($n<=1){ return 1; } $sum = 2; $pre = 1; $prepare = 1; for($j = 2; $j <= $n; $j++){ $total = $pre + $prepare; $prepare = $pre; $pre = $total; //当前最新值 echo $total."\\n"; //所有累计和 $sum += $total; } return $sum; } /** * 非递归实现-斐波拉且 * @return mixed */ private function other($n){ $arr[0] = $arr[1] = 1; for($i = 2; $i < $n; $i++){ $arr[$i] = $arr[$i - 1] + $arr[$i -2]; } return $arr; } }`}]},{path:"/content/php/base/php%E5%AF%BC%E5%87%BAexcel%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"php导出excel的几种方式",pathLocale:"/",contents:[{header:"php导出excel的几种方式",slug:"php导出excel的几种方式",content:`方式1 通过API返回的方式ob_start();
try { $writer = IOFactory::createWriter($spreadsheet, 'Xlsx'); $writer->save('php://output'); $data = ob_get_clean(); if (false === $data) { throw new ExportFailedException(); }
} catch (\\Throwable $throwable) { ob_end_clean(); throw new ExportFailedException();
} return new ExportResponseDto(base64_encode($data), $filename . '.xlsx'); 代码结构分析 1.开启输出缓冲区。
2.让 $writer 将 Excel 文件内容写到 php://output（实际上进入缓冲区）。
3.从缓冲区读取数据并清空。
4.如果出错则抛出异常。
5.将文件数据 base64 编码，并和文件名一起封装到 DTO 里返回。 使用场景 1.API 导出文件，因为直接传二进制文件在 JSON 中不方便，所以会先 base64 编码。
2.前端拿到数据后，可以 atob() 解码生成 Blob，然后触发下载。
3.避免直接写临时文件到磁盘，提高性能。 方式2 通过浏览器直接返回<?php namespace App\\Controller; use PhpOffice\\PhpSpreadsheet\\IOFactory;
use PhpOffice\\PhpSpreadsheet\\Spreadsheet;
use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route; class ExportController extends AbstractController
{
#[Route('/export', name: 'app_export_excel')]
public function export(): Response
{ // 1. 创建 Excel 对象 $spreadsheet = new Spreadsheet(); $sheet = $spreadsheet->getActiveSheet(); $sheet->setCellValue('A1', 'Hello World!'); $sheet->setCellValue('B1', date('Y-m-d H:i:s')); // 2. 创建 Writer $writer = IOFactory::createWriter($spreadsheet, 'Xlsx'); // 3. 输出头部，告诉浏览器是 Excel 文件 $filename = 'export_' . date('Ymd_His') . '.xlsx'; header('Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'); header('Content-Disposition: attachment;filename="' . $filename . '"'); header('Cache-Control: max-age=0'); header('Expires: 0'); header('Pragma: public'); // 4. 保存到 php://output（直接输出给浏览器） $writer->save('php://output'); exit; // 终止脚本 }
} 代码结构分析 1.不使用 ob_start()
因为我们不需要获取二进制数据进行二次处理，而是直接输出给浏览器。 2.设置正确的 HTTP 头
让浏览器识别为 Excel 文件并自动下载： Content-Type 指定 MIME 类型为 .xlsx Content-Disposition 指定下载文件名 Cache-Control / Expires / Pragma 用于防止缓存 3.php://output 的作用
它是一个特殊的写入流，写进去的内容会直接发到 HTTP 响应。 4.exit 结束执行
防止 Symfony 在后面再写额外的 HTML 或 JSON 内容破坏文件。`},{header:"php://output 原理",slug:"php-output-原理",content:"php://output 其实是 PHP 提供的一个 特殊的只写（write-only）流封装器，它的核心作用是： 让你用文件流的方式，直接把数据写到 PHP 的 HTTP 响应输出（也就是发送给客户端的内容）。"},{header:"1. 它是什么",slug:"_1-它是什么",content:`php://output 是 php:// 封装器 系列的一员。
类型是 只写流（write-only stream）。
它直接连接到 PHP 的 输出缓冲机制（Output Buffering System）。
写入 php://output 的数据 等效于 执行 echo、print 或 printf。`},{header:"2. 工作原理",slug:"_2-工作原理",content:`应用层写入 代码执行：
file_put_contents('php://output', "Hello World"); 或者库中：
$writer->save('php://output'); 都会将数据写入 php://output 流。 进入输出缓冲区（可选） 如果开启了 ob_start()，数据会先进入缓冲区。
如果没开启缓冲区，数据会直接进入 PHP 的输出处理阶段。 SAPI（Server API）阶段 PHP 会通过对应的 SAPI（如 Apache mod_php、FPM、CLI Server）把数据交给 Web 服务器或直接发给客户端。 客户端接收 最终数据随 HTTP 响应一起发给浏览器、curl、Postman 等客户端。`},{header:"3. 关键特性",slug:"_3-关键特性",content:`无文件落地
不会在磁盘上生成临时文件，直接走内存和输出通道。 可以配合任何支持写入流的 API
比如：
$writer = IOFactory::createWriter($spreadsheet, 'Xlsx');
$writer->save('php://output'); 这时，Excel 数据直接进 HTTP 响应，不用 echo 一堆二进制。 受输出缓冲区影响 如果 ob_start() 已经打开，php://output 会把数据先写入缓冲区，只有 ob_flush() / ob_end_flush() 才会真正发送。
如果没开启缓冲区，直接写到客户端。`},{header:"4. 对比其他 php:// 流",slug:"_4-对比其他-php-流",content:`封装器
用途 php://input
只读，读取原始 HTTP 请求体（比如 JSON、XML、文件上传的原始流） php://output
只写，直接写到 HTTP 响应 php://memory
读写内存中的数据（可随机访问） php://temp
像 memory，但数据超过限制会写到临时文件`},{header:"5. 典型应用",slug:"_5-典型应用",content:`文件导出（Excel、CSV、PDF 等）
header('Content-Type: text/csv');
header('Content-Disposition: attachment;filename="data.csv"');
$fp = fopen('php://output', 'w');
fputcsv($fp, ['id', 'name']);
fputcsv($fp, [1, 'Alice']);
fclose($fp); file_put_contents('php://output', "Hello World");
等价于
echo "Hello World"; 简单分析:
1.file_put_contents 调用: PHP 看到路径是 php://output，就不会去找磁盘文件，而是使用 php:// 封装器 里的 output 模块。 2.进入输出通道: 写入的数据会交给 PHP 的输出系统（Output Handler）。 3.可能先进入输出缓冲区（如果开启了 ob_start()）: 如果有输出缓冲，那么数据先暂存在内存，直到你 ob_flush() 或 ob_end_flush()。 如果没开启缓冲，直接进入下一步。 4.交给 SAPI（Server API）层: PHP 把数据交给运行环境： FPM 模式：交给 PHP-FPM，再发给 Nginx/Apache CLI 模式：直接输出到终端 内置服务器：直接发给浏览器 5.客户端接收并显示 浏览器、curl、Postman 等收到 Hello World。 流式响应大文件（避免一次性加载到内存） 与第三方库对接（很多库支持把生成的数据写到流，而不需要文件路径）`}]},{path:"/content/php/base/php%E5%B0%86%E6%96%87%E5%AD%97%E5%9C%A8%E5%9B%BE%E7%89%87%E4%B8%8A%E5%B1%85%E4%B8%AD.html",title:"php将文字在图片上居中",pathLocale:"/",contents:[{header:"",slug:"",content:`php将文字在图片上居中:
主要通过 imagettftext 实现，以下是示例代码，实际使用可以根据具体需求修改:
$srcImg = imagecreatefrompng($BackgroundImage); $NewpriceColor = imagecolorallocate($srcImg, 231, 71, 57);//设置颜色为红色 $Newprice = 10.00; $fontBox = imagettfbbox(55, 0, $Galyon, $Newprice);//获取文字所需的尺寸大小 // 居中算法
// ceil((700 - $fontBox[2]) / 2) 宽度
// ceil(($height - $fontBox[1] - $fontBox[7]) / 2) 高度 imagettftext($srcImg, 55, 0, ceil((700 - $fontBox[2]) / 2), 395, $NewpriceColor, $Galyon, $Newprice . "元"); imagesavealpha($srcImg,true); // imagepng($srcImg,__RUN__ . 'thumb.png'); header("Content-type:image/png");//png格式
imagepng($srcImg);//输出`}]},{path:"/content/php/base/php%E6%9F%A5%E7%9C%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF.html",title:"php查看配置文件信息",pathLocale:"/",contents:[{header:"",slug:"",content:`php查看配置文件信息:
$ php -i | grep "php.ini"`}]},{path:"/content/php/base/php%E7%9A%84file_exists%E5%92%8Cis_dir%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"php的file_exists和is_dir的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`php的file_exists和is_dir的区别: 在 PHP 中，file_exists 和 is_dir 都是用于检查文件系统的函数，但它们的用途和行为略有不同：
file_exists($path)：
检查指定路径（$path）是否存在，无论是文件还是目录。
返回值为 true 表示该路径存在（文件或目录均可）；为 false 表示路径不存在。
用途广泛，可以用于检查文件或目录是否存在，但不区分类型。
is_dir($path)：
专门用于检查指定路径是否为目录。
返回值为 true 表示路径存在且是目录；为 false 表示路径不存在或路径不是目录（即使它是一个文件）。
常用于在确认一个路径存在并且是目录的情况下进一步操作，比如遍历目录内容。
使用场景对比
如果只需要知道一个路径是否存在（不关心是文件还是目录），可以使用 file_exists。
如果需要确保路径存在且为目录（例如需要遍历或操作目录内容），应使用 is_dir。
示例代码
$path = '/path/to/something'; if (file_exists($path)) { echo "Path exists.\\n";
} if (is_dir($path)) { echo "Path is a directory.\\n";
} 在这个例子中，file_exists 仅判断路径是否存在，而 is_dir 确保路径存在且是目录。`}]},{path:"/content/php/base/php%E8%8E%B7%E5%8F%96%E6%97%B6%E5%8C%BA.html",title:"php获取时区",pathLocale:"/",contents:[{header:"",slug:"",content:`<?php
date_default_timezone_set('America/Los_Angeles');
echo date_default_timezone_get() . ' => ' . date('e') . ' => ' . date('T');
?> 输出:
America/Los_Angeles => America/Los_Angeles => PST`}]},{path:"/content/php/base/php%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95%E4%B9%8B_call.html",title:"php魔术方法之_call",pathLocale:"/",contents:[{header:"",slug:"",content:`在对象中调用一个不可访问的方法时，__call() 会被调用。它是 PHP 魔术方法 中的一种。
语法：
__call ( string $name , array $arguments )
$name 参数是要调用的方法名称。 $arguments 参数是一个枚举数组，包含着要传递给方法 $name 的参数。
调用受限方法：
如果一个类没有设置 __call() ，对象无法调用受限方法。
class Person
{ protected function eat($arg) {}
} 当对象调用受限方法时，会出现以下错误信息:
$person = new Person(); //error: Uncaught Error: Call to protected method Person::eat()
$person->eat('milk'); 设置魔术方法 __call():
class Person
{ protected function eat($args) { foreach ($args as $arg) { echo 'Do you like eating, ' . $arg . '?<br />'; } } public function __call($name, $arguments) { // 如果类中有这个方法，就调用 if ($name === 'eat') { $this->run($arguments); } else { echo 'Calling unavailable function ' . $name . '().<br />'; } }
} $person = new Person(); // Do you like eating, Jack?
// Do you like eating, Rose?
$person->eat('Jack', 'Rose'); 调用不存在的方法,给出调用无效方法的信息提示:
//Calling unavailable function drink().
$person->drink('Jack', 'Rose');`}]},{path:"/content/php/base/php%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95%E4%B9%8B_invoke%E5%92%8C_tostring.html",title:"php魔术方法之_invoke和_tostring_call",pathLocale:"/",contents:[{header:"",slug:"",content:`__tostring()魔术方法 将一个对象当做一个字符串来使用时，会自动调用该方法，并且在该方法中，可以返回一定的字符串，以表明该对象转换为字符串之后的结果。该魔术方法比较常用。 注意：如果没有定义该方法，则对象无法当做字符串来使用！
类里面未定义__tostring()方法的例子：
<?php
ini_set('display_errors', 1);
class A{ public $name; public $age; public $sex; function __construct($name, $age, $sex){ $this->name = $name; $this->age = $age; $this->sex = $sex; }
} $obj1 = new A('周伯通', 18, '男');
echo $obj1; //echo 后面为字符串，而对象不是字符串，会报错 $v1 = "asd" . $obj1; //.为字符串连接符，会报错
$v2 = "123" + $obj1; //+为加法运算符，会报错
?> 这样会报错,那么我们加入__tostring()方法 <?php
ini_set('display_errors', 1);
class A{ public $name; public $age; public $sex; function __construct($name, $age, $sex){ $this->name = $name; $this->age = $age; $this->sex = $sex; } function __tostring(){ $str = "姓名：" . $this->name; $str .= "年龄：" . $this->age; $str .= "，性别：" . $this->sex; return $str; //这里可以返回“任何字符串内容” }
} $obj1 = new A('张三', 28, '男');
echo $obj1; //调用__tostring(),不会报错 ?> 姓名：张三年龄：28，性别：男
可以看到__tostring自动将对象转字符串了 __invoke()魔术方法 将对象当作函数来使用时，会自动调用该方法。通常不推荐这么做。 <?php
class A{ function __invoke(){ echo "<br />函数来调用会出发这里哦！"; }
} $obj = new A();
$obj(); //此时就会调用类中的方法：__invoke()`}]},{path:"/content/php/base/sprintf%E5%92%8Cvsprintf%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"sprintf和vsprintf的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`sprintf和vsprintf的区别:主要是参数格式上的区别
//以参数的形式传递
$res = sprintf("%04d-%02d-%02d", 1988, 8, 1);
//以数组的形式传递
$res = vsprintf("%04d-%02d-%02d", explode('-', '1988-8-1')); dd($res);`}]},{path:"/content/php/base/usort%E6%8E%92%E5%BA%8F.html",title:"usort排序",pathLocale:"/",contents:[{header:"",slug:"",content:`在实际开发过程中，可能会对数组或者对象根据指定的属性排序,那么通过php的usort排序是非常好用的
<?php /** * 测试类 * * Created by PhpStorm. * User: guoshipeng * Date: 2022/10/20 * Time: 10:43 */
namespace App\\Http\\Controllers\\Test; use App\\Http\\Controllers\\Controller; class TestController extends Controller
{ /** * 测试,通过usort配合组合比较进行排序 */ public function index() { //这里简单的用一个普通数组排序，也可以对一个对象中的属性，比如说年龄排序，直接就是 $a->age <=> $b->age //官方文档有很好的说明了: https://www.php.net/manual/en/function.usort.php $a = array(3, 2, 5, 6, 1, 1); usort($a, [self::class, 'cmp']); dd($a);//[1,2,3,4,5,6] } /** * 组合比较 <=> * * @param $a * @param $b * @return int */ private static function cmp($a, $b){ // 太空符，直接比较 //return $a <=> $b; // 原生三目运算 //return $a > $b ? 1 : ( $a==$b ? 0 : -1 ); //return an integer that is either "less than, equal to, or greater than zero". There is no requirement to restrict the value returned to -1, 0, 1. //不一定要返回 1 0 -1，只要是有区分度的三个值都可以 return $a - $b; } }`}]},{path:"/content/php/base/%E5%85%B3%E4%BA%8Eubuntu22%E8%87%AA%E5%90%AF%E5%8A%A8nginx%E6%9C%8D%E5%8A%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"关于ubuntu22自启动nginx服务失败的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`关于ubuntu22自启动nginx服务失败的问题:
1>昨天安装了php8.3,但是过程中好像对apacahe2也自动做了操作
2>今天开机，发现nginx 服务启动不了，报: nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Unknown error)，预感 80 端口被占用，于是按照下面的命令查询
k8s@HPDEV-31:~/code/sciforum-backend-v2$ sudo netstat -anp | grep 80 (记得加sudo/root权限，否则看不到最后面的进程信息)
tcp 0 0 127.0.0.1:59080 127.0.0.1:7890 ESTABLISHED 10711/chrome --type tcp 0 0 188.188.54.160:60980 114.42.229.233:443 ESTABLISHED 10576/clash-linux tcp 0 0 127.0.0.1:7890 127.0.0.1:59080 ESTABLISHED 10576/clash-linux tcp 0 0 188.188.54.160:44326 91.189.91.98:80 TIME_WAIT - tcp6 0 0 :::80 :::* LISTEN 890/apache2 tcp6 0 0 :::20080 :::* LISTEN 5607/java udp 0 0 0.0.0.0:631 0.0.0.0:* 1802/cups-browsed ...
...
果真发现 80 端口被占用，而且是 apache2 占用的，解决方法 要么 stop ，但是下次开机还是有这个问题，要么直接卸载，我这里 直接修改apacahe2使用的默认端口为8088
$ sudo vim /etc/apache2/ports.conf
# If you just change the port or add more ports here, you will likely also
# have to change the VirtualHost statement in
# /etc/apache2/sites-enabled/000-default.conf Listen 8088 <IfModule ssl_module> Listen 443
</IfModule> <IfModule mod_gnutls.c> Listen 443
</IfModule> # vim: syntax=apache ts=4 sw=4 sts=4 sr noet 再重启 apache2:
$ sudo systemctl restart apache2 在执行：$ sudo netstat -anp | grep 80 现在80端口就没有被占用，同时 apache2占用了8088 3>重新启动nginx即可`}]},{path:"/content/php/base/%E5%86%8D%E6%AC%A1%E5%88%86%E6%9E%90php-fpm%E7%9A%84%E6%B1%A0(pool)%E6%8A%80%E6%9C%AF.html",title:"再次分析php-fpm的池(pool)技术",pathLocale:"/",contents:[{header:"",slug:"",content:`//再次分析php-fpm的池(pool)技术
对 PHP-FPM 池（Pool）的总结可以从以下几个方面进行：`},{header:"1. PHP-FPM 池的基本概念",slug:"_1-php-fpm-池的基本概念",content:`PHP-FPM（FastCGI Process Manager）是 PHP 的一个实现，它通过管理多个“池”来处理 PHP 请求。每个“池”负责处理一组特定的请求。
一个池代表一组 PHP 进程，这些进程处理来自 Web 服务器（如 Nginx 或 Apache）的请求。`},{header:"2. 池的配置",slug:"_2-池的配置",content:`每个池有独立的配置文件，通常位于 /usr/local/etc/php-fpm.d/ 目录下。池的配置文件通常以 .conf 为后缀。
默认池配置文件是 www.conf，你可以为不同的应用或服务定义多个池，以便为不同的请求提供不同的 PHP 设置。`},{header:"3. 配置文件中的主要参数",slug:"_3-配置文件中的主要参数",content:`[pool]：每个池的配置文件以 [pool_name] 开头，例如 [www] 表示默认池。你可以创建多个池，每个池可以有独立的配置。 listen：指定 PHP-FPM 监听的地址，可以是 Unix 套接字（.sock 文件）或者 TCP 端口。 例如：listen = /var/run/php-fpm-www.sock 或 listen = 127.0.0.1:9000。 user 和 group：设置 PHP-FPM 进程的运行用户和组，通常设置为 Web 服务器的用户（例如 www-data）。 例如：user = www-data 和 group = www-data。 pm (Process Manager)：控制 PHP-FPM 进程池的管理模式。PHP-FPM 提供三种模式：static、dynamic、ondemand。 static：指定固定数量的 PHP-FPM 进程。
dynamic：根据需求自动调整 PHP-FPM 进程的数量。
ondemand：按需启动进程，减少资源消耗。 pm.max_children：设置池中最大 PHP 进程数。 pm.start_servers、pm.min_spare_servers、pm.max_spare_servers：用于配置 dynamic 模式下的进程数量。 listen.owner 和 listen.group：控制套接字文件的所有者和组。 listen.mode：控制套接字文件的权限（例如 0660）。 slowlog：指定慢日志文件的位置，用于记录处理时间超过一定时间的请求。 request_slowlog_timeout：设置请求处理超过多少时间时，记录到慢日志。`},{header:"4. 多个池的使用场景",slug:"_4-多个池的使用场景",content:`当你需要针对不同的应用或服务使用不同的 PHP 配置时，可以创建多个池。例如，一个池用于处理一般的网页请求，另一个池用于处理大型的后台任务或高并发请求。
可以为不同的池配置不同的 pm 模式和进程数量，以适应不同的需求。`},{header:"5. 使用 Unix 套接字 vs TCP 端口",slug:"_5-使用-unix-套接字-vs-tcp-端口",content:`Unix 套接字：通常更高效，适用于同一台机器上的 Web 服务器与 PHP-FPM 进程之间的通信。
TCP 端口：适用于跨主机通信或在多个主机间进行负载均衡。`},{header:"6. 如何管理和监控池",slug:"_6-如何管理和监控池",content:`你可以通过命令行管理 PHP-FPM，例如：php-fpm -t 用于测试配置文件是否有效，php-fpm -s reload 用于重载 PHP-FPM 配置。
还可以查看每个池的状态，例如：pm.status_path 可以用来配置一个状态页面，供管理员查看 PHP-FPM 的实时状态。`},{header:"7. 池的启动与停止",slug:"_7-池的启动与停止",content:`每个池会由 PHP-FPM 启动时初始化，并根据配置中的设置管理 PHP 进程。如果池没有请求，它将根据 pm 模式的配置来决定进程是否保留在内存中。
你可以通过修改配置文件或重启 PHP-FPM 来启用、禁用或调整池的行为。`},{header:"8. 总结",slug:"_8-总结",content:`池是 PHP-FPM 中的基本单位，它管理着 PHP 进程的生命周期和请求的分配。
每个池可以有不同的配置，可以通过配置文件来调整每个池的行为，例如使用不同的进程管理模式、监听不同的端口或套接字。
Unix 套接字和 TCP 端口 是 PHP-FPM 池的常见监听方式，选择哪种方式取决于具体的需求和环境。 通过以上总结，PHP-FPM 池的配置可以让你灵活地控制和优化 PHP 的处理能力，适应不同的应用场景。
具体配置例子如下:
是的，如果你定义了多个 PHP-FPM 池，通常情况下，你会为每个池配置不同的监听地址或端口。这样做是因为 Unix 套接字（unix socket）是一个文件系统上的资源，而同一时刻一个套接字文件只能由一个进程监听，因此不同的 PHP-FPM 池不能共享同一个 Unix 套接字。`},{header:"使用不同的端口",slug:"使用不同的端口",content:`如果你希望每个池使用不同的监听地址（例如使用不同的端口），你可以为每个池配置不同的端口，例如： 第一个池使用端口 9000： [www]
listen = 127.0.0.1:9000
user = www-data
group = www-data
pm = dynamic
pm.max_children = 50
pm.start_servers = 5 第二个池使用端口 9001： [app1]
listen = 127.0.0.1:9001
user = app1-user
group = app1-group
pm = dynamic
pm.max_children = 20
pm.start_servers = 5 第三个池使用端口 9002： [app2]
listen = 127.0.0.1:9002
user = app2-user
group = app2-group
pm = dynamic
pm.max_children = 10
pm.start_servers = 5`},{header:"使用 Unix 套接字",slug:"使用-unix-套接字",content:`如果你希望多个池共享 Unix 套接字，最简单的做法是将每个池配置为使用不同的 Unix 套接字文件。例如： 第一个池使用 /var/run/php-fpm-www.sock： [www]
listen = /var/run/php-fpm-www.sock
user = www-data
group = www-data
pm = dynamic
pm.max_children = 50
pm.start_servers = 5 第二个池使用 /var/run/php-fpm-app1.sock： [app1]
listen = /var/run/php-fpm-app1.sock
user = app1-user
group = app1-group
pm = dynamic
pm.max_children = 20
pm.start_servers = 5 第三个池使用 /var/run/php-fpm-app2.sock： [app2]
listen = /var/run/php-fpm-app2.sock
user = app2-user
group = app2-group
pm = dynamic
pm.max_children = 10
pm.start_servers = 5`},{header:"配置的选择",slug:"配置的选择",content:`使用不同端口：适用于你有多个 PHP 应用并且需要通过不同端口与不同池通信的场景。例如，Web 服务器（如 Nginx 或 Apache）可以使用不同的端口来代理不同的 PHP 应用请求。
使用 Unix 套接字：如果你希望更高效的通信（因为 Unix 套接字通常比 TCP 套接字更快），并且希望将多个池的 PHP-FPM 请求通过不同的套接字进行管理，这也是一个常见的选择。`},{header:"总结",slug:"总结",content:`如果使用 Unix 套接字（/var/run/php-fpm.sock），每个池必须使用不同的套接字文件。
如果使用 TCP/IP 端口（127.0.0.1:9000），则可以为每个池分配不同的端口号，确保每个池有独立的端口。 因此，当定义多个池时，Unix 套接字和端口号的选择会根据你的具体需求而定。如果你希望使用 Unix 套接字，可以确保每个池使用不同的套接字文件；如果你希望使用端口号，可以为每个池分配不同的端口。
Unix 套接字文件（.sock 文件）通常是由 PHP-FPM 在启动时 自动创建 的。你不需要手动创建这些文件。只要在 PHP-FPM 池配置文件中指定了 listen 参数，并且该值指向一个 Unix 套接字路径（例如 /var/run/php-fpm.sock），PHP-FPM 就会自动创建并使用这个套接字文件。`},{header:"相关的自动创建过程：",slug:"相关的自动创建过程",content:"PHP-FPM 启动时：当你启动 PHP-FPM 服务时，配置文件中指定的 Unix 套接字文件会自动生成。 例如，在 PHP-FPM 池的配置文件中，listen 设置为 listen = /var/run/php-fpm.sock，那么在 PHP-FPM 启动时，PHP-FPM 会自动在 /var/run/ 目录下创建一个名为 php-fpm.sock 的套接字文件。 目录存在与否：如果配置文件指定的目录（如 /var/run/）不存在，PHP-FPM 启动时会报告错误，提示无法创建套接字文件。因此，确保配置的目录是存在的且有合适的权限。 套接字文件的权限：PHP-FPM 会根据配置的 user 和 group 设置来确定创建的套接字文件的权限和所有者。例如，listen.owner 和 listen.group 参数可以用来控制套接字文件的所有者。"},{header:"举例：",slug:"举例",content:`假设你在 PHP-FPM 配置中设置了如下内容：
[www]
listen = /var/run/php-fpm-www.sock
listen.owner = www-data
listen.group = www-data
listen.mode = 0660 当 PHP-FPM 启动时，会执行以下步骤： PHP-FPM 检查 /var/run/ 目录是否存在。如果该目录不存在，PHP-FPM 将报告错误。
PHP-FPM 在 /var/run/ 目录下自动创建 php-fpm-www.sock 文件。
PHP-FPM 根据配置设置套接字文件的所有者、组和权限（如 www-data 用户、组，以及权限为 0660）。`},{header:"手动删除套接字文件：",slug:"手动删除套接字文件",content:"如果你手动删除了套接字文件，PHP-FPM 在下次启动时会自动重新创建它。所以，无需担心手动删除套接字文件，PHP-FPM 会负责重新创建它。"},{header:"总结：",slug:"总结-1",content:`自动创建：PHP-FPM 会在启动时自动创建指定路径的 Unix 套接字文件，无需手动干预。
配置时：只需要在配置文件中正确指定 listen 参数为套接字路径，PHP-FPM 会自动处理文件的创建和管理。 //如果配置了多个端口，那么对于Dockerfile下的EXPOSE就需要多个
EXPOSE 9000 会暴露容器内的 9000 端口到外部。如果你在 PHP-FPM 配置中定义了多个端口（如 9000、9001、9002），那么 EXPOSE 9000 只会暴露容器内的 9000 端口，这就可能会导致访问其他端口（如 9001 或 9002）时出现问题。
为了处理这种情况，你需要在 Dockerfile 中使用多个 EXPOSE 指令，分别暴露不同的端口，例如：
EXPOSE 9000
EXPOSE 9001
EXPOSE 9002 这样，容器会同时暴露 9000、9001 和 9002 端口，允许外部访问对应的端口。`},{header:"另外的考虑：",slug:"另外的考虑",content:`Nginx 或其他 Web 服务器：如果你使用的是 Nginx 或其他 Web 服务器作为反向代理，确保你的配置文件正确地代理了不同的端口。
Docker Compose：如果你使用 Docker Compose 配置了多个服务，并希望每个服务绑定到不同的端口，可以在 docker-compose.yml 文件中配置端口映射，如： services: php-fpm: build: context: . ports: - "9000:9000" - "9001:9001" - "9002:9002" 这样做可以确保不同的端口映射到宿主机上，允许你根据需求访问容器的不同端口。不过一般不会暴露php的端口到外部，上面的可以不用配置ports`}]},{path:"/content/php/base/%E5%86%8D%E6%AC%A1%E6%8E%A2%E7%A9%B6FastCGI%E5%92%8CPHP-FPM%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"再次探究FastCGI和PHP-FPM之间的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`再次探究FastCGI和PHP-FPM之间的关系:
理解 FastCGI 和 PHP-FPM 之间的关系，确实有点容易混淆。让我帮你澄清一下两者的不同和它们之间的关系。`},{header:"FastCGI 是什么？",slug:"fastcgi-是什么",content:`FastCGI 是一种协议和标准，用于在 Web 服务器和应用服务器之间高效地传递数据。它的作用是使 Web 服务器能够与后端程序（如 PHP、Python、Perl 等）进行交互，并在 Web 请求处理过程中实现更高效的性能和并发。 FastCGI 协议 是 CGI（Common Gateway Interface）协议的一个改进版。它通过持续的进程和连接避免了每次请求都启动新的进程，从而提高性能。
FastCGI 允许 Web 服务器与应用程序进行持续的连接，从而减少了每次请求的启动成本。 FastCGI 的工作流程： Web 服务器（如 Nginx 或 Apache）通过 FastCGI 协议将请求发送给应用服务器（例如 PHP）。
FastCGI 会保持 Web 服务器与应用服务器之间的连接，使得处理多个请求时更加高效。
Web 服务器接收来自应用服务器的响应并返回给客户端。`},{header:"PHP-FPM 是什么？",slug:"php-fpm-是什么",content:`PHP-FPM（PHP FastCGI Process Manager）是 PHP 实现 FastCGI 协议的一个管理程序，专门用来处理 PHP 脚本的执行。它是 PHP 的一个进程管理器，用于高效地处理 PHP 请求。 PHP-FPM 是 PHP 提供的一个解决方案，用于管理多个 PHP 进程，并通过 FastCGI 协议与 Web 服务器（如 Nginx 或 Apache）进行通信。
它主要负责管理 PHP 的进程池、负载均衡、进程资源分配、监听端口或 Unix 套接字等。 PHP-FPM 的工作流程： PHP-FPM 接收到来自 Web 服务器的请求（通过 FastCGI 协议）。
PHP-FPM 管理的 PHP 进程池会处理 PHP 脚本，并执行其中的代码。
执行完成后，PHP-FPM 将结果返回给 Web 服务器，Web 服务器再把结果发送给客户端。`},{header:"FastCGI 和 PHP-FPM 的关系",slug:"fastcgi-和-php-fpm-的关系",content:`FastCGI 是一种协议，而 PHP-FPM 是 PHP 的实现，它采用了 FastCGI 协议来与 Web 服务器进行交互。
FastCGI 是一种通用的协议，可以用于多种应用服务器，而 PHP-FPM 是专为 PHP 设计的 FastCGI 进程管理器。
PHP-FPM 本质上是 PHP 实现 FastCGI 协议的一个工具，处理 PHP 请求时，Web 服务器通过 FastCGI 协议与 PHP-FPM 通信，传递 PHP 脚本执行请求和获取结果。`},{header:"简单的总结：",slug:"简单的总结",content:`FastCGI 是一个协议，它定义了 Web 服务器与应用服务器之间的通信方式。
PHP-FPM 是 PHP 实现 FastCGI 协议的进程管理器，它用来处理 Web 服务器发来的 PHP 请求。 因此，PHP-FPM 实际上是通过 FastCGI 协议与 Web 服务器（如 Nginx 或 Apache）交互的工具。`}]},{path:"/content/php/base/%E5%86%8D%E6%AC%A1%E6%8E%A2%E7%A9%B6php-cli%E5%92%8Cphp-fpm.html",title:"再次探究php-cli和php-fpm",pathLocale:"/",contents:[{header:"",slug:"",content:`再次探究php-cli和php-fpm:
1>加载的php.ini文件(docker环境下)
root@ca4989b3147e:/usr/local/etc# php-fpm -i | grep 'php.ini'
Configuration File (php.ini) Path => /usr/local/etc/php
Loaded Configuration File => /usr/local/etc/php/php.ini
/usr/local/etc/php/conf.d/php.ini root@ca4989b3147e:/usr/local/etc# php -i | grep 'php.ini'
Configuration File (php.ini) Path => /usr/local/etc/php
Loaded Configuration File => /usr/local/etc/php/php.ini
/usr/local/etc/php/conf.d/php.ini 通过上面的信息可以知道:
PHP-CLI 和 PHP-FPM 会共享相同的配置，包括扩展加载、内存限制等。
如果你在这个 php.ini 中做了修改，比如调整 memory_limit 或者添加扩展模块配置，两个环境都会受到影响。 也可以:
php --ini 查看所有的ini配置，如下:
root@ca4989b3147e:/usr/local/etc/php/conf.d# php --ini
Configuration File (php.ini) Path: /usr/local/etc/php
Loaded Configuration File: /usr/local/etc/php/php.ini
Scan for additional .ini files in: /usr/local/etc/php/conf.d
Additional .ini files parsed: /usr/local/etc/php/conf.d/date.ini,
/usr/local/etc/php/conf.d/docker-fpm.ini,
/usr/local/etc/php/conf.d/docker-php-ext-gd.ini,
/usr/local/etc/php/conf.d/docker-php-ext-intl.ini,
/usr/local/etc/php/conf.d/docker-php-ext-mysqli.ini,
/usr/local/etc/php/conf.d/docker-php-ext-pcntl.ini,
/usr/local/etc/php/conf.d/docker-php-ext-pdo_mysql.ini,
/usr/local/etc/php/conf.d/docker-php-ext-redis.ini,
/usr/local/etc/php/conf.d/docker-php-ext-sockets.ini,
/usr/local/etc/php/conf.d/docker-php-ext-sodium.ini,
/usr/local/etc/php/conf.d/docker-php-ext-xsl.ini,
/usr/local/etc/php/conf.d/docker-php-ext-zip.ini,
/usr/local/etc/php/conf.d/php.ini 2>docker环境下，默认php镜像会有如下环境变量 $PHP_INI_DIR, 会默认创建, 所以可以直接在脚本里面使用
root@ca4989b3147e:/usr/local/etc# echo $PHP_INI_DIR
/usr/local/etc/php 3>二者之间的关系
理解 PHP-CLI 和 PHP-FPM 之间的关系同样重要。两者都是 PHP 的运行模式，但它们适用于不同的场景和用途。让我们深入探讨一下它们的区别和联系。`},{header:"PHP-CLI（PHP Command Line Interface）",slug:"php-cli-php-command-line-interface",content:`PHP-CLI 是 PHP 的命令行接口，用于在命令行下执行 PHP 脚本。
这种模式不涉及 Web 服务器，因此它没有像 PHP-FPM 一样的请求处理机制。
PHP-CLI 主要用于执行脚本，通常是用于命令行工具、任务调度器、脚本自动化、测试等场景。
它适用于单独运行脚本，不依赖于 Web 服务器。`},{header:"特点：",slug:"特点",content:`直接通过命令行执行 PHP 脚本（例如，php myscript.php）。
不依赖 Web 服务器，独立于 HTTP 请求。
配置文件（php.ini）通常位于 /etc/php/cli 或类似目录。
没有请求处理和进程池管理的复杂性。`},{header:"PHP-FPM（PHP FastCGI Process Manager）",slug:"php-fpm-php-fastcgi-process-manager",content:`PHP-FPM 是一个 PHP 的进程管理器，专门用来处理 Web 服务器（如 Nginx 或 Apache）通过 FastCGI 协议发来的 PHP 请求。
它是为高并发的 Web 环境设计的，可以处理多个并发请求，通过配置进程池来高效管理 PHP 进程。
PHP-FPM 主要应用于生产环境，尤其是与 Web 服务器结合使用时，它通过 FastCGI 协议来接收和响应 Web 服务器的请求。`},{header:"特点：",slug:"特点-1",content:`与 Web 服务器（如 Nginx 或 Apache）结合，处理来自浏览器的 HTTP 请求。
通过 FastCGI 协议与 Web 服务器交互。
配置文件（php.ini 和 php-fpm.conf）通常位于 /etc/php-fpm.d/ 或类似目录。
具有进程池、负载均衡、动态进程管理等高级特性。`},{header:"PHP-CLI 与 PHP-FPM 的关系",slug:"php-cli-与-php-fpm-的关系",content:`虽然 PHP-CLI 和 PHP-FPM 都是运行 PHP 的方式，它们的主要区别在于使用场景和处理方式： PHP-CLI 用于 命令行执行，直接运行 PHP 脚本，通常不涉及 Web 请求。它是 PHP 的 "独立模式"。
PHP-FPM 用于 Web 环境，通过 FastCGI 协议与 Web 服务器（如 Nginx 或 Apache）配合工作，处理 HTTP 请求。`},{header:"如何切换：CLI 与 FPM 之间的不同",slug:"如何切换-cli-与-fpm-之间的不同",content:`CLI 模式下，执行的 PHP 脚本并不需要 Web 服务器的支持，也不需要处理 HTTP 请求。它更多用于后台任务或批量处理。
FPM 模式下，PHP 被配置为与 Web 服务器（如 Nginx）一起工作，处理用户发来的 HTTP 请求。这意味着 PHP 进程池的管理和资源分配变得更加重要。`},{header:"总结",slug:"总结",content:`PHP-CLI 是命令行接口，适用于脚本执行，常用于开发、测试和后台任务。
PHP-FPM 是 PHP 的进程管理器，专为 Web 环境设计，通过 FastCGI 协议与 Web 服务器协同工作处理 PHP 请求。 两者的选择取决于你要运行 PHP 的环境：是处理 Web 请求，还是执行后台任务。`}]},{path:"/content/php/base/%E5%86%8D%E6%AC%A1%E6%8E%A2%E7%A9%B6php-ini%E5%92%8Cphp-fpm%E9%85%8D%E7%BD%AE%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"再次探究php-ini和php-fpm配置的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`再次理解php.ini和php-fpm配置的关系,可以这样总结： php.ini 负责处理 PHP 的程序配置： php.ini 是 PHP 的全局配置文件，定义了 PHP 的核心行为和资源限制，影响所有 PHP 程序的执行。它管理诸如内存限制、最大执行时间、错误日志、文件上传限制等配置。
当 PHP 脚本在 PHP-FPM 进程中执行时，这些配置都会被加载并应用。 php-fpm 负责管理 PHP 进程池和与 Web 服务器的交互： php-fpm 是 PHP 的进程管理器，专门处理来自 Web 服务器（如 Nginx 或 Apache）发送的请求。它管理多个 PHP 进程池、负载均衡、进程资源分配等。
PHP-FPM 的任务是接收请求、分配合适的工作进程来处理 PHP 脚本请求，然后这些工作进程会加载 PHP 配置（包括 php.ini）来执行脚本。`},{header:"流程简述：",slug:"流程简述",content:`Web 服务器（如 Nginx 或 Apache） 接收到客户端的请求。
Web 服务器将请求传递给 PHP-FPM（通常通过 FastCGI 协议）。
PHP-FPM 根据配置决定如何处理请求： 它根据配置的进程池（php-fpm.d 中的 www.conf 等配置文件）分配一个 PHP 进程来处理请求。
该进程启动后，会加载 PHP 配置（包括 php.ini），并根据其中的设置来处理 PHP 脚本。 PHP 执行完脚本后，PHP-FPM 将执行结果返回给 Web 服务器，最终响应客户端。`},{header:"关键点：",slug:"关键点",content:`php.ini 影响 PHP 脚本的执行行为，而 php-fpm 主要负责进程管理和请求分发。
PHP 脚本的执行会遵循 php.ini 中的配置，所以 PHP-FPM 管理的工作进程会在执行时依照 php.ini 设置来处理脚本。 综上所述，你理解得非常正确，PHP-FPM 是管理和分配 PHP 请求的，而 PHP 脚本执行时的所有配置（如内存限制、错误处理等）都由 php.ini 来控制。`}]},{path:"/content/php/base/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E4%BB%A3%E4%B8%AD%E7%9A%84%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C.html",title:"如何解决代中的删除操作",pathLocale:"/",contents:[{header:"",slug:"",content:"接下来让我们看一看如何实现这个删除操作的: /** * 删除 * * @param $id * @return bool */ public static function destroy($id) { // 这是一个查询操作 $data = Company::query()->where('id', $id)->whereNull('deleted_at')->first(); if (!$data) { return false; } try { DB::transaction(function () use ($data, $id) { Company::destroy($id); $data->synTags(); $data->synDemandTags(); $data->syncCategories(); }); } catch (\\Throwable $e) { return false; } return true 再来一个定时任务的shell脚本 #!/bin/bash export JAVA_HOME=/usr export PATH=$PATH:$JAVA_HOME/bin start=`date -d yesterday +%Y-%m-%d` #date -d yesterday +%Y-%m-%d end=`date +%Y-%m-%d` while [ \"${start}\" != \"${end}\" ] do echo $start"}]},{path:"/content/php/base/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E4%BB%A3%E4%B8%AD%E7%9A%84%E6%96%B0%E5%A2%9E%E6%93%8D%E4%BD%9C.html",title:"如何解决代中的新增操作",pathLocale:"/",contents:[{header:"",slug:"",content:"/** * 保存 * * User: guoshipeng * @param array $params * @return bool */ public static function store($params = []) { $data['name'] = $params['name'] ?? ''; $data['mobile'] = $params['mobile'] ?? ''; $data['email'] = $params['email'] ?? ''; $data['wechat'] = $params['wechat'] ?? ''; $data['company_name'] = $params['company_name'] ?? ''; $data['position'] = $params['position'] ?? ''; $data['demand'] = $params['demand'] ?? ''; $data['desire'] = $params['desire'] ?? 0; $data['customer_type'] = $params['customer_type'] ?? 0; if (CustomerCompany::query()->create($data)) { return true; } return false; }"}]},{path:"/content/php/base/%E5%BF%BD%E7%95%A5phpstan%E5%AF%B9%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E7%9A%84%E6%A3%80%E6%9F%A5.html",title:"忽略phpstan对方法参数的检查",pathLocale:"/",contents:[{header:"",slug:"",content:`忽略phpstan对方法参数的检查:
ignoreErrors: - "#Method [a-zA-Z0-9\\\\_\\\\\\\\:\\\\(\\\\)]+ has parameter \\\\$[a-zA-Z0-9_]+ with no value type specified in iterable type array#" - "#Method [a-zA-Z0-9\\\\_\\\\\\\\:\\\\(\\\\)]+ return type has no value type specified in iterable type array#" - "#Property [a-zA-Z0-9\\\\$\\\\_\\\\\\\\:\\\\(\\\\)]+ type has no value type specified in iterable type array#" 参考:https://github.com/phpstan/phpstan/discussions/7287 上面是之前的写法，主要目的是: 想给 $left 和 $right 类型声明，但是 array 值的类型，一直不确定，后来发现可以按下面的方式解决，原来是mixed就可以了，不用添加如上配置 /** * @param array<mixed> $left * @param array<mixed> $right */ public function compareByDate($left = [], $right = [], string $order = 'asc'): int { $dateLeft = $left['date']->getTimestamp(); $dateRight = $right['date']->getTimestamp(); $result = ($dateLeft < $dateRight) ? -1 : 1; return ('asc' == $order) ? $result : -$result; }`}]},{path:"/content/php/base/%E6%96%B0%E4%B8%80%E4%BB%A3phpexcel%E5%AF%BC%E5%87%BA%E6%8F%92%E4%BB%B6.html",title:"新一代phpexcel导出插件",pathLocale:"/",contents:[{header:"",slug:"",content:`新一代phpexcel导出插件:
https://github.com/PHPOffice/PhpSpreadsheet`}]},{path:"/content/php/base/%E6%9F%A5%E7%9C%8Bphp-fpm%E9%85%8D%E7%BD%AE%E6%98%AF%E5%90%A6%E7%94%9F%E6%95%88.html",title:"查看php-fpm配置是否生效",pathLocale:"/",contents:[{header:"",slug:"",content:`//查看php-fpm配置是否生效:
root@ca4989b3147e:/usr/local/etc/php-fpm.d# php-fpm -t
[22-Jan-2025 11:24:24] NOTICE: configuration file /usr/local/etc/php-fpm.conf test is successful //查看当前php-fpm的哪些配置生效
root@ca4989b3147e:/usr/local/etc# php-fpm -tt [22-Jan-2025 10:52:04] NOTICE: [global]
[22-Jan-2025 10:52:04] NOTICE: pid = undefined
[22-Jan-2025 10:52:04] NOTICE: error_log = /proc/self/fd/2
[22-Jan-2025 10:52:04] NOTICE: syslog.ident = php-fpm
[22-Jan-2025 10:52:04] NOTICE: syslog.facility = 24
[22-Jan-2025 10:52:04] NOTICE: log_buffering = yes
[22-Jan-2025 10:52:04] NOTICE: log_level = unknown value
[22-Jan-2025 10:52:04] NOTICE: log_limit = 8192
[22-Jan-2025 10:52:04] NOTICE: emergency_restart_interval = 0s
[22-Jan-2025 10:52:04] NOTICE: emergency_restart_threshold = 0
[22-Jan-2025 10:52:04] NOTICE: process_control_timeout = 0s
[22-Jan-2025 10:52:04] NOTICE: process.max = 0
[22-Jan-2025 10:52:04] NOTICE: process.priority = undefined
[22-Jan-2025 10:52:04] NOTICE: daemonize = no
[22-Jan-2025 10:52:04] NOTICE: rlimit_files = 0
[22-Jan-2025 10:52:04] NOTICE: rlimit_core = 0
[22-Jan-2025 10:52:04] NOTICE: events.mechanism = epoll
[22-Jan-2025 10:52:04] NOTICE: [22-Jan-2025 10:52:04] NOTICE: [www]
[22-Jan-2025 10:52:04] NOTICE: prefix = undefined
[22-Jan-2025 10:52:04] NOTICE: user = www-data
[22-Jan-2025 10:52:04] NOTICE: group = www-data
[22-Jan-2025 10:52:04] NOTICE: listen = 9000
[22-Jan-2025 10:52:04] NOTICE: listen.backlog = -1
[22-Jan-2025 10:52:04] NOTICE: listen.owner = undefined
[22-Jan-2025 10:52:04] NOTICE: listen.group = undefined
[22-Jan-2025 10:52:04] NOTICE: listen.mode = undefined
[22-Jan-2025 10:52:04] NOTICE: listen.allowed_clients = undefined
[22-Jan-2025 10:52:04] NOTICE: process.priority = undefined
[22-Jan-2025 10:52:04] NOTICE: process.dumpable = no
[22-Jan-2025 10:52:04] NOTICE: pm = dynamic
[22-Jan-2025 10:52:04] NOTICE: pm.max_children = 5
[22-Jan-2025 10:52:04] NOTICE: pm.start_servers = 2
[22-Jan-2025 10:52:04] NOTICE: pm.min_spare_servers = 1
[22-Jan-2025 10:52:04] NOTICE: pm.max_spare_servers = 3
[22-Jan-2025 10:52:04] NOTICE: pm.max_spawn_rate = 32
[22-Jan-2025 10:52:04] NOTICE: pm.process_idle_timeout = 10
[22-Jan-2025 10:52:04] NOTICE: pm.max_requests = 0
[22-Jan-2025 10:52:04] NOTICE: pm.status_path = undefined
[22-Jan-2025 10:52:04] NOTICE: pm.status_listen = undefined
[22-Jan-2025 10:52:04] NOTICE: ping.path = undefined
[22-Jan-2025 10:52:04] NOTICE: ping.response = undefined
[22-Jan-2025 10:52:04] NOTICE: access.log = /proc/self/fd/2
[22-Jan-2025 10:52:04] NOTICE: access.format = %R - %u %t "%m %r" %s
[22-Jan-2025 10:52:04] NOTICE: slowlog = undefined
...
...`}]},{path:"/content/php/base/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E7%94%B1php%E6%AD%A3%E5%88%99%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"记录一个由php正则引起的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`记录一个由php正则引起的问题:
//有如下内容，需要正则匹配 Reviewer comments 后的内容，但是开始没有考虑到回车的问题，所以导致匹配内容为空的问题
$comments = '<strong>Reviewer recommendation:</strong> Revision<br/><strong>Reviewer comments:</strong> s revisions - there is some merit in this submission, but it fails to meet all the requirements for presenting it in this eve
55355345';
if (strpos($comments, 'Reviewer comments')) {
// preg_match('/<strong>Reviewer comments:<\\/strong>\\s*(.*?)$/', $comments, $matches); preg_match('/<strong>Reviewer comments:<\\/strong>\\s*(.*?)$/s', $comments, $matches); dd($matches);
} (.*?)解释: (.*?) 是一个非贪婪匹配组合，用于匹配任意字符，不包括换行符，但以最短的方式匹配。让我来解释一下它的各个部分：
( 和 )：这是捕获组，用于将匹配的内容捕获到一个单独的组中，以便稍后可以通过变量或数组引用。 .*?：这是一个非贪婪匹配的表达式，其中：
. 匹配任意字符（除了换行符）。
* 表示匹配前面的字符零次或多次。
? 表示非贪婪匹配，即以最短的方式匹配。 最短的方式:
意味着正则表达式引擎会尽可能地匹配最短的字符串
假如有这样的字符串: <p>Hello</p><p>World</p> 现在，我们使用正则表达式 /<p>.*?<\\/p>/ 来匹配两个 <p> 标签之间的内容。 在这个正则表达式中，.*? 是一个非贪婪匹配，它将匹配任意字符（包括换行符），但以最短的方式匹配。所以，整个表达式将匹配两个 <p> 标签之间的最短内容，即： <p>Hello</p>
<p>World</p> 如果我们使用贪婪匹配，即 /<p>.*<\\/p>/，那么整个表达式将匹配两个 <p> 标签之间的最长内容，即：
<p>Hello</p><p>World</p> 注意表达式里的两个 s 的意义不同: \\s 是用来匹配空白字符的元字符。具体来说，\\s 匹配空格、制表符、换行符等空白字符。 使用 /s 修饰符会改变 . 的行为，结尾的 /s 修饰符表示单行模式（single-line mode），使其匹配包括空白字符（whitespace）在内的任意字符。空白字符包括空格、制表符、换行符等。
具体来说，/s 修饰符会使得 . 匹配以下字符： 空格（space）
制表符（tab）
换行符（newline）
回车符（carriage return）
垂直制表符（vertical tab）
换页符（form feed）
所以，当你使用 /s 修饰符时，. 将匹配包括 <br> 标签中的换行符 \\n 在内的任意字符。 同时，由于 $ 锚点匹配行尾，不包括换行符在内。如果不使用 /s 修饰符，$ 将匹配行尾而不是整个字符串的末尾，因此不会包括换行符，以及换行符之后的内容。`}]},{path:"/content/search/solr/solr%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF.html",title:"solr的客户端",pathLocale:"/",contents:[{header:"",slug:"",content:`solr的客户端:
php:
composer require solarium/solarium 直接API调用:
设置了用户名和密码的,在header头下添加认证:
Authorization: Basic base64(username:password) // base64(username:password) 需要手动生成
然后就可以调用API了. php下生成加密信息:
//官方加密方式少了一个 ')' 号
base64(sha256(sha256(salt+password))) base64(salt)， 中间有个空格 //security.json配置如下:
{ "authentication":{ "blockUnknown": true, "class":"solr.BasicAuthPlugin", "credentials":{"solr":"ua1+S+w/1HipuKpWrOrhGkhH6mLJe+j0YvzPLOoe0KM= aGFoYQ=="}, // 分别是用户名和 加密的密码以及密码盐 "realm":"My Solr users", "forwardCredentials": false }
} //加密算法
$name= 'solr';
$pwd = 'hello solr';
$salt = 'haha'; $hash = hash('sha256', hash('sha256', $salt.$pwd, true), true); // true 表示输出原始二进制数据,必须要设置，否则生成的hash值验证不通过
$res_pwd = base64_encode($hash);
$res_salt = base64_encode($salt); dd($res_pwd.'-----'.$res_salt); base64在线工具: https://base64.us/`}]},{path:"/content/search/solr/ubuntu%E4%B8%8Bsolr%E5%AE%89%E8%A3%85.html",title:"ubuntu下solr安装",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu下solr安装:
打开下载链接:https://solr.apache.org/downloads.html，我是通过二进制安装的，直接可以执行bin文件 使用:https://www.fanhaobai.com/2017/08/solr-search.html solr的php客户端:https://github.com/solariumphp/solarium
symfony框架下对上面客户端的封装使用:https://github.com/nelmio/NelmioSolariumBundle 启动:
sudo ./bin/solr start -p 8983 -force //注意可能会报 java not found，那是因为 sudo 操作下的 环境变量[不是在 /etc/progile下]的问题，需要去sudo vim /etc/sudoers 下添加java的bin环境变量,加- force的原因是，solr 不希望使用root权限启动，但是可以通过force强制执行 重启:
sudo ./bin/solr restart -p 8983 -force 相关命令参考:
solr start -p p_num 启动solr
solr restart -p p_num 重启solr
solr stop -p p_num 关闭solr
solr create -c c_name 创建一个核心 出现下面的提示，即为ok了:
*** [WARN] *** Your open file limit is currently 1024. It should be set to 65000 to avoid operational disruption. If you no longer wish to see this warning, set SOLR_ULIMIT_CHECKS to false in your profile or solr.in.sh
Java 17 detected. Enabled workaround for SOLR-16463
Warning: Available entropy is low. As a result, use of the UUIDField, SSL, or any other features that require
RNG might not work properly. To check for the amount of available entropy, use 'cat /proc/sys/kernel/random/entropy_avail'. Waiting up to 180 seconds to see Solr running on port 8983 [|] Started Solr server on port 8983 (pid=50992). Happy searching! 报错:
Your open file limit is currently 1024. It should be set to 65000 to avoid operational disruption 解决办法: 打开/etc/systemd/system.conf，添加如下内容: DefaultLimitNOFILE=65000
DefaultLimitNPROC=65000 重新启动:
sudo systemctl daemon-reload 检查设置是否生效:
~ # systemctl show | egrep "NOFILE|NPROC"
DefaultLimitNOFILE=65000
DefaultLimitNOFILESoft=65000
DefaultLimitNPROC=65000
DefaultLimitNPROCSoft=65000 然而还是可能报上面的问题，但是不影响使用，只是一个警告 访问:http://localhost:8983/solr 即可打开页面 创建core:
进入到 /usr/local/solr-9.3.0/server/solr 创建core相关文件夹，比如我建立一个叫 paper_core的文件夹，然后进入这个文件夹，然后在这个文件夹下创建solrconfig.xml和schema.xml文件。这两个文件有了，就可以重新访问8983这个客户端链接，添加 名称为paper_core的core. solrconfig.xml配置[使用其中的一部分]
其中比较重要的：
<lib dir="\${solr.install.dir:../../../..}/dist/" regex="solr-dataimporthandler-.*\\.jar"/> //安装的更目录下有个dist文件夹
<lib dir="\${solr.install.dir:../../../..}/contrib/dataimporthandler/lib/" regex="mysql-connector-java-\\d.*\\.jar"/> //安装的更目录下有个contrib/dataimporthandler,需要手动创建一个lib，然后将mysql-connector-j-8.0.33.jar包放进去，此时mysql-connector-j和mysql-connector-java不匹配，所以要改一下,改成:mysql-connector-j-\\d.*\\.jar即可 https://blog.csdn.net/csdn_fan321/article/details/103110399
schema.xml配置[gpt生成] 官方使用文档:
https://solr.apache.org/guide/solr/latest/indexing-guide/indexing-with-update-handlers.html
旧版本:https://archive.apache.org/dist/lucene/solr/ //8.6之后废弃了dataimporthandler,所以，我重新安装了8.5， 导入数据:
https://learnku.com/articles/50702 报错:Could not load driver: com.mysql.jdbc.Driver Processing Document 需要配置jdbc的jar包，需要去 https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/ 下载[我的msyql是8.0版本下的8.0.34，目前只能下载8.0.33]
然后修改solrconfig.xml中的配置:
<lib dir="\${solr.install.dir:../../../..}/dist/" regex="solr-dataimporthandler-.*\\.jar"/> //安装的更目录下有个dist文件夹
<lib dir="\${solr.install.dir:../../../..}/contrib/dataimporthandler/lib/" regex="mysql-connector-java-\\d.*\\.jar"/> //安装的更目录下有个contrib/dataimporthandler,需要手动创建一个lib，然后将mysql-connector-j-8.0.33.jar包放进去，此时mysql-connector-j和mysql-connector-java不匹配，所以要改一下,改成:mysql-connector-j-\\d.*\\.jar即可 https://www.cnblogs.com/shoufeng/p/9801490.html 最后倒入成功了，但是报：Could not write property file. Delta imports will not work. Make sure your conf directory is writable，只需要在 定义的core目录下新建一个conf目录就可以了,记得给读写权限，看了这个文件夹，里面存储的是每次导入的时间节点，相当于一个版本控制吧`}]},{path:"/content/php/symfony/Symfony%E4%B9%8Bjwt%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"Symfony之jwt的使用",pathLocale:"/",contents:[{header:"Symfony之jwt的使用:",slug:"symfony之jwt的使用",content:`gesdinet/jwt-refresh-token-bundle 和 lexik/jwt-authentication-bundle 一起使用实现 生成token和 refresh_token操作
参考文档: https://github.com/markitosgv/JWTRefreshTokenBundle`},{header:"symfony7下关于 lexik/jwt-authentication-bundle 的补充",slug:"symfony7下关于-lexik-jwt-authentication-bundle-的补充",content:`直接执行 $ php bin/console lexik:jwt:generate-keypair 的时候，会生成 private.pem 和 public.pem, (实际上带有test)这是没有问题的. 然后通过环境变量读取:
JWT_SECRET_KEY=%kernel.project_dir%/config/jwt/private.pem
JWT_PUBLIC_KEY=%kernel.project_dir%/config/jwt/public.pem
JWT_PASSPHRASE= 使用验证，但是这样的 private.pem 是不安全的(测试环境当然是没问题的)，所以还有个配置 JWT_PASSPHRASE, 这个参数是在执行 php bin/console lexik:jwt:generate-keypair 之前，手动配置的，比如 JWT_PASSPHRASE=c8f13be9d73a48f2e97ef11bbfdf7e1e589ca45d2a679c37e0bc431c4fe12591，
然后再执行 php bin/console lexik:jwt:generate-keypair, 此时 private.pem 就是加密的. 可以用 openssl 验证一下私钥是否被加密:
$ openssl rsa -in config/jwt/private-test.pem
它会提示输入 pass phrase，说明私钥已经被加密保护。`}]},{path:"/content/php/symfony/symfony5%E4%B8%8B%E4%BD%BF%E7%94%A8mailcatcher%E5%81%9A%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8.html",title:"symfony5下使用mailcatcher做邮件服务器",pathLocale:"/",contents:[{header:"",slug:"",content:`有时候需要测试发邮件功能，可以通过 mailcatcher 实现
1.先安装mailcatcher
执行：gem install mailcatcher //需要Ruby环境 2.进入安装目录执行 mailcatcher
root@k-cluster:/usr/local$ mailcatcher
Starting MailCatcher v0.8.2
==> smtp://127.0.0.1:1025
==> http://127.0.0.1:1080`}]},{path:"/content/php/symfony/symfony5%E4%B9%8BOpenAPI%E6%89%A9%E5%B1%95%E5%8C%85%E5%AE%9E%E7%8E%B0swagger%E6%96%87%E6%A1%A3.html",title:"symfony5之OpenAPI扩展包实现swagger文档",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5之OpenAPI扩展包实现 swagger 文档:
最近需要将之前写的接口出一个文档，准备用一下当前比较流行的swagger，symfony框架下，用这个拓展包:https://github.com/nelmio/NelmioApiDocBundle
就可以了.
基本上composer 安装好以后，配置两个路由: api/doc 和 api/doc.json 就可以了,一个是页面展示小鬼，还有一个是以json文件的形式展示出来
下面是实际使用:
1.post请求注释
/** * @OA\\Post( * path="/api/post", * summary="Create a new post", * tags={"Posts"}, * @OA\\RequestBody( * required=true, * @OA\\JsonContent( * @OA\\Property(property="title", type="string", example="New Post"), * @OA\\Property(property="content", type="string", example="This is the content of the post.") * ) * ), * @OA\\Response( * response="201", * description="Post created successfully", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Post created successfully.") * ) * ), * @OA\\Response( * response="400", * description="Bad request", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Invalid input data.") * ) * ) * ) */ 在这个示例中，我们使用 @OA\\Post 注释来定义一个 POST 请求。path 参数指定了 API 的路径，summary 提供了关于此操作的简要描述，tags 列出了相关的标签。@OA\\RequestBody 用于定义请求体，这里我们使用 @OA\\JsonContent 来指定请求体的 JSON 格式。@OA\\Response 用于定义操作的响应，包括成功和错误情况。 2.post参数为枚举类型
/** * @OA\\Post( * path="/api/create_order", * summary="Create a new order", * tags={"Orders"}, * @OA\\RequestBody( * required=true, * @OA\\JsonContent( * @OA\\Property(property="product", type="string", enum={"product1", "product2", "product3"}), * @OA\\Property(property="quantity", type="integer", example=10) * ) * ), * @OA\\Response( * response="201", * description="Order created successfully", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Order created successfully.") * ) * ), * @OA\\Response( * response="400", * description="Bad request", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Invalid input data.") * ) * ) * ) */ 在上面的示例中，@OA\\Schema 注释用于定义一个枚举类型的对象。在 @OA\\Property 注释中，使用 enum 参数来指定允许的枚举值列表。这里我们定义了一个名为 "product" 的字段，其类型为字符串，且仅允许取值为 "product1"、"product2" 和 "product3" 中的一个。 3.post返回值包含对象
/** * @OA\\Post( * summary="Create a new post", * tags={"Posts"}, * @OA\\RequestBody( * required=true, * @OA\\JsonContent( * @OA\\Property(property="title", type="string"), * @OA\\Property(property="content", type="string") * ) * ), * @OA\\Response( * response="201", * description="Post created successfully", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Post created successfully."), * @OA\\Property(property="post_data", type="object", * @OA\\Property(property="id", type="integer", example=123), * @OA\\Property(property="title", type="string"), * @OA\\Property(property="content", type="string") * ) * ) * ), * @OA\\Response( * response="400", * description="Bad request", * @OA\\JsonContent( * @OA\\Property(property="message", type="string", example="Invalid input data.") * ) * ) * ) */ 在这个示例中，@OA\\Response 注解用于描述响应。在 @OA\\JsonContent 注解中，我们使用 @OA\\Property 来定义响应的属性。其中，post_data 是一个对象属性，我们在它的内部使用另一个 @OA\\Property 注解来定义该对象的属性，如 id、title 和 content。 4.普通GET请求
/** * @OA\\Get( * path="/api/resource", * summary="Get a list of resources", * tags={"Resource"}, * @OA\\Response( * response=200, * description="Successful response", * @OA\\JsonContent( * type="array", * @OA\\Items(ref="#/components/schemas/Resource") * ) * ) * ) */ 在上面的示例中，@OA\\Get 注释表示这是一个 GET 请求的配置。您需要指定请求的路径、概要、标签和响应。响应部分使用 @OA\\Response 注释来定义成功响应的状态码和数据结构。 5.带一个id路由参数的GET请求
/** * @OA\\Get( * path="/api/resource/{id}", * summary="Get a resource by ID", * tags={"Resource"}, * @OA\\Parameter( * name="id", * in="path", * required=true, * description="ID of the resource", * @OA\\Schema(type="integer") * ), * @OA\\Response( * response=200, * description="Successful response", * @OA\\JsonContent(ref="#/components/schemas/Resource") * ) * ) */ 在上面的示例中，我们在路径中使用 {id} 来表示路由参数，然后使用 @OA\\Parameter 注释来定义这个参数。注释中的属性说明如下： name: 参数的名称，这里是 "id"。
in: 参数的位置，这里是 "path"，表示在 URL 路径中。
required: 参数是否为必需的，这里设置为 true。
description: 参数的描述，解释了该参数的用途。
@OA\\Schema(type="integer"): 参数的数据类型，这里设置为整数类型。 6.@OA\\Property 和 @OA\\Parameter 的区别
@OA\\Property 和 @OA\\Parameter 都是 Swagger-PHP 中用于描述 API 文档的注解，但它们在使用场景和含义上有一些区别。 @OA\\Property:
用于描述请求体或响应体中的属性。通常用于描述 POST、PUT 等请求方法中的请求体的属性，或者响应中的属性。
适用于描述实体对象的属性，例如请求体中的字段、响应中的字段、嵌套对象等。
可以设置类型、示例值、描述等属性。
用于展示请求体和响应体中的属性。 @OA\\Parameter:
用于描述 URL 路径参数、查询参数、标头参数等。
适用于描述作为请求参数的属性，例如 GET 请求中的查询参数，或者 URL 中的路径参数。
可以设置类型、示例值、描述等属性。
用于展示接口的输入参数。 7.总结
其实这个swagger-php 的使用，主要就是属性的嵌套，习惯就好，唯一不好的就是，整个php代码会显得十分臃肿，主要还是注释部分`}]},{path:"/content/php/symfony/symfony5%E4%B9%8Bevent_dispatcher%E7%9A%84%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.html",title:"symfony5之event_dispatcher的使用注意事项",pathLocale:"/",contents:[{header:"",slug:"",content:`# This file is the entry point to configure your own services.
# Files in the packages/ subdirectory configure your dependencies. # Put parameters here that don't need to change on each machine where the app is deployed
# https://symfony.com/doc/current/best_practices.html#use-parameters-for-application-configuration
parameters: idp_scheme: '%env(IDP_SCHEME)%' idp_url: '%env(IDP_URL)%' academy_scheme: '%env(ACADEMY_SCHEME)%' mdpilogin_domain: '%env(MDPI_LOGIN_DOMAIN)%' academy_domain: '%env(ACADEMY_DOMAIN)%' sso_service: '%env(SSO_SERVICE)%' ffmpeg_binary: '%env(FFMPEG_BINARY_PATH)%' ffprobe_binary: '%env(FFPROBE_BINARY_PATH)%' services: # default configuration for services in *this* file _defaults: autowire: true # Automatically injects dependencies in your services. autoconfigure: true # Automatically registers your services as commands, event subscribers, etc. # makes classes in src/ available to be used as services # this creates a service per class whose id is the fully-qualified class name App\\: resource: '../src/' exclude: - '../src/DependencyInjection/' - '../src/Entity/' - '../src/Kernel.php' # add more service definitions when explicit configuration is needed # please note that last definitions always *replace* previous ones GuzzleHttp\\Client: ~ App\\EventListener\\LogoutSuccessListener: arguments: $idp_scheme: "%idp_scheme%" $idp_url: "%idp_url%" tags: - name: 'kernel.event_listener' event: 'Symfony\\Component\\Security\\Http\\Event\\LogoutEvent' dispatcher: security.event_dispatcher.main App\\Event\\AfterCoursePublishEvent: // 这个这只是一个服务名称，换成 tt 也是可以的 class: App\\EventListener\\CoursePublishListener tags: - {name: 'kernel.event_listener', event: App\\Event\\AfterCoursePublishEvent, method: 'onCoursePublish'} #下面这种写法也是可以的(直接定义listerner是，默认会将 App\\EventListener\\CoursePublishListener 映射为服务名称，这里必须写类名，不能随便起个名字 ,否则会报错)，和上面的执行效果相同 # App\\EventListener\\CoursePublishListener:
# tags:
# - {name: 'kernel.event_listener', event: App\\Event\\AfterCoursePublishEvent, method: 'onCoursePublish'} 再来看调用，在Repository层，注入Symfony\\Component\\EventDispatcher\\EventDispatcherInterface $this->eventDispatcher->dispatch(new AfterCoursePublishEvent($data)); //特别注意 这个diapatch 的第二个参数是event_name，这个一定不要传，否则dispatch 不生效，就是这个问题花了我好长时间，巨坑... 还有就是官方文档里关于event_dispatch的介绍，参考：https://symfony.com/doc/current/components/event_dispatcher.html，中有一个ContainerBuilder注册特别坑，根本不知道在哪里使用那几行代码，还有就是 文档里提到的： Registering service definitions and tagging them with the kernel.event_listener and kernel.event_subscriber tags is not enough to enable the event listeners and event subscribers. You must also register a compiler pass called RegisterListenersPass() in the container builder 这个翻译过过来，就是说光有tags 标注 没有用还要ContainerBuilder注册，实际上就是在service,yaml里 按照上面的两种写法写是可以生效的。 我是参考这个提问作者的问题 改的：https://stackoverflow.com/questions/34923306/dispatcher-doesnt-dispatch-my-event-symfony 关于Subscriber: ①如果是非symfony5框架核心event，需要手动在service,yaml里添加tag标签，比如，Entity调用doctrine.event_subscriber的事件： App\\EventSubscriber\\VideoSubscriber: tags: - { name: doctrine.event_subscriber } VideoSubscriber.php部分代码：
...
...
<?php namespace App\\EventSubscriber; use App\\Entity\\Video;
use Doctrine\\Common\\EventSubscriber;
use Doctrine\\ORM\\EntityManagerInterface;
use Doctrine\\ORM\\Event\\LifecycleEventArgs;
use Doctrine\\ORM\\Events; class VideoSubscriber implements EventSubscriber
{ private EntityManagerInterface $entityManager; public function __construct(EntityManagerInterface $entityManager) { $this->entityManager = $entityManager; } public function preUpdate(LifecycleEventArgs $args) { $entity = $args->getObject(); if ($entity instanceof Video) {// 这个就是来判断当前事件是来自哪个Entity的，如果不加这个加判断，preUpdate就会对所有Entity生效 $em = $args->getObjectManager();// 这个和$this->entityManager效果相同，但是通过$args获取到的$em 就是当初和$entity绑定的那一个entityManager $uow = $em->getUnitOfWork(); $changeSet = $uow->getEntityChangeSet($entity);// 获取属性变化，这里 $changeSet['view']，包括两个数据，改变前和改变后的值 if (!isset($changeSet['view']) && !isset($changeSet['voteNum']) && !isset($changeSet['extraView'])) { $entity->setUpdatedAt(new \\DateTime()); } file_put_contents('./1.txt', $entity->getTitle()); } } public function getSubscribedEvents() { // TODO: Implement getSubscribedEvents() method. return [ Events::preUpdate, ]; }
} ... ... ② 如果是symfony5框架核心event，那么可以不用在service,yaml里添加tag标签，像exception这些`}]},{path:"/content/php/symfony/symfony5%E4%B9%8Bform%E8%A1%A8%E5%8D%95%E5%B1%9E%E6%80%A7.html",title:"symfony5之form表单属性",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5之form表单属性:
这个主要是记录一下链接，还没怎么整理，感觉基本概念网上讲的很详细了:
https://symfony.com/doc/current/form/form_customization.html#form-label-form-view-label-variables
symfony5之form表单约束:
https://symfony.com/doc/current/reference/constraints/All.html#constraints`}]},{path:"/content/php/symfony/symfony5%E4%B9%8BgetRepository%E7%9A%84%E4%B8%A4%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF.html",title:"symfony5之getRepository的两种使用场景",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5之getRepository的两种使用场景:
symfony5的getRepository的两种使用场景，之前一直用的是第一种，其实有时候需要关联查询，可以直接用 createQueryBuilder 查询，如下第二种方式，第三种方式需要手动指定 from 的Entity //方式1
$pagination = $this->entityManager->getRepository(Course::class)->getPagination($params, $request->query->getInt('page', 1)); //方式2
$res = $this->entityManager->getRepository(Course::class)->createQueryBuilder('c')->leftJoin("c.courseManages", "cm")->where('c.id = 1')->select("c.id", "cm.type")->getQuery()->getResult(); //方式3
$res = $this->entityManager->createQueryBuilder()->from("App:Course", "c")->leftJoin("c.courseManages", "cm")->where("c.id = 1")->select("c.id", "cm.type")->getQuery()->getResult();`}]},{path:"/content/php/symfony/symfony5%E4%B9%8B%E6%89%A7%E8%A1%8C%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6.html",title:"symfony5之执行迁移文件",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5之执行迁移文件:
php bin/console doctrine:migration:diff //symfony查看数据库和entity之间的属性差异，使entity和数据库保持一致 bin/console doctrine:migrations:generate //生成迁移文件 php bin/console doctrine:migrations:status //查看迁移状态 php bin/console doctrine:migrations:list //这个会累出所有的迁移信息 php bin/console doctrine:migrations:migrate //迁移所有文件 bin/console doctrine:migrations:execute 'DoctrineMigrations\\Version20220224115156' //执行指定的迁移文件 php bin/console doctrine:migrations:execute --up 'DoctrineMigrations\\Version20221209020525' // 默认的不加 up 或者 down，那么执行的是up操作 php bin/console doctrine:migrations:execute --down 'DoctrineMigrations\\Version20221209020525' php bin/console doctrine:migrations:version --delete DoctrineMigrations\\Version20230831010609 //这个并没有从数据库删除轻易文件记录，但是我想是不是可以用来删除migrations下的迁移文件的 php bin/console manage-dashboard-items //symfony7执行指定的command 目前项目使用了 symfony7，所以再更新一些:
1.对于每次拉取项目之后，数据库需要执行如下操作
$ bin/console doctrine:migrations:migrate //生成表
$ bin/console doctrine:fixtures:load --append //应用填充数据到数据库 2.对于需要新建表操作的，一般按如下两个方式来弄
//手动创建迁移文件的另一种好用的方式
1>先手动创建指定的Entity, 添加需要的字段，以及关联关系，最后 set/get方法
2>通过下面的命令生成迁移文件，注意这个命令可能会把其它的Entity的相关信息也生成出来，需要根据实际需求处理，可以手动删掉本次不需要的迁移文件，同时 下面的方式还可以自动生成 index name，还是很标准的，比如: IDX_EED3565FA66BE622，就不用手动操作了
php bin/console doctrine:migration:diff
3>生成表
php bin/console doctrine:migration:migrate
这样，从整个Entity到数据库表的迁移就完成了 //直接生成迁移文件
1>bin/console doctrine:migrations:generate
2>在这个迁移文件里添加要的操作，比如 create alert 之类的
3>再去新建Entity
这样操作在laravel下是没有问题的，因为laravel就是这么干的，但是在 symfony下有问题，因为 symfony 下，Entity的属性要和表一致，否则可能会报错，综合考虑还是使用上面的方法更方便 symfony下通过 bin/console doctrine:migrations:generate 生成迁移文件，注意这里又对表做comment操作:
<?php declare(strict_types=1); namespace DoctrineMigrations; use Doctrine\\DBAL\\Schema\\Schema;
use Doctrine\\Migrations\\AbstractMigration; /** * Auto-generated Migration: Please modify to your needs! */
final class Version20231128024850 extends AbstractMigration
{ public function getDescription(): string { return ''; } public function up(Schema $schema): void { // this up() migration is auto-generated, please modify it to your needs $this->addSql('CREATE TABLE ask_history_comments(id int not null auto_increment primary key, comment longtext default null, ask_history_id int not null, user_id int not null, admin_id int not null, created_at DATETIME default null, updated_at DATETIME default null
) DEFAULT CHARACTER SET utf8 COLLATE \`utf8_unicode_ci\` ENGINE = InnoDB COMMENT=\\'aks history comments table\\''); } public function down(Schema $schema): void { // this down() migration is auto-generated, please modify it to your needs $this->addSql('DROP TABLE ask_history_comments'); }
} symfony7下执行command:
php bin/console manage-user-items`}]},{path:"/content/php/symfony/symfony5%E4%B9%8B%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"symfony5之环境变量和配置文件的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5之环境变量和配置文件的关系:
最近在项目上线的时候，遇到个问题，配置环境变量，然年后针对不同环境变量，配置不同的数据库参数
关于symfony5的环境变量配置文件的一些注意事项: 1. .env 是默认配置，默认 .env中的APP_ENV=dev 2. .env.local 是用来覆盖 .env 中的配置信息的，并且默认 .env.local 中的 APP_ENV=dev，说明当前运行环境是 dev 环境，这里有个问题，可能指定了 dev, 但是并没有一个叫 .env.dev的配置文件，那么这个 .env.local 配置文件就会起到 .env.dev 的作用，然后 对于 services_dev.yaml 也是生效的。 我分析了一下原因，执行下面的命令可以看到，由于配置了 APP_ENV=dev，那么程序回去找这个环境变量，但是没有找到.env.dev相关的配置，那么还是用 .env.local
执行：php bin/console debug:dotenv * ⨯ .env.local.php * ⨯ .env.dev.local * ⨯ .env.dev * ✓ .env.local * ✓ .env 其实 APP_ENV 可以使任何名字，比如我写成 APP_ENV=tt，执行命令以后，就会有下面的效果，找不到.env.tt相关的配置，那么还是用 .env.local * ⨯ .env.local.php * ⨯ .env.tt.local * ⨯ .env.tt * ✓ .env.local * ✓ .env 3. 如果既在 .env.local 中配置了 APP_ENV=staging, 又有 .env.staging，那么执行命令以后，就会有下面的效果，会发现找到了 .env.staging，那么就会加载这里面的配置
root@k8s:~/code/test$ php bin/console debug:dotenv Dotenv Variables & Files
======================== Scanned Files (in descending priority)
-------------------------------------- * ⨯ .env.local.php * ⨯ .env.staging.local * ✓ .env.staging * ✓ .env.local * ✓ .env Variables
--------- ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- ----------------------------------- Variable Value .env.staging .env.local .env ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- ----------------------------------- test_DOMAIN test.web.test test.web.test test.web.test test_SCHEME http http http APP_ENV staging staging staging dev APP_SECRET ThisTokenIsNotSoSecretChangeIt ThisTokenIsNotSoSecretChangeIt... ThisTokenIsNotSoSecretChangeIt... d6edd2e553f701556efbea65e8d868... DATABASE_URL mysql://root:123456@127.0.0.1:3306/test?serverVersion=8.0&charset=utf8mb4 mysql://root:123456@127.0.0.1:... mysql://root:123456@127.0.0.1:... mysql://app:!ChangeMe!@127.0.0... FFMPEG_BINARY_PATH /usr/bin/ffmpeg /usr/bin/ffmpeg /usr/bin/ffmpeg FFPROBE_BINARY_PATH /usr/bin/ffprobe /usr/bin/ffprobe /usr/bin/ffprobe IDP_SCHEME http http http IDP_URL duo.login.test duo.login.test duo.login.test MAILER_DSN smtp://localhost:1025 smtp://localhost:1025 smtp://localhost:1025 null://null MESSENGER_TRANSPORT_DSN redis://localhost:6379/messages redis://localhost:6379/message... redis://localhost:6379/message... doctrine://default?auto_setup=... SSO_SERVICE test test test USER_LOGIN_AUTHORITY test test test test USER_LOGIN_KEY test test test test ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- ----------------------------------- // Note real values might be different between web and CLI. 注意一个问题: .env.staging 中的 APP_ENV 也要配置成 staging，不能配置成其它的值，否则又会继续找定义的那个环境变量 4. 我在 config 下新建了 services_staging.yaml 文件(此时的 APP_ENV=staging，会调用这里面的配置)，用来覆盖 services.yaml中的某些配置，但是运行起来没有生效，我想会不会有缓存，于是我执行下面的清缓存命令后 再执行 配置才生效 root@k8s:~/code/test$ php bin/console cache:clear // Clearing the cache for the prod2 environment with debug true [OK] Cache for the "prod2" environment (debug=true) was successfully cleared. 5. 实际使用，一般会配置 .env.local .env.staging .env.prod .env.test`}]},{path:"/content/php/symfony/symfony5%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC%E8%AF%A6%E8%A7%A3.html",title:"symfony之事件监听详解",pathLocale:"/",contents:[{header:"",slug:"",content:`一直在用事件监听，但是之前记录的太简单了，还有很多细节没有理解，现在记录一下
首先是 kernel.event_listener 的 概念:
There is an optional attribute for the kernel.event_listener tag called event which is useful when listener $event argument is not typed. If you configure it, it will change type of $event object. For the kernel.exception event, it is ExceptionEvent. Check out the Symfony events reference to see what type of object each event provides. With this attribute, Symfony follows this logic to decide which method to call inside the event listener class: If the kernel.event_listener tag defines the method attribute, that's the name of the method to be called;
If no method attribute is defined, try to call the method whose name is on + "PascalCased event name" (e.g. onKernelException() method for the kernel.exception event);
If that method is not defined either, try to call the __invoke() magic method (which makes event listeners invokable);
If the __invoke() method is not defined either, throw an exception. 翻译过来，使用代码说明:
#service.yaml定义: App\\EventListener\\VideoSaveListener: tags:
# - {name: 'kernel.event_listener', event: App\\Event\\AfterVideoSaveEvent, method: 'onVideoSave'} #显 - {name: 'kernel.event_listener', event: App\\Event\\AfterVideoSaveEvent} #隐 VideoSaveListener:
<?php namespace App\\EventListener; use App\\Entity\\Video;
use App\\Event\\AfterVideoSaveEvent;
use App\\Service\\VideoService;
use Doctrine\\ORM\\EntityManagerInterface; class VideoSaveListener
{ private EntityManagerInterface $entityManager; /** * 既没有显式也没有隐式定义 method 的时候，会自动调用这个 __invoke 方法 * * @param AfterVideoSaveEvent $event * @return void */ public function __invoke(AfterVideoSaveEvent $event): void { file_put_contents('./3.txt', '3333'); } public function __construct(EntityManagerInterface $entityManager) { $this->entityManager = $entityManager; } /** * 显式 定义 method (需要在service 的 tags 里 指定 method 为下面这个方法名) */
// public function onVideoSave(AfterVideoSaveEvent $event): void
// {
// file_put_contents('./1.txt', '11111');
// $video = $event->getVideo();
// $length = (new VideoService())->getVideoLength($video->getPlayUrl());
// $video->setLength($length);
//
// $this->entityManager->getRepository(Video::class)->save($video, true);
// } /** * 隐式 定义 method (on + 事件名称空间+名称) */
// public function onAppEventAfterVideoSaveEvent(AfterVideoSaveEvent $event): void
// {
// file_put_contents('./2.txt', '22222');
// $video = $event->getVideo();
// $length = (new VideoService())->getVideoLength($video->getPlayUrl());
// $video->setLength($length);
//
// $this->entityManager->getRepository(Video::class)->save($video, true);
// }
} 参考:https://symfony.com/doc/current/event_dispatcher.html`}]},{path:"/content/php/symfony/symfony5%E4%BD%BF%E7%94%A8cookie%E5%92%8Csession.html",title:"symfony5使用cookie和session",pathLocale:"/",contents:[{header:"",slug:"",content:`关于symfony的session和cookie
Symfony HttpFoundation component provides cookie and session management in an object-oriented manner. Cookie provides client-side data storage and it only supports a small amount of data. Usually, it is 2KB per domain and it depends on the browser. Session provides server-side data storage and it supports a large amount of data. Let us see how to create a cookie and session in a Symfony web application. Cookie
Symfony provides Cookie class to create a cookie item. Let us create a cookie color, which expires in 24 hours with value blue. The constructor parameter of the cookie class is as follows. name (type: string) - cookie name
value (type: string) - cookie value
expire (type: integer / string / datetime) - expiry information
path (type: string) - the server path in which the cookie is available
domain (type: string) – the domain address in which the cookie is available
secure (type: boolean) - whether the cookie needs to be transmitted in HTTPS connection
httpOnly (type: boolean) - whether the cookie is available only in HTTP protocol ex:
use Symfony\\Component\\HttpFoundation\\Cookie; $cookie = new Cookie('color', 'green', strtotime('tomorrow'), '/', 'somedomain.com', true, true); Now, the created cookie needs to be attached to the http response object's header as follows.
$response->headers->setCookie($cookie); To get the cookie, we can use Request object as follows
$cookie = $request->cookie->get('color'); Session
Symfony provides a Session class implementing SessionInterface interface. The important session API are as follows, start − Starts the session. Session $session = new Session(); $session->start(); invalidate − Clears all session data and regenerates the session ID. set − Stores data in the session using a key. $session->set('key', 'value');
We can use any data in the session value, be in simple integer to complex objects. get − Gets data from the session using the key. $val = $session->get('key');
remove − Removes a key from the session. clear − Removes a session data.`}]},{path:"/content/php/symfony/symfony5%E4%BD%BF%E7%94%A8middleware%E6%8E%A7%E5%88%B6%E8%B7%AF%E7%94%B1.html",title:"symfony5使用middleware控制路由",pathLocale:"/",contents:[{header:"",slug:"",content:"因为symfony没有vmiddleware的概念，但是提供了event的概念，可以做同样的事情: https://stackoverflow.com/questions/48377175/how-to-add-middleware-for-one-or-two-controllers-in-symfony4 自定义AccessDeniedException异常处理: https://symfony.com/doc/current/security/access_denied_handler.html 还有就是找到一个middleware的composer包，不过感觉用的人挺少： https://github.com/kafkiansky/symfony-middleware 自定义authenticator，这个主要是为了定义多个firewall的时候用到，比如后台一套 接口一套: https://symfony.com/doc/current/security/custom_authenticator.html，使用:https://symfony.com/doc/current/security/entry_point.html#multiple-authenticators-with-separate-entry-points 虽然不能直接在控制器里定义roles，但是可以通过 $this->denyAccessUnlessGranted('ROLE_USER'); 来判断是否有 ROLE_USER 角色，进而判断用户是否登录，也可以通过 #[IsGranted('ROLE_ADMIN')] 来决定: https://symfony.com/doc/current/security.html#security-securing-controller"}]},{path:"/content/php/symfony/symfony5%E4%BD%BF%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%B8%A6%E7%9A%84Authenticator%E9%AA%8C%E8%AF%81form_login.html",title:"symfony5使用系统自带的Authenticator验证form_login",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5使用系统自带的Authenticator验证form_login原理:
核心的是下面这个listener
UsernamePasswordFormAuthenticationListener 这个listener里面有个 attemptAuthentication 方法，这个方法大致用来验证用户信息，生成token(UsernamePasswordToken)，和 自定义FormLoginAuthenticator 中的 authenticate 作用差不多 form_login的参数文档:https://symfony.com/doc/current/reference/configuration/security.html#form-login-authentication`}]},{path:"/content/php/symfony/symfony5%E4%BF%AE%E6%94%B9Entity%E7%9A%84%E9%BB%98%E8%AE%A4lazy%E5%B1%9E%E6%80%A7.html",title:"symfony5修改Entity的默认lazy属性",pathLocale:"/",contents:[{header:"",slug:"",content:`问题：又是或需要获取对象信息，但是获取到null 数据，同时会报：isInitialized: false问题
/** *解决办法就是再Entity 的属性上加上：fetch="EAGER 就可以获取到数据了 * @ORM\\ManyToOne(targetEntity="App\\Entity\\Event", inversedBy="situs", fetch="EAGER") */
private $event;`}]},{path:"/content/php/symfony/symfony5%E5%88%9B%E5%BB%BA%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html",title:"symfony5创建单元测试",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5创建单元测试:
①在测试环境中，这些环境文件被读取（如果其中有重复的变量，列表中较低的文件会覆盖之前的项目）：
.env：包含具有应用默认值的环境变量；
.env.test：覆盖/设置特定的测试值或变量；
.env.test.local: 覆盖本机的特定设置
例如:
# .env.test # ...
DATABASE_URL="mysql://db_user:db_password@127.0.0.1:3306/db_name_test?serverVersion=5.7" ②生成测试类
应用程序测试是PHP文件，通常在应用程序的test/Controller/目录下。它们通常扩展WebTestCase。这个类在KernelTestCase的基础上增加了特殊的逻辑。
例如你想测试PostController类处理的页面，首先使用SymfonyMakerBundle的make:test命令创建一个新的PostControllerTest：
$php bin/console make:test Which test type would you like?:
> WebTestCase The name of the test class (e.g. BlogPostTest):
> Controller\\PostControllerTest 会创建如下的测试类:
// tests/Controller/PostControllerTest.php
namespace App\\Tests\\Controller; use Symfony\\Bundle\\FrameworkBundle\\Test\\WebTestCase; class PostControllerTest extends WebTestCase
{ public function testSomething(): void { // This calls KernelTestCase::bootKernel(), and creates a // "client" that is acting as the browser $client = static::createClient(); // Request a specific page $crawler = $client->request('GET', '/'); // Validate a successful response and some content $this->assertResponseIsSuccessful(); $this->assertSelectorTextContains('h1', 'Hello World'); }
}`}]},{path:"/content/php/symfony/symfony5%E8%87%AA%E5%AE%9A%E4%B9%89log%E8%B7%AF%E5%BE%84%E4%BB%A5%E5%8F%8Achannnel.html",title:"symfony5自定义log路径以及channnel",pathLocale:"/",contents:[{header:"",slug:"",content:"参考文档"}]},{path:"/content/php/symfony/symfony5%E8%8E%B7%E5%8F%96Yaml%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0.html",title:"symfony5获取Yaml配置参数",pathLocale:"/",contents:[{header:"",slug:"",content:`如何获取app/config/services.yaml的配置文件内容
<?php namespace App\\Controller; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response; // 1. Include the ParameterBagInterface class
use Symfony\\Component\\DependencyInjection\\ParameterBag\\ParameterBagInterface; // 2. Basically what we do is autoinject the ParameterBagInterface as argument
// inside the method where you need to obtain a parameter from the services.yaml file
// and then, using the get method you can retrieve a specific parameter.
class MyController extends AbstractController
{ public function index(Request $request, ParameterBagInterface $params): Response { $uploadsDirectory = $params->get('uploads_directory'); // ... or retrieve them all with $params->all() }
}`}]},{path:"/content/php/symfony/symfony7%E4%B8%8BEnum%E4%B9%8Bcases%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7下Enum之cases的使用",pathLocale:"/",contents:[{header:"symfony7下Enum之cases的使用",slug:"symfony7下enum之cases的使用",content:`<?php namespace App\\Enum; enum OrderUserTabEnum: string
{ case ALL = 'all'; case PENDING_PAYMENT = 'pendingPayment'; case PENDING_UPDATED = 'pendingUpdated'; public static function casesAsKeyValue(): array { $result = []; foreach (self::cases() as $case) { $result[$case->name] = $case->value; } return $result; }
} 返回如下结构:
array:3 [ "ALL" => "all" "PENDING_PAYMENT" => "pendingPayment" "PENDING_UPDATED" => "pendingUpdated"
]`}]},{path:"/content/php/symfony/symfony7%E4%B8%8BEnum%E4%BD%BF%E7%94%A8from%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAEnum%E5%AF%B9%E8%B1%A1.html",title:"symfony7下Enum使用from创建一个Enum对象",pathLocale:"/",contents:[{header:"symfony7下Enum使用from创建一个Enum对象",slug:"symfony7下enum使用from创建一个enum对象",content:`if (!empty(array_intersect($userRoles, $allowedRoles))) { $actionEnum = SubmissionActionEnum::from($actionValue); $actionsData[] = new Dto\\Query\\Submission\\Dashboard\\SubmissionActionDto( $actionEnum->name, $actionEnum->value );
}`},{header:"代码分析",slug:"代码分析",content:"这段 Symfony 7 中的 PHP 代码逻辑如下："},{header:"✅ 作用总结：",slug:"✅-作用总结",content:"判断当前用户角色是否包含在允许的角色中，如果是，则将某个 enum 类型的 action 组装成一个 SubmissionActionDto 对象，并添加到 $actionsData 数组中。"},{header:"🔍 逐行分析：",slug:"🔍-逐行分析",content:`if (!empty(array_intersect($userRoles, $allowedRoles))) { array_intersect($userRoles, $allowedRoles)
取出 $userRoles 和 $allowedRoles 中共同存在的角色。
!empty(...)
如果两者有交集（即用户具有至少一个允许的角色），才执行下面的代码。 $actionEnum = SubmissionActionEnum::from($actionValue); SubmissionActionEnum::from($actionValue)
使用 PHP 8.1+ 的 Backed Enums 功能，从 $actionValue（应该是枚举的值，比如字符串或整数）生成一个 SubmissionActionEnum 枚举对象。
这个方法在无法匹配时会抛出 ValueError。 $actionsData[] = new Dto\\Query\\Submission\\Dashboard\\SubmissionActionDto( $actionEnum->name, $actionEnum->value
); 创建一个新的 SubmissionActionDto 实例，传入： $actionEnum->name：枚举的名称（如 SendReminder）
$actionEnum->value：枚举的值（如 "send_reminder"） 最后把这个 DTO 加入 $actionsData 数组中，供后续处理（比如返回前端、渲染列表等）。`},{header:"📌 示例：",slug:"📌-示例",content:`假设：
$userRoles = ['ROLE_ADMIN'];
$allowedRoles = ['ROLE_ADMIN', 'ROLE_MANAGER'];
$actionValue = 'send_reminder'; enum SubmissionActionEnum: string { case SendReminder = 'send_reminder'; case Archive = 'archive';
} 则： array_intersect($userRoles, $allowedRoles) 为 ['ROLE_ADMIN']，非空
SubmissionActionEnum::from('send_reminder') 返回枚举对象 SubmissionActionEnum::SendReminder
创建一个 DTO：new SubmissionActionDto('SendReminder', 'send_reminder')`},{header:"✅ 总结：",slug:"✅-总结",content:`该段代码是典型的“权限判断后，执行特定操作并封装数据”逻辑： 权限检查： 用户是否有权进行某个动作
动作转换： 将字符串 $actionValue 转换为枚举
数据封装： 使用 DTO 封装并保存结果`}]},{path:"/content/php/symfony/symfony7%E4%B8%8BSQL%E6%8F%92%E5%85%A5%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%97%B6%E5%80%99%E5%8D%95%E5%BC%95%E5%8F%B7%E9%97%AE%E9%A2%98.html",title:"symfony7下SQL插入语句的时候单引号问题",pathLocale:"/",contents:[{header:"symfony7下SQL插入语句的时候单引号问题",slug:"symfony7下sql插入语句的时候单引号问题",content:`symfony7下有如下sql 迁移
$this->addSql('INSERT INTO event_submission_publication_preference_types (id, name) VALUES (4, "I would like to contribute a full manuscript to the organizing journal's conference special issue.")'); 但是name的值有个 journal's 单引号，冲突了 解决办法:
$this->addSql('INSERT INTO event_submission_publication_preference_types (id, name) VALUES (?, ?)', [ 4, "I would like to contribute a full manuscript to the organizing journal's conference special issue.", ]);`}]},{path:"/content/php/symfony/symfony7%E4%B8%8B%E5%85%B3%E4%BA%8EHasLifecycleCallbacks%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7下关于HasLifecycleCallbacks的使用",pathLocale:"/",contents:[{header:"symfony7下关于HasLifecycleCallbacks的使用",slug:"symfony7下关于haslifecyclecallbacks的使用",content:`在 Symfony 7 中，#[ORM\\HasLifecycleCallbacks] 是 Doctrine ORM 提供的一个 PHP 8+ 属性（attribute），用于声明该实体类（如 CustomRegistrationOrder）包含生命周期回调方法（如 prePersist, postPersist 等）。这个属性的作用是告诉 Doctrine 要扫描这个类中带有生命周期钩子注解的方法，并在相应事件触发时自动调用它们。 例子:
use Doctrine\\ORM\\Mapping as ORM; #[ORM\\Table("custom_registration_orders")]
#[ORM\\HasLifecycleCallbacks]
class CustomRegistrationOrder
{ #[ORM\\Column(name: 'created_at', type: 'datetime', nullable: false)] protected \\DateTime $createdAt; #[ORM\\Column(name: 'updated_at', type: 'datetime', nullable: false)] protected \\DateTime $updatedAt; #[ORM\\PrePersist] public function updateTimestamps(): void { $this->createdAt = new \\DateTime(); $this->updatedAt = new \\DateTime(); } }`}]},{path:"/content/php/symfony/symfony7%E4%B8%8B%E5%85%B3%E4%BA%8EVoter%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7下关于Voter的使用",pathLocale:"/",contents:[{header:"symfony7下关于Voter的使用",slug:"symfony7下关于voter的使用",content:""},{header:"使用自定义的voter",slug:"使用自定义的voter",content:`//通过Enum 集中定义一些Voter名称(方便管理)
<?php namespace App\\Enum; enum VoterAttributeEnum: string
{ case MANAGE_ORDERS = 'MANAGE_ORDERS'; case MY_ORDER_DETAILS = 'MY_ORDER_DETAILS'; case UPDATE_ORDER_DETAILS = 'UPDATE_ORDER_DETAILS';
} <?php namespace App\\Security\\Voter\\Billing; use App\\Entity;
use App\\Enum\\VoterAttributeEnum;
use Doctrine\\ORM\\EntityManagerInterface;
use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;
use Symfony\\Component\\Security\\Core\\Authorization\\Voter\\Voter; class OrderVoter extends Voter
{ public function __construct( private readonly EntityManagerInterface $em, ) { } protected function supports(string $attribute, mixed $subject): bool { return VoterAttributeEnum::MANAGE_ORDERS->value === $attribute && ($subject instanceof Entity\\Special\\Event || $subject instanceof Entity\\Special\\EventRegistrationOrder); } protected function voteOnAttribute(string $attribute, mixed $subject, TokenInterface $token): bool { $user = $token->getUser(); //是否为Pub下的user if (!$user instanceof Entity\\Pub\\User) { return false; } $event = $subject; if ($subject instanceof Entity\\Sciforum\\EventRegistrationOrder) { $event = $subject->getEvent(); } //是否为超级用户 if ($user->isSuperUser()) { return true; } //只允许指定id的event可以被操作 $allowedEventIds = [55,66,88]; return in_array($event->getId(), $allowedEventIds); }
} //使用，在控制器的某个需要控制的方法上添加如下代码，通过 IsGranted 注释功能自动注入判断, 它会从控制器方法参数中找到名字叫 event 的参数, 整个过程会触发 IsGrantedAttributeListener 这个listener
#[IsGranted(VoterAttributeEnum::MANAGE_ORDERS->value, subject: 'event')]
public function getOrderStatuses( Entity\\Special\\Event $event, ): JsonResponse { return $this->response(); }`},{header:"使用默认的voter",slug:"使用默认的voter",content:`#[IsGranted(Role::ROLE_USER->value)] <?php /* * This file is part of the Symfony package. * * (c) Fabien Potencier <fabien@symfony.com> * * For the full copyright and license information, please view the LICENSE * file that was distributed with this source code. */ namespace Symfony\\Component\\Security\\Core\\Authorization\\Voter; use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface; /** * RoleVoter votes if any attribute starts with a given prefix. * * @author Fabien Potencier <fabien@symfony.com> */
class RoleVoter implements CacheableVoterInterface
{ public function __construct( private string $prefix = 'ROLE_', ) { } public function vote(TokenInterface $token, mixed $subject, array $attributes): int { $result = VoterInterface::ACCESS_ABSTAIN; $roles = $this->extractRoles($token); foreach ($attributes as $attribute) { if (!\\is_string($attribute) || !str_starts_with($attribute, $this->prefix)) { continue; } $result = VoterInterface::ACCESS_DENIED; if (\\in_array($attribute, $roles, true)) { return VoterInterface::ACCESS_GRANTED; } } return $result; } public function supportsAttribute(string $attribute): bool { return str_starts_with($attribute, $this->prefix); } public function supportsType(string $subjectType): bool { return true; } protected function extractRoles(TokenInterface $token): array { return $token->getRoleNames(); }
}`},{header:"二者使用总结",slug:"二者使用总结",content:`默认角色的voter原理:
/vendor/symfony/security-core/Authorization/Voter/RoleVoter.php
它的 supports() 会判断：如果 $attribute 以 'ROLE_' 开头，则接管处理 自定义voter原理:
在Security下的Voter目录自定义Voter, 最关键的是supports下的判断，因为可以定义很多个，symfony7会通过轮训所有找到适合的voter`},{header:"对 Voter 的 supports() 方法分析",slug:"对-voter-的-supports-方法分析",content:`在 Symfony Security Voter 机制 中，supports() 是抽象方法之一，定义在 Voter 基类中：
abstract protected function supports(string $attribute, mixed $subject): bool; 它的作用就是：决定当前 Voter 是否“支持”处理传入的 $attribute 和 $subject。`},{header:"参数解析",slug:"参数解析",content:`string $attribute 代表权限的“动作”或“操作”，通常是一个字符串常量，比如 "POST_EDIT", "USER_DELETE", "VIEW"。
在调用 isGranted($attribute, $subject) 或 denyAccessUnlessGranted($attribute, $subject) 时传入的第一个参数。 mixed $subject 代表权限校验的对象（可以是一个实体，如 Post、User），也可能是 null（有些场景下只基于 attribute 判断即可）。
第二个参数就是这个。`},{header:"方法逻辑",slug:"方法逻辑",content:`supports() 方法一般用于快速过滤，避免每个 Voter 都去处理所有的 attribute 和 subject。
返回： true：说明该 Voter 有兴趣 处理该组合（attribute + subject），接下来会调用 voteOnAttribute() 来做实际授权逻辑。
false：说明该 Voter 不关心，Security 系统会交给其它 Voter。`},{header:"示例",slug:"示例",content:`假设你写了一个 PostVoter：
use App\\Entity\\Post;
use Symfony\\Component\\Security\\Core\\Authorization\\Voter\\Voter;
use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface; class PostVoter extends Voter
{ public const EDIT = 'POST_EDIT'; public const VIEW = 'POST_VIEW'; protected function supports(string $attribute, mixed $subject): bool { // 1. 只关心定义的几个 attribute if (!in_array($attribute, [self::EDIT, self::VIEW])) { return false; } // 2. subject 必须是 Post 实例 if (!$subject instanceof Post) { return false; } return true; } protected function voteOnAttribute(string $attribute, mixed $subject, TokenInterface $token): bool { $user = $token->getUser(); if (!$user) { return false; } /** @var Post $post */ $post = $subject; return match ($attribute) { self::VIEW => true, self::EDIT => $user === $post->getAuthor(), default => false, }; }
}`},{header:"调用流程",slug:"调用流程",content:`你在控制器里写：
$this->denyAccessUnlessGranted('POST_EDIT', $post); Security 系统会遍历所有 Voter： 调用它们的 supports('POST_EDIT', $post)。
如果返回 true，再调用 voteOnAttribute('POST_EDIT', $post, $token)。
如果返回 false，忽略该 Voter。`},{header:"总结",slug:"总结",content:`supports() 的职责是：快速筛选，决定是否处理该权限判断。
典型模式： 检查 $attribute 是否是自己关心的常量。
检查 $subject 类型是否是自己负责的实体。 它不会做权限判断逻辑，真正的判断写在 voteOnAttribute()。`},{header:"当直接使用IsGranted的时候，如果需要第二个参数，，可以通过如下方式实现",slug:"当直接使用isgranted的时候-如果需要第二个参数-可以通过如下方式实现",content:`#[IsGranted(SubmissionVoterEnum::MANAGE_INVITED_REVIEWER->value, subject: 'assignment')]
public function respondInvitation(
#[MapRequestPayload]
Dto\\Input\\Submission\\Assignment\\RespondInvitationDto $respondInvitationDto,
Entity\\Sciforum\\SubmissionAssignment $assignment,
Service\\Submission\\Assignment\\ReviewerSubmissionActionService $reviewerSubmissionActionService,
): JsonResponse {
return $this->apiResponse->response($reviewerSubmissionActionService->respondInvitation($respondInvitationDto, $assignment, $this->getUser()));
} 这个subject: 'assignment' 中的 assignment 就是后面的 $assignment`},{header:"IsGranted 和 denyAccessUnlessGranted 的区别",slug:"isgranted-和-denyaccessunlessgranted-的区别",content:`官方文档： /** * Checks if the attribute is granted against the current authentication token and optionally supplied subject. * * @throws \\LogicException */ protected function isGranted(mixed $attribute, mixed $subject = null): bool { if (!$this->container->has('security.authorization_checker')) { throw new \\LogicException('The SecurityBundle is not registered in your application. Try running "composer require symfony/security-bundle".'); } return $this->container->get('security.authorization_checker')->isGranted($attribute, $subject); } /** * Throws an exception unless the attribute is granted against the current authentication token and optionally * supplied subject. * * @throws AccessDeniedException */ protected function denyAccessUnlessGranted(mixed $attribute, mixed $subject = null, string $message = 'Access Denied.'): void { if (!$this->isGranted($attribute, $subject)) { $exception = $this->createAccessDeniedException($message); $exception->setAttributes([$attribute]); $exception->setSubject($subject); throw $exception; } }`},{header:"分析",slug:"分析",content:"这段就是 AbstractController 里内置的两个常用安全方法："},{header:"🔎 方法差异",slug:"🔎-方法差异",content:""},{header:"isGranted($attribute, $subject = null): bool",slug:"isgranted-attribute-subject-null-bool",content:`返回值：布尔值 true / false 用法：当你只是想判断用户是否有权限时使用，不会中断程序。 调用链：内部其实就是调用了
$this->container->get('security.authorization_checker')->isGranted($attribute, $subject); 适用场景：
if ($this->isGranted('ROLE_ADMIN')) { // 显示 admin 按钮
}`},{header:"denyAccessUnlessGranted($attribute, $subject = null, string $message = 'Access Denied.')",slug:"denyaccessunlessgranted-attribute-subject-null-string-message-access-denied",content:`返回值：void，但如果没有权限会抛出 AccessDeniedException。 用法：当你要强制拦截用户访问时使用。 行为： 内部调用了 isGranted()；
如果返回 false → 创建 AccessDeniedException → throw 出去；
框架会捕获这个异常并返回 HTTP 403 Forbidden 响应。 适用场景：
$this->denyAccessUnlessGranted('POST_EDIT', $post);
// 如果没有权限，直接抛异常 → 返回 403`},{header:"✅ 总结对比",slug:"✅-总结对比",content:`方法
返回
行为
场景 isGranted()
bool
只是检查，不抛异常
模板里隐藏/显示按钮，条件判断 denyAccessUnlessGranted()
void（但可能抛 AccessDeniedException）
没权限就中断并返回 403
控制器中做访问控制 👉 所以： 模板 / UI 层 → 多用 isGranted()（比如 if is_granted('ROLE_ADMIN')）。
控制器 / API 层 → 多用 denyAccessUnlessGranted()（用户没权限直接拒绝访问）。`}]},{path:"/content/php/symfony/symfony7%E4%B8%8B%E5%85%B3%E4%BA%8E%E5%85%B3%E4%BA%8EDateTime%E4%BD%BF%E7%94%A8clone.html",title:"Typescript下定义 export enum 和  export const enum 哪个好",pathLocale:"/",contents:[{header:"Typescript下定义 export enum 和 export const enum 哪个好",slug:"typescript下定义-export-enum-和-export-const-enum-哪个好",content:`export enum 和 export const enum 都用于定义枚举，但它们之间有几个关键区别: export const enum Status { SUCCESS = "success", ERROR = "error",
} // 编译后，这行会直接变成：
console.log("success"); //实际上可以能到值
console.log(Object.values(Status)); // ❌ Status is not defined， 实际上也可以拿到值 export enum Status { SUCCESS = "success", ERROR = "error",
} console.log(Object.values(Status)); // ✅ ["success", "error"] 但是实际上两种定义都可以获取到枚举值，没有报错， 但是理论上:
编译时：TypeScript → JavaScript，做类型检查、值替换等
运行时：JS 代码开始执行的阶段，浏览器或 Node.js 运行
const enum 的所有值在 编译时就被替换掉了，所以 运行时根本没有那个枚举对象
只有普通的 enum 才能在运行时用 Object.values()、console.log(Status) 等方式访问 运行时 ≠ 编译过程
阶段 描述 举例说明
编译时 TypeScript 被转成 JavaScript 的阶段（ts → js） Status.SUCCESS → "success"
运行时 最终 JavaScript 被浏览器或 Node.js 执行的阶段 console.log(Status.SUCCESS) 会输出什么？`}]},{path:"/content/php/symfony/symfony7%E4%B9%8BDTO%E9%80%92%E5%BD%92%E9%AA%8C%E8%AF%81%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"symfony7之DTO递归验证的问题",pathLocale:"/",contents:[{header:"symfony7之DTO递归验证的问题",slug:"symfony7之dto递归验证的问题",content:`use App\\Validator as MainAssert;
use Symfony\\Component\\Validator\\Constraints as Assert; #[MainAssert\\LiveSession]
class LiveSessionDto
{ /** * @param ?FileMetadataDto $liveSessionReport * @param ?LiveSessionDataDto[] $liveSessionData */ public function __construct( protected readonly ?FileMetadataDto $liveSessionReport, #[Assert\\Valid] protected readonly ?array $liveSessionData, ) { } public function getLiveSessionReport(): ?FileMetadataDto { return $this->liveSessionReport; } public function getLiveSessionData(): ?array { return $this->liveSessionData; }
} 然后在LiveSessionDataDto下对title属性使用了NotBlank验证:
<?php namespace App\\Model\\Dto\\Input; use Symfony\\Component\\Validator\\Constraints as Assert; class LiveSessionDataDto
{ public function __construct( protected ?int $id, #[Assert\\NotBlank(message: 'This field is required.')] protected string $title, ) { } public function getId(): ?int { return $this->id; } public function getTitle(): string { return $this->title; }
} 要想让这个DTO中的 NotBlank 生效，需要给父级添加 #[Assert\\Valid], 否则不生效. 总结： 在 Symfony 里，递归验证需要用 #[Assert\\Valid] 标记在父 DTO 的属性上。`}]},{path:"/content/php/symfony/symfony7%E4%B9%8BDataFixtures%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.html",title:"symfony7下关于HasLifecycleCallbacks的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7之DataFixtures使用注意事项:
1>一般直接执行 php bin/console doctrine:fixtures:load --append 即可将数据初始化到数据库。一定要加 --append, 除非是第一次拉项目，初始化数据库, 否则操作会清空整个数据库(purging database)中的所有表，而不是仅仅清空与指定 group 相关的表. 这直接会把已经存在的数据清理掉.
2>假如后来在DataFixtures又有了新的fixture的话，我只想执行新添加的怎么办
①一开始想到的是如下方法
php bin/console doctrine:fixtures:load --fixtures=src/DataFixtures/LoadEventSubmissionFileRequiredOptionsData.php --fixtures=src/DataFixtures/LoadEventSubmissionFiletypesData.php --fixtures=src/DataFixtures/LoadEventSubmissionTypeWorkflowsData.php --fixtures=src/DataFixtures/LoadEventSubmissionWorkflowData.php
但是报：
doctrine:fixtures:load [--append] [--group GROUP] [--em EM] [--purger PURGER] [--purge-exclusions PURGE-EXCLUSIONS] [--purge-with-truncate]
也即是没有 --fixtures 选项(说明这个方法是错的，没用)
②使用 group 解决这个问题(真的很实用) 定义组标签：
首先，DataFixture 类中实现 FixtureGroupInterface，并定义一个组标签。例如：
<?php namespace App\\DataFixtures; use Doctrine\\Bundle\\FixturesBundle\\Fixture;
use Doctrine\\Persistence\\ObjectManager;
use Doctrine\\Bundle\\FixturesBundle\\FixtureGroupInterface; // 必须要实现这个FixtureGroupInterface
class UserFixtures extends Fixture implements FixtureGroupInterface
{ public function load(ObjectManager $manager): void { // 定义数据加载逻辑 } public static function getGroups(): array { return ['userGroup']; }
} 加载特定的组：
在执行命令时，可以通过 --group 参数指定要加载的 Fixtures 组：
php bin/console doctrine:fixtures:load --group=userGroup 如果想同时加载多个组，可以添加多个 --group 参数：
php bin/console doctrine:fixtures:load --group=userGroup --group=productGroup 3>小插曲
当时忘了加 --append, 然后无法直接取消，然后直接关了 terminal, 但是后台的进程肯定还在运行，再次执行加上了 --append, 直接报了下面的错误
An exception occurred while executing a query: SQLSTATE[HY000]: General error: 1205 Lock wait timeout exceeded; try restarting transaction
原因分析:
因为你在第一次执行 doctrine:fixtures:load 时没有使用 --append，导致数据库在执行清空操作时被锁定，而你中断了这个进程（关闭了 terminal 对话框）。这会导致事务没有正确结束，造成表被锁定，从而引发了后续的锁等待超时问题 (Lock wait timeout exceeded)。`},{header:"处理步骤",slug:"处理步骤",content:""},{header:"1. 检查并终止锁定的事务",slug:"_1-检查并终止锁定的事务",content:`你可以通过 MySQL 命令来查看和终止未完成的事务： 查看当前的锁定情况：
使用以下命令查看当前被锁定的事务：
SHOW ENGINE INNODB STATUS; 这个命令会返回详细的 InnoDB 状态信息，帮助你找出哪个事务占用了锁。 终止锁定的事务：
使用 SHOW FULL PROCESSLIST 查找长时间运行的查询，然后使用 KILL QUERY 终止它。
SHOW FULL PROCESSLIST; 查找到 state 为 Locked 的查询，记下对应的 ID，然后使用以下命令终止该查询：
KILL QUERY <ID>;`},{header:"2. 重启 MySQL 服务（如有必要）",slug:"_2-重启-mysql-服务-如有必要",content:`如果手动终止事务没有效果，或者你不确定哪个事务在持有锁，重启 MySQL 服务会释放所有锁定的事务：
sudo systemctl restart mysql`},{header:"3. 再次执行 doctrine:fixtures:load 并使用 --append",slug:"_3-再次执行-doctrine-fixtures-load-并使用-append",content:`清除锁定问题后，再次执行 doctrine:fixtures:load，并确保这次使用 --append，以防止数据被清空：
php bin/console doctrine:fixtures:load --group=event_submission --append 这样可以避免再次清空整个数据库，保留已有数据，同时加载指定的 Fixtures。`},{header:"总结",slug:"总结",content:`未正确结束的事务可能会造成数据库锁定，导致后续操作失败。
检查并终止锁定的事务，或者通过重启 MySQL 服务释放锁。
重新运行 doctrine:fixtures:load 时使用 --append，以避免再次触发 purging database 操作。`}]},{path:"/content/php/symfony/symfony7%E4%B9%8BNelmioApiDocBundle%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7之NelmioApiDocBundle的使用",pathLocale:"/",contents:[{header:"symfony7之NelmioApiDocBundle的使用",slug:"symfony7之nelmioapidocbundle的使用",content:`链接:https://github.com/nelmio/NelmioApiDocBundle 主要使用如下composer包:
nelmio/api-doc-bundle 这个包会依赖:
zircote/swagger-php 在nelmio/api-doc-bundle的composer.json下有定义`},{header:"项目中使用:",slug:"项目中使用",content:""},{header:"1.定义配置文件(nelmio_api_doc.yaml)",slug:"_1-定义配置文件-nelmio-api-doc-yaml",content:`nelmio_api_doc:
documentation:
info:
title: Qinhong
description: Event platform provided by QH AG
version: 1.0.0
components:
securitySchemes:
qinHongHeaderApiKey:
type: apiKey
in: header
name: X-QINHONG-API-TOKEN
Bearer:
type: http
scheme: bearer
in: header
bearerFormat: JWT
security:
- Bearer: []
areas:
path_patterns: # an array of regexps (document only routes under /api, except /api/doc)
- ^/api(?!/doc$)
documentation:
security:
- qinHongHeaderApiKey: [ ]
- Bearer: [ ] 其中:
info 定义了基本的信息
securitySchemes 定义了几种接口认证方式
security 定义了默认全局的认证方式
areas 定义了接口作用域
areas.path_patterns 定义了哪些路由将会生成接口
areas.documentation.security 定义了当前area下要使用的认证方式`},{header:"2.控制器下使用",slug:"_2-控制器下使用",content:`use Nelmio\\ApiDocBundle\\Annotation\\Model;
use OpenApi\\Attributes as OA; //定义在zircote/swagger-php #[Route('/country-distribution-count', name: 'country_distribution_count', methods: ['GET'])]
#[OA\\Response(
response: 200,
description: 'Return all country distribution count',
content: new Model(type: Dto\\Query\\Statistic\\DistributionCountDto::class)
)]
public function test(
Service\\\\RegistrationService $statisticsService,
): JsonResponse {
return $this->apiResponse->response($statisticsService->test());
} 当然还有其它的注释类可以使用，这里使用的是 OA\\Response`}]},{path:"/content/php/symfony/symfony7%E4%B9%8BUploadedFile%E4%B8%8A%E4%BC%A0%E7%9A%84%E5%8E%9F%E7%90%86.html",title:"symfony7之UploadedFile上传的原理",pathLocale:"/",contents:[{header:"symfony7之UploadedFile上传的原理",slug:"symfony7之uploadedfile上传的原理",content:`UploadedFile 类是 Symfony\\Component\\HttpFoundation\\File\\UploadedFile，查勘表源码可以看到它的move方法是对 php 原生的 move_uploaded_file 方法的封装. //UploadedFile中 move 方法的核心部分如下
$moved = move_uploaded_file($this->getPathname(), $target); // php内置的这个函数，如果目标文件已经存在，将会被覆盖。
@chmod($target, 0666 & ~umask()); // 这个是给新路径下的文件赋权限rw-rw-rw-rw, umask()是系统当前的 权限掩码, 这是标准写法，用来根据系统设置自动“减去”被屏蔽的权限。0666 是 八进制, 前面加个0和666十进制区分 在 PHP（和 C、JavaScript 等许多语言）中，前缀 0 表示“八进制”，就像：
0x 表示十六进制（例如 0xFF 是 255）
0b 表示二进制（例如 0b1010 是 10）
0 表示八进制（例如 0666 是权限） //php 默认前端上传的内容存放到了 /tmp下，格式如 pathname: "/tmp/phpRj5h4q"
但是请求完了之后，这个/tmp下的文件会被清除，所以我们需要在上传的逻辑里调用 move 方法，存到新的位置，后续继续处理(使用) 而UploadedFile 又继承自 File
class UploadedFile extends File
而File又继承自 PHP 内置的 \\SplFileInfo 类
class File extends \\SplFileInfo 为什么这样设计？
\\SplFileInfo 是 PHP 标准库（SPL）中的一个类，专门用来处理文件和目录的相关信息，比如文件名、路径、大小、修改时间等等。
Symfony 利用继承它，复用它提供的丰富文件操作接口，避免重复造轮子。
File 类在此基础上封装了更多功能（比如文件验证、路径处理等）。
UploadedFile 又继承 File，专门增加了针对 HTTP 上传文件的逻辑，比如错误码、临时文件路径、移动文件的方法。 \\SplFileInfo 提供的常用方法（被 File 和 UploadedFile 继承）:
getFilename() — 获取文件名（带扩展名）
getBasename() — 获取文件名（可去掉扩展名）
getPath() — 获取文件目录路径
getPathname() — 获取完整路径（绝对路径）
getExtension() — 获取扩展名
getSize() — 获取文件大小
getMTime() — 获取最后修改时间
isDir()、isFile() — 判断是否为目录或文件 Symfony 额外扩展的方法:
File 和 UploadedFile 增加了上传文件相关的：
getClientOriginalName() — 客户端上传时的原始文件名
getClientOriginalExtension() — 客户端文件扩展名
move() — 将临时文件移动到目标目录
isValid() — 判断文件上传是否成功
上传错误处理等`}]},{path:"/content/php/symfony/symfony7%E4%B9%8Bdoctrine%E9%85%8D%E7%BD%AE.html",title:"symfony7之doctrine配置",pathLocale:"/",contents:[{header:"symfony7之doctrine.yaml配置",slug:"symfony7之doctrine-yaml配置",content:`doctrine: dbal: connections: default: # 主数据库连接 server_version: '8.0' url: '%env(resolve:DATABASE_PRIMARY_URL)%' driver: pdo_mysql charset: utf8mb4 default_table_options: collate: utf8mb4_unicode_ci mapping_types: enum: string schema_filter: ~^(?!(messenger_messages|migration_versions)$)~ replicas: # 让 SELECT 语句自动走 secondary（从库） secondary: url: '%env(resolve:DATABASE_SECONDARY_URL)%' secondary: # 额外手动指定的从库连接 url: '%env(resolve:DATABASE_SECONDARY_URL)%' default_connection: default orm: auto_generate_proxy_classes: true enable_lazy_ghost_objects: true default_entity_manager: default # 默认 entity_manager entity_managers: default: connection: default # 绑定到 dbal.connections.default mappings: App: dir: '%kernel.project_dir%/src/Entity' prefix: 'App\\Entity' alias: App tree: type: attribute # or annotation or xml alias: Gedmo prefix: Gedmo\\Tree\\Entity dir: "%kernel.project_dir%/vendor/gedmo/doctrine-extensions/src/Tree/Entity" # add qinhongpub databases so doctrine can ignore them while executing 'doctrine:migration:diff' command schema_ignore_classes: - App\\Entity\\qinhongpub\\User - App\\Entity\\qinhongpub\\Continent - App\\Entity\\qinhongpub\\Country - App\\Entity\\qinhongpub\\UserJobtype - App\\Entity\\qinhongpub\\UserMultipleEmail - App\\Entity\\qinhongpub\\UserTitle - App\\Entity\\qinhongpub\\UserWorkplace - App\\Entity\\qinhongpub\\EmailUserRel - App\\Entity\\qinhongpub\\ExchangeRate dql: string_functions: concat_ws: DoctrineExtensions\\Query\\Mysql\\ConcatWs secondary: connection: secondary # 绑定 \`dbal.connections.secondary\` mappings: App: dir: '%kernel.project_dir%/src/Entity' prefix: 'App\\Entity' alias: App tree: type: attribute # or annotation or xml alias: Gedmo prefix: Gedmo\\Tree\\Entity dir: "%kernel.project_dir%/vendor/gedmo/doctrine-extensions/src/Tree/Entity" dql: string_functions: concat_ws: DoctrineExtensions\\Query\\Mysql\\ConcatWs`},{header:"使用",slug:"使用",content:`先在 service.yaml下配置binbd参数
bind: $em: "@doctrine.orm.default_entity_manager" # _entity_manager 是一个固定的格式，通常是为了与 Doctrine 的内部约定保持一致。Doctrine 会根据配置的 entity_managers 部分的名称自动生成这些实体管理器的服务名称。如果您定义了多个实体管理器（如 default、secondary、third），Doctrine 会为每个管理器生成对应的服务名称，后缀 _entity_manager 是固定的。 $emSlave: "@doctrine.orm.secondary_entity_manager" # _entity_manager 是一个固定的格式，通常是为了与 Doctrine 的内部约定保持一致。Doctrine 会根据配置的 entity_managers 部分的名称自动生成这些实体管理器的服务名称。如果您定义了多个实体管理器（如 default、secondary、third），Doctrine 会为每个管理器生成对应的服务名称，后缀 _entity_manager 是固定的。 例子:
use Doctrine\\ORM\\EntityManagerInterface; class MyService
{ private EntityManagerInterface $em; private EntityManagerInterface $emSlave; public function __construct(EntityManagerInterface $em, EntityManagerInterface $emSlave) { $this->em = $em; $this->emSlave = $emSlave; } public function fetchData() { // 从主数据库查询 $data = $this->em->getRepository(SomeEntity::class)->findAll(); // 从从数据库查询 $dataSlave = $this->emSlave->getRepository(SomeEntity::class)->findAll(); return [$data, $dataSlave]; }
} // 手动切换数据库连接
use Doctrine\\ORM\\EntityManagerInterface;
use Doctrine\\Persistence\\ManagerRegistry; class YourService
{ public function __construct( private readonly EntityManagerInterface $em, private readonly ManagerRegistry $doctrine, // 允许手动获取不同的 EntityManager ) { } public function getUserFromSlave(int $id) { $emSlave = $this->doctrine->getManager('secondary'); // 获取 secondary EntityManager return $emSlave->getRepository(User::class)->find($id); }
}`},{header:"分析",slug:"分析",content:`dbal（Database Abstraction Layer[数据库抽象层]） 和 orm（Object-Relational Mapper[ORM 映射层]） 是两个不同的部分，它们各自负责不同的任务，但相互配合使用。 dbal:
作用：
负责管理数据库连接
处理SQL 语句的执行
支持多个数据库连接
提供事务管理 上面配置分析:
dbal.connections.default
这是主数据库连接
replicas 让 SELECT 查询可以自动走 secondary (所以当前的配置，，默认就通过replicas实现了主从数据库操作) dbal.connections.secondary
这是额外定义的从库连接
主要用于手动切换 EntityManager 使用 default_connection: default
默认情况下，Doctrine 会使用 default 连接
👉 结论：dbal 只管数据库连接，不涉及 ORM 映射 orm:
作用：
负责实体（Entity）和数据库表的映射
让你用 PHP 对象 而不是 SQL 语句操作数据库
需要 EntityManager 来管理数据库操作
支持 多个 EntityManager，每个 EntityManager 可以绑定不同的数据库连接 上面配置分析:
default_entity_manager: default
默认 EntityManager 绑定 dbal.connections.default entity_managers.default.connection: default
这个 EntityManager 绑定到 default（主数据库） entity_managers.secondary.connection: secondary
这个 EntityManager 绑定到 secondary（从数据库） 最终效果：
默认 ORM 查询会自动使用 dbal.default
如果是 SELECT 语句，Doctrine 会自动切换到 replicas.secondary
如果是 INSERT/UPDATE/DELETE 语句，Doctrine 仍然使用 dbal.default（主库）
如果手动指定 orm.entity_managers.secondary，那么所有操作都走 dbal.connections.secondary`}]},{path:"/content/php/symfony/symfony7%E4%B9%8BgetSingleScalarResult%E6%96%B9%E6%B3%95.html",title:"symfony7之getSingleScalarResult方法",pathLocale:"/",contents:[{header:"symfony7之getSingleScalarResult方法",slug:"symfony7之getsinglescalarresult方法",content:`getSingleScalarResult() 是 Doctrine 中 Query 对象的方法之一，用于返回查询结果中的单个标量值，比如： 一个整数数量（如 COUNT() 的结果）；
一个单个字段的值（比如 MAX(price)）；`},{header:"✅ 常见用法场景",slug:"✅-常见用法场景",content:""},{header:"1. COUNT(...)",slug:"_1-count",content:`$count = $qb ->select('COUNT(o.id)') ->getQuery() ->getSingleScalarResult(); 返回的是一个字符串，需要手动强转为 int：
(int) $count`},{header:"2. SUM(...) / MAX(...) / MIN(...)",slug:"_2-sum-max-min",content:"$sum = $qb ->select('SUM(o.amount)') ->getQuery() ->getSingleScalarResult(); // 返回 string，例如 '1234.50'"},{header:"⚠️ 注意事项",slug:"⚠️-注意事项",content:"返回的是字符串（无论是数字还是其他类型），因此常常需要 (int) 或 (float) 转换； 只能用于返回单个结果，否则抛出异常： Doctrine\\ORM\\NonUniqueResultException"},{header:"🚫 不适用的情况：",slug:"🚫-不适用的情况",content:`如果你查询的是多列、多行（比如列表或多字段结构），应使用： getResult() → 返回多行多列（数组）
getOneOrNullResult() → 仅用于一个实体对象（或 null）
getArrayResult() → 返回数组结构`},{header:"symfony7对于 getSingleResult 的使用",slug:"symfony7对于-getsingleresult-的使用",content:`在 Symfony 7（Doctrine ORM）中，getSingleResult() 仍然会生效，即使执行的是一个 SELECT COUNT(...), SUM(...) 这样的聚合查询，并返回多列别名字段。 来看一下这段代码：
->select( 'COUNT(p.id) as total', "SUM(CASE WHEN p.status = :accepted THEN 1 ELSE 0 END) as accepted", "SUM(CASE WHEN p.status = :rejected THEN 1 ELSE 0 END) as rejected"
) 这是一个只会返回一行结果的聚合查询（没有 GROUP BY）, 调用：
$qb->getQuery()->getSingleResult(); 它将返回一个关联数组（如果你使用的是 Query::HYDRATE_ARRAY 或默认的 hydrate mode）：
[ 'total' => '10', 'accepted' => '5', 'rejected' => '1'
] 注意返回值中的数字是字符串形式（因为 SQL 查询返回的是字符串类型），所以你用：
return array_map('intval', $qb->getQuery()->getSingleResult()); 是正确且常见的做法 —— 把这些聚合数值字段全部转为 int 类型。
array_map('intval', $array) 会对数组中 每一个值 执行 intval() 转换操作，无论键名是什么（键名会保留）。
例如：
$data = [ 'total' => '10', 'accepted' => '5', 'rejected' => '1'
]; $result = array_map('intval', $data); 执行后 $result 为：
[ 'total' => 10, 'accepted' => 5, 'rejected' => 1
]`},{header:"✅ 总结：",slug:"✅-总结",content:`✅ 会转换每个 值 为整数。
✅ 键名不变。
❌ 不会处理嵌套数组（只是浅层转换）。 如果你只想转换某些字段，可以单独写：
$result = $qb->getQuery()->getSingleResult();
$result['total'] = (int) $result['total'];`},{header:"补充说明：",slug:"补充说明",content:""},{header:"如果用的是 DQL（Doctrine Query Language）：",slug:"如果用的是-dql-doctrine-query-language",content:"getSingleResult() 会返回一个索引数组或对象，取决于你的 DQL 查询和 hydration 方式。"},{header:"如果你想确保返回关联数组：",slug:"如果你想确保返回关联数组",content:`你可以显示设置 hydration mode 为 HYDRATE_ARRAY：
return array_map('intval', $qb->getQuery()->getSingleResult(\\Doctrine\\ORM\\Query::HYDRATE_ARRAY)); 但在使用 QueryBuilder 默认是 HYDRATE_ARRAY，你写法就已经 OK。 ✅ 结论： getSingleResult() 在你的这个 SQL 聚合查询中是生效的，会返回一行数组，array_map('intval', ...) 用于转整型也完全合理。可以放心使用。
适用于单行数据，而无论是单个字段还是多个字段`}]},{path:"/content/php/symfony/symfony7%E4%B9%8Bliteral%E5%AE%89%E5%85%A8%E6%9F%A5%E8%AF%A2.html",title:"symfony7之literal安全查询",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7之literal安全查询:
使用: $qb->expr()->literal()
1>
$qb->where( $qb->expr()->eq( 'u.id', $qb->expr()->literal($userId) )
) 2>
$qb->where( $qb->expr()->like( 'u.firstName', $qb->expr()->literal('%' . $userRoleDto->getSearch() . '%') )
) 总结:在进行任何类型的查询时使用 literal() 都是一个好习惯，因为它能提高安全性。使用 literal() 的好处：
安全性：防止 SQL 注入攻击。
正确处理数据类型：确保值被正确地转换和引用。
一致性：为所有类型的查询提供统一的处理方式。`}]},{path:"/content/php/symfony/symfony7%E4%B9%8Bserializer%E4%BD%BF%E7%94%A8.html",title:"symfony7之serializer使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7之serializer使用:
核心的方法:
$serializer->normalize https://symfony.com/doc/current/components/serializer.html#context`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E4%BD%BF%E7%94%A8JSON_ARRAYAGG%E5%92%8CJSON_OBJECT%E5%81%9A%E5%8E%9F%E7%94%9Fsql%E6%9F%A5%E8%AF%A2.html",title:"symfony7之使用JSON_ARRAYAGG和JSON_OBJECT做原生sql查询",pathLocale:"/",contents:[{header:"symfony7之使用JSON_ARRAYAGG和JSON_OBJECT做原生sql查询",slug:"symfony7之使用json-arrayagg和json-object做原生sql查询",content:`public function getCertificateListWithEvent(Dto\\Input\\Certificate\\CertificateListSearchDto $certificateListSearchDto)
{ $params = []; $where = []; if (!empty($certificateListSearchDto->getSearch())) { $where[] = '(e.title LIKE :search OR e.abbreviation LIKE :search)'; $params['search'] = '%' . $certificateListSearchDto->getSearch() . '%'; } if (!empty($certificateListSearchDto->getCertificateType())) { $where[] = 'ct.title = :certificateType'; $params['certificateType'] = $certificateListSearchDto->getCertificateType(); } $sql = "SELECT e.id, e.title, e.abbreviation, JSON_ARRAYAGG( JSON_OBJECT( 'id', ct.id, 'title', ct.title, 'certificateImage', ct.certificate_template_path, 'accessSetting', ct.access_setting, 'systemKey', ct.system_key, 'userDefined', ct.user_defined ) // 这里本来还想对 JSON_OBJECT 使用 order by ct.sort_order desc 的，虽然我的mysql是 8.0.34 > 8.0.14 但是还是报版本问题 ) AS certificateTypes FROM events e INNER JOIN certificate_types ct ON e.id = ct.event_id"; if (!empty($where)) { $sql .= ' WHERE ' . implode(' AND ', $where); } $sql .= ' GROUP BY e.id ORDER BY e.end_date DESC'; $connection = $this->getEntityManager()->getConnection(); $result = $connection->executeQuery($sql, $params); return $result->fetchAllAssociative();
} 关于 JSON_ARRAYAGG 和 JSON_OBJECT 的用法和区别，这两个是 MySQL（8.0+）提供的 JSON 生成函数，配合起来用就能生成结构化 JSON 数据。`},{header:"1️⃣ JSON_OBJECT",slug:"_1️⃣-json-object",content:`作用：生成一个 单个 JSON 对象（key-value 结构）
语法：
JSON_OBJECT(key1, value1, key2, value2, ...) 例子：
SELECT JSON_OBJECT( 'id', 1, 'title', 'Certificate A', 'sort_order', 5
); 结果：
{"id": 1, "title": "Certificate A", "sort_order": 5} 特点： 参数必须成对出现（key, value）。
key 必须是字符串，value 可以是任意表达式（数字、字符串、列名等）。
如果 key 重复，会取最后一个的值。
可以嵌套，比如 JSON_OBJECT('info', JSON_OBJECT('id', 1))。`},{header:"2️⃣ JSON_ARRAYAGG",slug:"_2️⃣-json-arrayagg",content:`作用：聚合多行数据为一个 JSON 数组
语法：
JSON_ARRAYAGG(value [ORDER BY sort_expr ASC|DESC]) 例子：
SELECT JSON_ARRAYAGG(title) AS titles
FROM certificate_types; 可能结果：
["Certificate A", "Certificate B", "Certificate C"] 特点： 类似 GROUP_CONCAT，但返回 JSON 数组，而不是字符串。
ORDER BY（8.0.14+）可以控制数组内部顺序。
value 可以是简单列值，也可以是 JSON 对象。`},{header:"3️⃣ 组合使用",slug:"_3️⃣-组合使用",content:`常用场景：先用 JSON_OBJECT 生成每一行的 JSON 对象，再用 JSON_ARRAYAGG 把这些对象聚合成一个数组。
理解： JSON_OBJECT：一行 → 一个 JSON 对象
JSON_ARRAYAGG：多行对象 → 一个 JSON 数组`},{header:"4️⃣ 版本限制",slug:"_4️⃣-版本限制",content:`JSON_OBJECT → MySQL 5.7.8+ 就支持
JSON_ARRAYAGG → MySQL 8.0+ 才支持
JSON_ARRAYAGG(... ORDER BY ...) → MySQL 8.0.14+ 才支持排序`},{header:"5️⃣ 你的场景解释",slug:"_5️⃣-你的场景解释",content:`你代码里：
JSON_ARRAYAGG( JSON_OBJECT( 'id', ct.id, 'title', ct.title, 'certificateImage', ct.certificate_template_path, 'accessSetting', ct.access_setting, 'systemKey', ct.system_key, 'userDefined', ct.user_defined )
) AS certificateTypes 等于： 对每个证书类型（ct） 生成一个 JSON 对象（id、title 等字段）。
聚合到一个 JSON 数组（所有属于某个 event 的证书类型放到一起）。
结合 GROUP BY e.id，保证每个活动 (event) 只返回一行，并且那一行的 certificateTypes 是该活动的所有证书类型数组。 关于 JSON_ARRAYAGG 和 JSON_OBJECT, 我之前一直以为是两个窗口函数，但是根据窗口函数的定义，它们不是的，`},{header:"1️⃣ 它们的类别",slug:"_1️⃣-它们的类别",content:`JSON_OBJECT → 普通函数（scalar function） 每一行执行一次，返回一个 JSON 对象。
和 CONCAT()、LENGTH() 这种函数一样，不涉及分组聚合。 JSON_ARRAYAGG → 聚合函数（aggregate function） 类似 SUM()、GROUP_CONCAT()，是基于分组（GROUP BY）对多行进行聚合，返回一个 JSON 数组。
不能单独在 SELECT 里随便用，除非有分组（或者整个表当成一个组）。`},{header:"2️⃣ 窗口函数是什么",slug:"_2️⃣-窗口函数是什么",content:`窗口函数（window function） 是在分组聚合之后，还能“保留行级细节”的函数，比如：
ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC) 特点： 必须和 OVER (...) 一起用。
不会合并成一行，而是返回每行对应的计算结果。`},{header:"3️⃣ 区别总结",slug:"_3️⃣-区别总结",content:`函数类型
示例
是否需要 GROUP BY
返回行数 普通函数
JSON_OBJECT()
不需要
和输入行一样多 聚合函数
JSON_ARRAYAGG()
通常需要
每组一行 窗口函数
ROW_NUMBER() OVER()
不需要（用 PARTITION 代替）
和输入行一样多`},{header:"4️⃣ 代码里的情况",slug:"_4️⃣-代码里的情况",content:`JSON_ARRAYAGG(JSON_OBJECT(...)) AS certificateTypes JSON_OBJECT(...)：普通函数，生成每行的 JSON 对象。
JSON_ARRAYAGG(...)：聚合函数，把当前 GROUP BY e.id 的多行对象合并成一个数组。 它俩配合起来用，就能实现“按 event 分组，每组输出一个 JSON 数组”。
这跟窗口函数是完全不同的机制。`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E4%BD%BF%E7%94%A8LPAD%E5%81%9Alike%E6%8B%BC%E6%8E%A5%E6%9F%A5%E8%AF%A2.html",title:"symfony7之使用LPAD做like拼接查询",pathLocale:"/",contents:[{header:"symfony7之使用LPAD做like拼接查询",slug:"symfony7之使用lpad做like拼接查询",content:"解释:\nLPAD 是 SQL 中的一个字符串函数，全称是 Left PAD，意思是：向字符串左边填充指定字符，直到达到指定长度。 语法:\nLPAD(string, length, pad_string)\nstring：要被填充的原字符串（可以是字段）\nlength：目标长度\npad_string：用来填充的字符（通常是 '0'） 使用:\n在 Symfony 7 + Doctrine 下使用 `LPAD`（`Lpad` 函数）确实需要通过引入 `beberlei/DoctrineExtensions` 中的自定义 DQL 函数 `DoctrineExtensions\\Query\\Mysql\\Lpad`。以下是完整的引入、配置和在 `QueryBuilder` 中正确使用的方式。"},{header:"✅ 1. 安装依赖",slug:"✅-1-安装依赖",content:`首先，确保安装了 beberlei/DoctrineExtensions：
composer require beberlei/DoctrineExtensions`},{header:"✅ 2. 注册 Lpad 函数到 Doctrine",slug:"✅-2-注册-lpad-函数到-doctrine",content:`在 config/packages/doctrine.yaml 中添加配置：
doctrine: orm: dql: string_functions: LPAD: DoctrineExtensions\\Query\\Mysql\\Lpad 注意：LPAD 是大小写敏感的，注册名（左侧）需要与 SQL 使用时一致。`},{header:"✅ 3. 正确使用 LPAD + CONCAT + LIKE 组合",slug:"✅-3-正确使用-lpad-concat-like-组合",content:`在 QueryBuilder 中不能直接使用 PHP 函数，需要用 DQL 表达式来写。你提供的语法：
$qb->expr()->like("CONCAT(e.abbreviation, '-', LPAD(s.indexNumber, 6, 0))", ':searchString') 是字符串，不能直接传给 expr()->like()。正确写法是使用 Expr 的 literal() 或手动拼接 DQL：
$qb->andWhere( $qb->expr()->like( "CONCAT(e.abbreviation, '-', LPAD(s.indexNumber, 6, '0'))", ':searchString' )
);
$qb->setParameter('searchString', '%' . $searchString . '%'); ⚠️ 注意几点： LPAD 第三个参数是字符，必须用 '0' 包括引号。
LPAD(s.indexNumber, 6, '0') 是 DQL 中自定义函数。
整个表达式作为字符串传给 like()，等价于原生 SQL。`},{header:"🧪 示例完整代码片段",slug:"🧪-示例完整代码片段",content:`$qb = $em->createQueryBuilder();
$qb->select('s') ->from(Submission::class, 's') ->join('s.event', 'e') ->andWhere( $qb->expr()->like( "CONCAT(e.abbreviation, '-', LPAD(s.indexNumber, 6, '0'))", ':searchString' ) ) ->setParameter('searchString', '%' . $searchTerm . '%'); 如果遇到 Function 'LPAD' does not exist，说明注册没有成功，确认： doctrine.yaml 中的配置是否在正确环境下（比如 dev, prod）。
配置是否清除缓存后重新加载了：运行 php bin/console cache:clear`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E4%BD%BF%E7%94%A8Validator%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html",title:"symfony7之使用Validator的三种方式",pathLocale:"/",contents:[{header:"symfony7之使用Validator的三种方式",slug:"symfony7之使用validator的三种方式",content:`在App\\Validator自定义如下Constraint <?php namespace App\\Validator; use Symfony\\Component\\Validator\\Constraint; #[\\Attribute]
class RegistrationInformation extends Constraint
{ public function validatedBy(): string { return static::class . 'Validator'; } public function getTargets(): string { return self::CLASS_CONSTRAINT; }
} <?php namespace App\\Validator; use App\\Entity;
use App\\Enum\\EventTypeEnum;
use App\\Model\\Dto\\Input\\RegistrationInformationDto;
use Doctrine\\ORM\\EntityManagerInterface;
use Symfony\\Component\\Validator\\Constraint;
use Symfony\\Component\\Validator\\ConstraintValidator; class RegistrationInformationValidator extends ConstraintValidator
{ public function __construct( private readonly EntityManagerInterface $em, ) { } /** * @param RegistrationInformationDto $registrationInformationDto */ public function validate($registrationInformationDto, Constraint $constraint): void { //some validate logic here. }
} 使用方式1 在DTO上
use App\\Validator as MainAssert;
#[MainAssert\\RegistrationInformation]
class RegistrationInformationDto { // define DTO here
} 在控制器上
public function process( #[MapRequestPayload] Dto\\Input\\RegistrationInformationDto $registrationInformationDto, Registration\\InformationService $informationService, ): JsonResponse { //logic here. } 那么 运行之后RegistrationInformation Validator 会自动生效 使用方式2 不加#[MapRequestPayload]
直接在servicce里: use Symfony\\Component\\Validator\\Validator\\ValidatorInterface; public function __construct( private readonly ValidatorInterface $validator, ) { } $validationErrors = $this->validator->validate($registrationInformationDto);
也可以, 因为 $registrationInformationDto 这个DTO 前面使用了 #[MainAssert\\RegistrationInformation] 注释, Validator 会根据 DTO 上的 attribute（如果有）自动查找所有的 constraint 使用方式3 加#[MapRequestPayload]
但是在DTO里没有
#[MainAssert\\RegistrationInformation]
然后在service里
$violations = $this->validator->validate(['action' => $emailTemplateAction, 'order' => $order], new RegistrationInformation()); 也可以，当然还有 validateProperty 可以用
这种方式其实就是，使用了标准的validator结构:
$validator->validate(array, new Constraint())
上面就是通过 new RegistrationInformation() 这个Constraint 来验证 ['action' => $emailTemplateAction, 'order' => $order]，和 DTO 没关系. 其实还有第四种方式`},{header:"通过对DTO的resolver的方式",slug:"通过对dto的resolver的方式",content:`symfony7下有如下自定义resolver， 我认为实际功能包括
1.在request里做validate
2.动态修改请求参数 //基础类
<?php namespace App\\Model\\Dto\\Resolver; use App\\Model\\Dto\\Interface\\ResolvableInterface;
use App\\Service\\AuthenticationService;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\HttpKernel\\Controller\\ValueResolverInterface;
use Symfony\\Component\\HttpKernel\\ControllerMetadata\\ArgumentMetadata;
use Symfony\\Component\\HttpKernel\\Exception\\HttpException;
use Symfony\\Component\\Serializer\\SerializerInterface;
use Symfony\\Component\\Validator\\Exception\\ValidationFailedException;
use Symfony\\Component\\Validator\\Validator\\ValidatorInterface; /** * @template TResolvableInterface as ResolvableInterface */
abstract class AbstractDtoResolver implements ValueResolverInterface
{ public function __construct( protected readonly AuthenticationService $security, protected readonly SerializerInterface $serializer, protected readonly ValidatorInterface $validator, ) { } /** * @return iterable<TResolvableInterface> */ public function resolve(Request $request, ArgumentMetadata $argument): iterable { if ($argument->getType() !== $this->getSupportedType()) { return []; } $deserializedDto = $this->serializer->deserialize($request->getContent(), $this->getSupportedType(), 'json'); $dtoObject = $this->postResolve($deserializedDto); $violations = $this->validator->validate($dtoObject); if (\\count($violations)) { throw new HttpException(Response::HTTP_UNPROCESSABLE_ENTITY, implode("\\n", array_map(static fn ($e) => $e->getMessage(), iterator_to_array($violations))), new ValidationFailedException($request->getPayload(), $violations)); } return [$dtoObject]; } /** * @param TResolvableInterface $resolvable * * @return TResolvableInterface */ abstract protected function postResolve(ResolvableInterface $resolvable): ResolvableInterface; abstract protected function getSupportedType(): string;
} // 次基础类
<?php namespace App\\Model\\Dto\\Resolver; use App\\Model\\Dto\\Interface\\ResolvableInterface;
use App\\Service\\AuthenticationService;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\RequestStack;
use Symfony\\Component\\Serializer\\SerializerInterface;
use Symfony\\Component\\Validator\\Validator\\ValidatorInterface; /** * @extends AbstractDtoResolver<ResolvableInterface> */
abstract class AbstractRequestDtoResolver extends AbstractDtoResolver
{ public function __construct( private readonly RequestStack $requestStack, AuthenticationService $security, SerializerInterface $serializer, ValidatorInterface $validator, ) { parent::__construct($security, $serializer, $validator); } protected function getRequest(): ?Request { return $this->requestStack->getCurrentRequest(); }
} //使用
<?php namespace App\\Model\\Dto\\Resolver; use App\\Model\\Dto\\Input\\Submission\\Assignment\\MakeRecommendationDto;
use App\\Model\\Dto\\Interface\\ResolvableInterface;
use PHPUnit\\Framework\\Attributes\\UsesClass; #[UsesClass(MakeRecommendationDto::class)]
class MakeRecommendationDtoResolver extends AbstractRequestDtoResolver
{ protected function getSupportedType(): string { return MakeRecommendationDto::class; } protected function postResolve(ResolvableInterface $resolvable): ResolvableInterface { $request = $this->getRequest(); if (null !== $request && $resolvable instanceof MakeRecommendationDto) { $assignmentId = $request->attributes->get('assignment');//这个其实路由参数，赋值给DTO if (null !== $assignmentId) { $resolvable->setAssignmentId($assignmentId); } } return $resolvable; }
} 然后在控制器里，直接使用 MakeRecommendationDto， 不需要 #[MapRequestPayload], 但是需要在 MakeRecommendationDto 前面添加类的 #[MainAssert\\xxxxx]，这个其实和前面的方式2 很像，但是却是在 resolver 下生效的`},{header:"上面代码其实具体实现了如下两个功能",slug:"上面代码其实具体实现了如下两个功能",content:""},{header:"1️⃣ 主要职责",slug:"_1️⃣-主要职责",content:"AbstractDtoResolver + AbstractRequestDtoResolver + MakeRecommendationDtoResolver 组合起来做了两个核心工作："},{header:"(A) 请求内容的验证（Validation）",slug:"a-请求内容的验证-validation",content:`resolve() 方法会： 反序列化请求的 JSON body 到指定 DTO 类：$deserializedDto = $this->serializer->deserialize($request->getContent(), $this->getSupportedType(), 'json'); 调用 postResolve() 做进一步处理（可选）。
使用 Symfony Validator 验证 DTO：$violations = $this->validator->validate($dtoObject);
if (\\count($violations)) { throw new HttpException(...);
} 如果验证失败，会抛出 422 Unprocessable Entity 并附带详细的验证错误。`},{header:"(B) 动态修改请求参数 / DTO 填充",slug:"b-动态修改请求参数-dto-填充",content:`postResolve() 是抽象方法，由子类实现。 MakeRecommendationDtoResolver 中实现了：
$assignmentId = $request->attributes->get('assignment');
if (null !== $assignmentId) { $resolvable->setAssignmentId($assignmentId);
} 这实际上是根据请求的路由参数动态给 DTO 填充 assignmentId。 🔹 注意：这里修改的是 DTO 对象，而不是直接修改 $request->request。但由于 Controller 会直接接收这个 DTO 参数，所以从 Controller 角度看，参数已经被动态修改了。后面控制器里面可以直接使用这个 resolve 后的DTO`},{header:"2️⃣ 工作流程总结",slug:"_2️⃣-工作流程总结",content:`Symfony 解析 Controller 参数时，会调用对应的 ValueResolver。
AbstractDtoResolver 检查 Controller 参数类型是否匹配。
JSON body → DTO（反序列化）。
postResolve() 做额外处理，例如动态填充 DTO 字段。
Validator 校验 DTO。
返回 DTO，注入到 Controller 方法参数中。`},{header:"3️⃣ 小结",slug:"_3️⃣-小结",content:`你的理解几乎正确： ✅ 在 request 里做 validate — ValidatorInterface 校验 DTO。
✅ 动态修改请求参数 — 通过 postResolve() 给 DTO 动态赋值，通常基于路由参数或其它 request 属性。
额外补充： 这种方式可以把 DTO 处理逻辑完全抽象出去，Controller 只需要接收 DTO，干净简洁。
也保证了请求在进入 Controller 前就被验证和准备好。`},{header:"关于DTO上同时使用了自定义的Constraint和属性上使用了字通自带的验证的话，那么它们的执行顺序是什么样的呢",slug:"关于dto上同时使用了自定义的constraint和属性上使用了字通自带的验证的话-那么它们的执行顺序是什么样的呢",content:`use Symfony\\Component\\Validator\\Constraints as Assert;
use App\\Validator as MainAssert; #[MainAssert\\RegistrationInformation]
class RegistrationInformationDto
{ #[Assert\\NotBlank(message: 'Password cannot be blank')] private readonly string $password; // 其他字段
} 执行顺序如下:
字段级别（Property constraints）
逐个属性执行验证，如 #[Assert\\NotBlank]、#[Assert\\Email] 等。
如果字段验证失败，返回字段的 ConstraintViolation。 类级别（Class constraints）
在所有字段验证之后，执行如 #[RegistrationInformation] 这类作用在类上的 constraint。 为什么是这个顺序？
字段级别先运行，可以优先捕捉输入格式类错误，避免在类级别中处理无效字段数据；
类级别更适合进行组合判断或逻辑验证（如 if A then B），这些往往依赖字段的前置有效性。`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E4%BD%BF%E7%94%A8redis%E7%BC%93%E5%AD%98.html",title:"symfony7之使用redis缓存",pathLocale:"/",contents:[{header:"symfony7之使用redis缓存",slug:"symfony7之使用redis缓存",content:`部分代码如下 //这个是 redis cache servvice 的部分定义
public function get(CachePrefixEnum $prefix, string $hashKey): mixed { $key = $this->buildCacheKey($prefix, $hashKey); $item = $this->cache->getItem($key); return $item->isHit() ? $item->get() : null; } 然后在使用的时候，有这么一个定义 $statisticsDto = $this->cacheService->get(Enum\\CachePrefixEnum::EVENT_STATS, $hashKey);
if ($statisticsDto instanceof Dto\\Query\\Statistic\\EventStatisticsDto) { $announcedEventsDto = $statisticsDto->getAnnouncedEvents();
} else { //other logic
} 问题是对于拿到的redis缓存数据，为什么可以用 instanceof？ 原因如下: 1. 缓存的是一个对象（例如 EventStatisticsDto 实例）。
2. Redis 缓存实际上存储的是序列化后的字符串（二进制数据）。
3. Symfony 的缓存组件在底层会帮你自动做序列化和反序列化操作。
4. 取缓存时 $item->get() 返回的就是你缓存时存进去的原始对象（经过自动反序列化后的对象）。 实际上直接使用redis缓存数据是不可能有这个 instanceof 的 1. Redis 里缓存的是序列化后的字符串，不是对象本身。
2. Symfony 缓存组件（symfony/cache）会自动对数据做序列化和反序列化，所以 $item->get() 返回的才是反序列化后的对象实例。
3. 如果绕过了 Symfony 缓存组件，直接用 Redis 客户端取数据（原始字符串）时，确实没法 instanceof，因为它就是字符串，不是对象。`},{header:"现在深入分析一下symfony7的缓存策略",slug:"现在深入分析一下symfony7的缓存策略",content:`通过 Symfony 缓存组件 API 来操作缓存（CacheItemPoolInterface），而不是直接使用redis命令操作.
关于 CacheItemPoolInterface 的解释如下 它是 PSR-6 缓存接口规范里定义的一个核心接口。
用于定义缓存池（Cache Pool）的行为。
Symfony 的缓存组件实现了这个接口（如 Symfony\\Component\\Cache\\Adapter\\RedisAdapter），以标准方式操作缓存项。 主要职责和作用 获取缓存项（key 对应的缓存数据项）。
保存缓存项（更新或新建缓存数据）。
删除缓存项。
清空缓存池。
批量操作。 核心方法interface CacheItemPoolInterface
{ // 根据缓存键获取缓存项对象 CacheItemInterface public function getItem(string $key): CacheItemInterface; // 获取多个缓存项对象 public function getItems(array $keys = []): iterable; // 检查缓存键是否存在且未过期 public function hasItem(string $key): bool; // 保存缓存项（写入缓存） public function save(CacheItemInterface $item): bool; // 延迟保存缓存项（可以批量写入） public function saveDeferred(CacheItemInterface $item): bool; // 提交所有延迟保存的缓存项 public function commit(): bool; // 删除指定缓存项 public function deleteItem(string $key): bool; // 删除多个缓存项 public function deleteItems(array $keys): bool; // 清空整个缓存池 public function clear(): bool;
} 之前的get()方法与 CacheItemInterface 的关系getItem($key) 返回一个 CacheItemInterface 对象，代表具体的缓存条目。
CacheItemInterface 负责管理缓存条目： 读取缓存值 (get()) 判断缓存是否命中 (isHit()) 设置缓存值 (set()) 设置过期时间 (expiresAt(), expiresAfter()) 总结1. CacheItemPoolInterface 是缓存“池”接口，负责获取、保存、删除缓存项。
2. 每个缓存项通过 CacheItemInterface 表示，封装了具体数据和值和元信息（如过期时间、是否命中）。
3. 它是 PSR-6 规范的一部分，保证缓存库接口的统一。
4. Symfony 实现了这个接口，适配 Redis、Memcached、Filesystem 等多种缓存存储。
5. 使用这个接口，可以优雅且标准地操作缓存，避免直接操作 Redis 客户端细节。 对于Symfony 7 里你想用 Redis 缓存，一般就是用 Adapter\\RedisAdapter，然后在配置文件里配置就可以了。`},{header:"1. Symfony 缓存适配器概念",slug:"_1-symfony-缓存适配器概念",content:`Symfony\\Component\\Cache\\Adapter\\RedisAdapter 是 Symfony Cache 组件提供的 Redis 缓存适配器。
它实现了 PSR-6 的 CacheItemPoolInterface，你可以用它操作缓存（读写缓存项）。`},{header:"2. 如何配置和使用 RedisAdapter",slug:"_2-如何配置和使用-redisadapter",content:""},{header:"方法一：在 Symfony 配置文件中配置缓存",slug:"方法一-在-symfony-配置文件中配置缓存",content:`如果是 Symfony Flex 项目，一般在 config/packages/cache.yaml 或 config/packages/framework.yaml 配置： framework: cache: pools: app.redis_cache: adapter: 'cache.adapter.redis' default_lifetime: 3600 provider: 'redis://localhost' # 或者用环境变量 这样配置后，你就可以在代码里通过依赖注入拿到这个缓存池： use Psr\\Cache\\CacheItemPoolInterface; public function __construct(CacheItemPoolInterface $redisCache)
{ $this->cache = $redisCache;
} 或者你直接通过服务名获取：app.redis_cache`},{header:"方法二：手动创建 RedisAdapter",slug:"方法二-手动创建-redisadapter",content:`如果你想手动创建：
use Symfony\\Component\\Cache\\Adapter\\RedisAdapter; $redisClient = RedisAdapter::createConnection('redis://localhost'); $cache = new RedisAdapter($redisClient, $namespace = '', $defaultLifetime = 3600); 然后 $cache 就是一个符合 PSR-6 的缓存池。`},{header:"3. 常见环境变量配置",slug:"_3-常见环境变量配置",content:`一般会把 Redis 连接串放到 .env 文件：
REDIS_URL=redis://localhost:6379 然后在 framework.yaml 里引用：
framework: cache: pools: app.redis_cache: adapter: 'cache.adapter.redis' provider: '%env(REDIS_URL)%'`},{header:"4. 使用示例",slug:"_4-使用示例",content:`$item = $cache->getItem('some_key');
if (!$item->isHit()) { $data = 'some expensive data'; $item->set($data); $cache->save($item);
} else { $data = $item->get();
}`},{header:"总结",slug:"总结",content:`Symfony 7 的缓存组件自带多种适配器（Redis、Filesystem、Memcached 等）。
你只要在配置文件中声明 adapter: cache.adapter.redis 和 Redis 连接字符串即可。
也可以直接用 RedisAdapter 手动创建缓存池对象。
通过依赖注入使用缓存，方便优雅。`},{header:"关于PSR6",slug:"关于psr6",content:`参考链接 https://www.php-fig.org/psr/psr-6/ CacheItemPoolInterface 来自 PSR-6（PHP Standards Recommendation 6），是 PHP-FIG（PHP Framework Interop Group）定义的缓存接口标准。 不是 PHP 自带:
PHP 本身（内核或标准库）没有缓存相关接口，这需要第三方库或者框架实现。 Symfony 的实现:
Symfony 7 及其缓存组件（symfony/cache 包）实现了 PSR-6 规范，并提供了具体的类（例如 Symfony\\Component\\Cache\\Adapter\\RedisAdapter）实现了这个接口。 安装方式:
需要通过 Composer 安装相关包（通常 symfony/cache 会自动依赖 psr/cache，其中包含接口定义）。也可以单独安装 composer require psr/cache symfony7包依赖关系 1. Symfony 7 框架 本身包含很多组件，但缓存相关功能主要由 symfony/cache 组件提供。
2. symfony/cache 组件实现了 PSR-6 和 PSR-16 缓存标准接口，支持多种缓存适配器（Redis、Memcached、Filesystem 等）。
3. PSR-6 规范接口 是由 psr/cache 这个包定义的，里面包含了 CacheItemPoolInterface、CacheItemInterface 等接口声明。`},{header:"关于 PHP-FIG",slug:"关于-php-fig",content:`PHP-FIG（PHP Framework Interop Group）是一个第三方组织，专门致力于推动 PHP 社区各大框架和库之间的互操作性和标准化。 全称：PHP Framework Interop Group
性质：开源社区组织（非盈利性质）
成立目的：
为了让不同 PHP 框架和库能更好地协同工作，制定一套统一的编码规范和接口标准（PSR，PHP Standards Recommendations）。
成员：来自多个主流 PHP 框架和库的开发者（比如 Symfony、Laravel、Zend Framework、Drupal 等）
工作方式：通过讨论和提案，发布规范（PSR），推动 PHP 生态标准化。`},{header:"主要贡献",slug:"主要贡献",content:`制定了很多重要的 PHP 标准规范，如： PSR-1：基础编码规范
PSR-4：自动加载规范
PSR-6：缓存接口规范
PSR-7：HTTP 消息接口
PSR-12：代码风格规范
等等...`},{header:"影响",slug:"影响",content:`PHP-FIG 的标准被绝大多数现代 PHP 框架和库广泛采纳。
它极大地促进了 PHP 生态系统的规范化和互通性。
Composer（PHP 包管理工具）也很大程度上依赖这些标准。`},{header:"简单总结",slug:"简单总结",content:`组织名
作用
特点 PHP-FIG
制定 PHP 标准规范（PSR 系列）
社区驱动，跨框架协作组织`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E6%8B%93%E5%B1%95doctrine%E6%9F%A5%E8%AF%A2.html",title:"symfony7之拓展doctrine查询",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7之拓展doctrine查询:
安装拓展包: composer require beberlei/doctrineextensions
配置: https://symfony.com/doc/current/doctrine/custom_dql_functions.html`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89command%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8dry-run.html",title:"symfony7之自定义command以及使用dry-run",pathLocale:"/",contents:[{header:"symfony7自定义command以及使用dry run",slug:"symfony7自定义command以及使用dry-run",content:`<?php namespace App\\Command; use Doctrine\\ORM\\EntityManagerInterface;
use Symfony\\Component\\Console\\Attribute\\AsCommand;
use Symfony\\Component\\Console\\Command\\Command;
use Symfony\\Component\\Console\\Input\\InputOption;
use Symfony\\Component\\Console\\Input\\InputInterface;
use Symfony\\Component\\Console\\Output\\OutputInterface; #[AsCommand( name: 'update-publication-preference-descriptions', description: 'Updates the description field in event_submission_publication_preferences to match the new names.',
)]
class UpdatePublicationPreferenceDescriptionsCommand extends Command
{ public function __construct( private readonly EntityManagerInterface $em, ) { parent::__construct(); } protected function configure(): void { $this ->addOption( 'dry-run', null, InputOption::VALUE_NONE, 'Preview the SQL updates without applying changes.' ); } protected function execute(InputInterface $input, OutputInterface $output): int { $dryRun = $input->getOption('dry-run'); $updates = [ 1 => "I do not want my abstract.", 2 => "I want my abstract to be published in the conference", 3 => "I would like to extend my abstract by submitting a full", ]; foreach ($updates as $typeId => $newDescription) { if ($dryRun) { $output->writeln(sprintf( "[Dry Run] Would update description to:\\n \\"%s\\"\\n WHERE event_submission_publication_preference_type_id = %d\\n", $newDescription, $typeId )); } else { $this->em->getConnection()->executeStatement( 'UPDATE event_submission_publication_preferences SET description = :description WHERE event_submission_publication_preference_type_id = :typeId', [ 'description' => $newDescription, 'typeId' => $typeId, ] ); $output->writeln("Updated description for type_id $typeId."); } } $output->writeln($dryRun ? 'Dry run complete.' : 'All descriptions updated successfully.'); return Command::SUCCESS; }
}`}]},{path:"/content/php/symfony/symfony7%E4%B9%8B%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84composer%E5%8C%85.html",title:"symfony7之配置自定义的composer包",pathLocale:"/",contents:[{header:"symfony7之配置自定义的composer包",slug:"symfony7之配置自定义的composer包",content:`{ ... "repositories": [ { "type": "composer", "url": "http://packages.duoxiaozhan.test/" } ], ... "config": { "http-basic": { "packages.duoxiaozhan.test" : { "username": "duoxiaozhan", "password": "alpha1" } }, "secure-http": false }, ...
}`}]},{path:"/content/php/symfony/symfony7%E4%BD%BF%E7%94%A8jwt%E8%AE%A4%E8%AF%81.html",title:"symfony7使用jwt认证",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7使用jwt认证:
https://github.com/lexik/LexikJWTAuthenticationBundle/blob/3.x/Resources/doc/index.rst#important-note-for-apache-users // 生成jwt token以及refresh_token
https://github.com/markitosgv/JWTRefreshTokenBundle // 刷新token`}]},{path:"/content/php/symfony/symfony7%E5%85%B3%E4%BA%8E%E5%8F%8C%E9%97%AE%E5%8F%B7%E5%92%8C%E9%97%AE%E5%8F%B7%E5%86%92%E5%8F%B7%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7关于双问号和问号冒号的使用",pathLocale:"/",contents:[{header:"symfony7关于??和?:的使用",slug:"symfony7关于-和-的使用",content:`??
只判断「是不是 null」
例子: 如果需求是只有 null 才用右边，而允许空字符串 ''，那应该用 PHP7+ 的 null 合并运算符 ??，比如：
$cityName = $event->getCityName() ?? $event->getCity()?->getName(); ?:
判断「假值」（null、false、空字符串、0 都算）
例子: 如果 $event->getCityName() 是空字符串 '' 也会走到右边。
$cityName = $event->getCityName() ?: $event->getCity()?->getName();`}]},{path:"/content/php/symfony/symfony7%E5%93%8D%E5%BA%94%E7%BC%93%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7响应缓存的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7响应缓存的使用:
目前使用symfony7做后台API的开发，部分接口会做响应缓存，基于 Caching Interface， 这个是PSR-6的标准: https://www.php-fig.org/psr/psr-6/
关于php的标准(PSR:PHP Standards Recommendations): https://www.php-fig.org/
//cache配置
config/packages/cache.yaml
framework: cache: app: cache.adapter.filesystem system: cache.adapter.system directory: '%kernel.cache_dir%/pools' # Unique name of your app: used to compute stable namespaces for cache keys. #prefix_seed: your_vendor_name/app_name # The "app" cache stores to the filesystem by default. # The data in this cache should persist between deploys. # Other options include: # Redis #app: cache.adapter.redis #default_redis_provider: redis://localhost # APCu (not recommended with heavy random-write workloads as memory fragmentation can cause perf issues) #app: cache.adapter.apcu # Namespaced pools use the above "app" backend by default #pools: #my.dedicated.cache: null //定义cache的listener
congig/services.yaml App\\EventListener\\RequestCacheListener: tags: - { name: kernel.event_listener, event: kernel.request, method: onKernelRequest } - { name: kernel.event_listener, event: kernel.response, method: onKernelResponse } <?php namespace App\\EventListener; use App\\Attribute\\RequestCache;
use Psr\\Cache\\CacheItemPoolInterface;
use Symfony\\Component\\HttpKernel\\Event\\RequestEvent;
use Symfony\\Component\\HttpKernel\\Event\\ResponseEvent;
use Symfony\\Component\\HttpKernel\\KernelInterface; class RequestCacheListener
{ public function __construct( private CacheItemPoolInterface $requestCachePool, private readonly KernelInterface $kernel, ) { } //这个方法在 request时会被调用，不管有没有缓存 public function onKernelRequest(RequestEvent $event): void { if (!$event->isMainRequest() || !in_array($this->kernel->getEnvironment(), ["prod", "staging"])) { return; } $request = $event->getRequest(); $controller = $request->attributes->get('_controller'); $controllerParts = explode('::', $controller); if (2 !== count($controllerParts)) { return; } $controllerClass = $controllerParts[0]; $controllerMethod = $controllerParts[1]; try { $reflectionController = new \\ReflectionMethod($controllerClass, $controllerMethod); $requestCache = $reflectionController->getAttributes(RequestCache::class, \\ReflectionAttribute::IS_INSTANCEOF); // 通过定义的指定attribute来决定缓存类型 } catch (\\ReflectionException $e) { return; } if (empty($requestCache)) { return; } $requestCache = $requestCache[0]->newInstance(); $cacheKey = md5($request->getUri()); $cachedItem = $this->requestCachePool->getItem($cacheKey); if ($cachedItem->isHit()) { $response = $cachedItem->get(); $event->setResponse($response); return; } $event->getRequest()->attributes->set('_request_cache', $requestCache); } //这个方法在 response时会被调用，不管有没有缓存 public function onKernelResponse(ResponseEvent $event): void { $requestCache = $event->getRequest()->attributes->get('_request_cache'); if (null === $requestCache) { $response = $event->getResponse(); $response->headers->set('X-Cache', 'Hit'); return; } $response = $event->getResponse(); $cacheKey = md5($event->getRequest()->getUri()); $cacheTime = $requestCache->expirationTime; // cache for 5s only for errors if (500 === $response->getStatusCode()) { $cacheTime = 5; } $response->headers->add(['X-Cache' => 'Miss']); $response->headers->addCacheControlDirective('public'); $response->setMaxAge($cacheTime); $cachedItem = $this->requestCachePool->getItem($cacheKey); $cachedItem->set($response); // 这里将整个响应结果缓存，比如有些接口会返回 国家 类型等列表，可以进行缓存 $cachedItem->expiresAfter($cacheTime); $this->requestCachePool->save($cachedItem); }
} //调用cache
//先定义一个attribute
<?php namespace App\\Attribute; #[\\Attribute(\\Attribute::TARGET_METHOD)]
class RequestCache
{ public function __construct( public int $expirationTime = 3600 // Default expiration time in seconds ) { }
} //控制器下使用这个attribute use App\\Attribute\\RequestCache; #[RequestCache(expirationTime: 86400)]
public function listEventStatuses( Service\\EventService $eventService
): JsonResponse { return new ApiSuccessResponse($eventService->getEventStatuses());
} //清理cache, CacheService.php, 我认为这个也可以做一个listener来控制什么时候清理缓存
public function __construct( private readonly CacheItemPoolInterface $requestCachePool, ) { }
public function clear(){ $this->requestCachePool->deleteItem("f2e644c1ffe9be69e85325ed0e746c97"); // 清理指定见 $this->requestCachePool->clear(); // 清理所有
}`},{header:"对如下缓存代码的分析:",slug:"对如下缓存代码的分析",content:`if ($cachedItem->isHit()) {
$response = $cachedItem->get();
$event->setResponse($response); return;
} 好，我们仔细分析一下这段关键代码在 Symfony 生命周期中的作用以及之后的流程：
if ($cachedItem->isHit()) { $response = $cachedItem->get(); $event->setResponse($response); return;
}`},{header:"1️⃣ 当前代码做了什么",slug:"_1️⃣-当前代码做了什么",content:`检查缓存命中 (isHit())。 如果命中： 从缓存池拿出之前存的 Response 对象 ($cachedItem->get())。
调用 $event->setResponse($response)，将这个 Response 设置给事件。 return：当前监听器不再继续处理，跳过下面代码逻辑（例如 _request_cache 注入）。`},{header:"2️⃣ Symfony 后续请求处理流程",slug:"_2️⃣-symfony-后续请求处理流程",content:`在 Symfony 中，请求处理大致顺序： kernel.request → 所有 RequestListener 被调用
kernel.controller → 调用 Controller
Controller 返回 Response
kernel.view → 如果 Controller 没返回 Response，可处理
kernel.response → 所有 ResponseListener 被调用
发送 Response 给客户端`},{header:"情况 A：缓存命中",slug:"情况-a-缓存命中",content:`已经 setResponse($response)，Symfony 会 短路 Controller： 不再执行 Controller 方法
不会触发 kernel.controller
不会生成新的 Response 但 仍会触发 kernel.response，因为 Symfony 需要把 Response 发出去。
在 onKernelResponse 可以对这个缓存 Response 做一些操作，例如： 添加 X-Cache header（可以改为 Hit）
设置 cache-control 等 最终这个缓存 Response 被发送给客户端。`},{header:"情况 B：缓存未命中",slug:"情况-b-缓存未命中",content:`代码执行到 return 之外，_request_cache 被写入 request attributes。
Controller 会正常执行生成 Response。
onKernelResponse 拿到 _request_cache： 将 Response 写入缓存池
设置缓存时间、headers 下次同样请求就能命中缓存。`},{header:"3️⃣ 总结：缓存命中后的“请求干什么”",slug:"_3️⃣-总结-缓存命中后的-请求干什么",content:`步骤
动作 kernel.request
检查缓存，命中 → setResponse，Controller 不执行 kernel.controller
被跳过 Controller
不执行 kernel.response
仍然触发，可以对缓存 Response 做 header、Cache-Control 等处理 客户端接收 Response
完整的缓存响应，包括 body、status、headers ✅ 关键点：缓存命中后，整个请求不会再执行 Controller，但 Symfony 会正常触发 Response 事件并发送 Response。`},{header:"这个缓存到底缓存的什么内容:",slug:"这个缓存到底缓存的什么内容",content:`$cachedItem = $this->requestCachePool->getItem($cacheKey);
$cachedItem->set($response);
$cachedItem->expiresAfter($cacheTime);
$this->requestCachePool->save($cachedItem);`},{header:"关键点 1：缓存的对象是 Symfony Response",slug:"关键点-1-缓存的对象是-symfony-response",content:`set($response) 这里直接把 $response 对象写入缓存。
也就是说，缓存里存的是 整个 Symfony\\Component\\HttpFoundation\\Response 对象，包含： HTTP 状态码（200、500 等）
headers（包括你加的 X-Cache）
内容 body（HTML、JSON 等）
cookies 等信息 所以并不是只缓存一个简单的字符串或者数组，而是整个响应对象。`},{header:"关键点 2：缓存读取时直接返回对象",slug:"关键点-2-缓存读取时直接返回对象",content:`在 onKernelRequest：
if ($cachedItem->isHit()) { $response = $cachedItem->get(); $event->setResponse($response); return;
} get() 拿出来的就是之前存的 Response 对象。
直接 setResponse($response)，请求就被短路，浏览器收到缓存内容，和正常生成响应完全一致。
所以你没看到“单独 set 值”，实际上 $response 就是缓存的完整内容。`},{header:"关键点 3：缓存策略",slug:"关键点-3-缓存策略",content:`缓存按 URI：$cacheKey = md5($request->getUri())，同一 URL 命中同一缓存。
缓存时间可控： 默认：注解里的 expirationTime
错误（500）：强制 5 秒 ✅ 总结一句话： 缓存的不是单独的数据字段，而是整个 Response 对象，包括状态码、headers 和 body。读取缓存时直接返回这个 Response，对客户端来说就像正常生成的一样。`},{header:"小优化:",slug:"小优化",content:`if ($cachedItem->isHit()) {
$response = $cachedItem->get();
$response->headers->set('X-Cache', 'Hit');
$event->setResponse($response); return;
}`}]},{path:"/content/php/symfony/symfony7%E5%BA%8F%E5%88%97%E5%8C%96%E5%AF%B9%E8%B1%A1%E4%B8%BA%E6%95%B0%E7%BB%84%E6%A0%BC%E5%BC%8F.html",title:"symfony7序列化对象为数组格式",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7序列化对象为数组格式:
use Symfony\\Component\\Serializer\\Serializer; 然后 Serializer 提供了如下方法normalize
$normalizedData = $this->normalize($data, $format, $context); 其中有个 $context 参数，这个参数很有用:
其作用主要包括以下几种情况： 1.控制属性的输出：可以通过设置 groups 来指定输出哪些属性。例如，['groups' => ['group_name']] 只会序列化属于 group_name 分组的属性。 2.属性的深度控制：可以通过 max_depth 设置序列化的最大深度。这个选项在对象嵌套层次很深时非常有用，避免无限递归。 3.回调自定义：你可以在 $context 中定义自定义回调函数，用于序列化前或反序列化后的数据处理。例如，可以为属性设置一个转换回调函数。 4.类型强制和格式控制：如果序列化到特定格式（例如 json 或 xml），可以在 $context 中设置格式的相关选项，使得规范化过程更灵活。 5.忽略空值：通过 skip_null_values 选项忽略空属性值，例如 ['skip_null_values' => true] 会跳过所有为 null 的属性。 可以看到定义的的DTO对象的属性有如下定义:
class TicketDto implements ResponsibleInterface
{ #[Groups("form")] private ?int $id; #[Groups(["table", "form"])] private string $title; #[Groups(["table"])] private \\DateTimeInterface $createdAt; ... ...
} 然后在控制器中，返回数据的时候：
return $this->apiResponse->response(new Dto\\Query\\TicketDto($ticket), context: ['groups' => 'form']); //这样只有在 form group中的属性才会被序列化, 我人为这样的好处是，对于同一个DTO，可以被复用，有些接口只需要其中一部分属性，这样就可以控制哪些可以返回给用户 再举个例子，关于回调的:
use Symfony\\Component\\Serializer\\SerializerInterface; $serializer = ...; // 假设已创建 Serializer 实例
$product = new ProductDTO("Sample Product", new \\DateTime("2024-11-11")); // 这个 context 会对其中的 createdAt 进行处理
$context = [ 'groups' => ['table'], // 指定分组 'callbacks' => [ 'createdAt' => function (\\DateTimeInterface $date) { return $date->format('Y-m-d'); // 自定义日期格式 } ]
]; $normalizedData = $serializer->normalize($product, 'json', $context); print_r($normalizedData);`}]},{path:"/content/php/symfony/symfony7%E6%8E%A7%E5%88%B6%E5%99%A8%E5%8F%82%E6%95%B0%E8%87%AA%E5%8A%A8reslove%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony7控制器参数自动reslove的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7.2控制器参数自动reslove的使用:
https://symfony.com/doc/current/controller/value_resolver.html#controller-argument-value-resolver 其中有一句描述很重要:
This tag is automatically added to every service implementing ValueResolverInterface, but you can set it yourself to change its priority or name attributes. To ensure your resolvers are added in the right position you can run the following command to see which argument resolvers are present and in which order they run:
root@ca4989b3147e:/app# php bin/console debug:container debug.argument_resolver.inner --show-arguments Information for Service "debug.argument_resolver.inner"
======================================================= Responsible for resolving the arguments passed to an action. ---------------- ----------------------------------------------------------------------------------------------------- Option Value ---------------- ----------------------------------------------------------------------------------------------------- Service ID debug.argument_resolver.inner Class Symfony\\Component\\HttpKernel\\Controller\\ArgumentResolver Tags - Public no Synthetic no Lazy no Shared yes Abstract no Autowired no Autoconfigured no Arguments Service(argument_metadata_factory) Iterator (25 element(s)) - Service(.debug.value_resolver.security.user_value_resolver) - Service(.debug.value_resolver.security.security_token_value_resolver) - Service(.debug.value_resolver.doctrine.orm.entity_value_resolver) - Service(.debug.value_resolver.argument_resolver.backed_enum_resolver) - Service(.debug.value_resolver.argument_resolver.datetime) - Service(.debug.value_resolver.argument_resolver.request_attribute) - Service(.debug.value_resolver.argument_resolver.request) - Service(.debug.value_resolver.argument_resolver.session) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\CustomFieldCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\DiscountCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\EventContributionTypeDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\EventPublicationOptionDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\EventReviewOverallRecommendationDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\EventSubmissionMarkingSchemeDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\ProcessPaymentDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\ProposalCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\RegistrationInformationDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\SectionCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\Model\\Dto\\Resolver\\TicketCreateUpdateDtoResolver) - Service(.debug.value_resolver.App\\ValueResolver\\FileUploadResolver) - Service(.debug.value_resolver.argument_resolver.service) - Service(.debug.value_resolver.argument_resolver.default) - Service(.debug.value_resolver.argument_resolver.variadic) - Service(.debug.value_resolver.argument_resolver.not_tagged_controller) Service(.service_locator.ubj5Sie) Usages debug.argument_resolver ---------------- ----------------------------------------------------------------------------------------------------- ! [NOTE] The "debug.argument_resolver.inner" service or alias has been removed or inlined when the container was ! compiled. 原来使用的是:
#[MapRequestPayload] 来实现参数自动映射功能, 和
#[MapEntity(id: 'eventId')] 实现Entity映射功能 上面这两个都extends ValueResolver 不同的是，现在使用的是ValueResolverInterface， 这个是 use Symfony\\Component\\HttpKernel\\Controller\\ValueResolverInterface; Symfony的Resolver注入原理主要基于依赖注入和参数解析机制： 类型自动识别:
根据控制器方法的参数类型
自动匹配对应的ValueResolver
通过类型注入和推断实现参数解析 我自己测试发现，只要这样定义
class EventSessionCreateEditDtoResolver extends AbstractRequestDtoResolver // 最终implemanets ValueResolverInterface
那么 EventSessionCreateEditDto 都可以被自动注入 //查看指定resolver的注入情况:
root@ca4989b3147e:/app# php bin/console debug:container App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver Information for Service "App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver"
================================================================================== ---------------- -------------------------------------------------------------------------------- Option Value ---------------- -------------------------------------------------------------------------------- Service ID App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver Class App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver Tags controller.argument_value_resolver Public no Synthetic no Lazy no Shared yes Abstract no Autowired yes Autoconfigured yes Usages .debug.value_resolver.App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver ---------------- -------------------------------------------------------------------------------- ! [NOTE] The "App\\Model\\Dto\\Resolver\\EventSessionCreateEditDtoResolver" service or alias has been removed or inlined ! when the container was compiled. Symfony会自动注入。核心机制是： 通过EventSessionCreateEditDtoResolver专门处理EventSessionCreateEditDto类型
控制器方法参数声明了Dto\\Input\\EventSessionCreateEditDto类型
ArgumentResolver会调用匹配的Resolver
Resolver负责创建或解析该对象实例 解析流程： 匹配参数类型
调用对应Resolver
创建EventSessionCreateEditDto实例
注入到控制器方法 其实最主要的一个方法是:
public function resolve(Request $request, ArgumentMetadata $argument): iterable { if ($argument->getType() !== $this->getSupportedType()) { return []; } $deserializedDto = $this->serializer->deserialize($request->getContent(), $this->getSupportedType(), 'json'); $dtoObject = $this->postResolve($deserializedDto); $violations = $this->validator->validate($dtoObject); if (\\count($violations)) { throw new HttpException(Response::HTTP_UNPROCESSABLE_ENTITY, implode("\\n", array_map(static fn ($e) => $e->getMessage(), iterator_to_array($violations))), new ValidationFailedException($request->getPayload(), $violations)); } return [$dtoObject]; } 其中:
if ($argument->getType() !== $this->getSupportedType()) { return []; } 这个$this->getSupportedType() 决定了，当前这个resolver会对哪个控制器的参数生效，如果没有这个判断，就会对所有的参数生效，这也是symfony的一个特色。和 EventSessionCreateEditDtoResolver 这个类名没关系，可以任意命名，最后都可以被请求到。我一直是根据这个类命名来决定处理哪个Dto的，其实不是的，就是根据上面的判断来决定对哪个类型($argument->getType())生效。 再来看文档中的这句:
This tag is automatically added to every service implementing ValueResolverInterface. 说明只要定义了resolver, 实现了ValueResolverInterface，都会被注入，最后对哪个Dto生效，取决于前面的if 类型判断。 有人出现郭这个问题:
https://stackoverflow.com/questions/79060922/symfony-7-x-custom-resolver-always-called 同时还可以在service.yaml文件下配置(而不影响使用和之前一样的效果):
App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver: tags: - controller.argument_value_resolver: name: addon_dto //取个名字 priority: 150 //设置优先级 // 再次查看
root@ca4989b3147e:/app# php bin/console debug:container App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver Information for Service "App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver"
============================================================================= ---------------- --------------------------------------------------------------------------- Option Value ---------------- --------------------------------------------------------------------------- Service ID App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver Class App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver Tags controller.argument_value_resolver (name: addon_dto, priority: 150) controller.argument_value_resolver Public no Synthetic no Lazy no Shared yes Abstract no Autowired yes Autoconfigured yes Usages .debug.value_resolver.App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver ---------------- --------------------------------------------------------------------------- ! [NOTE] The "App\\Model\\Dto\\Resolver\\AddonCreateUpdateDtoResolver" service or alias has been removed or inlined when ! the container was compiled. 证明了文档的这句:
but you can set it yourself to change its priority or name attributes. 总结:
这个功能和larvel下自定义request验证类似，都可以提前获取参数，以及格式化参数(添加或者删除部分参数).`}]},{path:"/content/php/symfony/symfony7%E6%9F%A5%E7%9C%8Benv%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%8A%A0%E8%BD%BD%E6%83%85%E5%86%B5.html",title:"symfony7查看env环境变量加载情况",pathLocale:"/",contents:[{header:"symfony7查看env环境变量加载情况",slug:"symfony7查看env环境变量加载情况",content:`//查看所有环境变量
php bin/console debug:dotenv //查看指定环境变量
php bin/console debug:dotenv ENCRYPTION_SECRET_KEY`}]},{path:"/content/php/symfony/symfony7%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E8%B7%AF%E7%94%B1.html",title:"symfony7查看所有路由",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7查看所有路由:
要在 Symfony 7 中查看所有路由，你可以使用 Symfony Console 命令。以下是具体步骤： 打开终端或命令提示符。
进入你的 Symfony 项目根目录。
运行以下命令： php bin/console debug:router 这个命令会列出你应用中所有定义的路由，包括它们的名称、HTTP 方法、路径模式和对应的控制器。
如果你想要更详细的输出，可以添加 --show-controllers 选项：
php bin/console debug:router --show-controllers 这将显示每个路由对应的具体控制器类和方法。
如果你想要筛选特定的路由，可以在命令后面加上搜索词：
php bin/console debug:router your_search_term 此外，如果你需要以其他格式输出（如 JSON），可以使用 --format 选项：
php bin/console debug:router --format=json 使用 php bin/console debug:router your_search_term 不能模糊匹配:
事实上，debug:router 命令的搜索功能确实不支持模糊匹配。这个命令使用的是精确匹配或前缀匹配。让我解释一下这个命令的行为，并提供一些替代方案： 精确匹配和前缀匹配 当你使用 php bin/console debug:router your_search_term 时，Symfony 会查找： 路由名称完全匹配 your_search_term 的路由
路由名称以 your_search_term 开头的路由
路径完全匹配 /your_search_term 的路由
路径以 /your_search_term 开头的路由 替代方案 虽然 debug:router 命令不直接支持模糊匹配，但你可以使用一些其他方法来实现类似的效果：
a. 使用管道和 grep（在 Unix-like 系统中）：
php bin/console debug:router | grep your_search_term //很有用 这会显示所有包含 your_search_term 的行。
b. 输出为 JSON 并使用 jq（需要安装 jq）：
php bin/console debug:router --format=json | jq '.[] | select(.path | contains("your_search_term"))' 这会显示路径中包含 your_search_term 的所有路由。 其他调试技巧 记住，除了 debug:router 命令，你还可以使用 Symfony Profiler 和 Web Debug Toolbar 来查看和调试路由。这些工具在开发环境中特别有用。`}]},{path:"/content/php/symfony/symfony7%E7%BB%99doctrine%E6%B7%BB%E5%8A%A0enum%E8%A7%A3%E6%9E%90.html",title:"symfony7给doctrine添加enum解析",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7中使用enum类型, 为什么需要如下的配置，那是因为默认doctrine不支持enum类型，需要这么一个映射配置:
1>配置 mapping_types 中的 enum 为 string 在 Doctrine 和 Symfony 中处理 ENUM 类型字段时是一个常见做法，因为它允许 Doctrine 将数据库中的 ENUM 类型映射为 PHP 中的字符串类型，并正常操作该字段的值。
doctrine: dbal: connections: default: # 其他 DB 配置 mapping_types: enum: string`},{header:"作用详解",slug:"作用详解",content:"在这种配置下，Doctrine 会将 MySQL 中的 ENUM 类型映射为 string，这样您可以在代码中直接以字符串的形式读取和操作 ENUM 字段，而不必自定义 Doctrine 类型来专门支持 ENUM。这一设置将自动应用于所有包含 ENUM 类型的字段，不会影响现有的字段操作。"},{header:"配合 columnDefinition 使用",slug:"配合-columndefinition-使用",content:`当您在实体中用 columnDefinition 定义 ENUM 字段类型时：
#[ORM\\Column(name: 'title', type: 'string', columnDefinition: "ENUM('Single-line text', 'Multi-line text', 'Single choice', 'Multiple choices')")]
private string $title; Doctrine 会在数据库中将 title 字段创建为 ENUM 类型，同时，在 PHP 中该字段的类型为 string。通过 mapping_types 配置的映射关系，Doctrine 能够识别数据库中的 ENUM 并将其当作 string 处理，不会导致类型不兼容的问题。`},{header:"这样配置的好处",slug:"这样配置的好处",content:`无需额外类型定义：避免为 ENUM 创建自定义 Doctrine 类型。
数据库兼容性：适用于使用 MySQL 数据库的项目，保持数据库层面的数据约束。
便捷操作：在代码中直接以 string 类型操作 ENUM 字段的值，符合 PHP 的使用习惯。`},{header:"总结",slug:"总结",content:`配置 mapping_types 来将 enum 映射为 string，可以让您在 Symfony 和 Doctrine 中轻松地定义和操作数据库的 ENUM 字段，且不会丢失数据库约束。
2>在 Symfony 7 和 Doctrine 中，您可以使用 columnDefinition 来为 enum 字段定义自定义的 SQL 类型。以下是这个定义的作用和相关注意事项：`},{header:"作用",slug:"作用",content:`通过以下定义：
#[ORM\\Column(name: 'title', type: 'string', columnDefinition: "ENUM('Single-line text', 'Multi-line text', 'Single choice', 'Multiple choices')")]
private string $title; 您为 title 字段指定了一个 ENUM 数据类型，这样做会在数据库中直接创建一个 ENUM 类型的字段，其可选值为 'Single-line text', 'Multi-line text', 'Single choice', 'Multiple choices'。字段在数据库层面上将被限制为这些值，任何其他值都会导致数据库约束错误。`},{header:"注意事项",slug:"注意事项",content:`直接定义 ENUM： 使用 columnDefinition 定义 ENUM 类型，能够利用数据库的原生 ENUM 特性，实现更严格的数据约束。
这种方式不会影响 Doctrine 实体的使用，您可以直接读取和设置 title 字段为字符串值，例如 $title = 'Single-line text'。 数据库兼容性： ENUM 类型是 MySQL 的特性，如果您的项目需要支持其他数据库（如 PostgreSQL、SQLite），则此配置可能会导致兼容性问题，因为其他数据库可能不支持 ENUM 或实现方式不同。
如果有跨数据库需求，建议使用 VARCHAR 类型加上代码级别的校验。 更新迁移： 如果以后需要增加或修改 ENUM 的选项，您需要手动更新数据库列。Doctrine 的自动迁移工具（如 doctrine:migrations:diff）可能不会自动检测 ENUM 选项的变化，您可能需要编写自定义 SQL 语句来更新这些选项。 使用代码校验（可选）： 虽然数据库会约束 title 字段的值，但在应用层面，也可以在 Symfony 实体中进行值校验，防止在到达数据库之前写入不符合 ENUM 定义的值。`},{header:"示例用法",slug:"示例用法",content:`在应用中，您可以正常读取和设置 title 字段的值：
$user = new User();
$user->setTitle('Single choice');
echo $user->getTitle(); // 输出: Single choice 这样使用可以很好地将数据库约束和代码逻辑结合起来，以确保数据一致性和正确性。`}]},{path:"/content/php/symfony/symfony7%E7%BB%99doctrine%E6%B7%BB%E5%8A%A0json%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%94%AF%E6%8C%81.html",title:"symfony7给doctrine添加json数据类型支持",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7给doctrine添加json数据类型支持:
symfony7 doctrine 支持json数据类型的拓展:
composer install dunglas/doctrine-json-odm json和jsonb(目前只有psql支持jsonb,而mysql不支持)：
https://www.cnblogs.com/chenyablog/p/14647273.html
配置:
doctrine: dbal: connections: default: server_version: '8.0' url: '%env(resolve:DATABASE_PRIMARY_URL)%' driver: pdo_mysql //使用mysql，需要安装对相应的php拓展 charset: utf8mb4 default_table_options: collate: utf8mb4_unicode_ci mapping_types: enum: string schema_filter: ~^(?!(messenger_messages|migration_versions)$)~ replicas: secondary: url: '%env(resolve:DATABASE_SECONDARY_URL)%' secondary: url: '%env(resolve:DATABASE_SECONDARY_URL)%' default_connection: default types: json_document: 'Dunglas\\DoctrineJsonOdm\\Type\\JsonDocumentType' //需要在dbal下定义这个配置
案例:
#[ORM\\Column(type: 'json_document', nullable: true)] private string $options;`}]},{path:"/content/php/symfony/symfony7%E7%BB%99swagger%E5%AD%97%E6%AE%B5%E6%B7%BB%E5%8A%A0%E6%8F%8F%E8%BF%B0%E4%BF%A1%E6%81%AF.html",title:"symfony7给swagger字段添加描述信息",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7给swagger字段添加描述信息:
use OpenApi\\Attributes as OA; class AffiliationDto implements ResponsibleInterface
{ #[OA\\Property(description: "The unique identifier of the affiliation", example: 123)] private int $id; #[OA\\Property(description: "The name of the affiliation", example: "hh")] private string $department; #[OA\\Property(description: "The description of the affiliation", example: "gg")] private string $institution;
}`},{header:"再补充一下信息，在控制器下直接使用DTO自动生成",slug:"再补充一下信息-在控制器下直接使用dto自动生成",content:`use OpenApi\\Attributes as OA; #[Route('/submissions/summary', name: 'submissions_summary', methods: ['GET'])]
#[OA\\Get(
description: "返回事件的提交统计数据摘要",
summary: "获取提交统计摘要"
)]
#[OA\\Response(
response: 200,
description: 'Return submissions summary',
content: new Model(type: Dto\\Query\\Submission\\Statistic\\SubmissionSummaryStatisticsDataDto::class)
)]
#[OA\\Response(
response: 404,
description: 'Event not found'
)]
public function getSubmissionSummary(
Sciforum\\Event $event,
Statistic\\SubmissionSessionDistributionService $submissionSessionDistributionService,
): JsonResponse {
return $this->apiResponse->response($submissionSessionDistributionService->getSubmissionSummary($event));
} 可以通过 OA\\Get 对这个Get方法进行说明，通过 OA\\Response 定义多个 response code 下的信息`}]},{path:"/content/php/symfony/symfony7%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1.html",title:"symfony7自定义服务",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7自定义服务:
services: App\\SomeService: arguments: $customCache: '@cache.custom_cache' 解释：
services: 这是 Symfony 服务配置的主要部分。
App\\SomeService: 这指定了我们正在配置的服务类。这里是 App\\SomeService 类。
arguments: 这部分用于指定服务构造函数的参数。
$customCache: '@cache.custom_cache' $customCache 是构造函数中参数的名称。
'@cache.custom_cache' 是一个服务引用。@ 符号表示这是对另一个服务的引用，而不是普通的字符串。 这个配置的作用是：当 Symfony 的依赖注入容器创建 App\\SomeService 的实例时，它会将 cache.custom_cache 服务注入到构造函数的 $customCache 参数中。 你的服务类可能看起来像这样： phpCopynamespace App; use Symfony\\Contracts\\Cache\\CacheInterface; class SomeService
{ private $cache; public function __construct(CacheInterface $customCache) { $this->cache = $customCache; } // 使用 $this->cache 的其他方法...
} 有了这个配置，你可以在应用的任何地方使用这个服务，而不需要手动创建缓存对象： phpCopyclass SomeController
{ public function someAction(App\\SomeService $someService) { // $someService 已经被注入了正确的缓存实例 // 可以直接使用 }
} 优点：
解耦：你的 SomeService 类不需要知道具体使用哪个缓存服务，这由配置决定。
灵活性：你可以轻松地在不同环境中切换不同的缓存实现，只需更改配置文件。
测试友好：在单元测试中，你可以轻松地注入一个模拟的缓存服务。`}]},{path:"/content/php/symfony/symfony7%E9%80%9A%E8%BF%87DBAL%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE.html",title:"symfony7通过DBAL查询数据",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7通过DBAL查询数据:
通过connection, 其实是实现自: use Doctrine\\DBAL\\Connection; // 可以在控制器下或service 下手动引入
使用:
use Doctrine\\DBAL\\Connection; public function __construct( private readonly EntityManagerInterface $em, private readonly Connection $connection, ) { } public function test(){ $data = $this->connection->fetchAllAssociative('SELECT * FROM events'); $user = $this->connection->fetchAssociative( 'SELECT * FROM mdpipub.users ORDER BY id ASC LIMIT 1' );
} 但是在迁移文件下，会自动继承 use Doctrine\\Migrations\\AbstractMigration; 里面默认有了connection实例 public function up(Schema $schema): void
{ // this up() migration is auto-generated, please modify it to your needs foreach ($this->connection->fetchAllAssociative('SELECT * FROM events') as $event) { $this->addSql('INSERT INTO ticket_sections (id, title, \`order\`, is_special, event_id, created_at, updated_at, created_user_id) VALUES (NULL, "Other tickets", 0, 1, :eventId, :createdAt, :updatedAt, 3555803)', [ 'eventId' => $event['id'], 'createdAt' => (new \\DateTime())->format('Y-m-d H:i:s'), 'updatedAt' => (new \\DateTime())->format('Y-m-d H:i:s'), ]); }
}`}]},{path:"/content/php/symfony/symfony7%E9%85%8D%E7%BD%AE%E8%BF%81%E7%A7%BB%E6%96%87%E4%BB%B6%E6%8C%89%E5%B9%B4%E5%88%86%E7%BB%84.html",title:"symfony7配置迁移文件按年分组",pathLocale:"/",contents:[{header:"symfony7配置迁移文件按年分组",slug:"symfony7配置迁移文件按年分组",content:`symfony7配置迁移文件按年分组: 在config/packages/doctrine_migrations.yaml doctrine_migrations: migrations_paths: # namespace is arbitrary but should be different from App\\Migrations # as migrations classes should NOT be autoloaded 'DoctrineMigrations': '%kernel.project_dir%/migrations' enable_profiler: false organize_migrations: BY_YEAR #通过这个配置实现 除了 BY_YEAR，Doctrine Migrations 还支持其他几种组织方式:
BY_YEAR_AND_MONTH：按年份和月份组织
false：不进行组织（默认）`}]},{path:"/content/php/symfony/symfony7%E9%A1%B9%E7%9B%AE%E4%BD%BF%E7%94%A8PHPunit%E5%81%9A%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html",title:"symfony7项目使用PHPunit做单元测试",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony7项目使用PHPunit做单元测试:
1>目前环境要求 php8.3
需要
$ sudo apt-get install php8.3-mbstring
$ sudo apt-get install php8.3-xdebug 2>
# ./vendor/bin/phpunit tests/Controller/System/ApiTokenTest.php --filter testUnauthorizedRequest 3>phpstorm + docker 使用phpUnit:
https://jesserun.com/2018/11/01/phpstorm-phpunit-on-docker/`}]},{path:"/content/php/symfony/symfony7%E9%AA%8C%E8%AF%81doctrine%E8%AF%86%E5%88%AB%E7%9A%84Entity.html",title:"symfony7验证doctrine识别的Entity",pathLocale:"/",contents:[{header:"symfony7验证doctrine识别的Entity",slug:"symfony7验证doctrine识别的entity",content:"root@ca4989b3147e:/app# php bin/console doctrine:mapping:info Found 108 mapped entities: [OK] App\\Entity\\Local\\UserWorkplace [OK] App\\Entity\\Local\\Country [OK] App\\Entity\\Local\\Organizer 它会列出 Doctrine 识别到的所有实体。没有加 #[ORM\\Entity] 的类不会出现在这里，可以用这个命令验证是否配置成功。"}]},{path:"/content/php/symfony/symfony%E4%B9%8B5%E7%A7%8D%E6%8E%88%E6%9D%83%E6%9C%BA%E5%88%B6.html",title:"symfony之5种授权机制",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5目前有以下5种授权机制:
# ...
x509:
# ...
remote_user:
# ...
guard:
# ...
form_login:
# ...
form_login_ldap:
# ...
json_login:
# ...
http_basic:
# ...
http_basic_ldap:
# ...
http_digest: symfony5.4以后和5.2是不一样的: https://symfony.com/doc/5.4/security/custom_authenticator.html //这个就是官方文档说的新的认证系统
https://symfony.com/doc/5.2/security/guard_authentication.html //旧的认证系统 旧的认证系统:
config/security.yaml
enable_authenticator_manager: false
main: guard: authenticators: - App\\Security\\TokenAuthenticator //这个Authenticator 必须extends Guard相关的interface,已经被弃用了 新的认证系统:
config/security.yaml
enable_authenticator_manager: true
main: custom_authenticators: - App\\Security\\TokenAuthenticator //这个Authenticator extends 自 AbstractAuthenticator 上面新旧两种方式，对于路由而言，加了#[IsGranted('ROLE_USER')]，生效的原理都是各自的Authenticator里的 supports 返回true, 后续验证[旧:checkCredentials 新:authenticate]成功，
只要返回成功，那么#[IsGranted('ROLE_USER')]就会生效,默认登录后的用户都有ROLE_USER这个角色.
//下面是一个新的认证的一个Authenticator
class ApiTokenAuthenticator extends AbstractAuthenticator
{ public function __construct(private EntityManagerInterface $em){} public function supports(Request $request): ?bool { return $request->headers->has('authorization'); // TODO: Implement supports() method. } //本地测试发现，这个验证完成以后会向 session 写入用户token信息(UsernamePasswordToken)， public function authenticate(Request $request) { $apiToken = $request->headers->get('authorization');//这里弄得比较简单，直接在authorization里传递了用户的 email 地址作为 apiToken if (null === $apiToken) { // The token header was empty, authentication fails with HTTP Status // Code 401 "Unauthorized" throw new CustomUserMessageAuthenticationException('No API token provided'); } // TODO: Implement authenticate() method. return new SelfValidatingPassport(new UserBadge($apiToken, (function($token){ return $this->em->getRepository(User::class)->findOneBy(['email'=>$token]); })->bindTo($this)));// 匿名函数的参数$token 即为 $apiToken } public function onAuthenticationSuccess(Request $request, TokenInterface $token, string $firewallName): ?Response { // TODO: Implement onAuthenticationSuccess() method. return null; } public function onAuthenticationFailure(Request $request, AuthenticationException $exception): ?Response { // TODO: Implement onAuthenticationFailure() method. return null; }
} 关于IsGranted:
这个类是symfony的一个拓展，主要用于处理授权请求，可以有如下格式:
①#[IsGranted('ROLE_USER', message: 'You are not allowed to access the admin dashboard.', statusCode: 421)]
②其它用法是，还在研究中
通过异常监听可以捕获这个异常请求:
if ($throwable instanceof AccessDeniedException && $event->getRequest()->isXmlHttpRequest()) { $data = [ 'code' => 1, 'msg' => $throwable->getMessage(), 'data' => [], ]; $event->setResponse(new JsonResponse($data, $throwable->getCode()));
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8BBadge%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony之Badge的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`关于Badge属性，以前比较陌生，但是最近项目开发过程中，有时用到，就特意记录一下.
这是Passport的一个属性，主要是为了给Passport添加额外的信息.
先看之前写的 Authenticator
$res = $this->userPasswordHasher->isPasswordValid( $this->em->getRepository(User::class)->findOneBy(['email' => $username]), $request->request->get('password', '') ); if ($res){ // 通过闭包获取用户信息，这个地方 UserBadge 后面可以传递一个闭包 返回User return new SelfValidatingPassport(new UserBadge($username, function ($email){ return $this->em->getRepository(User::class)->findOneBy(['email' => $email]); }), [new LoginPlatformBadge('pc')]); }else{ throw new BadCredentialsException('invalid email or password.'); } 还可以直接通过 Passport 对象处理数据: return new Passport( new UserBadge($username), new PasswordCredentials($password), [new LoginPlatformBadge('pc')] ); 可以看到我在上面都加了 自定义的 LoginPlatformBadge，这个就是给 Passport 一个附加属性，因为上面的Passport 会 触发 CheckPassportEvent(这是symfony内置的事件，相关事件还有好几个)，所以 我们可以监听这个事件
LoginPlatformSubscriber:
<?php namespace App\\EventSubscriber; use App\\Security\\LoginPlatformBadge;
use Symfony\\Component\\EventDispatcher\\EventSubscriberInterface;
use Symfony\\Component\\Security\\Http\\Event\\CheckPassportEvent; class LoginPlatformSubscriber implements EventSubscriberInterface
{ public function onCheckPassportEvent(CheckPassportEvent $event): void { $passport = $event->getPassport(); /** @var LoginPlatformBadge $badge */ $badge = $passport->getBadge(LoginPlatformBadge::class); if (null === $badge || $badge->isResolved()) { return; } dump($badge->getPlatform().time()); /** * 这里可以针对不同的 platform 做不同的逻辑操作 */ /** * 最后记得把这个 badge 设置为 解析过 状态 */ $badge->markResolved(); } public static function getSubscribedEvents(): array { // 因为上面的 Passport 最终会触发 CheckPassportEvent 这个事件，所以我们需要 设置一个监听 // TODO: Implement getSubscribedEvents() method. return [ CheckPassportEvent::class => 'onCheckPassportEvent', ]; }
} LoginPlatformBadge:
<?php namespace App\\Security; use Symfony\\Component\\Security\\Http\\Authenticator\\Passport\\Badge\\BadgeInterface; class LoginPlatformBadge implements BadgeInterface
{ private bool $resolved = false; public function __construct( private string $platform, ){} public function isResolved(): bool { // TODO: Implement isResolved() method. return $this->resolved; } public function markResolved():void{ $this->resolved = true; } public function getPlatform():string{ return $this->platform; }
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8BForm%E9%AA%8C%E8%AF%81%E9%AA%8C%E8%AF%81%E5%99%A8%E9%AA%8C%E8%AF%81%E5%92%8C%E9%97%AD%E5%8C%85%E5%87%BD%E6%95%B0%E9%AA%8C%E8%AF%81.html",title:"symfony之Form验证验证器验证和闭包函数验证",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目，需要做表单验证，我用两种方法，分别是 验证器验证和闭包函数验证，代码如下:
RegistrationFormType.php：
<?php namespace App\\Form; use App\\Entity\\User;
use App\\Validator\\EmailFormat;
use App\\Validator\\EmailUnique;
use QINGHONG\\CommonBundle\\Validator\\Constraints\\StrongPassword;
use Symfony\\Component\\Form\\AbstractType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\PasswordType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\TextType;
use Symfony\\Component\\Form\\FormBuilderInterface;
use Symfony\\Component\\OptionsResolver\\OptionsResolver;
use Symfony\\Component\\Validator\\Constraints\\Callback;
use Symfony\\Component\\Validator\\Constraints\\NotBlank;
use Symfony\\Component\\Validator\\Context\\ExecutionContext; class RegistrationFormType extends AbstractType
{ public function buildForm(FormBuilderInterface $builder, array $options): void { $builder ->add('email', TextType::class, [ 'constraints' => [ new NotBlank([ 'message' => 'Please enter a email', ]), new EmailFormat([ 'message' => 'Please enter a normal email', ]), new EmailUnique([ 'message' => 'Current email already exists!', ]) ], ]) ->add('password', PasswordType::class, [ 'mapped' => false, 'constraints' => [ new NotBlank([ 'message' => 'Please enter a password', ]), new StrongPassword(), ], ]) ->add('confirmPassword', PasswordType::class, [ 'mapped' => false, 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) { if (empty($value)) { $ctx->addViolation("Please enter a confirm password"); } elseif ($ctx->getRoot()['password']->getData() !== $value) {//这一行很重要，就是通过ctx 上下文获取数据 $ctx->addViolation("The entered passwords do not match"); } }]), ], ]) ->add('firstName', TextType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) use ($builder) { if (preg_match_all("/([\\x{4e00}-\\x{9fa5}]+)/u", trim($value), $match)) { $ctx->addViolation('Please do not enter chinese characters'); } if (strlen(trim($value)) > 30) { $ctx->addViolation("The content should not be more than 30 words"); } elseif (strlen(trim($value)) == 0) { $ctx->addViolation('Please enter the firstName'); } }]), ] ]) ->add('middleName', TextType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) use ($builder) { if (strlen(trim($value)) > 0) { if (preg_match_all("/([\\x{4e00}-\\x{9fa5}]+)/u", trim($value), $match)) { $ctx->addViolation('Please do not enter chinese characters'); } if (strlen(trim($value)) > 30) { $ctx->addViolation("The content should not be more than 30 words"); } } }]), ] ]) ->add('lastName', TextType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) use ($builder) { if (preg_match_all("/([\\x{4e00}-\\x{9fa5}]+)/u", trim($value), $match)) { $ctx->addViolation('Please do not enter chinese characters'); } if (strlen(trim($value)) > 30) { $ctx->addViolation("The content should not be more than 30 words"); } elseif (strlen(trim($value)) == 0) { $ctx->addViolation('Please enter the lastName'); } }]), ] ]); } public function configureOptions(OptionsResolver $resolver): void { $resolver->setDefaults([ 'data_class' => User::class, // enable/disable CSRF protection for this form 'csrf_protection' => true, // the name of the hidden HTML field that stores the token 'csrf_field_name' => '_token', // an arbitrary string used to generate the value of the token // using a different string for each form improves its security 'csrf_token_id' => 'user_register', ]); }
} 接下来准备改为基于 constraints 验证函数的方式
...
...
->add('password', RepeatedType::class, [ 'type' => PasswordType::class, 'first_name' => 'password', 'second_name' => 'confirmPassword', 'invalid_message' => 'The password fields must match', //这里有个问题就是，password 和 confirmPassword 只能公用一个提示信息，不能像上面那样分别提示 'constraints' => [ new NotBlank([ 'message' => 'Please enter the password', ]), new StrongPassword(), ] ])
...
... 只用一个 password 字段表示，通过 first_name 和 second_name 来区分页面展示的字段内容
<div class="form-label-group"> <label for="password" class="control-label">*</label> <input type="password" id="inputPassword" name="registration_form[password][password]" class="form-control inputPassword" placeholder="Password" required="" value="{{ user.password }}"> {% if errors and errors.password is defined %} <div class="invalid-feedback d-block">{{ errors['password'] }}</div> {% else %} <div class="invalid-feedback d-block hold-empty"></div> {% endif %} </div> <div class="form-label-group"> <label for="confirmPassword" class="control-label">*</label> <input type="password" id="inputConfirmPassword" name="registration_form[password][confirmPassword]" class="form-control inputConfirmPassword" placeholder="ConfirmPassword" required="" value="{{ user.password }}"> {% if errors and errors.password is defined %} <div class="invalid-feedback d-block">{{ errors['password'] }}</div> {% else %} <div class="invalid-feedback d-block hold-empty"></div> {% endif %} </div>`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bcustom_authenticator%E8%AF%A6%E7%BB%86%E4%BD%BF%E7%94%A8.html",title:"symfony之custom_authenticator详细使用",pathLocale:"/",contents:[{header:"",slug:"",content:`之前记录了一点关于login_form的，其中说到了authenticator，这里再记录几个注意点:
修改security.yaml
设置:enable_authenticator_manager: true
form_login: #这个会调用内置的 Symfony\\Component\\Security\\Http\\Authenticator\\FormLoginAuthenticator success_handler: App\\Security\\LoginSuccessHandler #由于不能直接修改 内置Authenticator的 onAuthenticationSucces 回调事件，可以通过form_login的success_handler来定义，如写 用户cookie信息 username_parameter: email password_parameter: password 打印输出:
provider	security.user.provider.concrete.main #这个其实是UserEntity
context	main
entry_point	security.authenticator.form_login.main
user_checker	security.user_checker
access_denied_handler	(none)
access_denied_url	(none)
authenticators [▼ "form_login"
] 注释掉 form_login，然后添加自定义Authenticator
custom_authenticator: App\\Security\\FormLoginAuthenticator #可以在这个 onAuthenticationSucces 里添加 授权成功以后的事件操作，如写 用户cookie信息
打印输出:
provider security.user.provider.concrete.main #这个其实是UserEntity
context main
entry_point App\\Security\\FormLoginAuthenticator
user_checker security.user_checker
access_denied_handler (none)
access_denied_url (none)
authenticators [▼ "App\\Security\\FormLoginAuthenticator"
] 同一个firewall下，上面两个Authenticator不能同时存在，否则会报错:
Because you have multiple authenticators in firewall "main", you need to set the "entry_point" key to one of your authenticators ("App\\Security\\FormLoginAuthenticator", "form_login") or a service ID impleme
nting "Symfony\\Component\\Security\\Http\\EntryPoint\\AuthenticationEntryPointInterface". The "entry_point" determines what should happen (e.g. redirect to "/login") when an anonymous user tries to access a pro
tected page
需要手动设置entry_point，来定义使用哪个Authenticator
另一种定义了多个 authenticator 的场景，extends 自不同的Authenticator，而不指定 entry_point 是可以的 main:
# lazy: true pattern: ^/ provider: main
# form_login:
# success_handler: App\\Security\\LoginSuccessHandler
# username_parameter: email
# password_parameter: password
# custom_authenticator: App\\Security\\FormLoginAuthenticator #当只有一个自定义的 authenticator 的时候，可以直接这样key value 定义，多个的话就用下面的数组定义 custom_authenticators: - App\\Security\\FormLoginAuthenticator # AbstractLoginFormAuthenticator - App\\Security\\RedirectAuthenticator # AbstractAuthenticator
# entry_point: App\\Security\\FormLoginAuthenticator logout: invalidate_session: true path: /logout security: true 查看指定 firewall下的配置信息: php bin/console debug:firewall main
关于Authenticator的调用源码:Symfony\\Component\\Security\\Http\\Authentication\\AuthenticatorManager # 重点在 147行 executeAuthenticators`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bdoctrine2.html",title:"symfony之doctrine2",pathLocale:"/",contents:[{header:"",slug:"",content:`doctrine2 Entity 配置了下面这个属性 ，那么当执行 persist 和remove 方法的时候，关联的Entity 也会执行相应的方法
#[ORM\\OneToOne(inversedBy: 'userRole', targetEntity: User::class, cascade: ['persist', 'remove'])]`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bdoctrine%E6%B7%BB%E5%8A%A0%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%A4%84%E7%90%86%E7%9A%84%E9%A2%9D%E5%A4%96%E6%8B%93%E5%B1%95.html",title:"symfony之doctrine添加查询结果处理的额外拓展",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之doctrine添加查询结果处理的额外拓展:
场景：现在需要把查询到的结果集，直接返回匹配到的数据的id数组，可以通过下面的方式实现 在 App\\Extensions\\DoctrineHydrators 目录下创建如下类: <?php namespace App\\Extensions\\DoctrineHydrators; use Doctrine\\DBAL\\Exception;
use Doctrine\\ORM\\Internal\\Hydration\\AbstractHydrator; class PluckHydrator extends AbstractHydrator
{ public const HYDRATE_PLUCK = 'hydrate_pluck'; /** * @return list<mixed> */ protected function hydrateAllData(): array { try { $pluckValues = $this->statement()->fetchFirstColumn(); } catch (Exception $e) { return []; } return $pluckValues; }
} 将 PluckHydrator 配置到 doctrine.yaml 文件里 doctrine: dbal: url: '%env(resolve:DATABASE_URL)%' # IMPORTANT: You MUST configure your server version, # either here or in the DATABASE_URL env var (see .env file) #server_version: '13' orm: auto_generate_proxy_classes: true naming_strategy: doctrine.orm.naming_strategy.underscore_number_aware auto_mapping: true mappings: App: is_bundle: false dir: '%kernel.project_dir%/src/Entity' prefix: 'App\\Entity' alias: App #添加下面这行配置即可 hydrators: hydrate_pluck: App\\Extensions\\DoctrineHydrators\\PluckHydrator 使用 return $this->createQueryBuilder("c") ->getQuery() ->getResult(PluckHydrator::HYDRATE_PLUCK); //这样就可以通过自定义模式返回想要的数据，不需要先返回结果集，再去处理得到想要的数据`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bentry_point.html",title:"symfony之entry_point",pathLocale:"/",contents:[{header:"",slug:"",content:`有时，一个防火墙有多种认证方式[就会有多个 authenticator]（例如，既有表单登录[form_login]，又有API令牌认证[json_login]）。在这些情况下，
现在需要配置认证入口点。该入口点用于在用户尚未认证但试图访问需要认证的页面时生成一个
响应。例如，这可以用来将用户重定向到登录页面。
比如:
# config/packages/security.yaml
security: enable_authenticator_manager: true # ... firewalls: main: # allow authentication using a form or HTTP basic form_login: ~ http_basic: ~ # configure the form authentication as the entry point for unauthenticated users entry_point: form_login 可以将某个授权方式配置为false，那么这个授权方式即为不可用，如: form_login: false`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bform_login_out%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BA%8B%E4%BB%B6.html",title:"symfony之form_login_out的几个事件",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之form_login_out的几个事件:
之前简单记录了form_login/out的定义方式，今天再仔细探究一下其中的细节
1.在Symfony上，使用内置的登录系统
①登录form login.html.twig
{% extends 'base.html.twig' %} {% block title %}Login{% endblock %} {% block base_stylesheets %} {{ encore_entry_link_tags('user_registers') }}
{% endblock %} {% block body %} <div class="admin-login-wrap"> <form class="admin-form-login" method="post" action="{{ path('login_check') }}" novalidate autocomplete="off"> <input type="hidden" name="_csrf_token" value="{{ csrf_token('authenticate') }}"></input> {% for message in app.session.flashbag.get('notice') %} <div class="text-center mb-4"> <h6 class="mb-3" style="font-size: 12px;color:red">{{ message }}</h6> </div> {% endfor %} <div class="text-center mb-4"> <h1 class="mb-3 login-title">Login With Email </h1> </div> <div class="form-label-group"> <input type="text" id="inputEmail" name="email" class="form-control" placeholder="Email" required="" autofocus="" value=""> </div> <div class="form-label-group"> <input type="password" id="inputPassword" name="password" class="form-control" placeholder="Password" required="" autofocus="" value=""> </div> <button class="btn btn-lg btn-block" type="submit">Login</button> </form> </div> {% endblock %} {% block base_javascripts %} {# {{ encore_entry_script_tags('user_registers') }}#}
{% endblock %} ②控制器
SecurityController
<?php namespace App\\Controller\\Front; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route; class SecurityController extends AbstractController
{ #[Route('/login', name: 'login_form')] public function showLogin(Request $request): Response { if (!$this->getParameter('sso_disable')) { if ($this->isGranted('IS_AUTHENTICATED_FULLY')) { return $this->redirectToRoute('front_index'); } else { throw $this->createAccessDeniedException(); } } if ($this->isGranted('IS_AUTHENTICATED_FULLY')) { return $this->redirectToRoute('front_index'); } return $this->render('security/index.html.twig'); } #[Route('/login_check', name: 'login_check', methods: ['post'])] public function loginCheck(Request $request) { return new Response(); } #[Route('/logout', name: 'logout')] public function logOut(Request $request): void { }
} ③security.yaml配置文件
security: enable_authenticator_manager: false # https://symfony.com/doc/current/security.html#registering-the-user-hashing-passwords password_hashers:
# Symfony\\Component\\Security\\Core\\User\\PasswordAuthenticatedUserInterface: 'auto' App\\Entity\\User: algorithm: bcrypt cost: 4 # https://symfony.com/doc/current/security.html#loading-the-user-the-user-provider providers: main: entity: class: App\\Entity\\User property: email users_in_memory: { memory: null } firewalls: dev: pattern: ^/(_(profiler|wdt)|css|images|js)/ security: false main: lazy: true pattern: ^/ provider: main form_login: success_handler: App\\Security\\LoginSuccessHandler #用于登录成功的钩子函数 failure_handler: App\\Security\\LoginFailHandler #用于登录失败的钩子函数 username_parameter: email password_parameter: password sso: require_previous_session: false provider: main check_path: /otp/validate/ # Same as in app/config/routing.yml sso_scheme: "%idp_scheme%" # Required sso_host: "%idp_url%" # Required sso_otp_scheme: "%qinghong_scheme%" # Optional sso_otp_host: "%qinghong_domain%" # Optional sso_failure_path: /login sso_path: /sso/login/ # SSO endpoint on IdP. sso_service: "%sso_service%" # Consumer name success_handler: App\\Security\\LoginSuccessHandler logout: invalidate_session: true path: /logout
# success_handler: App\\Security\\LogoutSuccessHandler #这个是退出登录的钩子函数，不过官方推荐用LogoutEvent,后面会介绍这个方法 security: true anonymous: true # activate different ways to authenticate # https://symfony.com/doc/current/security.html#the-firewall # https://symfony.com/doc/current/security/impersonating_user.html # switch_user: true # Easy way to control access for large sections of your site # Note: Only the *first* access control that matches will be used access_control: - { path: ^/admin, roles: ROLE_ADMIN }
# - { path: ^/api, roles: ROLE_USER } - { path: /.*, role: PUBLIC_ACCESS } when@test: security: password_hashers: # By default, password hashers are resource intensive and take time. This is # important to generate secure password hashes. In tests however, secure hashes # are not important, waste resources and increase test times. The following # reduces the work factor to the lowest possible values. Symfony\\Component\\Security\\Core\\User\\PasswordAuthenticatedUserInterface: algorithm: auto cost: 4 # Lowest possible value for bcrypt time_cost: 3 # Lowest possible value for argon memory_cost: 10 # Lowest possible value for argon 登录相关:
App\\Security目录下创建如下handler
LoginSuccessHandler.php
<?php namespace App\\Security; use App\\Entity\\User;
use Symfony\\Component\\HttpFoundation\\Cookie;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;
use Symfony\\Component\\Security\\Http\\Authentication\\DefaultAuthenticationSuccessHandler;
use Symfony\\Component\\HttpFoundation\\RedirectResponse;
use Symfony\\Component\\HttpFoundation\\Response; class LoginSuccessHandler extends DefaultAuthenticationSuccessHandler
{ public function onAuthenticationSuccess(Request $request, TokenInterface $token): RedirectResponse|Response { /** @var User $user */ $user = $token->getUser(); $userInfo = []; if ($user) { $userInfo['id'] = $user->getId(); $userInfo['email'] = $user->getEmail(); $userInfo['firstName'] = $user->getFirstName(); $userInfo['middleName'] = $user->getMiddleName(); $userInfo['lastName'] = $user->getLastName(); $userInfo['isAdmin'] = count($user->getRoles()) > 1 ? 1 : 0; $userInfo['image'] = $user->getImage(); $userInfo['avatar'] = $user->getAvatar(); } $response = $this->httpUtils->createRedirectResponse($request, $this->determineTargetUrl($request)); $cookie = new Cookie('userInfo', json_encode($userInfo), 0, '/', null, null, false); $response->headers->setCookie($cookie); return $response; }
} LoginFailHandler.php
<?php namespace App\\Security; use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Security\\Core\\Exception\\AuthenticationException;
use Symfony\\Component\\Security\\Http\\Authentication\\DefaultAuthenticationFailureHandler; class LoginFailHandler extends DefaultAuthenticationFailureHandler
{ public function onAuthenticationFailure(Request $request, AuthenticationException $exception): \\Symfony\\Component\\HttpFoundation\\RedirectResponse|Response { //要想在后续页面获取到session信息，必须要通过$request->getSession()获取当前ctx的sesson信息，而不是直接new session(),这样会有问题 $request->getSession()->getFlashBag()->add( 'notice',//这里很奇怪，只有type为notice的时候，再次跳转到上面 login.html.twig 通过 app.session.flashbag.get('notice') 可以获取导数据，其它type 怎么都获取不到数据 $exception->getMessage() ); return $this->httpUtils->createRedirectResponse($request, '/login'); }
} 退出登录相关:
App\\Security目录下创建如下如下handler，通过handler实现，不过这种方式已被遗弃，不推荐使用
LogoutSuccessHandler.php //这个在security.yaml的logout下直接配置
<?php namespace App\\Security; use Symfony\\Component\\HttpFoundation\\Cookie;
use Symfony\\Component\\HttpFoundation\\RedirectResponse;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\Security\\Http\\Logout\\LogoutSuccessHandlerInterface; class LogoutSuccessHandler implements LogoutSuccessHandlerInterface
{ public function onLogoutSuccess(Request $request) { file_put_contents('./3.txt', time()); $response = new RedirectResponse('/'); $cookie = new Cookie('userInfo', null, 0, '/', null, null, false); $response->headers->setCookie($cookie); return $response; }
} 也可以在services.yaml下添加如下配置,通过listener实现: App\\EventListener\\LogoutSuccessListener: arguments: $idp_scheme: "%idp_scheme%" $idp_url: "%idp_url%" tags: - name: 'kernel.event_listener' event: 'Symfony\\Component\\Security\\Http\\Event\\LogoutEvent' dispatcher: security.event_dispatcher.main LogoutSuccessListener.php
<?php namespace App\\EventListener; use Symfony\\Component\\DependencyInjection\\ParameterBag\\ContainerBagInterface;
use Symfony\\Component\\HttpFoundation\\Cookie;
use Symfony\\Component\\HttpFoundation\\RedirectResponse;
use Symfony\\Component\\Routing\\Generator\\UrlGeneratorInterface;
use Symfony\\Component\\Security\\Http\\Event\\LogoutEvent; class LogoutSuccessListener
{ protected $idp_url; private UrlGeneratorInterface $urlGenerator; private ContainerBagInterface $params; public function __construct($idp_scheme, $idp_url, UrlGeneratorInterface $urlGenerator, ContainerBagInterface $params) { $this->idp_url = $idp_scheme . "://" . $idp_url; $this->urlGenerator = $urlGenerator; $this->params = $params; } //这个方法来源于社区pr public function onSymfonyComponentSecurityHttpEventLogoutEvent(LogoutEvent $param): void { $sso_disable = $this->params->get('sso_disable'); if (!$sso_disable) { $url = $this->idp_url . '/sso/logout?service=qinghong'; } else { $url = '/'; } $response = new RedirectResponse($url); $cookie = new Cookie('userInfo', null, 0, '/', null, null, false); $response->headers->setCookie($cookie); $param->setResponse($response); }
} 还可以通过订阅 LogoutEvent 实现,这样就不用在services.yaml下添加额外配置:
LogoutSubscriber.php
<?php namespace App\\EventSubscriber; use Symfony\\Component\\EventDispatcher\\EventSubscriberInterface;
use Symfony\\Component\\HttpFoundation\\Cookie;
use Symfony\\Component\\HttpFoundation\\RedirectResponse;
use Symfony\\Component\\Security\\Http\\Event\\LogoutEvent; class LogoutSubscriber implements EventSubscriberInterface
{ public function onLogout(LogoutEvent $logoutEvent): void { file_put_contents('./4.txt', time()); $response = new RedirectResponse('/'); $cookie = new Cookie('userInfo', null, 0, '/', null, null, false); $response->headers->setCookie($cookie); $logoutEvent->setResponse($response); } public static function getSubscribedEvents(): array { return [ LogoutEvent::class => 'onLogout', ]; }
} 参考：https://stackoverflow.com/questions/60998790/symfony-5confirmation-message-after-logout 2.自定义
security.yaml的配置如下
security: enable_authenticator_manager: true #此时要配置为true # https://symfony.com/doc/current/security.html#registering-the-user-hashing-passwords password_hashers:
# Symfony\\Component\\Security\\Core\\User\\PasswordAuthenticatedUserInterface: 'auto' App\\Entity\\User: algorithm: bcrypt cost: 4 # https://symfony.com/doc/current/security.html#loading-the-user-the-user-provider providers: main: entity: class: App\\Entity\\User property: email users_in_memory: { memory: null } firewalls: dev: pattern: ^/(_(profiler|wdt)|css|images|js)/ security: false main:
# lazy: true pattern: ^/ provider: main
# form_login: true #这个可以不要，直接下面这个 custom_authenticator 即可 custom_authenticator: App\\Security\\FormLoginAuthenticator logout: invalidate_session: true path: /logout security: true
# anonymous: true # activate different ways to authenticate # https://symfony.com/doc/current/security.html#the-firewall # https://symfony.com/doc/current/security/impersonating_user.html # switch_user: true # Easy way to control access for large sections of your site # Note: Only the *first* access control that matches will be used access_control: - { path: ^/admin, roles: ROLE_ADMIN }
# - { path: ^/api, roles: ROLE_USER } - { path: /.*, role: IS_AUTHENTICATED_ANONYMOUSLY } when@test: security: password_hashers: # By default, password hashers are resource intensive and take time. This is # important to generate secure password hashes. In tests however, secure hashes # are not important, waste resources and increase test times. The following # reduces the work factor to the lowest possible values. Symfony\\Component\\Security\\Core\\User\\PasswordAuthenticatedUserInterface: algorithm: auto cost: 4 # Lowest possible value for bcrypt time_cost: 3 # Lowest possible value for argon memory_cost: 10 # Lowest possible value for argon FormLoginAuthenticator.php
<?php namespace App\\Security; use App\\Entity\\User;
use Doctrine\\ORM\\EntityManagerInterface;
use Symfony\\Component\\HttpFoundation\\RedirectResponse;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\PasswordHasher\\Hasher\\UserPasswordHasherInterface;
use Symfony\\Component\\Routing\\Generator\\UrlGeneratorInterface;
use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;
use Symfony\\Component\\Security\\Core\\Exception\\AuthenticationException;
use Symfony\\Component\\Security\\Core\\Exception\\BadCredentialsException;
use Symfony\\Component\\Security\\Core\\Security;
use Symfony\\Component\\Security\\Http\\Authenticator\\AbstractLoginFormAuthenticator;
use Symfony\\Component\\Security\\Http\\Authenticator\\Passport\\Badge\\UserBadge;
use Symfony\\Component\\Security\\Http\\Authenticator\\Passport\\Passport;
use Symfony\\Component\\Security\\Http\\Authenticator\\Passport\\SelfValidatingPassport;
use Symfony\\Component\\Security\\Http\\Util\\TargetPathTrait; class FormLoginAuthenticator extends AbstractLoginFormAuthenticator
{ use TargetPathTrait; public const LOGIN_ROUTE = 'login_form';//login form 路由，有异常可以自动跳转到这个地址 private UrlGeneratorInterface $urlGenerator; private UserPasswordHasherInterface $userPasswordHasher; public function __construct(UrlGeneratorInterface $urlGenerator, UserPasswordHasherInterface $userPasswordHasher, private EntityManagerInterface $em,) { $this->urlGenerator = $urlGenerator; $this->userPasswordHasher = $userPasswordHasher; } public function supports(Request $request): bool { return $request->attributes->get('_route') === 'login_success';//这个是验证submit的post路由 } /** *验证用户名和密码是否正确 * @throws \\Exception */ public function authenticate(Request $request): Passport { $username = $request->request->get('email', ''); $request->getSession()->set(Security::LAST_USERNAME, $username); $res = $this->userPasswordHasher->isPasswordValid( $this->em->getRepository(User::class)->findOneBy(['email' => $username]), $request->request->get('password', '') ); if ($res){ return new SelfValidatingPassport(new UserBadge($username)); }else{ throw new BadCredentialsException('invalid email or password.'); } } //验证通过 逻辑,这里直接跳首页 public function onAuthenticationSuccess(Request $request, TokenInterface $token, string $firewallName): ?Response { if ($targetPath = $this->getTargetPath($request->getSession(), $firewallName)) { return new RedirectResponse($targetPath); } return new RedirectResponse($this->urlGenerator->generate('front_index')); } //验证失败 逻辑 public function onAuthenticationFailure(Request $request, AuthenticationException $exception): Response { return parent::onAuthenticationFailure($request, $exception); // TODO: Change the autogenerated stub } protected function getLoginUrl(Request $request): string { return $this->urlGenerator->generate(self::LOGIN_ROUTE); }
} SecurityController.php
<?php namespace App\\Controller\\Front; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Cookie;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route; class SecurityController extends AbstractController
{ #[Route('/login', name: 'login_form', methods: ['get'])] public function showLogin(Request $request): Response { // if ($this->isGranted('IS_AUTHENTICATED_FULLY')) { return $this->redirectToRoute('front_index'); } else { return $this->render('security/index.html.twig'); } } #[Route('/login/success', name: 'login_success', methods: ['post'])] public function loginSuccess(Request $request) { } #[Route('/logout', name: 'logout')] public function logOut(Request $request): void { }
} 登录form login.html.twig
{% extends 'base.html.twig' %} {% block title %}Register{% endblock %} {% block base_stylesheets %} {{ encore_entry_link_tags('user_registers') }}
{% endblock %} {% block body %} <div class="admin-login-wrap"> <form class="admin-form-login" method="post" action="{{ path('login_success') }}" novalidate autocomplete="off"> <input type="hidden" name="_csrf_token" value="{{ csrf_token('authenticate') }}"></input> <div class="text-center mb-4"> <h1 class="mb-3 login-title">Login With Email </h1> </div> <div class="form-label-group"> <input type="text" id="inputEmail" name="email" class="form-control" placeholder="Email" required="" autofocus="" value=""> </div> <div class="form-label-group"> <input type="password" id="inputPassword" name="password" class="form-control" placeholder="Password" required="" autofocus="" value=""> </div> <button class="btn btn-lg btn-block" type="submit">Login</button> </form> </div> {% endblock %} {% block base_javascripts %} {# {{ encore_entry_script_tags('user_registers') }}#}
{% endblock %}`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bform_rest.html",title:"symfony之form_rest",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之form_rest的作用:
form_rest(form_view, variables)
This renders all fields that have not yet been rendered for the given form. It's a good idea to always have this somewhere inside your form as it'll render hidden fields for you and make any fields you forgot to render easier to spot (since it'll render the field for you). {{ form_rest(form) }} 翻译过来就是:
它会渲染给定表单中所有尚未渲染的字段。在表单中的某个地方设置这个字段是个好主意，因为它会为你呈现隐藏的字段，并使你忘记呈现的字段更容易被发现（因为它会为你呈现字段）。 尤其是会渲染 csrf_token 字段，其实 form_start 也会把隐藏的字段渲染出来(包括 csrf_token 这些)，以及把在 formType 里面定义了，但是没有在表单手动呈现的字段, 包括了 form_rest 的所有功能。
之前我以为 form_start 不会渲染没有手动呈现的字段，后来实际验证了，会呈现，所以包括了 form_start 的所有功能。`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bform%E8%A1%A8%E5%8D%95.html",title:"symfony之form表单",pathLocale:"/",contents:[{header:"",slug:"",content:"form 函数和页面元素模型的关系:"}]},{path:"/content/php/symfony/symfony%E4%B9%8Bform%E9%AA%8C%E8%AF%81.html",title:"symfony之form验证",pathLocale:"/",contents:[{header:"",slug:"",content:`<?php namespace App\\Form; use App\\Entity\\Course;
use Doctrine\\ORM\\EntityManagerInterface;
use Symfony\\Component\\Form\\AbstractType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\HiddenType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\IntegerType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\TextareaType;
use Symfony\\Component\\Form\\Extension\\Core\\Type\\TextType;
use Symfony\\Component\\Form\\FormBuilderInterface;
use Symfony\\Component\\OptionsResolver\\OptionsResolver;
use Symfony\\Component\\Validator\\Constraints\\Callback;
use Symfony\\Component\\Validator\\Constraints\\NotNull;
use Symfony\\Component\\Validator\\Context\\ExecutionContext; class CourseFormType extends AbstractType
{ private EntityManagerInterface $entityManager; public function __construct(EntityManagerInterface $entityManager) { $this->entityManager = $entityManager; } public function buildForm(FormBuilderInterface $builder, array $options): void { $builder ->add('title', TextType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) use ($builder) { if (strlen($value) > 50) { $ctx->addViolation("The content should not be more than 50 words"); } elseif (strlen($value) == 0) { $ctx->addViolation('Please fill in course title'); } else { $course = $this->entityManager->getRepository(Course::class)->findOneByField('title', $value); $course_id = $builder->getOption('course_id'); if ($course && $course->getId() != $course_id) { $ctx->addViolation('This collection should contain only unique elements.'); } } }]), ] ]) ->add('cover_picture', HiddenType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) { if (empty($value)) { $ctx->addViolation("Please upload cover_picture"); } }]), ], ]) ->add('description', TextareaType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) { if (strlen($value) > 1000) { $ctx->addViolation("The content should not be more than 1000 words"); } elseif (strlen($value) == 0) { $ctx->addViolation('Please fill in course description'); } }]), ] ]) ->add('tag', TextType::class, [ 'constraints' => [ new NotNull([], 'Please fill in tag') ] ]) ->add('need_certification', IntegerType::class) ->add('certification_name', TextType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) { if ($ctx->getRoot()['need_certification']->getData() == 1) { if (empty($value)) { $ctx->addViolation("Please fill incertification name"); } elseif (strlen($value) > 20) { $ctx->addViolation("The content should not be more than 20 words"); } } }]), ], ]) ->add('certification_url', HiddenType::class, [ 'constraints' => [ new Callback(['callback' => function ($value, ExecutionContext $ctx) { if ($ctx->getRoot()['need_certification']->getData() == 1) { if (empty($value)) { $ctx->addViolation("Please upload certification"); } } }]), ], ] ); } public function configureOptions(OptionsResolver $resolver): void { $resolver->setDefaults([ 'data_class' => Course::class, // enable/disable CSRF protection for this form 'csrf_protection' => true, // the name of the hidden HTML field that stores the token 'csrf_field_name' => '_token', // an arbitrary string used to generate the value of the token // using a different string for each form improves its security 'csrf_token_id' => 'course_create', //exclude self 'course_id' => 0 ]); }
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bjsoin%E8%BE%93%E5%87%BA%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"symfony之jsoin输出循环引用导致的问题",pathLocale:"/",contents:[{header:"",slug:"",content:`最近在使用 symfony5 执行$this->json() 返回结果是报错：
主要是Entity 里有ManyToOne的关联关系，然后有相关的解决办法解决办法给 Entity 字段分组，如下格式：
User
/** @Groups("main")
*/
private $id; /** @Groups("main")
*/
private $filename; /** @Groups("other")
ManyToOne
*/
private $countries 重要的是，给这个关联关系和其它字段取不一样的Groups 即可，但是这个有问题，当一个Entity有很多个字段的时候，需要加
好多个 Groups 太麻烦了。
上面的写法，用json输出就是：
return $this->json(
$user,
200,
[],
[
'groups' => ['main']
]
);
后来我研究了一下，只要取消 $countries 的 getCountries() 方法就可以了，保留setCountries()方法，这样在json()输出(serializer)以后
就不会报错了。`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bjson_login%E7%99%BB%E5%BD%95%E6%96%B9%E5%BC%8F.html",title:"symfony之json_login登录方式",pathLocale:"/",contents:[{header:"",slug:"",content:`之前使用到了form_login的登录方式，后来有新的需求，想直接通过接口的形式登录，比如常规的RESTFUL方式，查看
文档发现有 json_login可以实现，官方默认有5种登录方式，全部对应有自己的默认 authenticator,各个默认的authenticator
都定义在:/vendor/symfony/security-bundle/Resources/config/security_authenticator.php
关于 json_login :
官方文档:https://symfony.com/doc/current/security.html#json-login
这个文档中比较重要的一点是:ApiLoginController中的路由api_login方法体，会在用户授权成功之后(会先走默认的authenticator)被调用，然后在这个方法体里面添加需要返回给接口调用方的参数，比如 token信息: #[Route('/api/login', name: 'api_login')] public function apiLogin(Request $request, SessionInterface $session, TokenStorageInterface $tokenStorage, EventDispatcherInterface $eventDispatcher): Response { $user = $this->getUser(); $token = new UsernamePasswordToken($user, null, 'main', $user->getRoles()); $tokenStorage->setToken($token); $session->set('_security_main', serialize($token));//这个_security_main是默认授权成功之后的key // Fire the login event manually $event = new InteractiveLoginEvent($request, $token); $eventDispatcher->dispatch($event); return $this->json([ 'user' => $user->getemail(), ]); } 但是有个问题，就是如果配置了 success_handler,如下在security.yaml:
json_login: check_path: /api/login success_handler: App\\Security\\LoginSuccessHandler 那么会在授权成功之后直接走这个success_handler,不会再走api_login方法体.
JsonLoginConfig参数在:
namespace Symfony\\Config\\Security\\FirewallConfig;
JsonLoginConfig
如果使用jwt认证，推荐使用这个包: composer require lexik/jwt-authentication-bundle`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bpersist%E5%92%8Cflush%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"symfony之persist和flush的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之persist和flush的区别:
The main difference between persist() and persistFlush() is that persist() queues the entity for insertion into the database, but does not immediately execute the insert statement. Instead, the insert is executed when the transaction is committed or when the flush() method is called. persistFlush(), on the other hand, combines the persist() and flush() methods into a single call. It queues the entity for insertion and immediately executes the insert statement, flushing the changes to the database. Both persist() and persistFlush() can be useful in different situations. persist() can be useful when you want to queue multiple entities for insertion and flush them all to the database at once, while persistFlush() can be useful when you want to immediately persist an entity and ensure that it is saved to the database. In general, it's a good idea to use persist() when you want to optimize for performance and persistFlush() when you want to ensure that the entity is immediately persisted to the database. 上面的文章翻译过来就是:persist会先把插入数据库操作放到队列里面，然后通过flush一起持久化到数据库，flush会立即持久化到数据库 使用案列: public function updateVideo($params = []): array { $dateTime = TimeService::getDateTime(time()); try { $this->getEntityManager()->getConnection()->transactional(function () use ($params, $dateTime) { $data = $this->find($params['id']); $data->setTitle($params['title']); $data->setLength($params['length']); $data->setPlayUrl($params['playUrl']); $data->setUpdatedAt($dateTime); //① //$this->save($data, true); $cm = $this->getEntityManager()->getRepository(CourseManage::class)->findOneBy(['type' => 'video', 'contentId' => $params['id'], 'courseId' => $data->getCourseId()]); if ($cm) { $cm->setTitle($params['title']); $cm->setUpdatedAt($dateTime); //② //$this->getEntityManager()->getRepository(CourseManage::class)->save($cm, true); } //③ $this->getEntityManager()->flush(); }); } catch (\\Throwable $exception) { return ['status' => false, 'msg' => $exception->getMessage()]; } return ['status' => true, 'msg' => 'operate success']; } 上面代码分析：当①和② 都设置为true的时候，就会自动调用flush，当没有设置true的时候就只是persist到队列，没有flush，这个时候需要
手动调用$this->getEntityManager()->flush() 即可。同时如果没有①和②，直接调用$this->getEntityManager()->flush(),也是可以
把数据持久化到数据库的。
参考文档: https://www.doctrine-project.org/projects/doctrine1/en/latest/manual/component-overview.html`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bphpstan%E5%88%A4%E6%96%AD%E9%97%AE%E9%A2%98.html",title:"symfony之phpstan判断问题",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之phpstan判断问题:
有如下写法的代码，在phpstan做代码分析的时候，会出现两种不同的结果
/**
* @return \\DateTime
*/
public function getDateRegularRegistrationEnd()
{ return $this->date_regular_registration_end;
} //如果这样判断，那么就会一直为true，因为 getDateRegularRegistrationEnd 会返回一个对象
if ($event->getDateRegularRegistrationEnd()){ } /** * @return \\DateTime|null */
public function getDateRegularRegistrationEnd()
{ return $this->date_regular_registration_end;
} //如果这样判断，那么就可以返回fasle，因为 getDateRegularRegistrationEnd 有null属性
if ($event->getDateRegularRegistrationEnd()){ } 这个是通过phpstan判断出来的，尽管上面通过dd($event->getDateRegularRegistrationEnd()),可以返回null,但是却不能通过`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bservice%E4%B8%8Bfirewall%E7%9A%84%E9%85%8D%E7%BD%AE.html",title:"symfony之service下firewall的配置",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之service下firewall的配置，这个firewall 挺重要的，尤其是配合service使用的时候
symfony5 firewalls
文档:https://symfony.com/doc/current/reference/configuration/security.html#firewalls
教程:https://symfonycasts.com/screencast/symfony-security/security-listeners 定义了formLogin的配置：
namespace Symfony\\Config\\Security\\FirewallConfig;
FormLoginConfig LogoutConfig的配置
namespace Symfony\\Config\\Security\\FirewallConfig;
LogoutConfig 上面两个类 定义了 在service 下配置 form_login或者 logout的时候，需要自定义的参数名称，对于使用symfony5内置form_login还是很重要的.`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bstimulus%E4%BD%BF%E7%94%A8.html",title:"symfony之stimulus使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之stimulus使用，这个是和ux-twig配合使用的,都是后端返回(渲染)前端页面的一种
symfony5安装encore https://symfony.com/doc/current/frontend/encore/installation.html composer require symfony/webpack-encore-bundle https://symfony.com/doc/current/frontend/encore/installation.html#installing-encore-in-symfony-applications 安装完encore，使用:
https://symfony.com/doc/current/frontend/encore/simple-example.html`}]},{path:"/content/php/symfony/symfony%E4%B9%8Btags%E8%AF%A6%E8%A7%A3.html",title:"symfony之tags详解",pathLocale:"/",contents:[{header:"",slug:"",content:`一直在定义 监听或者订阅 的配置文件用到这个，就记录一下 这个参数的意义
Service tags are a way to tell Symfony or other third-party bundles that your service should be registered in some special way. Take the following example:
# config/services.yaml
services: App\\Twig\\AppExtension: tags: ['twig.extension'] Services tagged with the twig.extension tag are collected during the initialization of TwigBundle and added to Twig as extensions. Other tags are used to integrate your services into other systems. For a list of all the tags available in the core Symfony Framework, check out Built-in Symfony Service Tags(下面的链接,查看所有的tag). Each of these has a different effect on your service and many tags require additional arguments (beyond the name parameter). 参考:https://symfony.com/doc/current/service_container/tags.html 查看所有的tag(以及每个tag下绑定的services/hooks):
php bin/console debug:container --tags 比如：
tag: kernel.event_listener
Purpose: To listen to different events/hooks in Symfony (要在Symfony中监听不同的事件/钩子) ref:https://symfony.com/doc/current/reference/dic_tags.html
内置核心事件:https://symfony.com/doc/current/reference/events.html#kernel-events 安全事件中的 dispatcher定义: security.event_dispatcher.FIREWALLNAME https://symfony.com/doc/current/security.html#security-events 验证发现上面的 AuthenticationSuccessEvent 可以触发, 但是 LoginSuccessEvent 无法触发`}]},{path:"/content/php/symfony/symfony%E4%B9%8Btwig%E6%A8%A1%E6%9D%BF.html",title:"symfony之twig模板",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之twig模板:
在 Twig 模板语法中,{%- -%}中的 - 是用来去除前后多余的空白字符(包括空格、制表符和换行符)的语法。具体来说: {%- 表示从该标记开始,去除它前面的所有空白字符,直到遇到第一个非空白字符为止。
-%} 表示从该标记结束,去除它后面的所有空白字符,直到遇到第一个非空白字符为止。
使用这种语法的主要目的是为了减小输出的 HTML/CSS/JS 代码体积,提高加载速度。它经常被用于控制流程语句中,比如{% block %}、{% for %}等,以确保生成的标记不会因为多余的空白字符而影响页面布局。 使用:
<div> {%- block foo -%} <span>foo</span><span>bar</span> {%- endblock -%}
</div> 上面代码中的{%- block foo -%}\`\`{%- endblock -%}就去除了块前后的所有空白字符,确保输出时<span>元素之间没有多余空格。`}]},{path:"/content/php/symfony/symfony%E4%B9%8Buser-role%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E5%8E%9F%E7%90%86.html",title:"symfony之user-role权限管理原理",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony之user-role权限管理原理:
symfony的用户角色权限管理和java的差不多，都是通过 注释路由 来控制的，我还是觉得像 laravel下的 RBAC 权限控制系统比较好，更全面
通过 注释路由 来控制， 感觉太简单粗暴，适合简单的权限分配。 下面说一下这个验证过程:
symfony的默认权限验证 authenticate 调用的是 vendor/symfony/security-http/Firewall/AccessListener.php 中的 authenticate 方法
其中：
if (!$this->accessDecisionManager->decide($token, $attributes, $request, true)) { throw $this->createAccessDeniedException($request, $attributes); } decide 调用的是 vendor/symfony/security-core/Authorization/AccessDecisionManager.php 中的 decide 方法 其中:
return $this->strategy->decide( $this->collectResults($token, $attributes, $object) ); collectResults 中的 $voter->vote($token, $object, $attributes); 调用的是 vendor/symfony/security-core/Authorization/Voter/RoleVoter.php 中的 vote 方法, 这个 vote 方法的逻辑很简单就是对比 $token里的
用户角色信息 和 当前路由需要的权限信息，用了两个 foreach 实现，如果有相等的，那么就可以验证通过.`}]},{path:"/content/php/symfony/symfony%E4%B9%8Bux-twig%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8.html",title:"symfony之ux-twig组件使用",pathLocale:"/",contents:[{header:"",slug:"",content:"symfony之ux-twig组件使用，其实也是后端返回前端页面的一种 依赖 composer require symfony/ux-twig-component 参考(https://symfony.com/bundles/ux-twig-component/current/index.html ; https://symfony.com/doc/current/frontend/ux.html#how-does-symfony-ux-work)"}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E4%BD%BF%E7%94%A8redis.html",title:"symfony之使用redis",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony框架使用redis: 安装拓展 composer require snc/redis-bundle client选择 这里使用predis: composer require predis/predis
默认使用的是phpredis(需要 ext-redis 拓展，直接 use Redis;即可) 修改配置 config/packages/snc_redis.yaml snc_redis: clients: # Define your clients here. The example below connects to database 0 of the default Redis server.
#
# See https://github.com/snc/SncRedisBundle/blob/master/docs/README.md for instructions on
# how to configure the bundle.
# default: type: predis alias: default dsn: "%env(REDIS_URL)%" 使用
首先在services.yaml里添加配置 services: # default configuration for services in *this* file _defaults: autowire: true # Automatically injects dependencies in your services. autoconfigure: true # Automatically registers your services as commands, event subscribers, etc. # makes classes in src/ available to be used as services # this creates a service per class whose id is the fully-qualified class name App\\: resource: '../src/' exclude: - '../src/DependencyInjection/' - '../src/Entity/' - '../src/Kernel.php' # add more service definitions when explicit configuration is needed # please note that last definitions always *replace* previous ones #使用predis的client，service为 snc_redis.default Predis\\ClientInterface: '@snc_redis.default' 控制器中使用: <?php namespace App\\Controller\\Admin; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route;
use Predis\\ClientInterface;//使用上面配置的predis client，会自动注入 class IndexController extends AbstractController
{ #[Route('/admin', name: 'admin')] public function index(Request $request, ClientInterface $client): Response { //通过redis 命令进行操作 $client->select(1); $client->set('name','wuhan'); dd($client->get('name')); return $this->renderForm('admin/index.html.twig'); }
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%9A%84%E4%B8%80%E4%B8%AA%E9%94%99%E8%AF%AF.html",title:"symfony之依赖注入的一个错误",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony5有时候会有 service 参数注入的时候，报下面的错误
method "__construct()" has no type-hint, you should conf
igure its value explicitly
主要原因是，注入的参数没有定义类型，程序不能自动注入，但是有一种特殊的场景，就是这个注入的参数有多种类型，比如可能是Bool，也有可能是Array的情况，php 好像没有泛型的概念,所以这种场景就不能直接注入了`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E5%86%85%E7%BD%AE%E7%9A%84%E8%A7%92%E8%89%B2.html",title:"symfony之内置的角色",pathLocale:"/",contents:[{header:"",slug:"",content:`使用symfony的时候，经常会判断用户角色，常见的就是 是否登录
ROLE_ADMIN # 一般会自定义这样一个角色
ROLE_USER # 一般会自定义这样一个角色，Entity 初始化完成以后，会自动生成 PUBLIC_ACCESS
IS_AUTHENTICATED_ANONYMOUSLY #Deprecated: since Symfony 5.4
IS_AUTHENTICATED_FULLY namespace Symfony\\Component\\Security\\Core\\Authorization\\Voter;
AuthenticatedVoter User Deprecated: Since symfony/security-core 5.4: The "IS_AUTHENTICATED_ANONYMOUSLY" security attribute is deprecated, use "PUBLIC_ACCESS" for public resources, otherwise use "IS_AUTHENTICATED" or "IS_AUTHENTICATED_FULLY" instead if you want to check if the request is (fully) authenticated. 参考：https://symfony.com/doc/current/security.html#allowing-unsecured-access-i-e-anonymous-users，中 Checking to see if a User is Logged In 部分`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86bundle.html",title:"symfony之图片处理bundle",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony处理图片的bundle，其中比较有用的就是生成缩略图，以及将图片缓存
composer require liip/imagine-bundle 安装过程中会让用户选择，这里选择y
然后项目会自动注入依赖，配置文件等，不需要手动引入 最后的配置文件在： app/config/packages/liip_imagine.yaml 而不是demo里的 app/config/config.yml //liip_imagine.yaml 添加需要的配置如下
# Documentation on how to configure the bundle can be found at: https://symfony.com/doc/current/bundles/LiipImagineBundle/basic-usage.html
liip_imagine: # valid drivers options include "gd" or "gmagick" or "imagick" driver: "imagick" webp: generate: true filter_sets: squared_thumbnail_small: filters: thumbnail: size: [200, 200] mode: outbound allow_upscale: true loaders: default: filesystem: data_root: - "%kernel.project_dir%/public" twig模板使用：src="{{ asset(course.coverPicture)|imagine_filter('squared_thumbnail_small') }}`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E5%A4%A7%E6%96%87%E4%BB%B6%E5%88%86%E7%89%87%E4%B8%8A%E4%BC%A0.html",title:"symfony之大文件分片上传",pathLocale:"/",contents:[{header:"",slug:"",content:`最近在做视频上传的功能，遇到大视频上传的问题，主要是测试服务器限流了，所以可能会有超时的问题，所以决定搞个分片上传
主要工作包括如下两大块: 前端
1.文件格式校验
2.文件切片、md5计算
3.发起检查请求，把当前文件的hash发送给服务端，检查是否有相同hash的文件
4.上传进度计算
5.上传完成后通知后端合并切片
后端
1.检查接收到的hash是否有相同的文件，并通知前端当前hash是否有未完成的上传
2.接收切片
3.合并所有切片 代码如下:
index.html.twig
{% extends 'backend.html.twig' %} {% block title %}course management{% endblock %}
{% block stylesheets %} {{ encore_entry_link_tags('upload_splices') }}
{% endblock %}
{% block content %} <div id="app"> <div class="row"> <div class="col-12"> hello </div> </div> <div class="row"> <div class="col-12"> <upload-splice :upload_url="\`{{ upload_url }}\`" :check_url="\`{{ check_url }}\`" :merge_url="\`{{ merge_url }}\`" :read_url="\`{{ read_url }}\`" ></upload-splice> </div> </div> </div>
{% endblock %} {% block javascripts %} {{ encore_entry_script_tags('upload_splices') }}
{% endblock %} UploadSplice.vue，需要 yarn add spark-md5 这个包
<template> <div> <div> <el-upload class="upload-demo" action="#" :on-change="uploadFile" :show-file-list="true" :file-list="fileList" :auto-upload="false" ref="uploadfile" :limit="1"> <el-button size="small" type="primary" :loading="loadingFile">上传文件</el-button> </el-upload> </div> <div> <Button @click="getVideoStream">读取数据</Button> </div> <Video :src="playUrl" v-if="playUrl" controls="controls"></Video> </div>
</template> <script>
import SparkMD5 from "spark-md5";
import axios from 'axios'
const chunkSize = 5 * 1024 * 1024;//定义分片的大小 暂定为5M，方便测试
export default { name: 'UploadSplice', components: {}, props: { upload_url: { type: String, default: '' }, check_url: { type: String, default: '' }, merge_url: { type: String, default: '' }, read_url: { type: String, default: '' } }, data() { return { fileList: [], loadingFile: false, playUrl: '' } }, watch: {}, computed: {}, methods: { /** * 上传文件 */ async uploadFile(File) { this.loadingFile = true var self = this //获取用户选择的文件 const file = File.raw this.currentFile = file //文件大小(大于100m再分片哦，否则直接走普通文件上传的逻辑就可以了，这里只实现分片上传逻辑) const fileSize = File.size // 放入文件列表 this.fileList = [{ "name": File.name }] // 可以设置大于多少兆可以分片上传，否则走普通上传 if (fileSize <= chunkSize) { console.log("上传的文件大于10m才能分片上传") } //计算当前选择文件需要的分片数量 const chunkCount = Math.ceil(fileSize / chunkSize) console.log("文件大小：", (File.size / 1024 / 1024) + "Mb", "分片数：", chunkCount) //获取文件md5，这个fileMd5 很重要，每个视频只会生成一个相同(不管请求多少次)的fileMd5，可以通过这个md5字符串来区分视频，将各自的分片放到各自的md5目录下 const fileMd5 = await this.getFileMd5(file, chunkCount); console.log("文件md5：", fileMd5) console.log("向后端请求本次分片上传初始化") const initUploadParams = { "identifier": fileMd5, //文件的md5 "filename": File.name, //文件名 "totalChunks": chunkCount, //分片的总数量 } // axios.post(this.check_url, initUploadParams).then(async (resp) => { if (resp.status === 200) { if (resp.data.code === 0) { // 获取后端返回的已上传分片数字的数组 // var uploaded = res.data.uploaded // 定义分片开始上传的序号 // 由于是顺序上传，可以判断后端返回的分片数组的长度，为0则说明文件是第一次上传，分片开始序号从0开始 // 如果分片数组的长度不为0，我们取最后一个序号作为开始序号 // var num = uploaded.length == 0 ? 0 : uploaded[uploaded.length - 1] let num = 0 console.log(num, '分片开始序号') // 当前为顺序上传方式，若要测试并发上传，请将103 行 await 修饰符删除即可 // 循环调用上传 for (let i = num; i < chunkCount; i++) { //分片开始位置 let start = i * chunkSize //分片结束位置 let end = Math.min(fileSize, start + chunkSize) //取文件指定范围内的byte，从而得到分片数据 let _chunkFile = File.raw.slice(start, end) console.log(_chunkFile) // 打印出来是一个Blob 对象，包括 size和type信息 console.log("开始上传第" + i + "个分片") let formdata = new FormData() formdata.append('identifier', fileMd5) formdata.append('filename', File.name) formdata.append('totalChunks', chunkCount) formdata.append('chunkNumber', i) formdata.append('totalSize', fileSize) formdata.append('file', _chunkFile) // 通过await实现顺序上传 await this.getMethods(formdata) } // 文件上传完毕，请求后端合并文件并传入参数 self.composeFile(fileMd5, File.name, chunkCount) } else { this.open4(resp.data.msg) } } }).catch(function (error) { console.log(error) }) }, /** * 上传文件方法 * @param formdata 上传文件的参数 */ getMethods(formdata) { return new Promise((resolve, reject) => { axios.post(this.upload_url, formdata).then((resp) => { if (resp.status === 200) { if (resp.data.code === 0) { console.log(resp.data.data) console.log('ok') resolve(); } else { this.open4(resp.data.msg) } } }).catch(function (error) { console.log(error) }) }); }, /** * 获取文件MD5 * @param file * @param chunkCount * @returns {Promise<unknown>} */ getFileMd5(file, chunkCount) { return new Promise((resolve, reject) => { let blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice; let chunks = chunkCount; let currentChunk = 0; let spark = new SparkMD5.ArrayBuffer(); let fileReader = new FileReader(); fileReader.onload = function (e) { spark.append(e.target.result); currentChunk++; if (currentChunk < chunks) { loadNext(); } else { let md5 = spark.end(); resolve(md5); } }; fileReader.onerror = function (e) { reject(e); }; function loadNext() { let start = currentChunk * chunkSize; let end = start + chunkSize; if (end > file.size) { end = file.size; } fileReader.readAsArrayBuffer(blobSlice.call(file, start, end)); } loadNext(); }); }, /** * 请求后端合并文件 * @param fileMd5 文件md5 * @param fileName 文件名称 * @param count 文件分片总数 */ composeFile(fileMd5, fileName, count) { console.log("开始请求后端合并文件") let data = { "identifier": fileMd5, //文件的md5 "filename": fileName, //文件名 "totalChunks": count //分片的总数量 } axios.post(this.merge_url, data).then((resp) => { if (resp.status === 200) { if (resp.data.code === 0) { this.loadingFile = false this.$refs.uploadfile.clearFiles() } else { this.open4(resp.data.msg) } } }).catch(function (error) { console.log(error) }) }, getVideoStream(){ axios.get(this.read_url).then((resp) => { if (resp.status === 200) { if (resp.data.code === 0) { //本来想将后台的blob在前端转成 url的，但是由于当前的项目环境，访问起来是有问题的 //下面是两种转换方法，第二种已被chrome浏览器弃用了 //后来还是想在后台合并完blob文件以后，能不能转为mp4，现在是可以的，不知道为什么第一个分片为mp4格式，导致最后的合并blob 也成了mp4格式，算是歪打正着吧 // let binaryData = []; // binaryData.push('http://academy.web.test/'+resp.data.data.video); // this.playUrl = window.URL.createObjectURL(new Blob(binaryData)); // let url = window.URL.createObjectURL('http://academy.web.test/'+resp.data.data.video); this.playUrl = resp.data.data.video console.log(this.playUrl) } else { this.open4(resp.data.msg) } } }).catch(function (error) { console.log(error) }) } }, created() { }, mounted() { }
}
<\/script>
<style lang="less" scoped>
</style> UploadSpliceController.php
<?php namespace App\\Controller\\Admin; use App\\Service\\FileService;
use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route;
use Symfony\\Component\\Routing\\Generator\\UrlGeneratorInterface; class UploadSpliceController extends AbstractController
{ #[Route('/admin/upload/list', name: 'admin_upload_list')] public function index(Request $request): Response { return $this->render('admin/upload/index.html.twig', [ 'upload_url' => $this->generateUrl('admin_upload_splice', [], UrlGeneratorInterface::ABSOLUTE_URL), 'check_url' => $this->generateUrl('admin_upload_check', [], UrlGeneratorInterface::ABSOLUTE_URL), 'merge_url' => $this->generateUrl('admin_merge_splice', [], UrlGeneratorInterface::ABSOLUTE_URL), 'read_url' => $this->generateUrl('admin_blob_read', [], UrlGeneratorInterface::ABSOLUTE_URL), ]); } #[Route('/admin/upload/check', name: 'admin_upload_check')] public function checkExist(): Response { return $this->json([ 'code' => 0, 'msg' => 'success', 'data' => [], ]); } #[Route('/admin/upload/splice', name: 'admin_upload_splice')] public function uploadSplice(Request $request, FileService $fileService): Response { $file = $request->files->get('file'); $fileName = $request->get('filename'); $chunkNumber = $request->get('chunkNumber'); $date = (new \\DateTime())->format('Y-m-d'); $ext = $file->getClientOriginalExtension() ?: 'mp4'; $name = $file->getClientOriginalName(); //测试分片数据类型
// $pathName = $file->getPathname();
// $finfo = finfo_open(FILEINFO_MIME); // 返回 mime 类 需要在copmposer.json添加 "ext-fileinfo": "*" 拓展才能使用
// $reallyType = finfo_file($finfo, $pathName);//得到文件类型的字符串,这个是获取到资源的真实类型
// $mime = $file->getClientMimeType(); // if ($chunkNumber == 0){
// dd([$reallyType, $mime]);
// }
//
// if ($chunkNumber == 2){
// dd([$reallyType, $mime]);
// } if ($name) { $filename = $name; } else { $filename = md5(microtime()) . '.' . $ext; } $destDir = 'upload' . '/video' . '/' . $date . '/' . $chunkNumber . '/'; try { $file->move($destDir, $filename); } catch (\\Throwable $throwable) { $this->json([ 'code' => 1001, 'msg' => $throwable->getMessage(), 'data' => [], ]); } $filePath = $destDir . $filename; return $this->json([ 'code' => 0, 'msg' => 'success', 'data' => ['url' => $filePath, 'title' => $fileName], ]); } #[Route('/admin/merge/splice', name: 'admin_merge_splice')] public function mergeSplice(Request $request): Response { $params = json_decode($request->getContent(), true); $filename = $params['filename']; $totalChunks = $params['totalChunks']; $date = (new \\DateTime())->format('Y-m-d'); $allPath = 'upload' . '/video' . '/' . $date . '/all/' . $filename; // 从2个开始读取，第一个(0)的格式一直为mp4 不知道为什么 for ($i = 0; $i < $totalChunks; $i++) { $cacheFile = fopen('upload/video/2023-04-20/' . $i . '/blob', 'rb'); $content = fread($cacheFile, 5 * 1024 * 1024); file_put_contents($allPath, $content, FILE_APPEND); } return $this->json([ 'code' => 0, 'msg' => 'success', 'data' => [], ]); } #[Route('/admin/blob/read', name: 'admin_blob_read')] public function readData() { return $this->json([ 'code' => 0, 'msg' => 'success', 'data' => ['video' => 'http://academy.web.test/upload/video/2023-04-20/all/test4.mp4'], //这里返回一个固定的视频地址 ]); }
} 目前还没有做好的是，分片上传的时候，怎么计算上传的进度。这个md5校验还是很重要的，防止误传或者文件修改问题，导致数据错乱
补充：获取上传文件的真实格式，原因是我发现第一个分片的格式和后面所有的分片都不一样，第一个分片会保留原文件的一些元数据，比如
原文件是一个视频，那么第一个分片就是Mp4格式；而其它分片确实Blob格式，这样也有一个好处就是，可以直接把第一个分片和后面其他的
分片追加起来，就正好又是一个完整的原文件，如所示视频的话，可以直接file_put_contents为一个视频文件，还是很好用的。
使用：
$pathName = $file->getPathname(); //临时文件路径
$finfo = finfo_open(FILEINFO_MIME); // 返回 mime 类
$reallyType = finfo_file($finfo, $pathName); //得到文件类型的字符串,这个是获取到资源的真实类型
$mime = $file->getClientMimeType(); if ($chunkNumber == 0){ dd([$reallyType, $mime]);
}
if ($chunkNumber == 1){ dd([$reallyType, $mime]);
} 第一个分片的类型:
array:2 [ 0 => "video/mp4; charset=binary" //real 1 => "application/octet-stream" //mime
] 第二个分片以后都是下面的类型:
array:2 [ 0 => "application/octet-stream; charset=binary" //real 1 => "application/octet-stream" //mime
]`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6.html",title:"symfony之手动配置异步发送邮件",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony配置异步邮件发送，主要有两种方式 使用默认的messageHandler framework: messenger: failure_transport: failed transports: # https://symfony.com/doc/current/messenger.html#transport-configuration async: dsn: '%env(MESSENGER_TRANSPORT_DSN)%' options: use_notify: true check_delayed_interval: 60000 retry_strategy: max_retries: 3 multiplier: 2 failed: 'doctrine://default?queue_name=failed' sync: 'sync://' routing: Symfony\\Component\\Mailer\\Messenger\\SendEmailMessage: async # Route your messages to the transports # 'App\\Message\\YourMessage': async 使用自定义的messageHandler 1.先创建一个消息类
<?php namespace App\\Message; class EmailAsync
{ private $subject; private $body; private $bodyText; private $recipient; private $context = []; public function __construct($subject, $body, $bodyText, $recipient, $context) { $this->subject = $subject; $this->body = $body; $this->bodyText = $bodyText; $this->recipient = $recipient; $this->context = $context; }
} 2.创建一个消息处理类
<?php namespace App\\MessageHandler; use App\\Message\\EmailAsync;
use Symfony\\Component\\Mime\\Address;
use Symfony\\Bridge\\Twig\\Mime\\TemplatedEmail;
use Symfony\\Component\\Mailer\\MailerInterface;
use Symfony\\Component\\Messenger\\Handler\\MessageHandlerInterface; class EmailAsyncHandler implements MessageHandlerInterface { protected $mailer; public function __construct(MailerInterface $mailer) { $this->mailer = $mailer; } public function __invoke(EmailAsync $email) { $subject = $email->getSubject(); $body = $email->getBody(); $bodyText = $email->getBodyText(); $recipient = $email->getRecipient(); $context = $email->getContext(); $emailToSend = (new TemplatedEmail()) ->from("my-address@hello.com") ->to(new Address("your-address@hello.com")) ->subject($subject) // path of the Twig template to render ->htmlTemplate($body) ->textTemplate($bodyText) // pass variables (name => value) to the template ->context($context) ; $this->mailer->send($emailToSend); }
} 3.配置messageHandler
framework: messenger: transports: async: '%env(MESSENGER_TRANSPORT_DSN)%' routing: # Route your messages to the transports App\\Message\\EmailAsync: async 4.触发邮件发送服务
<?php namespace App\\Service; use App\\Message\\EmailAsync;
use Symfony\\Component\\Messenger\\MessageBusInterface; class MailManagerAsync
{ protected $bus; public function __construct(MessageBusInterface $bus) { $this->bus = $bus; } protected function sendMessage($subject, $body, $bodyText, $to, $context = []) { $emailAsync = new EmailAsync($subject, $body, $bodyText, $to, $context); $this->bus->dispatch($emailAsync); }
} 整个流程和普通的消息队列是一样的
注意点:
之前我这里有个问题，在config/packages/dev/mailer.yaml 里配置了:
framework: mailer: dsn: '%env(MAILER_DSN)%' message_bus: false 根据官网的介绍(https://symfony.com/doc/5.4/mailer.html#sending-messages-async)可以知道，这里配置
为false以后 asymc 就会失效，尤其是这个 dev 环境，直接覆盖了我的配置，所以导致 async 一直不生效`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E6%9F%A5%E7%9C%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F.html",title:"symfony之查看配置文件格式",pathLocale:"/",contents:[{header:"",slug:"",content:`通过如下命令即可实现:
①查看config/packages下所有bundle的配置文件格式
php bin/console config:dump-reference ==================================================================== --------------------------------------- -------------------------------------- Bundle name Extension alias --------------------------------------- -------------------------------------- DebugBundle debug DoctrineBundle doctrine DoctrineMigrationsBundle doctrine_migrations FrameworkBundle framework KnpPaginatorBundle knp_paginator KrtvSingleSignOnServiceProviderBundle krtv_single_sign_on_service_provider LiipImagineBundle liip_imagine MDPICommonBundle MakerBundle maker MonologBundle monolog SecurityBundle security SensioFrameworkExtraBundle sensio_framework_extra SymfonyCastsVerifyEmailBundle symfonycasts_verify_email TwigBundle twig TwigExtraBundle twig_extra WebProfilerBundle web_profiler WebpackEncoreBundle webpack_encore --------------------------------------- -------------------------------------- // Provide the name of a bundle as the first argument of this command to dump its default configuration. (e.g. // config:dump-reference FrameworkBundle) // // For dumping a specific option, add its path as the second argument of this command. (e.g. config:dump-reference // FrameworkBundle profiler.matcher to dump the framework.profiler.matcher configuration) ②查看security的默认配置格式
php bin/console config:dump-reference security
...
...
... ③查看security在项目中的实际配置
php bin/console debug:config security Current configuration for extension with alias "security"
========================================================= security: enable_authenticator_manager: false password_hashers: App\\Entity\\User: algorithm: bcrypt cost: 4 migrate_from: { } hash_algorithm: sha512 key_length: 40 ignore_case: false encode_as_base64: true iterations: 5000 memory_cost: null time_cost: null providers: main: entity: class: App\\Entity\\User property: email manager_name: null users_in_memory: memory: users: { } firewalls: dev: pattern: ^/(_(profiler|wdt)|css|images|js)/ security: false methods: { } user_checker: security.user_checker stateless: false lazy: false required_badges: { } main: lazy: true pattern: ^/ provider: main sso: require_previous_session: false provider: main check_path: /otp/validate/ sso_scheme: '%env(IDP_SCHEME)%' sso_host: '%env(IDP_URL)%' sso_otp_scheme: '%env(ACADEMY_SCHEME)%' sso_otp_host: '%env(ACADEMY_DOMAIN)%' sso_failure_path: /login sso_path: /sso/login/ sso_service: '%env(SSO_SERVICE)%' success_handler: App\\Security\\LoginSuccessHandler remember_me: true use_forward: false login_path: /login sso_service_parameter: service sso_service_extra: { } sso_service_extra_parameter: service_extra sso_login_required: 1 sso_login_required_parameter: login_required always_use_default_target_path: false default_target_path: / target_path_parameter: _target_path use_referer: false failure_path: null failure_forward: false failure_path_parameter: _failure_path logout: invalidate_session: true path: /logout csrf_parameter: _csrf_token csrf_token_id: logout target: / delete_cookies: { } handlers: { } security: true anonymous: lazy: false secret: null methods: { } user_checker: security.user_checker stateless: false required_badges: { } access_control: - path: ^/admin roles: - ROLE_ADMIN requires_channel: null host: null port: null ips: { } methods: { } allow_if: null - path: '/.*' roles: - PUBLIC_ACCESS requires_channel: null host: null port: null ips: { } methods: { } allow_if: null encoders: App\\Entity\\User: algorithm: bcrypt cost: 4 migrate_from: { } hash_algorithm: sha512 key_length: 40 ignore_case: false encode_as_base64: true iterations: 5000 memory_cost: null time_cost: null access_denied_url: null session_fixation_strategy: migrate hide_user_not_found: true always_authenticate_before_granting: false erase_credentials: true access_decision_manager: allow_if_all_abstain: false allow_if_equal_granted_denied: true role_hierarchy: { } //关于security的源码:https://github.com/symfony/symfony/blob/6.2/src/Symfony/Bundle/SecurityBundle/Security.php 查看symfony版本:
php bin/console --version 或者 php bin/console about -------------------- -------------------------------------------- Symfony -------------------- -------------------------------------------- Version 5.4.15 Long-Term Support Yes End of maintenance 11/2024 (in +582 days) End of life 11/2025 (in +947 days) -------------------- -------------------------------------------- Kernel -------------------- -------------------------------------------- Type App\\Kernel Environment dev Debug true Charset UTF-8 Cache directory ./var/cache/dev (3.9 GiB) Build directory ./var/cache/dev (3.9 GiB) Log directory ./var/log (475.5 MiB) -------------------- -------------------------------------------- PHP -------------------- -------------------------------------------- Version 8.1.2-1ubuntu2.11 Architecture 64 bits Intl locale n/a Timezone Asia/Chongqing (2023-04-28T11:31:14+08:00) OPcache true APCu false Xdebug false -------------------- --------------------------------------------`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%B8%B2%E6%9F%93.html",title:"symfony之模板渲染",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony模板渲染:
①常规方式
// src/Controller/ProductController.php
namespace App\\Controller; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Response; class ProductController extends AbstractController
{ public function index(): Response { // ... // the \`render()\` method returns a \`Response\` object with the // contents created by the template return $this->render('product/index.html.twig', [ 'category' => '...', 'promotions' => ['...', '...'], ]); // the \`renderView()\` method only returns the contents created by the // template, so you can use those contents later in a \`Response\` object $contents = $this->renderView('product/index.html.twig', [ 'category' => '...', 'promotions' => ['...', '...'], ]); return new Response($contents); //或者直接 render return $this->render('product/index.html.twig', [ 'pagination' => $pagination, 'query' => $request->query->all(), ]); }
} ②v5.4版本以后可以通过Annotation方式，虽然官网说是v6.2以后才行
// src/Controller/ProductController.php
namespace App\\Controller; use Symfony\\Bridge\\Twig\\Attribute\\Template;
use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Response; class ProductController extends AbstractController
{ #[Template('product/index.html.twig')] //Annotation方式 public function index() { // ... // when using the #[Template()] attribute, you only need to return // an array with the parameters to pass to the template (the attribute // is the one which will create and return the Response object). return [ 'category' => '...', 'promotions' => ['...', '...'], ]; }
} ③在非控制器(比如 service 里面)
// src/Service/SomeService.php
namespace App\\Service; use Twig\\Environment;//注意这个twig的环境变量 class SomeService
{ public function __construct( private Environment $twig, ) { } public function someMethod() { // ... $htmlContents = $this->twig->render('product/index.html.twig', [ 'category' => '...', 'promotions' => ['...', '...'], ]); }
} ④直接在 config/routes.yaml 渲染模板,虽然模板通常在控制器和服务中呈现，但你可以直接从路由定义中呈现不需要任何变量的静态页面。使用Symfony提供的特殊TemplateController：
acme_privacy: path: /admin/test //路由 controller: Symfony\\Bundle\\FrameworkBundle\\Controller\\TemplateController //这个控制器是symfony自带的，不许用我们处理 defaults: # the path of the template to render template: 'admin/test.html.twig' //只需要一个静态页面即可 # the response status code (default: 200) statusCode: 200 # special options defined by Symfony to set the page cache maxAge: 86400 sharedAge: 86400 # whether or not caching should apply for client caches only private: true # optionally you can define some arguments passed to the template context: site_name: 'ACME' theme: 'dark' 检查所有模板:$ php bin/console lint:twig
展示模板信息:$ php bin/console debug:twig`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%B6%88%E8%B4%B9.html",title:"symfony之消息发布与消费",pathLocale:"/",contents:[{header:"",slug:"",content:`最近做项目需要使用到消息队列，所以记录一下，本次消息队列基于redis 安装需要的依赖 composer require symfony/messenger 在App\\Message下创建消息文件 <?php namespace App\\Message; final class CourseMessage
{ private string $user_course_id; public function __construct(string $user_course_id) { $this->user_course_id = $user_course_id; } public function getCourseId(): string { return $this->user_course_id; }
} 在App\\MessageHandler下创建消息处理函数 <?php namespace App\\MessageHandler; use App\\Entity\\UserCourse;
use App\\Message\\CourseMessage;
use App\\Service\\TimeService;
use Doctrine\\ORM\\EntityManagerInterface;
use Psr\\Log\\LoggerInterface;
use Symfony\\Component\\Messenger\\Handler\\MessageHandlerInterface; final class CourseMessageHandler implements MessageHandlerInterface
{ private EntityManagerInterface $entityManager; private LoggerInterface $logger; public function __construct(EntityManagerInterface $entityManager, LoggerInterface $logger) { $this->entityManager = $entityManager; $this->logger = $logger; } // 通过__invoke处理相关的逻辑 public function __invoke(CourseMessage $message) { // do something with your message $user_course_id = $message->getCourseId(); $userCourse = $this->entityManager->getRepository(UserCourse::class)->find($user_course_id); $dateTime = TimeService::getDateTime(time()); $userCourse->setFinishedAt($dateTime); $this->entityManager->getRepository(UserCourse::class)->save($userCourse, true); $this->logger->info("user course done!"); }
} 关键是里面的 __invoke 方法，根据参数判断要消费的消息类型, 可以为同一个消息类，配置多个不同的handler, 但是invoke的参数一致, Symfony 会扫描所有被注册的 Handler 服务，自动根据类型提示找到对应的 Handler。 在配置文件 config/packages/messager.yaml下配置 framework: messenger: failure_transport: failed transports: # https://symfony.com/doc/current/messenger.html#transport-configuration async: dsn: '%env(MESSENGER_TRANSPORT_DSN)%' options: use_notify: true check_delayed_interval: 60000 retry_strategy: max_retries: 3 multiplier: 2 failed: 'doctrine://default?queue_name=failed' sync: 'sync://' routing: Symfony\\Component\\Mailer\\Messenger\\SendEmailMessage: sync Symfony\\Component\\Notifier\\Message\\ChatMessage: async Symfony\\Component\\Notifier\\Message\\SmsMessage: async App\\Message\\CourseMessage: async # Route your messages to the transports # 'App\\Message\\YourMessage': async 触发message <?php namespace App\\Controller\\Admin; use App\\Message\\CourseMessage;
use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Messenger\\MessageBusInterface;
use Symfony\\Component\\Routing\\Annotation\\Route; class IndexController extends AbstractController
{ #[Route('/admin', name: 'admin')] public function index(Request $request, MessageBusInterface $bus): Response { //这里通过 $bus 手动触发 message $bus->dispatch(new CourseMessage(1)); return $this->renderForm('admin/index.html.twig'); }
} 消费消息 1.通过命令行的方式
php bin/console messenger:consume async -vv 2.通过supervisor守护进程方式
通过supervisor操作:
;/etc/supervisor/conf.d/messenger-worker.conf
[program:messenger-consume]
command=php /path/to/your/app/bin/console messenger:consume async --time-limit=3600 #async 为异步使用的transport
user=ubuntu
numprocs=2
startsecs=0
autostart=true
autorestart=true
startretries=10
process_name=%(program_name)s_%(process_num)02d 官方文档(https://symfony.com/doc/current/messenger.html)`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5%E5%8E%9F%E7%90%86.html",title:"symfony之自动注入原理",pathLocale:"/",contents:[{header:"",slug:"",content:`今天在分析之前的项目的时候，发现有几处配置不太清楚，就翻了一下symfony的官方文档，总结如下:
全面讲解symfony的自动注入原理: https://symfony.com/doc/5.4/service_container/autowiring.html # config/services.yaml
services: # ... # the id is not a class, so it won't be used for autowiring app.rot13.transformer: class: App\\Util\\Rot13Transformer # ... # but this fixes it! # the "app.rot13.transformer" service will be injected when # an App\\Util\\Rot13Transformer type-hint is detected App\\Util\\Rot13Transformer: '@app.rot13.transformer' This creates a service "alias", whose id is App\\Util\\Rot13Transformer. Thanks to this, autowiring sees this and uses it whenever the Rot13Transformer class is type-hinted
(这创建了一个服务 "别名"，其ID是App\\Util\\Rot13Transformer。多亏了这一点，自动布线看到了这一点，并在Rot13Transformer类被类型提示时使用它) 通过别名实现自动注入: https://symfony.com/doc/5.4/service_container/autowiring.html#using-aliases-to-enable-autowiring 通过setter方法注入: https://symfony.com/doc/5.4/service_container/autowiring.html#autowiring-other-methods-e-g-setters-and-public-typed-properties 控制器里自动注入: https://symfony.com/doc/5.4/controller.html#controller-accessing-services 你怎么知道要使用LoggerInterface的类型提示？你可以阅读你所使用的任何功能的文档，或者通过运行以下程序获得一个可自动连接的类型提示列表: php bin/console debug:autowiring 对于容器中所有可能的服务的完整列表，请运行: php bin/console debug:container 还有一种与服务有关的参数。在YAML配置中，任何以@开头的字符串都被认为是服务的ID，而不是普通字符串：
# config/services.yaml
services: App\\Service\\MessageGenerator: arguments: # this is not a string, but a reference to a service called 'logger' - '@logger' # if the value of a string argument starts with '@', you need to escape # it by adding another '@' so Symfony doesn't consider it a service # the following example would be parsed as the string '@securepassword' # - '@@securepassword' 其实内容还是比较多的，实际使用主要是在 config/service.yaml文件里配置各种服务。`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA%E4%BB%A5%E5%8F%8A%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E6%97%B6%E5%8C%BA.html",title:"symfony之设置时区以及获取当前时区",pathLocale:"/",contents:[{header:"",slug:"",content:`项目开发过程中有时候需要设置时区以及获取当前时区，步骤如下: 设置时区(修改默认的时区) 1.在.env配置时区
APP_TIMEZONE=Asia/Chongqing 2.在config/services.yaml定义配置
parameters: timezone: '%env(APP_TIMEZONE)%' 3.在Kernel类中覆盖boot方法并从容器中获取时区参数。用date_default_timezone_set函数来设置日期和时间函数所使用的默认时区。
<?php namespace App; use Symfony\\Bundle\\FrameworkBundle\\Kernel\\MicroKernelTrait;
use Symfony\\Component\\HttpKernel\\Kernel as BaseKernel; class Kernel extends BaseKernel
{ use MicroKernelTrait; public function boot(): void { parent::boot(); date_default_timezone_set($this->getContainer()->getParameter('timezone')); }
} 获取当前时区 <?php namespace App\\Controller; use DateTime;
use Symfony\\Component\\HttpFoundation\\Response;
use Symfony\\Component\\Routing\\Annotation\\Route; class TestController
{ #[Route('/')] public function index(): Response { $now = new DateTime(); return new Response($now->getTimezone()->getName()); // Output: Asia/Chongqing }
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E8%B7%AF%E7%94%B1%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.html",title:"symfony之路由文件详解",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony路由文件详解:
①查看所有路由
php bin/console debug:router ②查看指定路由信息
php bin/console debug:router admin_course_list ③根据指定路由名称获取url
如果你的控制器扩展自AbstractController，使用generateUrl()帮助器:
$this->generateUrl('sign_up'); 如果你的控制器没有从AbstractController扩展，你需要在你的控制器中获取服务，并遵循下一节的指示:
// src/Service/SomeService.php
namespace App\\Service; use Symfony\\Component\\Routing\\Generator\\UrlGeneratorInterface; class SomeService
{ public function __construct( private UrlGeneratorInterface $router, ) { } public function someMethod() { // ... // generate a URL with no route arguments $signUpPage = $this->router->generate('sign_up'); // generate a URL with route arguments $userProfilePage = $this->router->generate('user_profile', [ 'username' => $user->getUserIdentifier(), ]); // generated URLs are "absolute paths" by default. Pass a third optional // argument to generate different URLs (e.g. an "absolute URL") $signUpPage = $this->router->generate('sign_up', [], UrlGeneratorInterface::ABSOLUTE_URL); // when a route is localized, Symfony uses by default the current request locale // pass a different '_locale' value if you want to set the locale explicitly $signUpPageInDutch = $this->router->generate('sign_up', ['_locale' => 'nl']); }
}`}]},{path:"/content/php/symfony/symfony%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.html",title:"symfony之配置文件详解",pathLocale:"/",contents:[{header:"",slug:"",content:`一直对symfony的几个配置文件有些疑问，尤其在使用的时候，今天特意记录一下:
Symfony应用程序是通过存储在config/目录下的文件来配置的，该目录的默认结构如下:
your-project/
├─ config/
│ ├─ packages/
│ ├─ bundles.php
│ ├─ routes.yaml
│ └─ services.yaml routes.yaml文件定义了路由配置；
services.yaml文件配置了服务容器的服务；
bundles.php文件在你的应用程序中启用/禁用包；
config/packages/目录存储了你的应用程序中安装的每个包的配置。 Packages（在Symfony中也称为 "捆绑"，在其他项目中称为 "插件/模块"）为你的项目添加随时可用的功能 ①环境变量
dev用于本地开发、
prod用于生产服务器、
test用于自动测试。 当运行应用程序时，Symfony按照这个顺序加载配置文件（最后一个文件可以覆盖前面的文件中设置的值）： config/packages/*.<extension>中的文件；
config/packages/<environment-name>/*.<extension>中的文件；
config/services.<extension>；
config/services_<environment-name>.<extension>。 如果你需要覆盖一个环境值（例如，在你的本地机器上覆盖一个不同的值），你可以在一个.env.local文件中完成：
# .env.local
DATABASE_URL="mysql://root:@127.0.0.1:3306/my_database_name" 这个文件应该被git忽略，也不应该被提交到你的版本库。其他几个.env文件可以在适当的情况下设置环境变量： .env：定义了应用程序所需的环境变量的默认值；
.env.local: 覆盖所有环境的默认值，但只在包含该文件的机器上。这个文件不应该被提交到版本库，在测试环境中被忽略（因为测试应该对每个人产生相同的结果）；
.env.<environment> (e.g. .env.test): 只在一个环境中覆盖环境变量，但在所有机器上（这些文件被提交）；
.env.<environment>.local (e.g. .env.test.local): 只为一个环境定义特定机器的环境变量覆盖。它类似于.env.local，但这些覆盖只适用于一个环境。 在生产中，.env文件也会在每个请求中被解析和加载。因此，定义环境变量的最简单方法是在你的生产服务器上创建一个.env.local文件，其中包含你的生产值，为了提高性能，你可以选择运行dump-env命令事实上：
$ composer dump-env
Successfully dumped .env files in .env.local.php 运行这个命令后，Symfony会加载.env.local.php文件来获取环境变量，不会花时间解析.env文件。 ②列出环境变量
$ php bin/console debug:dotenv Dotenv Variables & Files
======================== Scanned Files (in descending priority)
-------------------------------------- * ⨯ .env.local.php * ⨯ .env.dev.local * ⨯ .env.dev * ✓ .env.local * ✓ .env Variables
--------- ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- Variable Value .env.local .env ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- DUOXAIO_DOMAIN DUOXAIO.web.test DUOXAIO.web.test DUOXAIO_SCHEME http http APP_ENV dev dev dev APP_SECRET ThisTokenIsNotSoSecretChangeIt ThisTokenIsNotSoSecretChangeIt... d6edd2e553f701556efbea65e8d868... DATABASE_URL mysql://root:123456@127.0.0.1:3306/DUOXAIO?serverVersion=8.0&charset=utf8mb4 mysql://root:123456@127.0.0.1:... mysql://app:!ChangeMe!@127.0.0... FFMPEG_BINARY_PATH /usr/bin/ffmpeg /usr/bin/ffmpeg FFPROBE_BINARY_PATH /usr/bin/ffprobe /usr/bin/ffprobe IDP_SCHEME http http IDP_URL qinhong.login.test qinhong.login.test MAILER_DSN smtp://localhost:1025 smtp://localhost:1025 null://null qinhong_LOGIN_HOST qinhong.login.test qinhong.login.test MESSENGER_TRANSPORT_DSN redis://localhost:6379/messages redis://localhost:6379/message... doctrine://default?auto_setup=... SSO_SERVICE DUOXAIO DUOXAIO USER_LOGIN_AUTHORITY DUOXAIO DUOXAIO DUOXAIO USER_LOGIN_KEY DUOXAIO DUOXAIO DUOXAIO ------------------------- ------------------------------------------------------------------------------ ----------------------------------- ----------------------------------- // Note real values might be different between web and CLI. ③此外，无论你如何设置环境变量，你都可以看到Symfony的容器配置中引用的所有环境变量及其值
$ php bin/console debug:container --env-vars Symfony Container Environment Variables
======================================= ------------------------- ------------------ -------------------------------------------------------------------------------- Name Default value Real value ------------------------- ------------------ -------------------------------------------------------------------------------- DUOXAIO_DOMAIN n/a "DUOXAIO.web.test" DUOXAIO_SCHEME n/a "http" APP_SECRET n/a "ThisTokenIsNotSoSecretChangeIt" DATABASE_URL n/a "mysql://root:123456@127.0.0.1:3306/DUOXAIO?serverVersion=8.0&charset=utf8mb4" FFMPEG_BINARY_PATH n/a "/usr/bin/ffmpeg" FFPROBE_BINARY_PATH n/a "/usr/bin/ffprobe" IDP_SCHEME n/a "http" IDP_URL n/a "qinhong.login.test" MAILER_DSN n/a "smtp://localhost:1025" QINGHONG_LOGIN_HOST n/a "qinhong.login.test" MESSENGER_TRANSPORT_DSN n/a "redis://localhost:6379/messages" SSO_SERVICE n/a "DUOXAIO" USER_LOGIN_AUTHORITY n/a "DUOXAIO" USER_LOGIN_KEY n/a "DUOXAIO" VAR_DUMPER_SERVER "127.0.0.1:9912" n/a ------------------------- ------------------ -------------------------------------------------------------------------------- // Note real values might be different between web and CLI ④运行下面的命令可以看到你的应用程序中存在的所有参数 $ php bin/console debug:container --parameters Symfony Container Parameters
============================ ----------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------- Parameter Value ----------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------- DUOXAIO_domain %env(DUOXAIO_DOMAIN)% DUOXAIO_scheme %env(DUOXAIO_SCHEME)% asset.request_context.base_path null asset.request_context.secure null cache.prefix.seed _/home/qinhong/code/DUOXAIO.App_KernelDevDebugContainer central_dms_dir /var/www/dms/ console.command.ids [] data_collector.templates {"data_collector.request":["request","@WebProfiler\\/Collecto... debug.container.dump /home/qinhong/code/DUOXAIO/var/cache/dev/App_KernelDevDebugContainer.xml debug.error_handler.throw_at -1 debug.file_link_format null doctrine.class Doctrine\\Bundle\\DoctrineBundle\\Registry doctrine.connections {"default":"doctrine.dbal.default_connection"} doctrine.data_collector.class Doctrine\\Bundle\\DoctrineBundle\\DataCollector\\DoctrineDataCollector doctrine.dbal.configuration.class Doctrine\\DBAL\\Configuration doctrine.dbal.connection.event_manager.class Symfony\\Bridge\\Doctrine\\ContainerAwareEventManager doctrine.dbal.connection_factory.class Doctrine\\Bundle\\DoctrineBundle\\ConnectionFactory doctrine.dbal.connection_factory.types [] doctrine.dbal.events.mysql_session_init.class Doctrine\\DBAL\\Event\\Listeners\\MysqlSessionInit doctrine.dbal.events.oracle_session_init.class Doctrine\\DBAL\\Event\\Listeners\\OracleSessionInit doctrine.dbal.logger.chain.class Doctrine\\DBAL\\Logging\\LoggerChain doctrine.dbal.logger.class Symfony\\Bridge\\Doctrine\\Logger\\DbalLogger doctrine.dbal.logger.profiling.class Doctrine\\DBAL\\Logging\\DebugStack doctrine.default_connection default doctrine.default_entity_manager default doctrine.entity_managers {"default":"doctrine.orm.default_entity_manager"} doctrine.migrations.preferred_connection null doctrine.migrations.preferred_em null doctrine.orm.auto_generate_proxy_classes true doctrine.orm.cache.apc.class Doctrine\\Common\\Cache\\ApcCache doctrine.orm.cache.array.class Doctrine\\Common\\Cache\\ArrayCache doctrine.orm.cache.memcache.class Doctrine\\Common\\Cache\\MemcacheCache doctrine.orm.cache.memcache_host localhost doctrine.orm.cache.memcache_instance.class Memcache doctrine.orm.cache.memcache_port 11211 doctrine.orm.cache.memcached.class Doctrine\\Common\\Cache\\MemcachedCache doctrine.orm.cache.memcached_host localhost doctrine.orm.cache.memcached_instance.class Memcached doctrine.orm.cache.memcached_port 11211 doctrine.orm.cache.redis.class Doctrine\\Common\\Cache\\RedisCache doctrine.orm.cache.redis_host localhost doctrine.orm.cache.redis_instance.class Redis doctrine.orm.cache.redis_port 6379 doctrine.orm.cache.wincache.class Doctrine\\Common\\Cache\\WinCacheCache doctrine.orm.cache.xcache.class Doctrine\\Common\\Cache\\XcacheCache doctrine.orm.cache.zenddata.class Doctrine\\Common\\Cache\\ZendDataCache doctrine.orm.configuration.class Doctrine\\ORM\\Configuration doctrine.orm.entity_listener_resolver.class Doctrine\\Bundle\\DoctrineBundle\\Mapping\\ContainerEntityListenerResolver doctrine.orm.entity_manager.class Doctrine\\ORM\\EntityManager doctrine.orm.listeners.attach_entity_listeners.class Doctrine\\ORM\\Tools\\AttachEntityListenersListener doctrine.orm.listeners.resolve_target_entity.class Doctrine\\ORM\\Tools\\ResolveTargetEntityListener doctrine.orm.manager_configurator.class Doctrine\\Bundle\\DoctrineBundle\\ManagerConfigurator doctrine.orm.metadata.annotation.class Doctrine\\ORM\\Mapping\\Driver\\AnnotationDriver doctrine.orm.metadata.attribute.class Doctrine\\ORM\\Mapping\\Driver\\AttributeDriver doctrine.orm.metadata.driver_chain.class Doctrine\\Persistence\\Mapping\\Driver\\MappingDriverChain doctrine.orm.metadata.php.class Doctrine\\ORM\\Mapping\\Driver\\PHPDriver doctrine.orm.metadata.staticphp.class Doctrine\\ORM\\Mapping\\Driver\\StaticPHPDriver doctrine.orm.metadata.xml.class Doctrine\\ORM\\Mapping\\Driver\\SimplifiedXmlDriver doctrine.orm.metadata.yml.class Doctrine\\ORM\\Mapping\\Driver\\SimplifiedYamlDriver doctrine.orm.naming_strategy.default.class Doctrine\\ORM\\Mapping\\DefaultNamingStrategy doctrine.orm.naming_strategy.underscore.class Doctrine\\ORM\\Mapping\\UnderscoreNamingStrategy doctrine.orm.proxy_cache_warmer.class Symfony\\Bridge\\Doctrine\\CacheWarmer\\ProxyCacheWarmer doctrine.orm.proxy_dir /home/qinhong/code/DUOXAIO/var/cache/dev/doctrine/orm/Proxies doctrine.orm.proxy_namespace Proxies doctrine.orm.quote_strategy.ansi.class Doctrine\\ORM\\Mapping\\AnsiQuoteStrategy doctrine.orm.quote_strategy.default.class Doctrine\\ORM\\Mapping\\DefaultQuoteStrategy doctrine.orm.second_level_cache.cache_configuration.class Doctrine\\ORM\\Cache\\CacheConfiguration doctrine.orm.second_level_cache.default_cache_factory.class Doctrine\\ORM\\Cache\\DefaultCacheFactory doctrine.orm.second_level_cache.default_region.class Doctrine\\ORM\\Cache\\Region\\DefaultRegion doctrine.orm.second_level_cache.filelock_region.class Doctrine\\ORM\\Cache\\Region\\FileLockRegion doctrine.orm.second_level_cache.logger_chain.class Doctrine\\ORM\\Cache\\Logging\\CacheLoggerChain doctrine.orm.second_level_cache.logger_statistics.class Doctrine\\ORM\\Cache\\Logging\\StatisticsCacheLogger doctrine.orm.second_level_cache.regions_configuration.class Doctrine\\ORM\\Cache\\RegionsConfiguration doctrine.orm.security.user.provider.class Symfony\\Bridge\\Doctrine\\Security\\User\\EntityUserProvider doctrine.orm.validator.unique.class Symfony\\Bridge\\Doctrine\\Validator\\Constraints\\UniqueEntityValidator doctrine.orm.validator_initializer.class Symfony\\Bridge\\Doctrine\\Validator\\DoctrineInitializer env(VAR_DUMPER_SERVER) 127.0.0.1:9912 event_dispatcher.event_aliases {"Symfony\\\\Component\\\\Console\\\\Event\\\\ConsoleCommandEvent":"... ffmpeg_binary %env(FFMPEG_BINARY_PATH)% ffprobe_binary %env(FFPROBE_BINARY_PATH)% form.type_extension.csrf.enabled true form.type_extension.csrf.field_name _token form.type_guesser.doctrine.class Symfony\\Bridge\\Doctrine\\Form\\DoctrineOrmTypeGuesser fragment.path /_fragment fragment.renderer.hinclude.global_template null idp_scheme %env(IDP_SCHEME)% idp_url %env(IDP_URL)% kernel.build_dir /home/qinhong/code/DUOXAIO/var/cache/dev kernel.bundles {"FrameworkBundle":"Symfony\\\\Bundle\\\\FrameworkBundle\\\\Framew... kernel.bundles_metadata {"FrameworkBundle":{"path":"\\/home\\/qinhong\\/code\\/DUOXAIO\\/ven... kernel.cache_dir /home/qinhong/code/DUOXAIO/var/cache/dev kernel.charset UTF-8 kernel.container_class App_KernelDevDebugContainer kernel.debug true kernel.default_locale en kernel.enabled_locales [] kernel.environment dev kernel.error_controller error_controller kernel.http_method_override false kernel.logs_dir /home/qinhong/code/DUOXAIO/var/log kernel.project_dir /home/qinhong/code/DUOXAIO kernel.runtime_environment %env(default:kernel.environment:APP_RUNTIME_ENV)% kernel.secret %env(APP_SECRET)% kernel.trusted_hosts [] knp_paginator.page_limit null knp_paginator.page_range 5 knp_paginator.template.filtration @KnpPaginator/Pagination/bootstrap_v5_filtration.html.twig knp_paginator.template.pagination @KnpPaginator/Pagination/bootstrap_v5_pagination.html.twig knp_paginator.template.sortable @KnpPaginator/Pagination/bootstrap_v5_md_sortable_link.html.twig krtv_single_sign_on_service_provider.authentication.entry_point.sso.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\EntryPoint\\SingleSignOnAuthenticationEntryPoint krtv_single_sign_on_service_provider.authentication.handler.authentication_failure.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Authentication\\Handler\\AuthenticationFailureHandler krtv_single_sign_on_service_provider.authentication.provider.otp.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Authentication\\Provider\\OneTimePasswordAuthenticationProvider krtv_single_sign_on_service_provider.context_factory.attribute _sso_context krtv_single_sign_on_service_provider.context_factory.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Context\\AuthenticationContextFactory krtv_single_sign_on_service_provider.context_listener.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\EventListener\\AuthenticationContextSubscriber krtv_single_sign_on_service_provider.encoder.otp.class Krtv\\SingleSignOn\\Encoder\\OneTimePasswordEncoder krtv_single_sign_on_service_provider.factory.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Factory\\SingleSignOnFactory krtv_single_sign_on_service_provider.host %env(qinhong_LOGIN_HOST)% krtv_single_sign_on_service_provider.host_scheme http krtv_single_sign_on_service_provider.listener.otp.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Firewall\\OneTimePasswordListener krtv_single_sign_on_service_provider.login_path /sso/login/ krtv_single_sign_on_service_provider.options.main {"require_previous_session":false,"provider":"main","check_p... krtv_single_sign_on_service_provider.otp_manager {"name":"http","managers":{"http":{"provider":"guzzle","prov... krtv_single_sign_on_service_provider.otp_parameter _otp krtv_single_sign_on_service_provider.secret_parameter kernel.secret krtv_single_sign_on_service_provider.security.authentication.otp_manager.http.class Krtv\\SingleSignOn\\Manager\\Http\\OneTimePasswordManager krtv_single_sign_on_service_provider.security.authentication.otp_manager.http.provider.guzzle.class Krtv\\SingleSignOn\\Manager\\Http\\Provider\\Guzzle\\OneTimePasswordProvider krtv_single_sign_on_service_provider.twig.extension.url_signer.class Krtv\\Bundle\\SingleSignOnServiceProviderBundle\\Twig\\Extension\\UrlSignerExtension liip_imagine.binary.loader.default default liip_imagine.cache.resolver.default default liip_imagine.controller.filter_action Liip\\ImagineBundle\\Controller\\ImagineController::filterAction liip_imagine.controller.filter_runtime_action Liip\\ImagineBundle\\Controller\\ImagineController::filterRuntimeAction liip_imagine.cwebp.alphaFilter fast liip_imagine.cwebp.alphaMethod 1 liip_imagine.cwebp.alphaQ 100 liip_imagine.cwebp.binary /usr/bin/cwebp liip_imagine.cwebp.exact false liip_imagine.cwebp.m 4 liip_imagine.cwebp.metadata ["none"] liip_imagine.cwebp.q 75 liip_imagine.cwebp.tempDir null liip_imagine.default_image null liip_imagine.driver_service liip_imagine.imagick liip_imagine.filter_sets {"squared_thumbnail_small":{"quality":100,"jpeg_quality":nul... liip_imagine.jpegoptim.binary /usr/bin/jpegoptim liip_imagine.jpegoptim.max null liip_imagine.jpegoptim.progressive true liip_imagine.jpegoptim.stripAll true liip_imagine.jpegoptim.tempDir null liip_imagine.loaders {"default":{"filesystem":{"data_root":["\\/home\\/qinhong\\/code\\/... liip_imagine.mozjpeg.binary /opt/mozjpeg/bin/cjpeg liip_imagine.optipng.binary /usr/bin/optipng liip_imagine.optipng.level 7 liip_imagine.optipng.stripAll true liip_imagine.optipng.tempDir null liip_imagine.pngquant.binary /usr/bin/pngquant liip_imagine.resolvers {"default":{"web_path":{"web_root":"\\/home\\/qinhong\\/code\\/acad... liip_imagine.webp.generate true liip_imagine.webp.options {"quality":100,"cache":null,"data_loader":null,"post_process... monolog.handlers_to_channels {"monolog.handler.console":{"type":"exclusive","elements":["... monolog.swift_mailer.handlers [] monolog.use_microseconds true profiler.storage.dsn file:/home/qinhong/code/DUOXAIO/var/cache/dev/profiler profiler_listener.only_exceptions false profiler_listener.only_main_requests false request_listener.http_port 80 request_listener.https_port 443 router.request_context.base_url router.request_context.host localhost router.request_context.scheme http router.resource kernel::loadRoutes security.access.always_authenticate_before_granting false security.access.denied_url null security.authentication.hide_user_not_found true security.authentication.manager.erase_credentials true security.authentication.session_strategy.strategy migrate security.firewalls ["dev","main"] security.main._indexed_authenticators [] security.role_hierarchy.roles [] serializer.mapping.cache.file /home/qinhong/code/DUOXAIO/var/cache/dev/serialization.php session.metadata.storage_key _sf2_meta session.metadata.update_threshold 0 session.save_path /home/qinhong/code/DUOXAIO/var/cache/dev/sessions session.storage.options {"cache_limiter":"0","name":"DUOXAIOSSESSID","cookie_httponl... sso_service %env(SSO_SERVICE)% translator.default_path /home/qinhong/code/DUOXAIO/translations translator.logging false twig.default_path /home/qinhong/code/DUOXAIO/templates twig.form.resources ["form_div_layout.html.twig","@LiipImagine\\/Form\\/form_div_l... user_login_authority %env(USER_LOGIN_AUTHORITY)% user_login_key %env(USER_LOGIN_KEY)% validator.mapping.cache.file /home/qinhong/code/DUOXAIO/var/cache/dev/validation.php validator.translation_domain validators web_profiler.debug_toolbar.intercept_redirects false web_profiler.debug_toolbar.mode 2 ----------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------- // To search for a specific parameter, re-run this command with a search term. (e.g. debug:container // --parameter=kernel.debug) 其中我认为最常用的是:kernel.build_dir 这个在很多地方都会有，其实就是项目的根目录 ⑤获取/使用环境变量的几种场景(以前总是通过 ParamBagInterface获取，但是这种方法不好，后来用的最多的还是下面的第二种场景)
在从AbstractController延伸出来的控制器中，使用getParameter()辅助工具：
// src/Controller/UserController.php
namespace App\\Controller; use Symfony\\Bundle\\FrameworkBundle\\Controller\\AbstractController;
use Symfony\\Component\\HttpFoundation\\Response; class UserController extends AbstractController
{ // ... public function index(): Response { $projectDir = $this->getParameter('kernel.project_dir'); $adminEmail = $this->getParameter('app.admin_email'); // ... }
} 在服务和不从AbstractController扩展的控制器中，将参数作为构造函数的参数注入。你必须明确地注入它们，因为服务自动布线对参数不起作用：
# config/services.yaml
parameters: app.contents_dir: '...' services: App\\Service\\MessageGenerator: arguments: $contentsDir: '%app.contents_dir%' 如果你反复注入相同的参数，请使用services._defaults.bind选项来代替。该选项中定义的参数会在服务构造函数或控制器动作定义具有该确切名称的参数时自动注入。例如，每当服务/控制器定义$projectDir参数时，要注入kernel.project_dir参数的值，使用这个： # config/services.yaml
services: _defaults: bind: # pass this value to any $projectDir argument for any service # that's created in this file (including controller arguments) $projectDir: '%kernel.project_dir%' # ... 最后，如果某些服务需要访问很多参数(构造函数注入的太多)，你可以通过用ContainerBagInterface对其任何构造参数进行类型提示，一次性注入所有应用参数，而不是单独注入每个参数：
// src/Service/MessageGenerator.php
namespace App\\Service; // ... use Symfony\\Component\\DependencyInjection\\ParameterBag\\ContainerBagInterface; class MessageGenerator
{ public function __construct( private ContainerBagInterface $params, ) { } public function someMethod() { // get any container parameter from $this->params, which stores all of them $sender = $this->params->get('mailer_sender'); // 可以直接获取到 /config/services.yaml 的 parameters 配置参数 // ... }
}`}]},{path:"/content/php/symfony/symfony%E4%BD%BF%E7%94%A8Swift_Mailer%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6.html",title:"symfony使用Swift_Mailer发送邮件",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony使用Swift_Mailer发送邮件:
\\Swift_Mailer $mailer, $message = (new \\Swift_Message('Hello Email')) ->setContentType('text/html') ->setFrom('send@example.com') ->setTo('events@sciforum.net') ->setBody('This is the email body'); $mailer->send($message); 一直没有发成功，是因为我加了 dd() 打印，会导致请求没有完成吧，不知道为什么，去掉之后 就可以发了`}]},{path:"/content/php/symfony/symfony%E4%BD%BF%E7%94%A8make%E7%94%9F%E6%88%90entity%E4%BB%A5%E5%8F%8Arepository.html",title:"symfony使用make生成entity以及repository",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony使用make生成entity以及repository:
在 Symfony 中，如果你使用的是 Doctrine ORM，那么 Repository 类会在你生成实体类的同时自动生成。具体步骤如下: 确保你已经配置好了 Doctrine ORM 相关的 bundle,并映射了实体路径。
使用 Symfony 提供的命令来生成实体类和 Repository 类:
php bin/console make:entity
这个命令会引导你输入实体的详细信息。 在该命令的引导过程中,会询问你是否需要为该实体生成 Repository 类,选择"Yes"。
命令执行完毕后,就会在 src/Repository 目录下生成对应的 Repository 类。
就像你提供的 AffiliationRepository 类代码一样,Symfony会自动为你生成类继承自 Doctrine\\ORM\\EntityRepository 的仓库类。 这个自动生成的仓库类中是空的,因为预期你会在其中自行添加自定义的查询方法。你可以在该类中编写针对该实体的查询逻辑。 如果你后续需要为已有的实体生成仓库类,可以运行:
php bin/console make:entity --entity=Entity\\ExistingEntity --regenerate
其中 --entity 选项指定了要为哪个已存在的实体类生成仓库类, --regenerate 选项表示重新生成仓库类(如果已存在则覆盖)。`}]},{path:"/content/php/symfony/symfony%E5%8F%96%E6%B6%88debug%E6%A8%A1%E5%BC%8F.html",title:"symfony取消debug模式",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony取消debug模式:
本来想通过在config/packages/framework.yaml 下配置debug:false 的，但是后来报错了，说是没有这个配置，所以通过不同的环境配置来控制Debug模式，通常，Symfony使用三种环境：dev（开发环境）、test（测试环境）和prod（生产环境）。在dev环境中，Debug模式通常是开启的，而在prod环境中，它是关闭的。所以吧.env下的环境设置为prod就可以了. 自定义异常页面:
代码里定义了 throw new HttpException(403); 抛出异常，那么会自动加载下面的异常页面.
https://symfony.com/doc/current/controller/error_pages.html#overriding-the-default-error-templates`}]},{path:"/content/php/symfony/symfony%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9.html",title:"symfony官方文档常用知识点",pathLocale:"/",contents:[{header:"",slug:"",content:"symfony官方文档常用知识点: symfony自带的几个内核事件 https://symfony.com/doc/current/reference/events.html#kernel-events symfony自带的service-tag https://symfony.com/doc/6.2/reference/dic_tags.html#security-voter symfony的form option的配置 https://symfony.com/doc/current/reference/forms/types/form.html#allow-extra-fields"}]},{path:"/content/php/symfony/symfony%E7%9A%84form_option%E5%85%B3%E4%BA%8Evalidation_groups%E9%85%8D%E7%BD%AE%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"symfony的form_option关于validation_groups配置的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`symfony的form_option关于validation_groups配置的使用:
场景:
①一个entity和一个entityFormType关联，创建form，这个时候可能用不到validation_groups,默认的validation_groups值为 Default ②一个entity和多个entityFormType关联
比如某个entity的字段比较多，可能需要多个表单才能创建数据，比如，分了第一步操作，第二步操作，然后提交，那么这个entity才算信息完全。
这个时候就需要多个entityFormType，对entity的数据进行验证，entityFormType-A 可能验证了 userName userEmail, entityFormType-B 可能验证了 avatar like favor信息 那么就可以在entity下配置:
@MainAssert\\Event(groups={"Default", "basic_information", "basic_information_phys", "state_change", "event_builder"})
@MainAssert\\EventAwards(groups={"awards"}) 这里 entityFormType-A可能配置了 validation_groups:
$resolver->setDefaults([ 'validation_groups' => ['basic_information'], //只会执行在这个组的validator ]); 这里 entityFormType-B可能配置了 validation_groups:
$resolver->setDefaults([ 'validation_groups' => ['awards'], //只会执行在这个组的validator ]); 最后控制器下:
$form = $this->createForm(Form\\EventAFormType::class, $event); // entityFormType-A $form = $this->createForm(Form\\EventBFormType::class, $event); // entityFormType-B ③关于form验证的位置可以有三个地方可以配置
1>在formType下的constraints里配置
$builder ->add('email', TextType::class, [ 'constraints' => [ new NotBlank([ //NotBlank 为框架内置 'message' => 'Please enter a email', ]), new EmailFormat([ //EmailFormat 为自定义 'message' => 'Please enter a normal email', ]), new EmailUnique([ //EmailUnique 为自定义 'message' => 'Current email already exists!', ]) ], ]) 2>在entity的最外层，全局定义
/** * @ORM\\Entity(repositoryClass="App\\Repository\\EventRepository") * @ORM\\Table(name="conferences", indexes={@ORM\\Index(name="name_system", columns={"name_system"}), * @ORM\\Index(name="workflow_id", columns={"workflow_id"}), * @ORM\\Index(name="state", columns={"state"}) * }) * @ORM\\HasLifecycleCallbacks * * @MainAssert\\Event(groups={"Default", "basic_information", "basic_information_phys", "state_change", "event_builder"}) * @MainAssert\\EventBasicInformation(groups={"basic_information", "public_page_edit_basic_information", "connected_webinar_edit_basic_information", "connected_webinar_basic_information"}) * @MainAssert\\EventKeywords(groups={"basic_information", "public_page_edit_basic_information", "connected_webinar_basic_information"}) * @MainAssert\\EventRegistrationSettingsBasic(groups={"registration_basic"}) * @MainAssert\\EventRegistrationSettingsFull(groups={"registration_full"}) * @MainAssert\\EventRegistrationSettingsDates(groups={"registration_basic", "registration_full", "public_page_edit_basic_information"}) * @MainAssert\\EventSubmissionSettings(groups={"submission_settings"}) * @MainAssert\\EventSubmissionSettingsDates(groups={"submission_settings", "public_page_edit_basic_information"}) * @MainAssert\\EventAwards(groups={"awards"}) * @MainAssert\\EventPrograms(groups={"programs"}) * @Annotation\\FileUploads(subFolder="/") * @Annotation\\MultiFileUploads */ 3>在entity的指定字段上定义 /** * @var string|null * * @ORM\\Column(name="sponsors_description", type="text", nullable=true) * @AcmeAssert\\TinymceField(groups={"sponsor_tinymce"}) // use App\\Validator\\Constraints as AcmeAssert; */ protected $sponsorsDescription; /** * @var string|null * * @ORM\\Column(type="string", nullable=true) * @Assert\\NotBlank(groups={"basic_information", "public_page_edit_basic_information", "connected_webinar_basic_information", "connected_webinar_edit_basic_information"}) // use Symfony\\Component\\Validator\\Constraints as Assert; * @Assert\\EnableAutoMapping */ protected $name_full;`}]},{path:"/content/php/symfony/symfony%E7%9B%B4%E6%8E%A5%E5%9C%A8%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%8B%E4%BD%BF%E7%94%A8validator.html",title:"symfony直接在控制器下使用validator",pathLocale:"/",contents:[{header:"",slug:"",content:"symfony直接在控制器下使用 validator，就像laravel一样: public function eventPaperSubscribeAction(Request $request, Service\\ScilitCommentManagementService $commentService, Entity\\Paper $paper, ValidatorInterface $validator) { $email = $request->request->get('email'); $constraints = [ new \\Symfony\\Component\\Validator\\Constraints\\Email(), new \\Symfony\\Component\\Validator\\Constraints\\NotBlank(), ]; $error = $validator->validate($email, $constraints); if (count($error) > 0) { return new JsonResponse(['success' => false, 'status' => 'ERROR', 'message' => 'Invalid email addresss']); } $validateSubscriber = $commentService->validateSubscriber($paper, $email); if (!$validateSubscriber['success']) { return new JsonResponse($validateSubscriber); } $subscribeUser = $commentService->subscribeUser($paper, $email, $this->getUser()); return new JsonResponse($subscribeUser); }"}]},{path:"/content/php/symfony/%E5%85%B3%E4%BA%8EMapRequestPayload%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"关于MapRequestPayload的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`关于MapRequestPayload的使用:
//对于 JSON API 添加 format: 'json' #[Route(path: '/api/register', name: 'api_register', methods: ['POST'], format: 'json')] 参考: https://symfony.com/doc/current/controller.html#mapping-request-payload php8.2之为readonly properties 设置默认值:
https://www.php.net/releases/8.2/en.php#readonly-properties-default-values`}]},{path:"/content/php/symfony/%E5%85%B3%E4%BA%8ESymfony_Profiler%E5%92%8CWeb_Debug_Toolbar.html",title:"关于Symfony_Profiler和Web_Debug_Toolbar",pathLocale:"/",contents:[{header:"",slug:"",content:`关于Symfony_Profiler和Web_Debug_Toolbar:
Symfony Profiler 和 Web Debug Toolbar 是 Symfony 框架中非常强大的调试工具。让我为你详细介绍它们的使用方法：
1.Web Debug Toolbar
Web Debug Toolbar 是在浏览器底部显示的一个工具栏，提供了关于当前请求的各种信息。
使用方法： 确保你的应用运行在开发环境（APP_ENV=dev）。
访问你的应用的任何页面，你应该能在底部看到这个工具栏。 主要功能： 显示 Symfony 版本
显示当前路由信息
显示请求和响应信息
显示性能数据（如执行时间、内存使用）
数据库查询数量和时间
显示日志信息
提供链接直接进入 Symfony Profiler 2.Symfony Profiler
Symfony Profiler 提供了更详细的调试信息。
使用方法： 点击 Web Debug Toolbar 上的任何链接，或者直接访问 /_profiler 路由。
你也可以在控制器中使用 $this->getDoctrine()->getManager()->getConnection()->getConfiguration()->setSQLLogger(new \\Doctrine\\DBAL\\Logging\\DebugStack()); 来记录数据库查询。 主要功能： 请求/响应信息
性能时间线
数据库查询详情
日志和异常
安全信息
路由详情
缓存使用情况 3.配置和使用技巧 在 config/packages/dev/web_profiler.yaml 中可以配置 Profiler： web_profiler: toolbar: true intercept_redirects: false 你可以在控制器中注入 Profiler 服务： use Symfony\\Component\\HttpKernel\\Profiler\\Profiler; public function someAction(Profiler $profiler)
{ // 使用 profiler
} 在模板中，你可以使用 {{ profiler_dump(var) }} 来输出变量的详细信息。 4.性能考虑
记住，Profiler 和 Debug Toolbar 会对应用性能产生影响，所以只应在开发环境中使用。在生产环境中，确保它们被禁用。
5.远程调试
Symfony Profiler 还支持远程调试。你可以在一台机器上收集数据，然后在另一台机器上查看。这对于调试生产环境的问题特别有用。
6.自定义 Data Collectors
你可以创建自定义的 Data Collectors 来收集和显示特定的信息。这对于监控应用的特定方面非常有用。
symfony7项目可以通过如下命令查看 /_profiler/ 路径
其实是通过 web_profiler.yaml 配置的
这个基于 symfony/web-profiler-bundle 包
php bin/console debug:router
我发现和 安装symfony/debug-bundle 包 没关系，没安装也可以访问`}]},{path:"/content/service/deploy/%E5%9F%BA%E4%BA%8EHaproxy_%E5%AE%B9%E5%99%A8_Nginx%E7%9A%84%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2.html",title:"基于Haproxy容器Nginx的项目部署",pathLocale:"/",contents:[{header:"基于Haproxy+容器+Nginx的项目部署:",slug:"基于haproxy-容器-nginx的项目部署",content:`最近在看项目部署相关的东西，这些都是实际工作中用到的.
首先做了如下部署：
ha 里面做了 http-->https的转发到 duo_staging_backend duo_staging_backend 即为后台服务: 10.10.0.121:4431-----docker容器映射------> nginx 443 服务，staging.duo.com staging.duo.com 绑定的公网IP就是这个 175.63.194.210`},{header:"再看下面这段代码就知道了这么部署的原理:",slug:"再看下面这段代码就知道了这么部署的原理",content:'frontend http_frontend bind *:80 mode http option httplog redirect scheme https code 301 if !{ ssl_fc } frontend https_frontend bind *:443 ssl crt /etc/haproxy/certs/your_domain.pem mode http option httplog default_backend https_backend //这里其实还可以使用 ACL（Access Control List）检查请求的 "Host" 头部是否为 www.hello.test。如果是，将使用 https_backend 后端。 acl is_hello_test hdr(host) -i www.hello.test use_backend https_backend if is_hello_test backend https_backend mode http option httplog server backend_server 192.168.1.2:8443 ssl verify none'},{header:"上面配置分析",slug:"上面配置分析",content:`在上述配置中：
1.http_frontend 是一个前端，监听80端口，通过 HTTP 转发到 HTTPS。
2.redirect scheme https code 301 if !{ ssl_fc } 将所有 HTTP 请求重定向到 HTTPS。
3.https_frontend 是另一个前端，监听443端口，用于终止 SSL/TLS，使用 /etc/haproxy/certs/your_domain.pem 证书文件进行 SSL 处理。
4.default_backend https_backend 将 HTTPS 请求转发到后端的 HTTPS 服务器。
5.这里 192.168.1.2:8443 是一个后端服务器，IP 地址是 192.168.1.2，端口是 8443。ssl 关键字表示使用 SSL/TLS 连接。verify none 表示不进行证书验证，这在测试环境中可能可以接受。
然后，你需要确保在你的容器环境中，将容器的443端口正确映射到主机的 192.168.1.2:8443 地址上。 6.当然了，192.168.1.2:8443 也可以映射到容器的80端口，aca 项目的第一次配置就是这么配置的，相当于haproxy做了一次 80--->443--->80的转换，但是这样导致，项目代母里面获取到的总是http协议，而不是https协议，就会报下面的错误:
7037.a1ad5b79.js:1 Mixed Content: The page at 'https://staging.duo.com/admin/course/manage/list/1' was loaded over HTTPS, but requested an insecure XMLHttpRequest endpoint 'http://staging.duo.com/admin/course/quiz?course_id=1'. This request has been blocked; the content must be served over HTTPS. 所以后来和运维讨论了这个问题，他就把 192.168.1.2:8443 映射到了容器的443端口(当然又重新配置了https证书) 7.上面这种配置是一种常见的做法，可以将外部请求通过 HAProxy 转发到内部容器的安全端口，从而实现隔离和安全性。 8.上面有个 acl 配置，这里的 www.hello.test，DNS 解析为宿主机的公网IP，但是使用的时候 www.hello.test 配置在 容器的 nginx server_name 里面的，这样配置有个使用前提：需要在主机上运行一个 HTTP 服务器来处理 www.hello.test 域名的请求，这里就是使用了 haproxy 来处理的。所以整个过程配合的十分巧妙。 细节可以参考： chatGPT下的 nginx服务 对话，感觉 chatGPT 还是很强大的，直接帮我验证了这一理论。`},{header:"这个配置还是很实用的，实际上的backend可以有多个，通过Haproxy做负载均衡，如下所示:",slug:"这个配置还是很实用的-实际上的backend可以有多个-通过haproxy做负载均衡-如下所示",content:"backend nginx_backend mode http option httplog balance roundrobin # 使用循环算法进行负载均衡 server container_server1 172.17.0.2:80 check server container_server2 172.17.0.3:80 check server container_server3 172.17.0.4:80 check //当然 container_server1 container_server2 container_server3 对应的容器服务里的 nginx server_name配置也要是相同的的 上面没有使用 KeepAlived，原因是，已经够用了，当然如果使用 KeepAlived，那就会更复杂有些"},{header:"HAProxy ACL 常用 fetch 方法 + 匹配运算符表",slug:"haproxy-acl-常用-fetch-方法-匹配运算符表",content:`fetch 方法
作用 hdr(<name>)
取请求头 <name>，比如 hdr(User-Agent) path
取 URL 的 path 部分（不含 query string） url_param(<name>)
取 URL 参数 <name> 的值 method
取 HTTP 方法，如 GET、POST src
取客户端 IP 地址 dst
取目标服务器 IP 地址 ssl_fc
判断是否是 SSL 前端连接 (true/false) nbsrv(<backend>)
获取某个 backend 当前可用的 server 数量 req_len
请求报文大小 resp_len
响应报文大小`},{header:"🟡 常用匹配运算符",slug:"🟡-常用匹配运算符",content:`运算符 / 简写
含义 -m sub → _sub
子串匹配（包含） -m beg → _beg
前缀匹配（以…开头） -m end → _end
后缀匹配（以…结尾） -m reg → _reg
正则匹配 -i
忽略大小写（可和上面组合） eq / lt / gt
数值比较（等于 / 小于 / 大于） len
长度比较`},{header:"🔵 组合示例",slug:"🔵-组合示例",content:`匹配移动端 UA
acl is_mobile hdr_sub(User-Agent) -i mobile → hdr(User-Agent) + sub，检查 UA 里是否包含 mobile（忽略大小写）。 匹配 /api/ 开头的路径
acl is_api path_beg /api/ → path + beg，检查 URL path 是否以 /api/ 开头。 判断来源 IP 是否内网
acl is_admin src 192.168.1.0/24 判断后端存活数是否 < 2
acl high_load nbsrv(web_backend) lt 2`}]},{path:"/content/service/deploy/%E5%9F%BA%E4%BA%8Edocker%E7%9A%84Haproxy%E7%9A%84%E7%83%AD%E5%8F%91%E5%B8%83%E9%85%8D%E7%BD%AE.html",title:"基于docker的Haproxy的热发布配置",pathLocale:"/",contents:[{header:"基于docker的Haproxy的热发布配置",slug:"基于docker的haproxy的热发布配置",content:`为什么想写这个，因为最近继续研究haproxy，突然想到如果能实现热发布，配合haproxy的超强代理配置，那么可以实现的功能就更加丰富了 项目目录结构haproxy-demo/
├── docker-compose.yml
├── Dockerfile.haproxy ├── haproxy.cfg
├── setup.sh
├── reload.sh
├── web1/
│ └── index.html
└── web2/
└── index.html 操作流程 创建文件mkdir haproxy-demo && cd haproxy-demo 初始化页面内容, vim setup.sh, 内容如下mkdir -p web1 web2
echo "<h1>Web Server 1</h1>" > web1/index.html echo "<h1>Web Server 2</h1>" > web2/index.html chmod +x ./setup.sh 添加haproxy配置, vim haproxy.cfgglobal log stdout local0 maxconn 4096 defaults mode http log global option httplog timeout connect 5000ms timeout client 50000ms timeout server 50000ms frontend stats bind *:8404 stats enable stats uri /stats stats refresh 30s frontend web_frontend bind *:80 http-response add-header X-Load-Balancer "HAProxy" # 自定义信息 http-response add-header X-Server-Version "v1.0" 自定义信息 default_backend web_servers backend web_servers balance roundrobin option httpchk GET / http-response set-header X-Backend-Server v8 自定义信息 server web1 web1:80 check server web2 web2:80 check 添加docker compose 内容， vim docker-compose.ymlservices: haproxy: build: context: . dockerfile: Dockerfile.haproxy container_name: haproxy ports: - "8081:80" - "8404:8404" volumes: - haproxy_config:/usr/local/etc/haproxy restart: unless-stopped command: ["haproxy", "-f", "/usr/local/etc/haproxy/haproxy.cfg", "-W"] web1: image: nginx:alpine container_name: web1 volumes: - ./web1:/usr/share/nginx/html web2: image: nginx:alpine container_name: web2 volumes: - ./web2:/usr/share/nginx/html volumes: haproxy_config: 添加 Dockerfile 内容, vim Dockerfile.haproxyFROM haproxy:latest # 复制配置文件到镜像中
COPY haproxy.cfg /usr/local/etc/haproxy/haproxy.cfg # 下面两个暂时不要
# 确保配置文件权限正确
#RUN chmod 644 /usr/local/etc/haproxy/haproxy.cfg # 验证配置文件语法
#RUN haproxy -f /usr/local/etc/haproxy/haproxy.cfg -c 启动docker服务 1.先执行 ./setup.sh 2.$ docker-compose up -d --build 查看服务$ docker ps
2eb152e70d82 nginx:alpine "/docker-entrypoint.…" 23 minutes ago Up 22 minutes 80/tcp web1
46eb39650f05 nginx:alpine "/docker-entrypoint.…" 23 minutes ago Up 22 minutes 80/tcp web2
d1d99bae1a4b haproxy-demo-haproxy "docker-entrypoint.s…" 23 minutes ago Up 22 minutes 0.0.0.0:8404->8404/tcp, :::8404->8404/tcp, 0.0.0.0:8081->80/tcp, :::8081->80/tcp haproxy 页面法访问http://localhost:8081/ 可以看到 Response Headers 有如下自定义字段 X-Backend-Server:v8
X-Load-Balancer:HAProxy
X-Server-Version:v1.0 修改haproxy.cfg的配置信息， 比如 v8 改为v9
重点来了，通过haproxy的热启动，让配置生效，脚本 reload.sh 如下 #!/bin/bash # HAProxy配置热重启脚本
# 用法: chmod +x, ./reload.sh echo "🔄 HAProxy配置热重启开始..." # 1. 复制配置文件到容器
echo "📝 复制配置文件到容器..."
if docker cp haproxy.cfg haproxy:/usr/local/etc/haproxy/haproxy.cfg; then echo "✅ 配置文件复制成功"
else echo "❌ 配置文件复制失败" exit 1
fi # 2. 发送热重启信号
echo "🔥 发送热重启信号..."
if docker-compose kill -s HUP haproxy; then echo "✅ 热重启信号发送成功"
else echo "❌ 热重启信号发送失败" exit 1
fi # 3. 等待一下让重启完成
echo "⏳ 等待重启完成..."
sleep 2 # 4. 验证配置是否生效
echo "🔍 验证配置..."
echo "响应头信息:"
curl -s -I http://localhost:8081 | grep -E "(HTTP|X-|Server)" echo ""
echo "🎉 HAProxy配置热重启完成！"
echo "💡 访问 http://localhost:8081 测试服务"
echo "📊 访问 http://localhost:8404/stats 查看状态" 再次页面法访问http://localhost:8081/ 可以看到 Response Headers 有如下自定义字段 X-Backend-Server:v9 #内容发生变化
X-Load-Balancer:HAProxy
X-Server-Version:v1.0 为什么要使用这种方式，因为和docker的两种挂载方式有关，我会单独开一篇讲解二者的不同`}]},{path:"/content/service/deploy/%E7%AB%99%E7%82%B9%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90.html",title:"站点系统架构分析",pathLocale:"/",contents:[{header:"",slug:"",content:`站点系统架构分析:
流量路径：用户 → Cloudflare服务器 → 源服务器`}]},{path:"/content/service/deploy/%E9%A1%B9%E7%9B%AE%E5%8F%91%E5%B8%83%E7%B3%BB%E7%BB%9F.html",title:"项目发布系统",pathLocale:"/",contents:[{header:"项目发布系统(将当前项目发送到不同的服务器)",slug:"项目发布系统-将当前项目发送到不同的服务器",content:""},{header:"1.环境准备",slug:"_1-环境准备",content:`ubuntu22(宿主机)
docker(web1 web2)
rsync`},{header:"2.创建网络(模拟内网)",slug:"_2-创建网络-模拟内网",content:"docker network create --subnet=10.10.0.0/24 deploy-net"},{header:"3.创建两个模拟“远程服务器”",slug:"_3-创建两个模拟-远程服务器",content:`# 容器 A
docker run -dit --name web-node-1 --hostname web1 \\ --net deploy-net --ip 10.10.0.11 \\ -v /opt/web-node-1:/opt/srv/laravel12 \\ ubuntu:22.04 bash # 容器 B
docker run -dit --name web-node-2 --hostname web2 \\ --net deploy-net --ip 10.10.0.12 \\ -v /opt/web-node-2:/opt/srv/laravel12 \\ ubuntu:22.04 bash 鉴于这是一bash 命令，docker重启后，不能自动启动，所以下次 docker start -ai web-node-1/2 启动容器`},{header:"4.配置 SSH 服务（在容器中）",slug:"_4-配置-ssh-服务-在容器中",content:`docker exec -it web-node-1 bash
# 安装 SSH
apt update && apt install openssh-server -y
mkdir -p /var/run/sshd
passwd -d root # 免密,删除root用户的密码（开发环境测试用）
echo "PermitRootLogin yes" >> /etc/ssh/sshd_config # 允许root登陆
echo "PasswordAuthentication no" >> /etc/ssh/sshd_config # 不允许密码登陆，只能ssh密钥登陆
mkdir -p /root/.ssh
exit 重复上述步骤给 web-node-2 配置`},{header:"5.然后启动 SSH 服务：",slug:"_5-然后启动-ssh-服务",content:`docker exec -d web-node-1 service ssh start
docker exec -d web-node-2 service ssh start`},{header:"6.配置 SSH 免密登录",slug:"_6-配置-ssh-免密登录",content:`在主机上生成 SSH 密钥（如果没有）：
ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa -N "" 将公钥拷贝进两个容器：
docker exec -i web-node-1 bash -c 'cat >> /root/.ssh/authorized_keys' < ~/.ssh/id_rsa.pub
docker exec -i web-node-2 bash -c 'cat >> /root/.ssh/authorized_keys' < ~/.ssh/id_rsa.pub 测试连接:
ssh root@10.10.0.11
ssh root@10.10.0.12 可能需要手动输入一个yes， 因为:
SSH 客户端检测到你是第一次连接这个 IP 的主机，它会：
检查你本地的 ~/.ssh/known_hosts 文件
发现这个 IP 没有记录
出于安全，要求你手动确认是否信任这个主机`},{header:"7.准备部署平台目录结构（在宿主机）",slug:"_7-准备部署平台目录结构-在宿主机",content:`mkdir -p ~/projects/deploy-platform/.pac/hooks cd ~/projects/deploy-platform echo '#!/bin/bash' > .pac/hooks/deploy.sh
chmod +x .pac/hooks/deploy.sh cat > .pac/config.sh <<EOF
SSH=/usr/bin/ssh
SSH_USER=root
SSH_PORT=22
SSH_HOSTS=(10.10.0.11 10.10.0.12)
RSYNC=/usr/bin/rsync
LOCAL_DIR=/home/guoshipeng/Documents/code/deploy-platform
HOOKS_DIR=$LOCAL_DIR/.pac/hooks
REMOTE_DIR=/opt/srv/laravel12
DEP_MODE=mix
LIMIT_RELEASES=3
RSYNC_EXCLUDE_FILE=$HOOKS_DIR/rsync_exclude
EOF`},{header:"8.模拟一次部署",slug:"_8-模拟一次部署",content:`本来应该在.pac/hooks/deploy.sh 里添加一个标准的发布命令的，但是有些复杂，这里主要想验证代码是否发布成功
所以直接在项目的根目录下创建一个deploy.sh 脚本，用来发布当前项目,内容如下 #!/bin/bash source .pac/config.sh for HOST in "\${SSH_HOSTS[@]}"; do echo "🚀 Deploying to $HOST..." TIMESTAMP=$(date +%Y%m%d%H%M%S) TARGET_DIR="$REMOTE_DIR/releases/$TIMESTAMP" echo "📁 初始化远程目录结构" ssh -p "$SSH_PORT" "$SSH_USER@$HOST" "mkdir -p $REMOTE_DIR/releases && mkdir -p $REMOTE_DIR/shared" echo "📦 使用 rsync 同步项目到远程: $TARGET_DIR" rsync -az --exclude-from="$RSYNC_EXCLUDE_FILE" . "$SSH_USER@$HOST:$TARGET_DIR" echo "🔗 创建或更新 current 软链接" ssh -p "$SSH_PORT" "$SSH_USER@$HOST" "ln -sfn $TARGET_DIR $REMOTE_DIR/current" echo "✅ [$HOST] 部署成功: $TARGET_DIR -> current" echo
done 然后直接在项目更目录执行:
$ bash ./deploy.sh
🚀 Deploying to 10.10.0.11...
📁 初始化远程目录结构
ssh: connect to host 10.10.0.11 port 22: No route to host
📦 使用 rsync 同步项目到远程: /opt/srv/laravel12/releases/20250417001247
ssh: connect to host 10.10.0.11 port 22: No route to host
rsync: connection unexpectedly closed (0 bytes received so far) [sender]
rsync error: unexplained error (code 255) at io.c(232) [sender=3.2.7]
🔗 创建或更新 current 软链接
ssh: connect to host 10.10.0.11 port 22: No route to host
✅ [10.10.0.11] 部署成功: /opt/srv/laravel12/releases/20250417001247 -> current 🚀 Deploying to 10.10.0.12...
📁 初始化远程目录结构
ssh: connect to host 10.10.0.12 port 22: Connection refused
📦 使用 rsync 同步项目到远程: /opt/srv/laravel12/releases/20250417001257
ssh: connect to host 10.10.0.12 port 22: Connection refused
rsync: connection unexpectedly closed (0 bytes received so far) [sender]
rsync error: unexplained error (code 255) at io.c(232) [sender=3.2.7]
🔗 创建或更新 current 软链接
ssh: connect to host 10.10.0.12 port 22: Connection refused
✅ [10.10.0.12] 部署成功: /opt/srv/laravel12/releases/20250417001257 -> current 上面命令可能会报:
rsync: command not found
这是因为远程服务器没有安装 rsync， 执行：
sudo apt update
sudo apt install rsync rsync --versio 为什么，远程服务器也需要安装 rsync?
rsync 的工作原理是：
部署平台通过 SSH 登录远程服务器，然后在远程服务器上启动 rsync 服务端进程，与本地的 rsync 客户端进行交互，同步文件。再详细的说就是:
本地部署平台（Client）： 你运行 rsync 命令。 它连接远程主机的 SSH（默认22端口）。 它在远程服务器上运行一个 rsync --server 命令（这一步是自动的！你看不到，但确实发生了）。 远程服务器（Server）： 并不需要运行 rsync 守护进程（daemon）。 只需要安装 rsync 命令行工具（client/server 二合一）。 它接收到 SSH 发起的 rsync 命令之后，会临时启动 rsync 进程，进入服务端模式，等待数据同步。 然后双方交换文件列表并同步差异。 很多人以为 rsync 需要像 FTP 那样一直跑一个服务监听873端口，其实 “rsync over SSH” 根本不需要：
只要远程机器装了 rsync 命令就够。
同步是通过 SSH 通道临时执行 rsync 的，不是守护进程。 最后在容器里，/opt/srv/laravel12/releases 分别可以看到代码，其中current 是一个软连接，用来指向当前最新发布，后续可以将这个current指向nginx的root 目录，运行项目`}]},{path:"/content/service/docker/PHP_Dockerfile_%E6%96%87%E4%BB%B6%E4%B8%8B%E5%AE%89%E8%A3%85composer.html",title:"PHP Dockerfile 文件下安装composer",pathLocale:"/",contents:[{header:"",slug:"",content:'PHP Dockerfile 文件下安装composer:\n# Install Composer\nRUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer\n详细解释一下 `php --` 这部分的含义： 在命令 `curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer` 中，`php --` 的作用如下：\n1. `php` 部分： 这是调用 PHP 命令行解释器来执行通过管道传递的 PHP 脚本（Composer 安装器）。\n2. `--` 部分： 这两个连字符 `--` 在命令行参数中有特殊含义。它用于分隔命令行选项和脚本参数。 - 在 `--` 之前的选项是给 PHP 解释器的。 - 在 `--` 之后的参数是传递给 PHP 脚本（在这里是 Composer 安装器）的。\n3. 为什么需要 `--`： - 它确保 `--install-dir` 和 `--filename` 这些参数被正确地传递给 Composer 安装脚本，而不是被 PHP 解释器误解为自己的参数。 - 这种做法在处理可能与 PHP 本身的选项冲突的脚本参数时特别有用。\n4. 实际效果： - PHP 执行从 curl 下载的安装脚本。 - 安装脚本接收到 `--install-dir=/usr/local/bin` 和 `--filename=composer` 这两个参数。 - 基于这些参数，安装脚本知道将 Composer 安装到 `/usr/local/bin` 目录，并命名为 `composer`。 如果没有 `--`，PHP 可能会将后面的参数误认为是给自己的，而不是传递给要执行的脚本的。\n简化的理解方式：\n可以把 `php --` 看作是一个分界点：它告诉系统"之前的部分是对 PHP 的指令，之后的部分是给 PHP 执行的脚本的参数"。\n这种用法在shell脚本和命令行操作中很常见，尤其是在处理复杂的命令行参数时。它提供了一种清晰的方式来分隔不同部分的参数，确保它们被正确地解释和使用。'}]},{path:"/content/service/docker/docker-build%E5%92%8Cdocker-buildx%E7%AD%96%E7%95%A5.html",title:"docker build 和 docker buildx 策略",pathLocale:"/",contents:[{header:"",slug:"",content:`docker build 和 docker buildx 策略:
https://docs.docker.com/reference/cli/docker/build-legacy/
https://docs.docker.com/reference/cli/docker/buildx/build/ 在go项目使用: https://waynerv.com/posts/building-multi-architecture-images-with-docker-buildx/ //优秀博客`}]},{path:"/content/service/docker/docker-p%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"docker -p 参数的使用",pathLocale:"/",contents:[{header:"",slug:"",content:'docker -p 参数的使用: 问题： 两个laravel11项目，分别通过docker管理，都有如下配置 docker compose build nginx\ndocker compose build php\ndocker compose build solr 但是当一个运行起来之后，就会停止另一个项目的container,并且image也只有一份，我也设置了不同的APP_NAME，按道理说会有两套运行的container以及对应的image才是，但是结果不是这样 如下是和docker-compose.yml同级的start.sh脚本 #!/bin/bash\nset -u cd "$(dirname "$0")" # the local user\'s UID & GID are required to build the php Docker container\nexport USER_ID=$(id -u)\nexport GROUP_ID=$(id -g) # Delete all untagged images\nif [[ $(docker images -q --filter "dangling=true") ]]; then echo "Removing untagged Docker images..." docker rmi $(docker images -q --filter "dangling=true")\nfi # create docker networks if not existing yet, 这个地方相当于在docker compose 外部创建了网络，作为全局服务之间的通信\necho "Creating Docker networks..." # build images (will actually only build if images not yet built or if something changed)\necho "Building Docker images..."\ndocker compose build nginx\ndocker compose build php\ndocker compose build solr # compose up the stack in detached mode and start to follow the logs output\necho "Starting Docker Compose stack in detached mode..."\n#clear\ndocker compose up -d /bin/bash ./start-monitor.sh 改进一下: #!/bin/bash\nset -eu cd "$(dirname "$0")" # 加载 .env 文件\nif [ -f .env ]; then export $(grep -v \'^#\' .env | xargs)\nelse echo ".env file not found" exit 1\nfi # 确保 APP_NAME 被设置\nif [ -z "${APP_NAME:-}" ]; then echo "APP_NAME is not set in .env file" exit 1\nfi export USER_ID=$(id -u)\nexport GROUP_ID=$(id -g) # 清理属于这个项目的悬空镜像\nif [[ $(docker images -q --filter "dangling=true" --filter "label=project=${APP_NAME}") ]]; then echo "Removing untagged Docker images for ${APP_NAME}..." docker rmi $(docker images -q --filter "dangling=true" --filter "label=project=${APP_NAME}")\nfi # 停止并移除现有容器\ndocker compose -p ${APP_NAME} down --remove-orphans # 构建镜像\necho "Building Docker images for ${APP_NAME}..."\ndocker compose -p ${APP_NAME} build nginx || { echo "Failed to build nginx"; exit 1; }\ndocker compose -p ${APP_NAME} build php || { echo "Failed to build php"; exit 1; }\ndocker compose -p ${APP_NAME} build solr || { echo "Failed to build solr"; exit 1; } # 启动栈\necho "Starting Docker Compose stack for ${APP_NAME} in detached mode..."\ndocker compose -p ${APP_NAME} up -d # 启动监控\n/bin/bash ./start-monitor.sh ${APP_NAME} 上面主要的改动为 添加了读取 .env环境变量的代码，以及通过 -p 使用这个环境变量。再次运行，这个时候两个项目的image会单独生成，对应的container也互相不影响 还有一个stop.sh脚本 #!/bin/bash\nset -u -e cd "$(dirname "$0")" export USER_ID=$(id -u)\nexport GROUP_ID=$(id -g) docker compose down 也需要添加 环境变量以及 -p 参数:\n#!/bin/bash\nset -eu cd "$(dirname "$0")" # 加载 .env 文件\nif [ -f .env ]; then export $(grep -v \'^#\' .env | xargs)\nelse echo ".env file not found" exit 1\nfi # 确保 APP_NAME 被设置\nif [ -z "${APP_NAME:-}" ]; then echo "APP_NAME is not set in .env file" exit 1\nfi export USER_ID=$(id -u)\nexport GROUP_ID=$(id -g) echo "Stopping Docker Compose stack for ${APP_NAME}..."\ndocker compose -p ${APP_NAME} down //\n这个修改后的 stop.sh 脚本做了以下改进： 加载 .env 文件，确保我们有 APP_NAME 和其他必要的环境变量。\n检查 APP_NAME 是否被正确设置。\n使用 docker compose -p ${APP_NAME} down 命令，这确保我们只停止和删除属于特定项目的容器和网络。 使用 -p ${APP_NAME} 参数的好处是： 它只会影响属于该特定项目的容器和网络。\n如果您在同一台机器上运行多个项目，这可以防止意外停止其他项目的容器。\n它与 start.sh 中的 up 命令保持一致，确保您启动和停止的是同一组容器。 这个方法更安全，因为它只会影响特定项目的 Docker 资源，而不是停止所有以某个前缀开头的容器 疑问: 为什么我明明在通过APP_NAME对两个项目的container做了区分，为什么还会有问题，加了 -p 参数就没问题了 详细解释一下 `-p` 参数的作用，以及为什么即使 `APP_NAME` 只作为容器名称的前缀也能生效： 1. Docker Compose 项目名称： `-p` 参数设置 Docker Compose 项目名称。这个名称用于给 Docker Compose 创建的所有资源（容器、网络、卷等）添加一个命名空间。 2. 资源前缀： 当您使用 `-p` 参数时，Docker Compose 会自动将项目名称作为前缀添加到它创建的所有资源名称中，除非您在 docker-compose.yml 文件中明确指定了完整的名称。 3. 容器命名： - 如果您在 docker-compose.yml 中没有指定 `container_name`，Docker Compose 会使用 "项目名称_服务名称_数字" 的格式来命名容器。 - 如果您指定了 `container_name`，Docker Compose 会使用您指定的名称，但仍然会将这个容器与项目关联。 4. 项目隔离： 使用 `-p` 参数可以创建逻辑上独立的项目，即使它们使用相同的 docker-compose.yml 文件。 5. 为什么它仍然有效： 即使您的 `APP_NAME` 只是作为容器名称的前缀，`-p` 参数仍然有效，因为： - Docker Compose 内部会记录哪些容器属于哪个项目。 - 当您运行 `docker compose -p ${APP_NAME} down` 时，它会查找所有与该项目名称关联的资源，而不仅仅是依赖容器名称。 6. 实际工作原理： - Docker Compose 使用标签（labels）来跟踪项目中的资源。 - 每个由 Docker Compose 创建的资源都会带有 `com.docker.compose.project` 标签，其值为项目名称。 - 当您使用 `-p` 参数时，Docker Compose 会查找带有对应项目标签的所有资源。 7. 额外好处： 使用 `-p` 参数可以让您在同一台机器上运行多个相同配置的项目实例，而不会发生命名冲突。 举例说明：\n假设您有两个项目，`APP_NAME` 分别为 "project1" 和 "project2"： docker compose -p project1 up -d\ndocker compose -p project2 up -d 即使容器名称可能类似（如 "project1-nginx" 和 "project2-nginx"），Docker Compose 仍然能够正确地管理这两个独立的项目。 总结：\n虽然 `APP_NAME` 主要用作容器名称的前缀，但使用 `-p ${APP_NAME}` 参数可以确保 Docker Compose 正确地管理和隔离不同项目的资源，即使它们使用相似的配置。这提供了更好的项目隔离和管理能力。 总结: 使用 `-p` 参数确实起到了命名空间的作用： 1. 命名空间的作用： - `-p` 参数为 Docker Compose 项目创建了一个逻辑上的命名空间。 - 这个命名空间确保了不同项目之间的资源隔离，即使它们使用相似或相同的服务名称。 2. 问题的根源： - 之前没有使用 `-p` 参数时，多个项目可能在 Docker 的默认命名空间中发生冲突。 - 这可能导致一个项目的操作意外影响到另一个项目的容器或资源。 3. 解决方案的效果： - 使用 `-p ${APP_NAME}` 后，每个项目都在自己的命名空间中运行。 - 这确保了启动、停止、或其他操作只影响指定项目的容器和资源。 4. 增强的项目管理： - 现在可以在同一台机器上并行运行多个项目，而不会相互干扰。 - 每个项目的资源（容器、网络、卷等）都被清晰地分组和标识。 5. 一致性和可维护性： - 结合使用 `container_name: "${APP_NAME}-servicename"` 和 `-p ${APP_NAME}` 提供了双重保障。 - 容器名称直观可读，而项目级别的隔离则由 Docker Compose 在底层管理。 6. 最佳实践： - 始终在 Docker Compose 命令中使用 `-p` 参数（例如：`docker compose -p ${APP_NAME} up -d`）。 - 在 CI/CD 流程或脚本中也要确保包含这个参数。 7. 额外好处： - 更容易进行项目级别的操作，如一次性停止或删除所有相关资源。 - 简化了多环境部署（如开发、测试、预生产环境）的管理。 这个发现强调了在使用 Docker Compose 管理多项目环境时，正确使用项目名称（通过 `-p` 参数）的重要性。它不仅解决了您之前遇到的问题，还为未来的项目管理和扩展提供了更健壮的基础。'}]},{path:"/content/service/docker/docker_compose%E5%8A%A0%E8%BD%BD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8Fenv%E6%96%87%E4%BB%B6.html",title:"docker_compose加载配置文件",pathLocale:"/",contents:[{header:"",slug:"",content:"docker_compose加载环境变量env文件:\n和docker-compose.yml文件同级的 .env文件会被自动加载:\n关于 `.env` 文件的自动加载，有几点需要说明： 1. Docker Compose 默认行为:\nDocker Compose 默认会查找并使用当前目录下的 `.env` 文件。这意味着在大多数情况下，你不需要明确指定 `--env-file .env`。 2. 自动加载:\n- 当你运行 `docker-compose up` 或其他 Docker Compose 命令时，它会自动寻找并加载同目录下的 `.env` 文件。\n- 这个过程是自动的，你不需要额外的配置来使其工作。 3. 优先级:\n- 环境变量的加载有一定的优先级：命令行中设置的变量 > 环境中已存在的变量 > `.env` 文件中的变量。\n- 这意味着 `.env` 文件中的变量可以被其他方式设置的同名变量覆盖。 4. 确保加载:\n虽然通常不需要，但如果你想确保使用特定的 `.env` 文件，可以使用 `--env-file` 选项： docker-compose --env-file .env up -d 5. 在 Compose 文件中引用:\n你可以在 `docker-compose.yml` 文件中直接引用 `.env` 文件中定义的变量，使用 `${VARIABLE_NAME}` 语法。 6. 注意事项:\n- 确保 `.env` 文件和 `docker-compose.yml` 文件在同一目录下。\n- `.env` 文件应该被包含在你的 `.gitignore` 文件中，以避免敏感信息被提交到版本控制系统。 总结来说，是的，`.env` 文件通常会被 Docker Compose 自动加载和使用，无需特殊配置。只要确保文件位置正确，并且变量名在 `docker-compose.yml` 中正确引用即可。 如果你在实践中发现环境变量没有正确加载，可以尝试以下调试步骤：\n1. 使用 `docker-compose config` 命令查看解析后的配置，确认变量是否被正确替换。\n2. 在 `docker-compose.yml` 中的某个服务下添加 `env_file: .env` 来明确指定使用 `.env` 文件。"}]},{path:"/content/service/docker/docker_compose%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AE%9A%E4%B9%89networks%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"docker_compose文件中定义networks的两种方式的区别",pathLocale:"/",contents:[{header:"",slug:"",content:"Docker Compose 文件中定义的网络和通过命令行创建的网络的一些区别：\n1. 作用域和生命周期: - Docker Compose 文件中定义的网络: - 作用域限于该 Compose 项目。 - 随 `docker compose up` 创建，随 `docker compose down` 删除（除非定义为外部网络）。 - 网络名称会自动加上项目名称作为前缀。 - 命令行创建的网络: - 全局作用域，可被任何容器或 Compose 项目使用。 - 持久存在，除非手动删除。 - 网络名称就是创建时指定的名称，没有额外前缀。\n2. 管理方式: - Docker Compose 文件中的网络由 Docker Compose 管理，与项目其他部分（如服务、卷）集成。 - 命令行创建的网络需要手动管理，包括创建和删除。\n3. 可重用性: - 命令行创建的网络更容易在多个项目间共享。 - Compose 文件中的网络默认只用于当前项目，但可以通过 `external: true` 选项引用外部网络。\n4. 配置灵活性: - Compose 文件允许更详细的网络配置，如设置驱动选项、IPAM 配置等。 - 命令行创建的网络通常使用默认配置，除非在创建时指定特定选项。\n5. 版本控制: - Compose 文件中的网络定义可以版本控制，方便团队协作和环境一致性。 - 命令行创建的网络配置不容易版本控制，除非将创建命令写入脚本。\n在您的情况下，如果想要在 Compose 文件中使用脚本创建的网络，您可以在 Compose 文件中将这些网络声明为外部网络：\n```yaml\nnetworks: laravel-dev-v2-internal: external: true 这样，Compose 将使用已存在的网络，而不是创建新的。\n总的来说，除非有特殊需求（如跨项目共享网络），通常建议在 Docker Compose 文件中定义和管理网络，以保持项目的自包含性和一致性。如果确实需要预先创建的网络，最好在 Compose 文件中明确引用它们。"}]},{path:"/content/service/docker/docker_compose%E6%96%87%E4%BB%B6%E8%AE%BE%E7%BD%AE%E6%9C%8D%E5%8A%A1%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5.html",title:"docker_compose文件设置服务重启策略",pathLocale:"/",contents:[{header:"",slug:"",content:`docker_compose文件设置服务重启策略:
设置 restart: always 确实会使容器在系统重启后自动启动。这个设置的具体作用如下： 系统重启后：当系统重新启动并且Docker服务开始运行时，所有设置了 restart: always 的容器都会自动启动。
容器崩溃时：如果容器因为任何原因崩溃或停止，Docker 会自动尝试重新启动它。
Docker 服务重启时：如果 Docker 服务本身重启，所有设置了 restart: always 的容器也会重新启动。 这个设置非常适合那些需要持续运行的服务，比如数据库、web 服务器等。 也可以通过命令行来修改: docker update --restart always container_name_or_id`}]},{path:"/content/service/docker/docker_compose%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E6%9C%8D%E5%8A%A1%E4%B8%8B%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%BF%A1%E6%81%AF.html",title:"docker_compose查看指定服务下的环境变量信息",pathLocale:"/",contents:[{header:"",slug:"",content:`docker_compose查看指定服务下的环境变量信息:
在docker-compsoe.yml同级目录下执行
$ docker-compose config
可以查看所有 service 的配置信息，比如引用了哪些环境变量 查看单个容器的环境变量:
$ docker exec -it k8s-dev-v2-php env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=49c87b3bc8b9
TERM=xterm
MAIL_NAME=k8s-dev-v2-mailcatcher
MAIL_SMTP_PORT=1025
PHPIZE_DEPS=autoconf dpkg-dev file g++ gcc libc-dev make pkg-config re2c
PHP_INI_DIR=/usr/local/etc/php
PHP_CFLAGS=-fstack-protector-strong -fpic -fpie -O2 -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64
PHP_CPPFLAGS=-fstack-protector-strong -fpic -fpie -O2 -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64
PHP_LDFLAGS=-Wl,-O1 -pie
GPG_KEYS=1198C0117593497A5EC5C199286AF1F9897469DC C28D937575603EB4ABB725861C0779DC5C0A9DE4 AFD8691FDAEDF03BDF6E460563F15A9B715376CA
PHP_VERSION=8.3.0alpha1
PHP_URL=https://downloads.php.net/~jakub/php-8.3.0alpha1.tar.xz
PHP_ASC_URL=https://downloads.php.net/~jakub/php-8.3.0alpha1.tar.xz.asc
PHP_SHA256=7df01cbae615cccdc01a811094a74326119080e1141988fd57aeefd6b751165c
HOME=/root 对于特定的环境变量:
$ docker exec -it k8s-dev-v2-php printenv PHP_VERSION
8.3.0alpha1 当然也可以通过bash进入container，然后访问环境变量:
$ docker exec -it k8s-dev-v2-php bash
root@49c87b3bc8b9:/var/www# printenv
HOSTNAME=49c87b3bc8b9
PHP_VERSION=8.3.0alpha1
PHP_INI_DIR=/usr/local/etc/php
GPG_KEYS=1198C0117593497A5EC5C199286AF1F9897469DC C28D937575603EB4ABB725861C0779DC5C0A9DE4 AFD8691FDAEDF03BDF6E460563F15A9B715376CA
PHP_LDFLAGS=-Wl,-O1 -pie
MAIL_SMTP_PORT=1025
PWD=/var/www
HOME=/root
PHP_SHA256=7df01cbae615cccdc01a811094a74326119080e1141988fd57aeefd6b751165c
PHPIZE_DEPS=autoconf dpkg-dev file g++ gcc libc-dev make pkg-config re2c
TERM=xterm
PHP_URL=https://downloads.php.net/~jakub/php-8.3.0alpha1.tar.xz
SHLVL=1
PHP_CFLAGS=-fstack-protector-strong -fpic -fpie -O2 -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
MAIL_NAME=k8s-dev-v2-mailcatcher
PHP_ASC_URL=https://downloads.php.net/~jakub/php-8.3.0alpha1.tar.xz.asc
PHP_CPPFLAGS=-fstack-protector-strong -fpic -fpie -O2 -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64
_=/usr/bin/printenv root@49c87b3bc8b9:/var/www# echo $PHP_VERSION
8.3.0alpha1 也可以直接通过 env 命令 访问全部环境变量，通过 sort 排序:`}]},{path:"/content/service/docker/docker_compose%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE.html",title:"docker_compose网络设置",pathLocale:"/",contents:[{header:"",slug:"",content:`docker_compose网络设置:
通过分析docker-compose.yml文件发现其中有关于网络设置，如下:
networks: network-laravel-internal: network-laravel-front:
分析:
这个地方创建的两个网络，都是在docker compose内部创建的，用于服务之间的通信，但是通过 docker network inspect docker-network-laravel-internal 发现其中的 Internal 为 false，以下是相关说明:
让我解释一下为什么在 \`docker network inspect\` 的输出中，即使对于内部通信网络，\`"Internal"\` 字段也显示为 \`false\`：
1. Docker 网络的 "Internal" 标志： - 这个标志并不是指网络是否用于内部通信。 - 它实际上表示这个网络是否完全隔离于外部网络（包括宿主机）。
2. 默认行为： - 当你在 Docker Compose 中创建一个网络而不指定 \`internal: true\` 时，Docker 会创建一个非内部（\`"Internal": false\`）的网络。 - 这种网络允许容器访问外部网络（如互联网），同时也允许容器之间相互通信。
3. 真正的内部网络： - 如果你确实想创建一个完全隔离的内部网络（\`"Internal": true\`），你需要在 Docker Compose 文件中明确指定： \`\`\`yaml networks: internal: internal: true \`\`\`
4. 用途区别： - 非内部网络（\`"Internal": false\`）：适用于大多数场景，允许容器访问外部资源，同时也能相互通信。 - 内部网络（\`"Internal": true\`）：用于创建完全隔离的网络环境，容器无法访问外部资源，只能在网络内部通信。
5. 您的使用场景： - 对于大多数应用，包括您描述的 PHP 项目，通常不需要完全隔离的内部网络。 - 允许容器访问外部资源（如下载更新、连接外部 API 等）通常是有益的。
6. 安全性： - 即使 \`"Internal"\` 为 \`false\`，您的服务仍然是安全的，因为它们默认不会暴露端口到宿主机，除非您明确配置。
总结：
\`"Internal": false\` 并不意味着这个网络不适合内部通信。它只是表示这个网络不是完全隔离的。对于大多数应用场景，包括服务间的内部通信，这种配置是完全适合且推荐的。
如果您有特殊的安全需求，需要完全隔离某些服务，那么您可以考虑创建一个真正的内部网络。但在大多数情况下，当前的配置已经足够安全和实用了。 针对上面的，假如我暴露了端口给宿主机，那么我是可以通过宿主机访问这个服务的，和 networks中的网络没有关系，即使它设置 internal: true，原因如下:
1. 网络的 \`Internal: true\` 配置： - 当一个 Docker 网络被设置为 internal（内部的），它会完全隔离该网络中的容器，使它们无法直接访问外部网络。 - 这主要影响容器内部的网络通信能力。 2. 端口映射（\`ports\`）： - 端口映射是在 Docker 主机级别进行的，不受容器所连接的网络的 internal 设置直接影响。 - 即使容器连接到一个 internal 网络，只要配置了端口映射，外部仍然可以通过映射的端口访问容器。 3. 在您的场景中： - 如果您将 \`network-internal\` 配置为 \`internal: true\`，并且保留了 \`ports\` 映射： \`\`\`yaml nginx: ports: - "\${APP_PORT}:80" networks: - network-internal networks: network-internal: internal: true \`\`\` - 外部仍然可以通过 \`\${APP_PORT}\` 访问 Nginx 容器。 - 但是，Nginx 容器本身将无法访问外部网络（如果它需要的话, 比如 curl wget apt-get update、yum update 等命令, 也不能访问外部API, 也就是说断网了） 4. 影响： - 内部服务（如 PHP、MySQL 等）之间的通信不受影响。 - Nginx 容器可能无法进行外部网络操作（如下载更新）。 - 其他连接到这个内部网络的服务也将无法访问外部网络。 5. 使用场景： - 完全 internal 的网络通常用于高度安全敏感的环境，где您希望确保某些服务完全与外部网络隔离。 - 对于大多数 Web 应用程序架构，完全 internal 的网络可能过于限制。 6. 建议： - 除非您有特殊的安全需求，否则通常不需要将网络设置为 \`internal: true\`。 - 标准的 Docker 网络配置（\`internal: false\`）已经提供了足够的隔离性，同时保持了必要的灵活性。 总结：
即使将网络设置为 \`internal: true\`，只要配置了端口映射，外部仍然可以通过暴露的端口访问服务。但这会限制容器的出站连接能力。在大多数情况下，保持默认的网络配置（非 internal）就足够了，除非您有特殊的安全隔离需求。 通过命令行创建的网络, 如：
docker network ls | grep laravel-dev-v2-network > /dev/null || docker network create laravel-dev-v2-network
分析:
通过命令行创建 Docker 网络确实有许多优势。让我们详细探讨一下这些好处： 灵活性和精确控制： 可以精确指定网络的各种参数，如子网、网关、IP 范围等。
能够创建不同类型的网络（bridge, overlay, macvlan 等）以满足特定需求。 可重用性： 创建的网络可以被多个项目或容器共享，不局限于单个 Docker Compose 文件。 持久性： 命令行创建的网络独立于任何特定的应用或服务，即使所有容器停止，网络仍然存在。 适合全局或跨项目使用： 特别适合需要在多个项目间共享的网络，如全局代理网络。 动态管理： 可以随时添加、删除或修改网络，而不需要修改 Docker Compose 文件。 配合 Docker Swarm： 在使用 Docker Swarm 时，命令行创建的网络更容易管理和扩展。 脚本化和自动化： 可以轻松地将网络创建集成到脚本或 CI/CD 流程中。 调试和测试： 便于快速创建临时网络进行测试或故障排除。 更好的可视性： 使用 docker network ls 和 docker network inspect 可以方便地查看和管理所有网络。 与外部工具集成： 命令行创建的网络更容易与外部网络管理工具和监控系统集成。 学习和理解 Docker 网络： 通过命令行操作，可以更深入地理解 Docker 网络的工作原理。 特殊配置： 某些高级网络配置（如配置 IPAM 驱动）在命令行中更容易实现。 实际应用示例：
# 创建一个自定义网桥网络
docker network create --driver bridge --subnet 172.18.0.0/16 my-custom-net # 创建一个覆盖网络（用于 Swarm）
docker network create --driver overlay my-overlay-net # 创建一个带有自定义选项的网络
docker network create --opt com.docker.network.bridge.name=my-bridge my-opt-net 这种方法特别适合您之前提到的全局 nginx-proxy 设置。您可以创建一个专门的网络用于代理，然后在不同的项目中重复使用它：
docker network create proxy-network 然后在您的 Docker Compose 文件中引用这个网络：
networks: proxy-network: external: true 这种方法为您的多项目环境提供了一个一致和可管理的网络结构。
补充: 对于docker-compose.yml内，如果有如下格式的网络设置的话:
networks:
proxy-network:
external: true
表示这个 proxy-network 网络需要在docker compsoe外部创建之后才能使用，当我们在 Docker Compose 文件中将网络标记为 external: true 时，我们需要预先创建这个网络。
具体来说： 需要预先创建：
在运行使用这个外部网络的 Docker Compose 项目之前，我们必须手动创建这个网络。
创建方法：
我们可以使用以下 Docker 命令来创建网络：docker network create proxy-network 创建时机：
这个网络创建操作只需要执行一次。之后，所有需要使用这个网络的项目都可以直接引用它。
如果网络不存在：
如果我们在没有预先创建网络的情况下尝试启动标记了 external: true 的 Compose 项目，Docker Compose 会报错，提示找不到指定的网络。
检查现有网络：
我们可以使用 docker network ls 命令来查看当前系统中已存在的网络。
持久性：
这个外部创建的网络不会随着 Compose 项目的停止而被删除，除非我们手动删除它。
所以，对于您的全局 nginx-proxy 设置，正确的步骤顺序是：
创建网络：docker network create proxy-network
启动包含 nginx-proxy 的 Docker Compose 项目
启动其他需要使用这个代理的项目
这种方法确保了网络的一致性和可重用性，非常适合您的跨项目共享 nginx-proxy 的需求。 不管是通过命令行（外部）还是在 Docker Compose 文件（内部）中创建网络，都可以设置 Internal 属性。让我们详细比较这两种方法： 命令行创建网络（外部）：
# 创建标准网络（默认 Internal: false）
docker network create my-network # 创建内部网络（Internal: true）
docker network create --internal my-internal-network Docker Compose 文件中创建网络（内部）：
networks: my-network: # 默认 Internal: false my-internal-network: internal: true 关键点： 灵活性： 两种方法都允许您控制网络是否为内部网络。 默认行为： 无论使用哪种方法，默认情况下创建的都是非内部网络（Internal: false）。 使用场景： 命令行创建适合全局或跨项目使用的网络。
Compose 文件创建适合特定项目或应用的网络。 持久性： 命令行创建的网络在 Docker 环境中持续存在，除非手动删除。
Compose 文件创建的网络通常随项目的启动和停止而创建和删除。 复用性： 命令行创建的网络更容易在多个项目间共享。
Compose 文件中的网络主要用于单个项目内部。 管理方式： 命令行创建的网络可以通过 Docker CLI 直接管理。
Compose 文件中的网络主要通过 Docker Compose 命令管理。
实际应用建议： 全局共享网络：
使用命令行创建，例如您之前提到的代理网络：docker network create proxy-network 项目特定网络：
在 Docker Compose 文件中定义：networks: backend: internal: true 混合使用：
在 Compose 文件中引用外部创建的网络：networks: proxy-network: external: true backend: internal: true 这种灵活性允许您根据具体需求选择最合适的网络配置方法。对于您的 PHP 项目，您可能会发现混合使用这两种方法是最有效的：使用命令行创建共享的代理网络，同时在 Compose 文件中定义项目特定的内部网络。`}]},{path:"/content/service/docker/docker%E4%B8%8B%E4%BD%BF%E7%94%A8vim_%E6%8F%90%E7%A4%BAcommand_not_found_%E9%97%AE%E9%A2%98.html",title:"docker下使用vim_提示command_not_found_问题",pathLocale:"/",contents:[{header:"",slug:"",content:`docker下使用vim，提示 command not found 问题:
# vim qh.conf.template bash: vim: command not found root@d9212faa2c32:/etc/nginx# apt-get install vim
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
E: Unable to locate package vim 这时候需要敲：apt-get update，这个命令的作用是：同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引，这样才能获取到最新的软件包。 执行了 apt-get install 之后，就可以再次运行 apt-get install vim 安装vim了`}]},{path:"/content/service/docker/docker%E4%B9%8Bcp%E5%9C%A8%E4%B8%A4%E7%A7%8D%E6%8C%82%E8%BD%BD%E6%96%B9%E5%BC%8F%E4%B8%8A%E7%9A%84%E8%A1%A8%E7%8E%B0.html",title:"docker之cp在两种挂载方式上的表现",pathLocale:"/",contents:[{header:"docker之cp在两种挂载方式上的表现",slug:"docker之cp在两种挂载方式上的表现",content:""},{header:"docker cp 的作用在 命名卷 的使用",slug:"docker-cp-的作用在-命名卷-的使用",content:`docker cp <宿主机路径> <容器:路径>
docker cp <容器:路径> <宿主机路径> 它是直接在 宿主机文件系统 和 容器文件系统（mount namespace 里的视角） 之间拷贝文件。
它并不直接操作 volume 对象。`},{header:"对于 命名卷 的情况",slug:"对于-命名卷-的情况",content:`命名卷会挂载到容器里的某个目录，比如：
docker run -d -v myvolume:/app/data myimage 这里： myvolume → 实际在宿主机 /var/lib/docker/volumes/myvolume/_data 下存储
容器内 /app/data → 就是这个卷的挂载点 因此： 你用 docker cp somefile.txt mycontainer:/app/data/ 可以把文件复制到卷里（因为容器的 /app/data 就是那个卷）。
同样 docker cp mycontainer:/app/data/file.txt ./ 可以把卷里的内容拷贝出来。`},{header:"另一种方式（不通过 docker cp）",slug:"另一种方式-不通过-docker-cp",content:`因为命名卷在宿主机上实际存放在 /var/lib/docker/volumes/...，所以也可以直接去这个目录修改内容。但： 这种方式依赖 Docker 内部实现路径，不同系统可能不同。
权限可能麻烦。
一般不推荐，除非明确知道自己在做什么。 ✅ 结论：
在容器挂载了命名卷的情况下，可以用 docker cp 来复制文件到容器指定路径，从而间接写入卷。`},{header:"docker cp 的作用在 绑定挂载 下使用会报 device or resource busy 之类的错误。",slug:"docker-cp-的作用在-绑定挂载-下使用会报-device-or-resource-busy-之类的错误。",content:"这个和 绑定挂载 (bind mount) 的工作方式有关，拆开分析一下为什么 docker cp 在绑定挂载时容易报 device or resource busy 之类的错误。"},{header:"1. 为什么命名卷能用 docker cp",slug:"_1-为什么命名卷能用-docker-cp",content:`命名卷（-v myvolume:/app/data）：容器里的 /app/data 是挂载点，底层在 /var/lib/docker/volumes/.../_data。
当你执行 docker cp ./conf mycontainer:/app/data/ 时，Docker 直接把文件复制到容器的挂载路径里 → 实际就是写入到卷目录。
Docker 在这个过程中“中转”了一下数据，不会直接和宿主机文件系统产生冲突，所以不会报 busy。`},{header:"2. 为什么绑定挂载会出问题",slug:"_2-为什么绑定挂载会出问题",content:`绑定挂载（-v /host/path:/app/data）：容器里的 /app/data 就是宿主机的 /host/path。 如果你执行
docker cp ./conf mycontainer:/app/data/ Docker 的逻辑是： 宿主机 → 容器文件系统
发现 /app/data 实际上是 一个 bind mount
容器内的路径和宿主机的路径直接映射 → Docker 需要在宿主机上对 /host/path 直接操作 这时候如果 /host/path 被容器占用（例如进程持有 fd、锁住文件），就可能触发 device or resource busy 报错。`},{header:"3. 生产环境为什么常用 docker cp",slug:"_3-生产环境为什么常用-docker-cp",content:`绑定挂载虽然方便实时调试，但生产环境往往不适合，因为： 宿主机路径和容器耦合太强，迁移麻烦
权限、安全风险高
docker cp 这类操作更容易冲突 命名卷则更稳定，docker cp 可以安全地注入配置文件，容器重建时卷还在，数据不会丢。`},{header:"4. 推荐的做法（生产环境）",slug:"_4-推荐的做法-生产环境",content:`初始化配置文件 在镜像里放默认配置
或者容器启动后用 docker cp 写入一次配置文件到命名卷 更新配置文件 用 docker cp 再次覆盖目标路径（命名卷安全）
或者提供一个 API / reload 脚本在容器内拉取最新配置 避免在生产里用绑定挂载 除非是日志输出到宿主机目录（相对安全）
否则配置、数据目录最好用卷 ✅ 总结： docker cp 在 命名卷 下可行、安全，适合生产。
在 绑定挂载 下可能报 busy 错误，因为容器进程会锁定挂载目录里的文件。
所以生产一般不用 bind mount，而是用命名卷 + docker cp 或配置管理工具。`}]},{path:"/content/service/docker/docker%E4%B9%8B%E5%8A%A0%E9%80%9F%E5%99%A8%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E4%BB%93%E5%BA%93%E5%9C%B0%E5%9D%80.html",title:"docker之加速器配置以及修改默认仓库地址",pathLocale:"/",contents:[{header:"docker之加速器配置以及修改默认仓库地址",slug:"docker之加速器配置以及修改默认仓库地址",content:`通过如下命令进入docker仓库配置
$ vim /etc/docker/daemon.json`},{header:"docker 镜像加速器配置",slug:"docker-镜像加速器配置",content:`{
"registry-mirrors": [
"https://docker.1ms.run"
]
}
👌 你这个配置里的
{ "registry-mirrors": [ "https://docker.1ms.run" ]
} 是 配置镜像加速器（mirror），而不是直接改 Docker 的默认仓库地址。
区别要搞清楚： 默认仓库 (default registry) https://registry-1.docker.io （官方 Docker Hub 的注册服务器） 在镜像名称中简写为 docker.io 默认的命名空间是 library，所以 nginx 实际全名是 docker.io/library/nginx 也就是说，docker pull nginx 依然是去拉 docker.io/library/nginx:latest。 镜像加速器 (registry-mirror) Docker 在访问 docker.io 时，会先通过你配置的镜像加速器（https://docker.1ms.run）去拉。
如果加速器有缓存，就直接下；如果没有，它会再去 Docker Hub 拉取，然后缓存起来。
常见于国内网络环境，用于解决访问 Docker Hub 慢或者被墙的问题。 如果你想改成真正的“默认仓库”（比如所有 docker pull xxx 都不是从 Docker Hub，而是从你自己的仓库），需要改成这样： { "registry-mirrors": ["https://docker.1ms.run"], "registry": "https://registry.mycompany.com"
} 这样 docker pull nginx 就会去你的 registry.mycompany.com 找，而不是 docker.io。`},{header:"修改默认仓库地址",slug:"修改默认仓库地址",content:`{
"registry": "https://registry.mycompany.com"
}`},{header:"1. 默认情况下",slug:"_1-默认情况下",content:`docker pull nginx 等价于：
docker pull docker.io/library/nginx:latest 镜像会显示为：
REPOSITORY TAG IMAGE ID ...
nginx latest xxxx 但实际上完整名是 docker.io/library/nginx:latest。`},{header:"2. 如果你在 /etc/docker/daemon.json 配置了",slug:"_2-如果你在-etc-docker-daemon-json-配置了",content:`{ "registry": "https://registry.mycompany.com"
} 那么：
docker pull nginx 就会变成去拉：
registry.mycompany.com/library/nginx:latest 镜像本地保存时的完整信息就是：
registry.mycompany.com/library/nginx:latest （注意：Docker Hub 的 library 命名空间是“默认公共库”的概念，你自己私有仓库可能也需要加 library 才能兼容）`},{header:"3. 验证方式",slug:"_3-验证方式",content:`你可以在拉取后执行：
docker images 会看到：
REPOSITORY TAG IMAGE ID ...
registry.mycompany.com/library/nginx latest xxxx 如果不想带上 library，你需要在拉取时明确写出仓库路径，比如：
docker pull registry.mycompany.com/nginx:latest 那保存下来的就是 registry.mycompany.com/nginx:latest。`},{header:"docker官方仓库: https://hub.docker.com/u/library",slug:"docker官方仓库-https-hub-docker-com-u-library",content:""},{header:"如果要自己搭建一个mirror，主要有三种方式",slug:"如果要自己搭建一个mirror-主要有三种方式",content:"搭建自己的Docker镜像源有几种方案，我来详细介绍："},{header:"方案一：使用官方Docker Registry作为Mirror",slug:"方案一-使用官方docker-registry作为mirror",content:""},{header:"方案二：使用docker-compose部署(具体配置，这个下次自己操作以后再写)",slug:"方案二-使用docker-compose部署-具体配置-这个下次自己操作以后再写",content:""},{header:"方案三：使用Nginx作为缓存代理",slug:"方案三-使用nginx作为缓存代理",content:""},{header:"1. 使用docker-compose方式（推荐,下面基于方案二来理解,因为没有自己搭建，所以先记录一下）",slug:"_1-使用docker-compose方式-推荐-下面基于方案二来理解-因为没有自己搭建-所以先记录一下",content:`# 创建目录
mkdir docker-mirror && cd docker-mirror # 下载上面的配置文件
# 创建数据目录
mkdir data # 启动服务
docker-compose up -d # 查看状态
docker-compose logs -f`},{header:"2. 配置客户端使用",slug:"_2-配置客户端使用",content:`{ "registry-mirrors": [ "http://your-server-ip:5000" ]
}`},{header:"3. 验证是否工作",slug:"_3-验证是否工作",content:`# 测试拉取
docker pull hello-world # 检查镜像源日志
docker-compose logs docker-mirror`},{header:"高级配置",slug:"高级配置",content:""},{header:"1. 添加HTTPS支持",slug:"_1-添加https支持",content:`# 生成证书
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\ -keyout tls.key -out tls.crt`},{header:"2. 添加认证",slug:"_2-添加认证",content:`# 在config.yml中添加
auth: htpasswd: realm: basic-realm path: /etc/docker/registry/htpasswd`},{header:"3. 多镜像源支持",slug:"_3-多镜像源支持",content:`可以同时代理多个镜像仓库： Docker Hub
Quay.io
GCR.io
阿里云等`},{header:"注意事项",slug:"注意事项",content:`存储空间 - 缓存会占用大量磁盘空间
网络带宽 - 首次拉取仍需要从官方下载
定期清理 - 设置缓存清理策略
安全性 - 考虑访问控制和HTTPS
监控 - 添加日志和监控指标 这样你就有了自己的Docker镜像源，既能加速下载，又能在网络受限时提供服务！`},{header:"自建 Docker 镜像加速&缓存服务(下面是别人搭建的，但是和我上面的差不多)",slug:"自建-docker-镜像加速-缓存服务-下面是别人搭建的-但是和我上面的差不多",content:`https://v2ex.com/t/1048655
https://github.com/brighill/registry-mirror`}]},{path:"/content/service/docker/docker%E4%B9%8B%E5%91%BD%E5%90%8D%E5%8D%B7%E6%8C%82%E8%BD%BD%E5%92%8C%E7%BB%91%E5%AE%9A%E6%8C%82%E8%BD%BD%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"docker之命名卷挂载和绑定挂载的区别",pathLocale:"/",contents:[{header:"docker之命名卷挂载和绑定挂载的区别",slug:"docker之命名卷挂载和绑定挂载的区别",content:"我们来仔细分析一下 Docker 命名卷挂载（named volume） 和 绑定挂载（bind mount） 的区别。它们都是把宿主机的存储和容器的文件系统关联起来，但原理和用途不同。"},{header:"1. 基本概念",slug:"_1-基本概念",content:`类型
定义 命名卷（Named Volume）
Docker 管理的卷，有名字，存储在 Docker 默认位置（Linux 默认在 /var/lib/docker/volumes/），Docker 对其内容负责。 绑定挂载（Bind Mount）
将宿主机的任意路径直接挂载到容器内，Docker 不管理内容，容器和宿主机操作同一份数据。`},{header:"2. 创建和使用方式",slug:"_2-创建和使用方式",content:""},{header:"命名卷",slug:"命名卷",content:`docker volume create myvolume
docker run -d -v myvolume:/app/data myimage myvolume 是 Docker 管理的卷。
容器内的 /app/data 会挂载到卷。
即使宿主机路径变化，卷依然有效。`},{header:"绑定挂载",slug:"绑定挂载",content:`docker run -d -v /host/path:/app/data myimage 容器内 /app/data 直接映射到宿主机 /host/path。
宿主机可以直接看到容器数据，反之亦然。`},{header:"3. 存储位置",slug:"_3-存储位置",content:`类型
存储位置
Docker 管理 命名卷
Docker 默认存储路径（可通过 docker volume inspect 查看）
是 绑定挂载
宿主机指定路径
否`},{header:"4. 优缺点对比",slug:"_4-优缺点对比",content:""},{header:"命名卷",slug:"命名卷-1",content:`优点： Docker 自动管理，易于迁移和备份。
默认权限配置较安全。
多容器共享容易，只需挂载同一个卷。
支持 volume driver（如 NFS、cloud storage） 缺点： 不直接访问宿主机路径，调试不方便。
不容易查看文件内容（需要通过容器或 docker cp）。`},{header:"绑定挂载",slug:"绑定挂载-1",content:`优点： 宿主机和容器共享文件，调试方便。
可以挂载任意宿主机路径。 缺点： Docker 不管理，权限问题可能复杂。
容器迁移不便，因为依赖宿主机路径。
共享多容器时可能有冲突，需要手动管理。`},{header:"5. 生命周期和数据持久性",slug:"_5-生命周期和数据持久性",content:`类型
生命周期
数据持久性 命名卷
与 Docker Volume 独立，删除容器卷可选择保留数据
高 绑定挂载
与宿主机路径绑定，容器删除不影响宿主机文件
高，但依赖宿主机路径存在`},{header:"6. 使用场景建议",slug:"_6-使用场景建议",content:`命名卷： 数据库数据（MySQL、PostgreSQL）
日志、上传文件等需要持久化的内容
多容器共享的数据 绑定挂载： 开发调试代码（实时同步宿主机代码到容器）
配置文件调试
需要直接访问宿主机文件系统的情况 ✅ 总结： 命名卷：Docker 管理，更安全、迁移方便、适合持久化和共享数据。
绑定挂载：直接映射宿主机路径，调试方便，但依赖宿主机路径管理，迁移和权限可能麻烦。`}]},{path:"/content/service/docker/docker%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95%E5%88%86%E6%9E%90.html",title:"docker之数据目录分析",pathLocale:"/",contents:[{header:"docker之数据目录分析",slug:"docker之数据目录分析",content:"/var/lib/docker/ 在 Linux 下是 Docker 的默认数据根目录（Docker Root Dir），也就是 Docker 用来存储所有容器、镜像、卷、网络等数据的地方。"},{header:"1. 目录结构概览",slug:"_1-目录结构概览",content:`假设默认安装在 Linux 上 /var/lib/docker，典型目录：
/var/lib/docker/
├── aufs # 如果使用 AUFS 存储驱动，会有容器镜像层
├── overlay2 # overlay2 存储驱动的容器镜像层
├── containers # 存放所有容器的具体数据（日志、挂载卷等）
├── volumes # 存放命名卷的数据
├── image # 存放镜像元数据
├── network # 存放 Docker 网络相关数据
├── swarm # 如果启用 swarm 模式
├── plugins # Docker 插件数据
├── tmp # 临时文件
└── builder # 构建缓存`},{header:"2. 关键说明",slug:"_2-关键说明",content:`子目录
作用 containers/
每个容器的元数据和日志 volumes/
命名卷的数据，卷名目录下 _data 就是卷里内容 image/
存放镜像元数据和层 overlay2/
容器文件系统层（overlayFS 驱动） network/
网络配置和状态 plugins/
插件数据`},{header:"3. 特性",slug:"_3-特性",content:`由 Docker 管理：不要随意直接修改里面的内容，尤其是卷、镜像和容器数据。
可以通过 Docker 命令访问：例如 docker volume inspect、docker container ls 等，不必直接操作 /var/lib/docker/。
可以更改默认路径：在 dockerd 配置中设置 --data-root=/my/docker-data。 ✅ 总结：
/var/lib/docker/ 就是 Docker 在 Linux 上的 数据根目录，所有容器、卷、镜像、网络和日志都存放在这里。`}]},{path:"/content/service/docker/docker%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%8E%A8%E9%80%81%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95.html",title:"docker之配置推送自动登录",pathLocale:"/",contents:[{header:"",slug:"",content:`在发布镜像的时候，经常要先执行 docker login -u xxx -p xxx 操作，但是在通过脚本发布项目的时候，就会有问题，因为不能直接交互，
所以 可以在执行脚本的机器上先执行 docker login -u xxx -p xxx 这个是docker 仓库默认登录操作，如果是推送到自己的仓库，那么需
要执行如下命令，下面这个我推到了阿里云的镜像仓库:
[root@k8smaster .docker]# docker login --username=xxx registry.cn-qingdao.aliyuncs.com
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 执行按以后就可以执行推送命令了:
[root@k8smaster ~]# docker push registry.cn-qingdao.aliyuncs.com/xxx/httpd:v1.0.2 以后可以直接 docker push 到指定仓库，不需要再登录，原因是在 /root/.docker/config.json (~/.docker/config.json) 这个文件里面保存了仓库的授权信息
格式如下：
{ "auths": { "https://index.docker.io/v1/": { "auth": "faddsdsgdfgfddfssfdg" }, "registry.cn-qingdao.aliyuncs.com": { "auth": "zxvcfdsfegvbfbsdfsdsddsfd" } }
} 同时config.json里的授权文件可以复制到其它服务器上，仍然有效，可以直接使用，这个在做k8s的项目自动打包发布的时候特别有用，在后面的项目里面我会用到这个`}]},{path:"/content/service/docker/docker%E4%BB%93%E5%BA%93%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80.html",title:"docker仓库镜像地址",pathLocale:"/",contents:[{header:"",slug:"",content:`docker仓库镜像地址:
使用aliyun镜像工具:
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
"registry-mirrors": ["https://ohvr36te.mirror.aliyuncs.com"] //这个现在也不能用了，所以 aliyun 的路子走不通了
}
EOF 下面这个可以，但是还是需要开VPN:
{ "registry-mirrors": [ "https://dockerhub.icu", "https://docker.awsl9527.cn" ]
}
上面(处理后)的直接访问只有：
"https://dockerhub.icu",
"https://docker.awsl9527.cn" // 有网站：https://docker.awsl9527.cn/ 博客：https://songxwn.com/ (值得借鉴) 下面这个也可以： { "registry-mirrors": [ "https://docker.m.daocloud.io", ]
} 配置好以后执行:
sudo systemctl daemon-reload
sudo systemctl restart docker 相关链接:
https://blog.csdn.net/weixin_50160384/article/details/139861337 //docker源请求超时, 写的比较多`}]},{path:"/content/service/docker/docker%E5%88%A0%E9%99%A4none%E9%95%9C%E5%83%8F.html",title:"docker删除none镜像",pathLocale:"/",contents:[{header:"",slug:"",content:`docker删除none镜像:
docker image 有很多 none的镜像，可以通过如下命令删除:
$ docker image ls
<none>
...
... $ docker image prune -f , 这个会删除所有 dangling（无标签）镜像 // 查看所有运行的容器
$ docker ps // 查看所有容器，包括运行的和停止的
$ docker ps -a`}]},{path:"/content/service/docker/docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4.html",title:"docker基本操作命令",pathLocale:"/",contents:[{header:"",slug:"",content:`docker基本操作命令: 删除所有镜像: docker rmi $(docker images -q) 清理docker缓存: docker builder prune 查看volume信息: docker volume COMMAND
Commands: create Create a volume inspect Display detailed information on one or more volumes ls List volumes prune Remove unused local volumes rm Remove one or more volumes update Update a volume (cluster volumes only) 如:
$ docker volume ls
$ docker volume inspect docker_volume-mysql-laravel 查看网络信息: docker network COMMAND
Commands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networks 如:
$ docker network ls
$ docker network inspect docker_network-laravel-fron docker image排序: $ docker image ls --format "{{.Repository}}:{{.Tag}}" | sort
docker-nginx:latest
docker-php:latest
docker-solr:latest
ghcr.io/open-webui/open-webui:main
jwilder/nginx-proxy:latest
laravel-dev-v2-nginx:latest
laravel-dev-v2-php:latest
laravel-dev-v2-solr:latest
meta-dev-v2-nginx:latest
meta-dev-v2-php:latest
meta-dev-v2-solr:latest
mysql:8-debian
schickling/mailcatcher:latest docker停止并且删除指定开头名称的container $ docker ps -a --format '{{.Names}}' | grep '^laravel\\|^meta' | xargs -r docker stop && docker ps -a --format '{{.Names}}' | grep '^laravel\\|^meta' | xargs -r docker rm
这个命令的工作原理如下： docker ps -a --format '{{.Names}}': 列出所有容器的名称（包括停止的容器）。
grep '^laravel\\|^meta': 过滤出以 "laravel" 或 "meta" 开头的容器名称。
xargs -r docker stop: 停止这些容器。-r 选项确保在没有匹配项时不会执行 docker stop。
&&: 如果停止操作成功，则继续执行后面的命令。
重复相同的过程来删除这些容器。 如果不先停止，直接删除，可以这样:
docker ps -a --format '{{.Names}}' | grep '^laravel\\|^meta' | xargs -r docker rm -f
这个命令使用 docker rm -f 来强制删除容器，即使它们正在运行。这样就不需要先停止再删除了。`}]},{path:"/content/service/docker/docker%E5%AE%B9%E5%99%A8%E5%86%85%E4%BD%BF%E7%94%A8vim.html",title:"docker容器内使用vim",pathLocale:"/",contents:[{header:"",slug:"",content:`docker容器内使用vim的时候,报 vim not found:
root@135c249bafad:/etc/nginx/conf.d# apt-get install -y vim
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
E: Unable to locate package vim
root@135c249bafad:/etc/nginx/conf.d# root@135c249bafad:/etc/nginx/conf.d# apt-get update && apt-get install -y vim
Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]
Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]
Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]
Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8789 kB]
Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [8856 B] Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [236 kB] Fetched 9288 kB in 20s (473 kB/s) Reading package lists... Done
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
...
...`}]},{path:"/content/service/docker/docker%E6%9F%A5%E7%9C%8B%E6%9F%90%E4%B8%AA%E9%95%9C%E5%83%8F%E7%9A%84%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5.html",title:"docker查看某个镜像的使用情况",pathLocale:"/",contents:[{header:"",slug:"",content:`docker查看某个镜像的使用情况:
如下 dd3e65840448 为IMAGE ID
$ docker ps -a --filter "ancestor=dd3e65840448"`}]},{path:"/content/service/docker/gitlab%E4%B9%8Bci%E8%84%9A%E6%9C%AC%E5%AE%9E%E7%8E%B0php%E9%A1%B9%E7%9B%AE%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83.html",title:"gitlab之ci脚本实现php项目自动发布",pathLocale:"/",contents:[{header:"gitlab之ci脚本实现php项目自动发布",slug:"gitlab之ci脚本实现php项目自动发布",content:`//在宿主机创建
1.laravel项目创建, 通过命令行 composer create-project --prefer-dist laravel/laravel project_name
$ composer create-project --prefer-dist laravel/laravel meta-known //在gitlab-runner 容器里内
2.安装php8.3 ()
ubuntu22下(如果是root用户，就不用sudo): 添加php8.3官方源:
sudo apt update
sudo apt install -y software-properties-common ca-certificates lsb-release apt-transport-https
sudo add-apt-repository ppa:ondrej/php -y
sudo apt update 安装php8.3:
sudo apt install -y php8.3 php8.3-cli php8.3-mbstring php8.3-xml php8.3-zip php8.3-curl unzip 根据需求安装拓展:
sudo apt install -y php8.3-cli php8.3-fpm php8.3-mysql php8.3-mbstring php8.3-xml php8.3-curl php8.3-zip php8.3-bcmath php8.3-intl php8.3-gd php8.3-soap 3.php -v 查看版本 没有可以添加
sudo ln -s /usr/bin/php8.3 /usr/local/bin/php 再次执行
php -v 我这里安装完php,执行php -v 报：
PHP 8.3.17 (cli) (built: Feb 15 2025 09:08:37) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.17, Copyright (c) Zend Technologies
with Zend OPcache v8.3.17, Copyright (c), by Zend Technologies 说明已经做了软连接 查看php指向:
# which php
/usr/bin/php 查看具体指向:
ls -l $(which php)
lrwxrwxrwx 1 root root 21 Mar 12 15:20 /usr/bin/php -> /etc/alternatives/php 查看具体指向哪个版本:
ls -l /etc/alternatives/php
lrwxrwxrwx 1 root root 15 Mar 12 15:20 /etc/alternatives/php -> /usr/bin/php8.3 4.安装composer
下载 Composer 安装脚本:
curl -sS https://getcomposer.org/installer | php 将 Composer 安装到全局路径： 将下载的 Composer 可执行文件移动到 /usr/local/bin，这样你可以在任何地方通过 composer 命令使用它：
sudo mv composer.phar /usr/local/bin/composer 查看版本:
composer --version
Composer version 2.8.6 2025-02-25 13:03:50
PHP version 8.3.17 (/usr/bin/php8.3)
Run the "diagnose" command to get more detailed diagnostics output. 5.安装 rsync 工具，用于同步文件
apt-get install -y rsync rsync --version
rsync version 3.1.3 protocol version 31
Copyright (C) 1996-2018 by Andrew Tridgell, Wayne Davison, and others.
Web site: http://rsync.samba.org/
Capabilities:
64-bit files, 64-bit inums, 64-bit timestamps, 64-bit long ints,
socketpairs, hardlinks, symlinks, IPv6, batchfiles, inplace,
append, ACLs, xattrs, iconv, symtimes, prealloc rsync comes with ABSOLUTELY NO WARRANTY. This is free software, and you
are welcome to redistribute it under certain conditions. See the GNU
General Public Licence for details. 6.宿主机上执行:
guoshipeng@tianyi510s:~/Documents/code/meta-known$ sudo mkdir -p /data/www/meta-known-backend-v1 这里因为安装gitlab-runner的时候，没有将 宿主机的 /data 挂载到容器的 /data 上，所以这里我就直接在容器里创建 mkdir -p /data/www/meta-known-backend-v1 默认有gitlab-runner用户和用户组:
root@8446a748968a:/# chown -R gitlab-runner:gitlab-runner /data
root@8446a748968a:/# chmod -R 775 /data 但是我还是想分配给 www-data:www-data 先查看www-data是否存在:
root@8446a748968a:/# getent passwd www-data
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
root@8446a748968a:/#
root@8446a748968a:/#
root@8446a748968a:/# getent group www-data
www-data:x:33: 说明 www-data 用户和用户组都存在 或者直接:
root@8446a748968a:/# id www-data
uid=33(www-data) gid=33(www-data) groups=33(www-data) 如果不存在，先创建用户组，再创建用户，加到用户组:
创建 www-data 组：
sudo groupadd www-data 创建 www-data 用户并加入 www-data 组：
sudo useradd -r -g www-data -s /usr/sbin/nologin www-data 解释 sudo useradd -r -g www-data -s /usr/sbin/nologin www-data：
useradd → 添加一个新用户
-r → 创建一个 系统用户（UID 小于 1000，一般用于守护进程）
-g www-data → 指定主组为 www-data
-s /usr/sbin/nologin → 让 www-data 用户无法直接登录系统
www-data → 这个是用户名 实际上可能需要sudo,但是gitlab-runner 容器默认没有装，所以需要手动安装:
root@8446a748968a:/# apt-get update && apt-get install -y sudo 查看:
root@8446a748968a:/# sudo --version
Sudo version 1.8.31
Configure options: --build=x86_64-linux-gnu --prefix=/usr --includedir=\${prefix}/include --mandir=\${prefix}/share/man --infodir=\${prefix}/share/info --sysconfdir=/etc --localstatedir=/var --disable-silent-rules --libdir=\${prefix}/lib/x86_64-linux-gnu --libexecdir=\${prefix}/lib/x86_64-linux-gnu --disable-maintainer-mode --disable-dependency-tracking -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-exampledir=/usr/share/doc/sudo/examples --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p: --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-rundir=/run/sudo --libexecdir=/usr/lib --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux --with-linux-audit --enable-tmpfiles.d=yes
Sudoers policy plugin version 1.8.31
Sudoers file grammar version 46 Sudoers path: /etc/sudoers
Authentication methods: 'pam'
...
... gitlab-runner配置里面执行sudo,j结果需要密码，报:
sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper 在gitlab-runner容器里执行:
root@8446a748968a:/# sudo visudo 然后在末端添加如下内容(修改 sudoers，允许 gitlab-runner 无密码执行 sudo):
gitlab-runner ALL=(ALL) NOPASSWD: ALL 如下:
#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults env_reset
Defaults mail_badpass
Defaults secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin" # Host alias specification # User alias specification # Cmnd alias specification # User privilege specification
root ALL=(ALL:ALL) ALL # Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL # Allow members of group sudo to execute any command
%sudo ALL=(ALL:ALL) ALL # See sudoers(5) for more information on "#include" directives: #includedir /etc/sudoers.d
gitlab-runner ALL=(ALL) NOPASSWD: ALL 保存退出 现在gitlab-ci.yml脚本里的:
script:
- sudo rsync -rL --delete --exclude={'.buildpath','.git','.gitignore'} ./* /data/www/meta-known-backend-v1/
- sudo chown -R www-data:www-data /data/www/meta-known-backend-v1/ 可以成功执行了，默认通过 gitlab-runner 用户无密码执行. 分析 rsync 命令的行为:
sudo rsync -rL --delete --exclude={'.buildpath','.git','.gitignore'} ./* /data/www/meta-known-backend-v1/ 1>覆盖已有文件：rsync 会将 ./*（CI 运行目录下的所有文件）同步到 /data/www/meta-known-backend-v1/，如果目标目录已经有相同的文件，rsync 会用新文件覆盖旧文件。
2>删除目标目录中不存在的文件：--delete 选项会删除 /data/www/meta-known-backend-v1/ 中在源目录（CI 目录）中不存在的文件，确保目标目录和源目录完全一致。
3>保留排除的文件：--exclude={'.buildpath','.git','.gitignore'} 这些文件不会被同步（不会被上传到目标目录）。 所以 /data/www/meta-known-backend-v1/ 的变化
1>新增的文件（在 CI 目录里但目标目录没有）会被添加到 /data/www/meta-known-backend-v1/。
2>已存在的文件会被覆盖为新版本。
3>目标目录中存在，但 CI 目录中已删除的文件，会被删除。`},{header:"下面以laravel12项目为例子分析",slug:"下面以laravel12项目为例子分析",content:`1.通过命令行 composer create-project --prefer-dist laravel/laravel project_name $ composer create-project --prefer-dist laravel/laravel meta-known 2.安装php8.3 ubuntu22下(如果是root用户，就不用sudo): 添加php8.3官方源:
sudo apt update
sudo apt install -y software-properties-common ca-certificates lsb-release apt-transport-https
sudo add-apt-repository ppa:ondrej/php -y
sudo apt update 安装php8.3:
sudo apt install -y php8.3 php8.3-cli php8.3-mbstring php8.3-xml php8.3-zip php8.3-curl unzip 根据需求安装拓展:
sudo apt install -y php8.3-cli php8.3-fpm php8.3-mysql php8.3-mbstring php8.3-xml php8.3-curl php8.3-zip php8.3-bcmath php8.3-intl php8.3-gd php8.3-soap 3.php -v 查看版本 没有可以添加
sudo ln -s /usr/bin/php8.3 /usr/local/bin/php 再次执行
php -v 我这里安装完php,执行php -v 报：
PHP 8.3.17 (cli) (built: Feb 15 2025 09:08:37) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.17, Copyright (c) Zend Technologies with Zend OPcache v8.3.17, Copyright (c), by Zend Technologies 说明已经做了软连接 查看php指向:
# which php
/usr/bin/php 查看具体指向:
ls -l $(which php)
lrwxrwxrwx 1 root root 21 Mar 12 15:20 /usr/bin/php -> /etc/alternatives/php 查看具体指向哪个版本:
ls -l /etc/alternatives/php
lrwxrwxrwx 1 root root 15 Mar 12 15:20 /etc/alternatives/php -> /usr/bin/php8.3 4.安装composer
下载 Composer 安装脚本:
curl -sS https://getcomposer.org/installer | php 将 Composer 安装到全局路径： 将下载的 Composer 可执行文件移动到 /usr/local/bin，这样你可以在任何地方通过 composer 命令使用它：
sudo mv composer.phar /usr/local/bin/composer 查看版本:
composer --version
Composer version 2.8.6 2025-02-25 13:03:50
PHP version 8.3.17 (/usr/bin/php8.3)
Run the "diagnose" command to get more detailed diagnostics output. 5.安装 rsync 工具，用于同步文件
apt-get install -y rsync rsync --version
rsync version 3.1.3 protocol version 31
Copyright (C) 1996-2018 by Andrew Tridgell, Wayne Davison, and others.
Web site: http://rsync.samba.org/
Capabilities: 64-bit files, 64-bit inums, 64-bit timestamps, 64-bit long ints, socketpairs, hardlinks, symlinks, IPv6, batchfiles, inplace, append, ACLs, xattrs, iconv, symtimes, prealloc rsync comes with ABSOLUTELY NO WARRANTY. This is free software, and you
are welcome to redistribute it under certain conditions. See the GNU
General Public Licence for details. 6.宿主机上执行:
guoshipeng@tianyi510s:~/Documents/code/meta-known$ sudo mkdir -p /data/www/meta-known-backend-v1 这里因为安装gitlab-runner的时候，没有将 宿主机的 /data 挂载到容器的 /data 上，所以这里我就直接在容器里创建 mkdir -p /data/www/meta-known-backend-v1 默认有gitlab-runner用户和用户组:
root@8446a748968a:/# chown -R gitlab-runner:gitlab-runner /data
root@8446a748968a:/# chmod -R 775 /data 但是我还是想分配给 www-data:www-data 先查看www-data是否存在:
root@8446a748968a:/# getent passwd www-data
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
root@8446a748968a:/# root@8446a748968a:/# root@8446a748968a:/# getent group www-data
www-data:x:33: 说明 www-data 用户和用户组都存在 或者直接:
root@8446a748968a:/# id www-data
uid=33(www-data) gid=33(www-data) groups=33(www-data) 如果不存在，先创建用户组，再创建用户，加到用户组:
创建 www-data 组：
sudo groupadd www-data 创建 www-data 用户并加入 www-data 组：
sudo useradd -r -g www-data -s /usr/sbin/nologin www-data 解释 sudo useradd -r -g www-data -s /usr/sbin/nologin www-data：
useradd → 添加一个新用户
-r → 创建一个 系统用户（UID 小于 1000，一般用于守护进程）
-g www-data → 指定主组为 www-data
-s /usr/sbin/nologin → 让 www-data 用户无法直接登录系统
www-data → 这个是用户名 实际上可能需要sudo,但是gitlab-runner 容器默认没有装，所以需要手动安装:
root@8446a748968a:/# apt-get update && apt-get install -y sudo 查看:
root@8446a748968a:/# sudo --version
Sudo version 1.8.31
Configure options: --build=x86_64-linux-gnu --prefix=/usr --includedir=\${prefix}/include --mandir=\${prefix}/share/man --infodir=\${prefix}/share/info --sysconfdir=/etc --localstatedir=/var --disable-silent-rules --libdir=\${prefix}/lib/x86_64-linux-gnu --libexecdir=\${prefix}/lib/x86_64-linux-gnu --disable-maintainer-mode --disable-dependency-tracking -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-exampledir=/usr/share/doc/sudo/examples --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p: --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-rundir=/run/sudo --libexecdir=/usr/lib --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux --with-linux-audit --enable-tmpfiles.d=yes
Sudoers policy plugin version 1.8.31
Sudoers file grammar version 46 Sudoers path: /etc/sudoers
Authentication methods: 'pam'
...
... gitlab-runner配置里面执行sudo,j结果需要密码，报:
sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper 在gitlab-runner容器里执行:
root@8446a748968a:/# sudo visudo 然后在末端添加如下内容(修改 sudoers，允许 gitlab-runner 无密码执行 sudo):
gitlab-runner ALL=(ALL) NOPASSWD: ALL 如下:
#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults env_reset
Defaults mail_badpass
Defaults secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin" # Host alias specification # User alias specification # Cmnd alias specification # User privilege specification
root ALL=(ALL:ALL) ALL # Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL # Allow members of group sudo to execute any command
%sudo ALL=(ALL:ALL) ALL # See sudoers(5) for more information on "#include" directives: #includedir /etc/sudoers.d
gitlab-runner ALL=(ALL) NOPASSWD: ALL 保存退出 现在gitlab-ci.yml脚本里的:
# update the dev env on gitlab
deploy: stage: deploy tags: - tag1 # 使用 "tag1" 的 Runner script: - cat .env.example > /tmp/.env_backup || echo "No .env.example found, skipping" - sudo rsync -rL --delete --exclude={'.buildpath','.git','.gitignore'} ./* /data/www/meta-known-backend-v1/ - if [ ! -f /data/www/meta-known-backend-v1/.env ]; then sudo cp /tmp/.env_backup /data/www/meta-known-backend-v1/.env; fi - sudo cp ./.env.dev /data/www/meta-known-backend-v1/.env - sudo rm -f /tmp/.env_backup - sudo chown -R www-data:www-data /data/www/meta-known-backend-v1/ - cd /data/www/meta-known-backend-v1 && sudo -u www-data php artisan migrate --force rules: - if: $CI_PIPELINE_SOURCE == 'merge_request_event' when: never - if: $CI_PIPELINE_SOURCE == "schedule" when: never - if: '$CI_COMMIT_BRANCH == "master"' 可以成功执行了，默认通过 gitlab-runner 用户无密码执行. 分析 rsync 命令的行为:
sudo rsync -rL --delete --exclude={'.buildpath','.git','.gitignore'} ./* /data/www/meta-known-backend-v1/ 覆盖已有文件：rsync 会将 ./*（CI 运行目录下的所有文件）同步到 /data/www/meta-known-backend-v1/，如果目标目录已经有相同的文件，rsync 会用新文件覆盖旧文件。
删除目标目录中不存在的文件：--delete 选项会删除 /data/www/meta-known-backend-v1/ 中在源目录（CI 目录）中不存在的文件，确保目标目录和源目录完全一致。
保留排除的文件：--exclude={'.buildpath','.git','.gitignore'} 这些文件不会被同步（不会被上传到目标目录）。 所以 /data/www/meta-known-backend-v1/ 的变化
新增的文件（在 CI 目录里但目标目录没有）会被添加到 /data/www/meta-known-backend-v1/。
已存在的文件会被覆盖为新版本。
目标目录中存在，但 CI 目录中已删除的文件，会被删除。 7.在gitlab-runner 安装 mysql 客户端
apt-get update
apt-get install mysql-client -y 容器测试连接:
root@8446a748968a:/# mysql -h laravel-dev-v2-mysql -P 3306 -u laravel -proot_pwd mysql: [Warning] Using a password on the command line interface can be insecure.
ERROR 2005 (HY000): Unknown MySQL server host 'laravel-dev-v2-mysql' (-2) 通过国宿主机连接:
root@8446a748968a:/# mysql -h 192.168.5.17 -P 3309 -u laravel -plaravel_pwd mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor. Commands end with ; or \\g.
Your MySQL connection id is 10
Server version: 8.0.34 MySQL Community Server - GPL Copyright (c) 2000, 2025, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> 使用，报：
could not find driver (Connection: mysql, SQL: select exists (select 1 from information_schema.tables where table_schema = schema() and table_name = 'migrations' and table_type in ('BASE TABLE', 'SYSTEM VERSIONED')) as exists) at vendor/laravel/framework/src/Illuminate/Database/Connection.php:823 root@8446a748968a:/# sudo apt install -y php8.3-mysql 在次运行, ok了 上面的操作，实现的是gitlab-ci下项目的rsync操作，如果/data/www 和宿主机挂载，那么接下来可以直接使用宿主机运行这个项目，这个rsync相当于实时同步了代码，但是当时启动gitlab-runner的时候，没有将/data和宿主机挂载，导致这个部署方式不能使用， 接下来还是想基于docker部署laravel项目:
1.项目下创建Dockerfile
# 使用 PHP 8.3 + FPM
FROM php:8.3-fpm # 安装必要的扩展
RUN apt-get update && apt-get install -y \\ unzip libpng-dev libjpeg-dev libfreetype6-dev \\ && docker-php-ext-install pdo_mysql gd # 安装 Nginx
RUN apt-get install -y nginx # 设置工作目录
WORKDIR /var/www/html # 复制 Laravel 代码
COPY . . # 安装 Composer 依赖
RUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer
RUN composer install --no-dev --no-interaction --prefer-dist # 配置 Nginx
COPY ./nginx/laravel.conf /etc/nginx/sites-available/default # 赋予 storage 目录权限
RUN chmod -R 777 storage bootstrap/cache # 启动 Nginx 和 PHP-FPM
CMD service nginx start && php-fpm 2.项目下创建 nginx/laravel.conf
server { listen 80; server_name localhost; root /var/www/html/public; index index.php index.html index.htm; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php8.3-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /\\.ht { deny all; }
} 3.构建和运行
# 构建 Docker 镜像
docker build -t laravel-app . # 运行容器
docker run -d -p 8990:80 --name my-laravel-app laravel-app 此时，Nginx 将在容器的 80 端口运行，而 PHP 将通过 php-fpm 处理请求。你可以访问 http://localhost:8990 来查看 Laravel 项目。 但是报nginx 错误
然后到 my-laravel-app 容器里查看nginx错误日志:
2025/03/18 14:47:34 [crit] 22#22: *5 connect() to unix:/var/run/php/php8.3-fpm.sock failed (2: No such file or directory) while connecting to upstream, client: 172.17.0.1, server: localhost, request: "GET / HTTP/1.1", upstream: "fastcgi://unix:/var/run/php/php8.3-fpm.sock:", host: "localhost:8990 发现 php8.3-fpm.sock 文件没有，但是 127.0.0.1:9000 端口有服务，于是修改
fastcgi_pass 127.0.0.1:9000; 然后重启nginx
# service nginx restart
Restarting nginx: nginx. # service nginx status nginx is running. 再次访问 http://localhost:8990 可以访问成功`},{header:"终极版本",slug:"终极版本",content:`1.Dockerfile文件
# 使用 PHP 8.3 + FPM
FROM php:8.3-fpm # 安装必要的扩展
RUN apt-get update && apt-get install -y \\ unzip libpng-dev libjpeg-dev libfreetype6-dev vim \\ && docker-php-ext-install pdo_mysql gd # 安装 Nginx
RUN apt-get install -y nginx # 设置工作目录
WORKDIR /var/www/html # 复制 Laravel 代码
COPY . . # 复制 .env.dev 到 .env
RUN cp .env.dev .env # 安装 Composer 依赖
RUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer
RUN composer install --no-dev --no-interaction --prefer-dist # 生成 Laravel APP_KEY
RUN php artisan key:generate # 配置 Nginx
COPY ./nginx/laravel.conf /etc/nginx/sites-available/default # 赋予 storage 和 bootstrap/cache 目录权限
RUN chown -R www-data:www-data /var/www/html \\ && chmod -R 775 storage bootstrap/cache # 创建启动脚本，这个方式其实和我之前的效果一样，并不需要在启动nginx或者php-fpm的时候切换到www-data，需要root
RUN echo '#!/bin/bash\\nservice nginx start\\nphp-fpm' > /start.sh \\ && chmod +x /start.sh # 使用启动脚本
CMD ["/start.sh"] 2.gitlab-ci.yml文件
stages: - build - deploy variables: IMAGE_NAME: "meta-known-image" # 替换为你的镜像名称 CONTAINER_NAME: "meta-known-app" DOCKER_REGISTRY: "localhost:5000" # 替换为你的 Docker 注册表（如果使用私有仓库） before_script: - echo "Logging into Docker Registry..." - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$DOCKER_REGISTRY" # 登录 Docker 仓库 build: stage: build tags: - tag1 # 使用 "tag1" 的 Runner script: - IMAGE_TAG=$(date +%Y%m%d%H%M%S) # 生成时间戳作为 tag - docker build --rm -t $DOCKER_REGISTRY/$IMAGE_NAME:$IMAGE_TAG . - docker push $DOCKER_REGISTRY/$IMAGE_NAME:$IMAGE_TAG - docker tag $DOCKER_REGISTRY/$IMAGE_NAME:$IMAGE_TAG $DOCKER_REGISTRY/$IMAGE_NAME:latest - docker push $DOCKER_REGISTRY/$IMAGE_NAME:latest # 推送镜像到 Docker 仓库 only: - master # 仅在 master 分支执行才可以u deploy: stage: deploy tags: - tag1 # 使用 "tag1" 的 Runner script: - docker stop $CONTAINER_NAME || true # 停止旧容器（如果存在） - docker rm $CONTAINER_NAME || true # 删除旧容器（如果存在） - docker pull $DOCKER_REGISTRY/$IMAGE_NAME:latest # 拉取最新镜像 - docker run -d --name $CONTAINER_NAME -p 8990:80 --restart=always $DOCKER_REGISTRY/$IMAGE_NAME:latest # 运行容器 only: - master # 部署仅在 master 分支执行`},{header:"其它命令",slug:"其它命令",content:`# ps aux | grep php-fpm
bash: ps: command not found 安装ps:
apt install procps 再次查看 php-fpm:
# ps aux | grep php-fpm
root 1 0.0 0.0 2580 1536 ? Ss 14:41 0:00 /bin/sh -c service nginx start && php-fpm
root 25 0.0 0.1 82528 23168 ? Ss 14:41 0:00 php-fpm: master process (/usr/local/etc/php-fpm.conf)
www-data 33 0.0 0.1 91248 24404 ? S 14:41 0:00 php-fpm: pool www
www-data 34 0.0 0.1 91184 23432 ? S 14:41 0:00 php-fpm: pool www
root 342 0.0 0.0 3328 1664 pts/0 S+ 15:23 0:00 grep php-fpm # netstat -tulnp | grep php-fpm
bash: netstat: command not found 安装netstat:
apt update && apt install -y net-tools 再次查看php-fpm 端口情况：
# netstat -tulnp | grep php-fpm
tcp6 0 0 :::9000 :::* LISTEN 25/php-fpm: master php-fpm 监听在 :::9000，这表示它监听的是 IPv6（tcp6）, 既然 php-fpm 监听在 9000 端口，可以修改你的 Nginx 配置，让它通过 127.0.0.1:9000 连接，而不是 Unix Socket。(前面的步骤就是这么解决问题的)
造成这个现象的俄原因是,之前的Dockerfile的最后CMD命令操作: CMD service nginx start && php-fpm 会直接通过执行 php-fpm 启动PHP-FPM 进程，它会自动作为守护进程在容器内运行，等待处理 PHP 请求，而没有使用像 service 这样的服务管理工具。 如果在容器下再次执行，会报错:
# php-fpm
[18-Mar-2025 15:51:47] NOTICE: Failed implicitly binding to ::, retrying with 0.0.0.0
[18-Mar-2025 15:51:47] ERROR: unable to bind listening socket for address '9000': Address already in use (98)
[18-Mar-2025 15:51:47] ERROR: FPM initialization failed 默认配置：
PHP-FPM 默认会监听 9000 端口。这是 PHP-FPM 配置中的默认设置。
可以在 PHP-FPM 配置文件中调整监听方式，例如使用 Unix 套接字或 TCP 端口。常见的配置文件路径为 /etc/php/8.3/fpm/pool.d/www.conf 但是在容器下，/etc/php/8.3/ 目录不存在，于是想知道php8.3-fpm被安装到哪里了 # which php-fpm
/usr/local/sbin/php-fpm
root@e9c062a5ddf1:/etc/nginx/sites-available# root@e9c062a5ddf1:/etc/nginx/sites-available# php -v
PHP 8.3.19 (cli) (built: Mar 17 2025 23:16:41) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.19, Copyright (c) Zend Technologies # php -i | grep "Configuration File"
Configuration File (php.ini) Path => /usr/local/etc/php
Loaded Configuration File => (none) 发现php8.3-fpm的配置在(但是路径却没有php8.3-fpm)
# cd /usr/local/etc/php-fpm.d/
root@e9c062a5ddf1:/usr/local/etc/php-fpm.d# ls
docker.conf www.conf www.conf.default zz-docker.conf 查看默认开启的是监听9000端口:
root@e9c062a5ddf1:/usr/local/etc/php-fpm.d# vim www.conf
listen = 127.0.0.1:9000 而不是sock文件，难怪nginx不能使用sock文件了 还有个疑问，为什么一直不展示php8.3-fpm,而是php-fpm # php -v
PHP 8.3.19 (cli) (built: Mar 17 2025 23:16:41) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.3.19, Copyright (c) Zend Technologies
root@e9c062a5ddf1:/usr/local/etc/php-fpm.d# root@e9c062a5ddf1:/usr/local/etc/php-fpm.d# root@e9c062a5ddf1:/usr/local/etc/php-fpm.d# php-fpm -v
PHP 8.3.19 (fpm-fcgi) (built: Mar 17 2025 23:16:48)
Copyright (c) The PHP Group
Zend Engine v4.3.19, Copyright (c) Zend Technologies 都表明，使用了php8.3-fpm
没有显式使用 php8.3-fpm，因为在 php:8.3-fpm 镜像中，php-fpm 命令默认指向 PHP 8.3 版本的 FPM 服务，所以直接执行 php-fpm 即可启动 PHP 8.3 的 FPM 进程。`}]},{path:"/content/service/docker/gitlab%E4%B9%8Bserver%E7%AB%AFhook%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E5%88%86%E6%94%AF.html",title:"gitlab之server端hook自动创建项目分支",pathLocale:"/",contents:[{header:"gitlab之server端hook自动创建项目分支",slug:"gitlab之server端hook自动创建项目分支",content:`之前已经搭建了gitlab下的server hook，做了简单的测试，是可以生效的，接下来准备通过这个hook实现，代码分支的自动发布
思路如下: 1.在gitlab的server的post-receive下定义一个脚本
2.在这个脚本里面通过ssh登录到宿主机，然后执行宿主机上的脚本,在这个脚本里面，执行拉取代码操作 环境准备: 由于要使用ssh服务，所以必须要在系统安装ssh
1.检查ssh是否安装
systemctl status ssh 2.如果没有安装，可以通过如下方式安装
$ sudo apt install -y openssh-server
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed: ncurses-term openssh-sftp-server ssh-import-id
Suggested packages: molly-guard monkeysphere ssh-askpass
The following NEW packages will be installed: ncurses-term openssh-server openssh-sftp-server ssh-import-id
0 upgraded, 4 newly installed, 0 to remove and 247 not upgraded.
Need to get 751 kB of archives.
After this operation, 6,046 kB of additional disk space will be used.
Get:1 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 openssh-sftp-server amd64 1:8.9p1-3ubuntu0.11 [38.7 kB]
Get:2 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 openssh-server amd64 1:8.9p1-3ubuntu0.11 [435 kB]
Get:3 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 ncurses-term all 6.3-2ubuntu0.1 [267 kB]
Get:4 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/main amd64 ssh-import-id all 5.11-0ubuntu1 [10.1 kB]
Fetched 751 kB in 3s (245 kB/s) Preconfiguring packages ...
Selecting previously unselected package openssh-sftp-server.
(Reading database ... 287328 files and directories currently installed.)
Preparing to unpack .../openssh-sftp-server_1%3a8.9p1-3ubuntu0.11_amd64.deb ...
Unpacking openssh-sftp-server (1:8.9p1-3ubuntu0.11) ...
Selecting previously unselected package openssh-server.
Preparing to unpack .../openssh-server_1%3a8.9p1-3ubuntu0.11_amd64.deb ...
Unpacking openssh-server (1:8.9p1-3ubuntu0.11) ...
Selecting previously unselected package ncurses-term.
Preparing to unpack .../ncurses-term_6.3-2ubuntu0.1_all.deb ...
Unpacking ncurses-term (6.3-2ubuntu0.1) ...
Selecting previously unselected package ssh-import-id.
Preparing to unpack .../ssh-import-id_5.11-0ubuntu1_all.deb ...
Unpacking ssh-import-id (5.11-0ubuntu1) ...
Setting up openssh-sftp-server (1:8.9p1-3ubuntu0.11) ...
Setting up openssh-server (1:8.9p1-3ubuntu0.11) ... Creating config file /etc/ssh/sshd_config with new version
Creating SSH2 RSA key; this may take some time ...
3072 SHA256:Bc6mfCjp5qrlFU0x7wu1fcSGY718FeEXXnwcU4PHeDA root@tianyi510s (RSA)
Creating SSH2 ECDSA key; this may take some time ...
256 SHA256:wirUnlfZcsdMjIy3lhIEfkWnItdXByl+uxTyVEpzNzQ root@tianyi510s (ECDSA)
Creating SSH2 ED25519 key; this may take some time ...
256 SHA256:hMriVpK3rh8cVNiQvlU82t3hw0KUDkIvAYhJC1munkQ root@tianyi510s (ED25519)
Created symlink /etc/systemd/system/sshd.service → /lib/systemd/system/ssh.service.
Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service → /lib/systemd/system/ssh.service.
rescue-ssh.target is a disabled or a static unit, not starting it.
ssh.socket is a disabled or a static unit, not starting it.
Setting up ssh-import-id (5.11-0ubuntu1) ...
Setting up ncurses-term (6.3-2ubuntu0.1) ...
Processing triggers for man-db (2.10.2-1) ...
Processing triggers for ufw (0.36.1-4build1) ...
guoshipeng@tianyi510s:~$ guoshipeng@tianyi510s:~$ sudo systemctl start ssh
guoshipeng@tianyi510s:~$ guoshipeng@tianyi510s:~$ systemctl status ssh
● ssh.service - OpenBSD Secure Shell server Loaded: loaded (/lib/systemd/system/ssh.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2025-03-06 00:16:38 CST; 27s ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 22674 (sshd) Tasks: 1 (limit: 18753) Memory: 1.7M CPU: 11ms CGroup: /system.slice/ssh.service └─22674 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups" Mar 06 00:16:38 tianyi510s systemd[1]: Starting OpenBSD Secure Shell server...
Mar 06 00:16:38 tianyi510s sshd[22674]: Server listening on 0.0.0.0 port 22.
Mar 06 00:16:38 tianyi510s sshd[22674]: Server listening on :: port 22.
Mar 06 00:16:38 tianyi510s systemd[1]: Started OpenBSD Secure Shell server.
guoshipeng@tianyi510s:~$ guoshipeng@tianyi510s:~$ sudo systemctl enable ssh //设置开机自启动 步骤如下:`},{header:"第一部分，配置ssh连接",slug:"第一部分-配置ssh连接",content:`1.由于需要ssh 连接到宿主机，需要将本地主机的SSH公钥安装到远程主机的授权密钥文件中
1>在容器中通过openssh 生成SSH密钥
root@gitlab:/# apt-get install -y openssh-client
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed: openssh-server openssh-sftp-server
Suggested packages: keychain libpam-ssh monkeysphere ssh-askpass molly-guard ufw
Recommended packages: xauth default-logind | logind | libpam-systemd ncurses-term ssh-import-id
The following packages will be upgraded: openssh-client openssh-server openssh-sftp-server
3 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.
Need to get 1376 kB of archives.
After this operation, 0 B of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openssh-sftp-server amd64 1:8.9p1-3ubuntu0.11 [38.7 kB]
Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openssh-server amd64 1:8.9p1-3ubuntu0.11 [435 kB]
Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openssh-client amd64 1:8.9p1-3ubuntu0.11 [903 kB]
Fetched 1376 kB in 3s (479 kB/s) debconf: delaying package configuration, since apt-utils is not installed
(Reading database ... 112282 files and directories currently installed.)
Preparing to unpack .../openssh-sftp-server_1%3a8.9p1-3ubuntu0.11_amd64.deb ...
Unpacking openssh-sftp-server (1:8.9p1-3ubuntu0.11) over (1:8.9p1-3ubuntu0.10) ...
Preparing to unpack .../openssh-server_1%3a8.9p1-3ubuntu0.11_amd64.deb ...
Unpacking openssh-server (1:8.9p1-3ubuntu0.11) over (1:8.9p1-3ubuntu0.10) ...
Preparing to unpack .../openssh-client_1%3a8.9p1-3ubuntu0.11_amd64.deb ...
Unpacking openssh-client (1:8.9p1-3ubuntu0.11) over (1:8.9p1-3ubuntu0.10) ...
Setting up openssh-client (1:8.9p1-3ubuntu0.11) ...
Setting up openssh-sftp-server (1:8.9p1-3ubuntu0.11) ...
Setting up openssh-server (1:8.9p1-3ubuntu0.11) ...
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)
debconf: falling back to frontend: Readline
invoke-rc.d: could not determine current runlevel
invoke-rc.d: policy-rc.d denied execution of restart.
root@gitlab:/# root@gitlab:/# root@gitlab:/# root@gitlab:/# ssh-keygen -t rsa -b 4096
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): Created directory '/root/.ssh'.
Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa
Your public key has been saved in /root/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:3c4MshoBmZ4/mH7PqsAbJY6fxa5lHkopWN8cXp8YKkE root@gitlab.example.com
The key's randomart image is:
+---[RSA 4096]----+
| |
| o |
| E |
| o o . . |
| o = o S o . |
|.= * O = * * |
|+ B @ O o o + |
| + & o.= |
| *.=oooo |
+----[SHA256]-----+
root@gitlab:/# root@gitlab:/# cd ~/.ssh/
root@gitlab:~/.ssh# ls
id_rsa id_rsa.pub 2>通过 ssh-copy-id 命令，将本地主机的SSH公钥安装到远程主机的授权密钥文件中
root@gitlab:~/.ssh# ssh-copy-id guoshipeng@192.168.5.17
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
The authenticity of host '192.168.5.17 (192.168.5.17)' can't be established.
ED25519 key fingerprint is SHA256:hMriVpK3rh8cVNiQvlU82t3hw0KUDkIvAYhJC1munkQ.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
guoshipeng@192.168.5.17's password: Permission denied, please try again.
guoshipeng@192.168.5.17's password: Number of key(s) added: 1 Now try logging into the machine, with: "ssh 'guoshipeng@192.168.5.17'"
and check to make sure that only the key(s) you wanted were added. root@gitlab:~/.ssh# 3>ssh-copy-id 原理
它会读取本地的SSH公钥（通常是 ~/.ssh/id_rsa.pub）
将公钥上传到远程服务器
添加到远程服务器的授权密钥列表中 语法:
ssh-copy-id user@hostname 参数:
user：远程服务器的用户名
hostname：远程服务器的IP地址或域名 注意:
执行这个命令时：
会提示你输入远程服务器的密码
成功后，你就可以无密码SSH登录该服务器了
确保只对可信的服务器使用 2.配置SSH配置文件，在容器中编辑 ~/.ssh/config 文件，简化连接，内容如下:
Host hostmachine HostName 宿主机IP地址 User 宿主机用户名 IdentityFile ~/.ssh/id_rsa 对于 ~/.ssh/config 文件，如果不存在，可以直接创建：
touch ~/.ssh/config
chmod 600 ~/.ssh/config 我的配置内容如下:
Host myserver HostName 192.168.5.17 User guoshipeng Port 22 IdentityFile ~/.ssh/id_rsa 这样配置后，就可以直接使用 ssh myserver 连接，而不需要每次输入完整的用户名和IP(ssh user@host 的方式)。所以最好取一个有意义的名称(别名)，这里是myserver
需要注意的是：
文件权限必须是600（仅对所有者可读可写）
可以配置多个不同的主机
简化日常SSH连接操作 3.确保宿主机SSH服务器配置，在宿主机 /etc/ssh/sshd_config 中确认以下配置:
PubkeyAuthentication yes
AuthorizedKeysFile .ssh/authorized_keys 查看宿主机相关配置，如下(根据需要爱哦已经做了修改):
#PubkeyAuthentication yes
PubkeyAuthentication yes # Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2
AuthorizedKeysFile .ssh/authorized_keys 然后重启宿主机的ssh:
sudo systemctl restart ssh 关于AuthorizedKeysFile的解释:
这个配置项 AuthorizedKeysFile .ssh/authorized_keys 中的 .ssh/authorized_keys 是一个文件路径，它指定了用于SSH公钥认证的授权密钥存储位置。
具体解释： .ssh/ 是一个目录，位于用户的主目录下
authorized_keys 是存储授权公钥的文件
完整路径通常是 ~/.ssh/authorized_keys（针对普通用户）或 /root/.ssh/authorized_keys（针对root用户） 这个文件的作用是： 存储所有被允许通过SSH密钥登录到此账户的公钥
每个公钥占一行
当有人尝试使用SSH密钥登录时，服务器会检查该文件中是否包含对应的公钥 当你运行 ssh-copy-id 命令时，它实际上是把你的公钥添加到远程服务器上这个文件中。
文件格式示例：
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAA... 用户@主机
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABBB... 另一个用户@另一个主机 4.测试ssh 连接是否可用
# 使用别名连接
ssh hostmachine
# 或直接连接
ssh user@宿主机IP 我这里执行:
root@gitlab:~/.ssh# ssh myserver
Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 6.8.0-52-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage * Introducing Expanded Security Maintenance for Applications. Receive updates to over 25,000 software packages with your Ubuntu Pro subscription. Free for personal use. https://ubuntu.com/pro Expanded Security Maintenance for Applications is not enabled. 201 updates can be applied immediately.
To see these additional updates run: apt list --upgradable 3 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.2 LTS' available.
Run 'do-release-upgrade' to upgrade to it. Last login: Sun Mar 9 19:01:30 2025 from 172.17.0.4
guoshipeng@tianyi510s:~$ 或者:
root@gitlab:~/.ssh# ssh guoshipeng@192.168.5.17
Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 6.8.0-52-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage * Introducing Expanded Security Maintenance for Applications. Receive updates to over 25,000 software packages with your Ubuntu Pro subscription. Free for personal use. https://ubuntu.com/pro Expanded Security Maintenance for Applications is not enabled. 201 updates can be applied immediately.
To see these additional updates run: apt list --upgradable 3 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.2 LTS' available.
Run 'do-release-upgrade' to upgrade to it. Last login: Sun Mar 9 19:21:10 2025 from 172.17.0.4
guoshipeng@tianyi510s:~$ 说明是可以在容器里，使用ssh连接宿主机的, 接下来就是编写脚本了`},{header:"第二部分，编写脚本",slug:"第二部分-编写脚本",content:`1.修改post-receive，添加如下内容 #!/bin/bash read oldrev newrev refname BRANCH="refs/heads/dev" if [ "$refname" == "$BRANCH" ]; then echo "$(date '+%Y-%m-%d %H:%M:%S') - Push to dev branch detected: $newrev" >> /var/log/gitlab/custom_hooks.log echo "Detected push to $BRANCH branch, triggering deploy..." ssh -vvv guoshipeng@192.168.5.17 "/home/guoshipeng/Documents/code/deploy/deploy.sh" >> /var/log/gitlab/custom_hooks.log 2>&1
fi 2.在宿主机 /home/guoshipeng/Documents/code/deploy/ 下新建如下 deploy.sh 脚本
#!/bin/bash PROJECT_DIR="/home/guoshipeng/Documents/code/deploy/laravel-12"
#GIT_REPO="git@gitlab.example.com:9022/dev/laravel12.git"
#由于使用的是ssh，所以要加这个前缀，否则 git clone 失败，报: remote: The project you were looking for could not be found or you don't have permission to view it.
GIT_REPO="ssh://git@gitlab.example.com:9022/dev/laravel12.git"
BRANCH="dev" echo "==== [$(date)] 开始部署 Laravel 12 ====" # 如果目录不存在，克隆仓库
if [ ! -d "$PROJECT_DIR/.git" ]; then echo ">>> 目录不存在，克隆仓库..." git clone -b $BRANCH $GIT_REPO $PROJECT_DIR
else echo ">>> 目录已存在，拉取最新代码..." cd $PROJECT_DIR || exit git fetch origin $BRANCH git reset --hard origin/$BRANCH
fi # 安装依赖
echo ">>> 安装 PHP 依赖..."
#docker run --rm -v $PROJECT_DIR:/app -w /app composer install --no-dev --optimize-autoloader # 运行数据库迁移
echo ">>> 运行数据库迁移..."
#docker-compose -f $DOCKER_COMPOSE_FILE exec app php artisan migrate --force # 重新启动 Laravel 项目
echo ">>> 重新启动 Laravel 项目..."
#docker-compose -f $DOCKER_COMPOSE_FILE up -d --build echo "==== [$(date)] 部署完成 ====" 上面脚本的内容只是做一个简单的测试，所以具体的逻辑还没使用，只是做了echo 操作`},{header:"第三部分，测试脚本",slug:"第三部分-测试脚本",content:`新建项目(这里是laravel12)，然后拉到本地，新建dev分支，然后 push 到远程仓库，到宿主机的 /home/guoshipeng/Documents/code/deploy/目录下看有没有laravel-12项目，结果发现没有 但是脚本中的日志 /var/log/gitlab/custom_hooks.log echo "$(date '+%Y-%m-%d %H:%M:%S') - Push to dev branch detected: $newrev" >> /var/log/gitlab/custom_hooks.log 有日志信息，证明这个脚本是执行了,但是ssh没有执行 我直接在gitlab容器里执行:
root@gitlab:/var/opt/gitlab/git-data/repositories/@hashed/9f/14/9f14025af0065b30e47e23ebb3b491d39ae8ed17d33739e5ff3827ffb3634953.git/custom_hooks# ssh guoshipeng@192.168.5.17 "/home/guoshipeng/Documents/code/deploy/deploy.sh"
==== [Fri Mar 7 12:07:37 AM CST 2025] 开始部署 Laravel 12 ====
>>> 目录不存在，克隆仓库...
Cloning into '/home/guoshipeng/Documents/code/deploy/laravel-12'...
remote: remote: ========================================================================
remote: remote: The project you were looking for could not be found or you don't have permission to view it. //这是另一个问题，上面已经解决
remote: remote: ========================================================================
remote: fatal: Could not read from remote repository. Please make sure you have the correct access rights
and the repository exists.
>>> 安装 PHP 依赖...
>>> 运行数据库迁移...
>>> 重新启动 Laravel 项目...
==== [Fri Mar 7 12:07:37 AM CST 2025] 部署完成 ==== 发现脚本是可以执行的，那就很奇怪了，为什么hook下，ssh没有执行`},{header:"第四部分，解决hook下，ssh没有执行的问题",slug:"第四部分-解决hook下-ssh没有执行的问题",content:`目前的问题:
手动执行 ssh guoshipeng@192.168.5.17 "/home/guoshipeng/Documents/code/deploy/deploy.sh" 可以正常执行；
自动执行 post-receive hook 时，这个 SSH 命令没有被执行。 这表明： SSH 可能无法在 git 用户的环境中执行
在gitlab容器里查看日志 vim /var/log/gitlab/custom_hooks.log
...
...
debug1: Authenticating to 192.168.5.17:22 as 'guoshipeng'^M
debug1: load_hostkeys: fopen /var/opt/gitlab/.ssh/known_hosts: No such file or directory^M
debug1: load_hostkeys: fopen /var/opt/gitlab/.ssh/known_hosts2: No such file or directory^M
debug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory^M
debug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory^M
debug3: order_hostkeyalgs: no algorithms matched; accept original^M
debug3: send packet: type 20^M
debug1: SSH2_MSG_KEXINIT sent^M
debug3: receive packet: type 20^M
debug1: SSH2_MSG_KEXINIT received^M
debug2: local client KEXINIT proposal^M
...
... 这说明 hook 脚本里执行 ssh 的用户为 git 用户，但是这个 git 用户没有被认证，这个 git 用户的默认加目录为： /var/opt/gitlab，而不是root用户的/root，之前在第一部分添加的认证其实都是root用户的，所以这里git用户执行ssh会失败 解决办法:
1.在容器里切换到git用户
sudo -u git mkdir -p /var/opt/gitlab/.ssh
sudo -u git ssh-keyscan 192.168.5.17 >> /var/opt/gitlab/.ssh/known_hosts
sudo -u git chmod 644 /var/opt/gitlab/.ssh/known_hosts 但是很遗憾，报:
root@gitlab:~# sudo -u git
bash: sudo: command not found 这是因为: 在 GitLab 容器里，默认是 没有 sudo 的，因为容器通常是最小化的环境 2.在 GitLab 容器里，并且是 root，切换到 git 用户：
su - git
如下:
root@gitlab:~# su - git
$ pwd /var/opt/gitlab
然后执行:
mkdir -p ~/.ssh
ssh-keyscan 192.168.5.17 >> ~/.ssh/known_hosts
chmod 644 ~/.ssh/known_hosts 但是很遗憾，报:
git 用户下，执行脚本报
cannot create /var/opt/gitlab/.ssh/known_hosts: Permission denied
但是 前面的 mkdir -p ~/.ssh 却执行了，我想可能是 ssh-keyscan 没有权限吧 3.git 用户没有权限写入 /var/opt/gitlab/.ssh/known_hosts，可以用 root 用户 先创建 .ssh 目录并赋权给 git 用户：
从上面的git用户exit 出到root，执行:
mkdir -p /var/opt/gitlab/.ssh //这个其实不用执行了，因为上面已经创将了
chown -R git:git /var/opt/gitlab/.ssh
chmod 700 /var/opt/gitlab/.ssh 然后:
su - git # # 添加 SSH 服务器的 key 到 known_hosts，避免 SSH 连接报错
ssh-keyscan 192.168.5.17 >> /var/opt/gitlab/.ssh/known_hosts //如果哦还有问题，就直接在root用户下执行，然后修改目录归属
chmod 644 /var/opt/gitlab/.ssh/known_hosts 我这里执行 ssh-keyscan 192.168.5.17 >> /var/opt/gitlab/.ssh/known_hosts 的效果如下:
ssh-keyscan 192.168.5.17 >> ~/.ssh/known_hosts //这个是我之前使用root的时候为root用户生成的, 其实root用户和git用户的known_hosts 存的内容都一样
# 192.168.5.17:22 SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.11
# 192.168.5.17:22 SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.11
# 192.168.5.17:22 SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.11
# 192.168.5.17:22 SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.11
# 192.168.5.17:22 SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.11
$ $ ls -l ~/.ssh/known_hosts
-rw-r--r-- 1 git git 834 Mar 8 14:58 /var/opt/gitlab/.ssh/known_hosts vim /var/opt/gitlab/.ssh/known_hosts, 内容如下:
192.168.5.17 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLE4ptNJOj0gOQRqtADbuxXvWW+B+7GLTlqh2/MzRKgB2vchs5e3HlDdQ80UkQC6UqtUgzEdPljEw9+DfAUwd1kFw8YyL4ht/mu/m6Ru6xikvRml6m+5ZR8WeS0x9DTIByLplLWNRQvN9v3FMQNXo2b2l+rhVidsMMHhkS+eB9AUFr1dT101Nega+VHmLeVZTU96jFTxxHZCm9COID4ygwyDBTqLHr743D4H/dfEvkdy7GhMKtXPCdrBBATxykfD9KbGm65mlGxPAbyu7igo4rmNvsCBPxji90mL2UrtuSTB1UFuV2LabcQCHIUwAIdJF9JLyfPiROMcM4EAkl8xkCj/sOC+AfxGZx/HHpEdqo3iU+9xInnlgyuzSTcWXs2IiHE67Gczg4rovkMgXTrVRwotfAgy13XKX1TFGWvmg50qbBO6RUKRxNfONcXsnUdAi46kYRUqUuZ4NG8Fet6LyQvA6Gb0mO26lek6t2oo6KSeULHL/a5OYSPxhuUNEIyys=
192.168.5.17 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFERYqCHXozlOK5lE7F+FX5Cy3ejnURAs0XxzAPLmOVixwZgPKJ63HA8LrvZn2J9XUgSnFWSfN3wS85defqrLCg=
192.168.5.17 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICKLoOAsvzRv7gLc/edywOmsH7ewq+KVay+N/9n63eDP 在git 用户下测试:
ssh -T guoshipeng@192.168.5.17 ...
...
debug1: Next authentication method: publickey^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_rsa^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_rsa: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_ecdsa^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_ecdsa: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_ecdsa_sk^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_ecdsa_sk: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_ed25519^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_ed25519: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_ed25519_sk^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_ed25519_sk: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_xmss^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_xmss: No such file or directory^M
debug1: Trying private key: /var/opt/gitlab/.ssh/id_dsa^M
debug3: no such identity: /var/opt/gitlab/.ssh/id_dsa: No such file or directory^M
debug2: we did not send a packet, disable method^M
debug3: authmethod_lookup password^M
debug3: remaining preferred: ,password^M
debug3: authmethod_is_enabled password^M
debug1: Next authentication method: password^M
...
... 如果有 Permission denied (publickey)的问题，那说明 git 用户的 SSH Key 不正确或者不存在，大概率是不存在，执行:
su - git //切换到git用户
ssh-keygen -t rsa -b 4096 -C "git@gitlab" -f ~/.ssh/id_rsa -N "" 然后将 id_rsa.pub 复制到 192.168.5.17：
ssh-copy-id -i ~/.ssh/id_rsa.pub guoshipeng@192.168.5.17
会提示输入远程服务器的密码
成功后，就可以无密码SSH登录该服务器了 通过一下命令验证git 的 ssh key 是否被添加:
root@gitlab:~/.ssh# ssh -i /var/opt/gitlab/.ssh/id_rsa guoshipeng@192.168.5.17
Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 6.8.0-52-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage * Introducing Expanded Security Maintenance for Applications. Receive updates to over 25,000 software packages with your Ubuntu Pro subscription. Free for personal use. https://ubuntu.com/pro Expanded Security Maintenance for Applications is not enabled. 201 updates can be applied immediately.
To see these additional updates run: apt list --upgradable 3 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.2 LTS' available.
Run 'do-release-upgrade' to upgrade to it. Last login: Sun Mar 9 19:21:50 2025 from 172.17.0.4
guoshipeng@tianyi510s:~$ 说明添加成功 还有个问题，对于 git 用户，我没有在它的.ssh目录下添加 config，用来添加host 别名，以简化连接，如果需要也可以为git用户添加一个 ~/.ssh/config，类似root用户的。 接下来，再重新提交代码，可以发现 /home/guoshipeng/Documents/code/deploy 下有了 laravel-12 这个目录，说明post-receive 这个脚本中的 ssh 被执行了`},{header:"第五部分，关于known_hosts的作用",slug:"第五部分-关于known-hosts的作用",content:`ssh-keyscan 192.168.5.17 >> ~/.ssh/known_hosts 的作用
这个命令的作用是 将 192.168.5.17 服务器的 SSH 主机密钥添加到 known_hosts 文件，避免 SSH 连接时手动确认主机身份。 原理如下:
SSH 连接时，客户端会检查服务器的身份，具体流程如下：
客户端尝试连接服务器（如 ssh user@192.168.5.17）。
服务器返回自己的 SSH 公钥（host key）。
客户端检查 ~/.ssh/known_hosts 文件：
如果 文件里已经有匹配的主机密钥，SSH 连接继续。
如果 文件里没有该服务器的密钥，SSH 会提示：
The authenticity of host '192.168.5.17 (192.168.5.17)' can't be established.
ECDSA key fingerprint is SHA256:xxxxx.
Are you sure you want to continue connecting (yes/no)? 选择 yes 后，该密钥会存入 known_hosts，以后就不会再提示。 ssh-keyscan 的作用:
ssh-keyscan 自动获取服务器的 SSH 主机密钥，并写入 known_hosts，避免手动确认。
如：
ssh-keyscan 192.168.5.17 >> ~/.ssh/known_hosts
等价于：
连接 192.168.5.17 获取 SSH 主机密钥（但不会真的 SSH 登录）。
把这个主机密钥追加 (>>) 到 ~/.ssh/known_hosts，避免手动输入 yes。 ssh-keyscan 可用于批量获取多台服务器的密钥：
ssh-keyscan 192.168.5.17 192.168.5.18 192.168.5.19 >> ~/.ssh/known_hosts ssh-keyscan 不会验证 服务器身份，只是盲目地获取密钥，所以如果 DNS 劫持或中间人攻击发生，可能会存储错误的密钥。ssh-keyscan 可以获取任意服务器的 SSH 主机密钥，前提是该服务器允许通过 SSH 进行连接。ssh-keyscan 的作用就是 扫描并获取远程服务器的公钥，并将其输出到标准输出（通常是终端或指定文件）。它并不会尝试进行登录操作，只是读取服务器的公钥信息。`},{header:"第六部分,关于ssh-copy-id",slug:"第六部分-关于ssh-copy-id",content:`ssh-copy-id 是一个非常实用的命令，用于将本地主机的SSH公钥安装到远程主机的授权密钥文件中。细解释一下：
基本功能:
ssh-copy-id 的主要作用是简化SSH免密登录的配置过程。它会自动将你的公钥添加到远程服务器的 ~/.ssh/authorized_keys 文件中。这个命令大大简化了SSH免密登录的配置过程，是系统管理员和开发人员常用的效率工具。 工作原理:
它会读取本地的SSH公钥（通常是 ~/.ssh/id_rsa.pub）
将公钥上传到远程服务器
添加到远程服务器的授权密钥列表中 示例:
ssh-copy-id user@hostname user：远程服务器的用户名
hostname：远程服务器的IP地址或域名 具体操作流程:
# 1. 先生成SSH密钥（如果还没有）
ssh-keygen -t rsa # 2. 复制公钥到远程服务器
ssh-copy-id root@192.168.1.100
执行这个命令时：
会提示你输入远程服务器的密码
成功后，你就可以无密码SSH登录该服务器了 安全注意事项:
确保只对可信的服务器使用
保护好私钥
不要随意分享私钥`},{header:"第七部分，检查宿主机下的 authorized_keys 有哪些",slug:"第七部分-检查宿主机下的-authorized-keys-有哪些",content:`guoshipeng@tianyi510s:~$ pwd
/home/guoshipeng
guoshipeng@tianyi510s:~$ vim ~/.ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDLr/1E9ipQEN1au7R2SkjVXEuYFlnH3OHbRxXmWC7Ib4e+tj8jwwv/WSX2wV2FOTHZ7csoHdxqAHE8C9fTPBBAHyk+vhV+8BS/yYp+poqqTLHDO+Rkqy2ZZ2VIx3cQAhUTOtsYCP1Pkf55YeJmOpEunqE9CQyGNPuwCv1EF5zeTe+knV4g6EhTBJ/hXIRfb3kd1YJSOIJYWMElF5hiiiUuDu3+ZovlBmVHE3YNavV7GzJzPDkgHIWRMqMz9dVA+of4N3UHR5Sc54RhSlL3LErQ00Q24DEBfW29LC/oqNeKMDs+BPS7ArsCiHPVNZd1vSexufqh6GDf/B879II1FNB1/gFYTnphAH20JRcJK4JMEncC3UybUMDNCDiS7rarSSldmKhc0yrUL2bazUoFfCpmoQVUqaQHPsbDaIpfiJOSz64dOqUkVZfIxj73Q+02WN73dfaRskqySftRmoP36PhHIqLAKRjZZDft20hvrE0/KVXVuNem7W6Dq0uHGdYunLEhF82TpDZTNoZfvdtMACF8cAOVFRoLIJjRqBWQmKTTQF+xFo/P9JmnkgxJ9puDFm/bHH/fou9OcYKP7TPXIB7LGyEpkxX8iM6DqOOs/6XxJzQ+NFVvSVrHHceDRpJAYdKiQjAhC88qhxC6S1seCwWCs4xHgpiPsw37vl/BYYgMWw== root@gitlab.example.com
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDDMN/yVIWUufSrJBtB1hXSu3/zXwlcrXwihycTbjmc9L+3ukDXwa3JkEMJgrYPVNZQy/iEc6u9HbGEQv2ld60BtDuUagZvMgJfiinFq6D/BXxvdeCOo1TE2NrDvHrhUC67G0pT40vYgfa/Y5o/JYemu/MhRuj/rW/g1LZ+9vUOXhXuDDPSzGUueRJUmAOzDUkcsihHpFH6NlgQ9Adn+cUod9pw/z1EsUltroyuMZC3qJzADt3dXdEmiYDV0sw0B5oSE3v9Sm4nm+02hC0OL12xBisPXZR7FyxLHEW983XXGsomTX4f9rsdHVkaDv9ObI/pzbClYgFsWwj46xqt/rExZ550IExtUnh1CpXz2UD57m9AoLYph7bV21+0c48lMUwh/m7AYLXuBtAm7vPGA0mJWVei5Iuw5XIr+dNhg+IS+LWsjBKQis2UrqDLBNWYMGnlg0HLye6qIuPRiNb5quMfzx63KUygMHwkcG+/L9+7a7iA13/guMVNNEqjc8Ibe7Ikj33uc56rW+WVPF9MI9ITQsOOwTsW1cdx7856e+iYhs+WIs5da8llGrwaqbXuniSy5INbrG/E75+lu9iceptdt9853jL2giWiP7+jaQjqkV2zIHGtk4IulWZ+6myk/i+YUrxHiU5oEXeS+KJZxSXjvvZcGzmNS+b02ueD01ax6Q== git@gitlab 说明之前为 root 和 git 添加的 ssh key 都被保存到宿主机.`},{header:"第八部分，总结",slug:"第八部分-总结",content:`一定要为当前执行ssh的用户添加相应的权限，包括和目标服务器的连接.
四部分:
1.add known-hosts
2.generate SSH key
3.copy SSH key
4.grant role`}]},{path:"/content/service/docker/gitlab%E4%B9%8Bserver%E7%AB%AFhook%E9%85%8D%E7%BD%AE.html",title:"gitlab之server端hook配置",pathLocale:"/",contents:[{header:"gitlab之server端hook配置，主要有两种方式",slug:"gitlab之server端hook配置-主要有两种方式",content:`server端，全局配置
server端，为指定仓库配置`},{header:"本次我通过为指定仓库配置",slug:"本次我通过为指定仓库配置",content:`1.进入docker容器
docker exec -it gitlab bash 2.找到目标仓库
由于 GitLab 启用了 hashed storage，仓库不再是 group/project.git 结构，而是 @hashed/<hash>.git。可以用以下命令查找某个仓库的 hash 路径
ls -l /var/opt/gitlab/git-data/repositories/@hashed/ 我的实际操作, 进入到指定目录:
root@gitlab:/var/opt/gitlab/git-data/repositories/@hashed/d4/73# ls
d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.wiki.git 3.创建 custom_hooks 目录
cd d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git
mkdir -p custom_hooks 然后:
cd custom_hooks 4.创建 Hook 脚本
1>创建 pre-receive hook
vim pre-receive
写入如下内容:
#!/bin/bash
while read oldrev newrev refname; do if [[ "$refname" == "refs/heads/main" ]]; then echo "$(date '+%Y-%m-%d %H:%M:%S') - Push to main branch detected: $newrev" >> /var/log/gitlab/custom_hooks.log fi
done 内容分析:
Git 会通过 标准输入 (stdin) 传递每个推送的分支信息，格式如下：
<旧提交哈希> <新提交哈希> <引用名称> 例如:
1234567 abcdef0 refs/heads/main 然后给这个custom_hooks目录权限，如下，修改为git用户以及用户组(GitLab 作为一个托管 Git 仓库的服务，所有与 Git 操作相关的进程（如 git push 触发的服务器端钩子）都是 以 git 用户身份 运行的，而不是 root 或其他用户)，同时给读写权限:
chown -R git:git /var/opt/gitlab/git-data/repositories/@hashed/d4/73/d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git/custom_hooks
chmod -R 775 /var/opt/gitlab/git-data/repositories/@hashed/d4/73/d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git/custom_hooks 2>本地推代码到仓库，编辑器日志可能会报:
remote: /var/opt/gitlab/git-data/repositories/@hashed/d4/73/d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git/custom_hooks/pre-receive: line 4: /var/log/gitlab/custom_hooks.log: Permission denied error: failed to push some refs to 'ssh://gitlab.example.com:9022/front/laravel-15.git'
To ssh://gitlab.example.com:9022/front/laravel-15.git
!	refs/heads/main:refs/heads/main	[remote rejected] (pre-receive hook declined)
Done 分析:
pre-receive Hook 试图向 /var/log/gitlab/custom_hooks.log 写入日志，但权限不足，导致 GitLab 阻止了推送。 解决方案:
确保 custom_hooks.log 文件存在
ls -l /var/log/gitlab/custom_hooks.log
如果不存在，执行:
touch /var/log/gitlab/custom_hooks.log 赋予权限:
chown git:git /var/log/gitlab/custom_hooks.log
chmod 664 /var/log/gitlab/custom_hooks.log 3>本地再次推代码到仓库，然后打开日志可以发现如下内容
2025-03-03 15:32:48 - Push to main branch detected: 60928f4edb1fb6dc7476b5de396543e81ca92f40 说明，hook被触发 4>实际开发过程中，配置 post-receive 会比较多一些，比如我的配置，记录 推送者的用户名，可以用 $GL_USERNAME（GitLab 变量）:
#!/bin/bash
while read oldrev newrev refname; do if [[ "$refname" == "refs/heads/main" ]]; then echo "$(date '+%Y-%m-%d %H:%M:%S') - User: $GL_USERNAME pushed to main: $newrev" >> /var/log/gitlab/custom_hooks.log fi
done 然后可以在日志下看到:
2025-03-03 15:47:20 - User: root pushed to main: 00d8d9ff4368e460e93c5481ac9a3f78625b5e04`}]},{path:"/content/service/docker/hub_docker%E5%92%8Cregistry_docker%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"hub_docker和registry_docker的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`https://hub.docker.com/和https://registry-1.docker.io的关系:
https://registry-1.docker.io 实际上就是 Docker Hub 的地址。https://hub.docker.com/ 是 Docker Hub 的 Web 页面（用于浏览镜像、查看文档等），而 https://registry-1.docker.io 是 Docker Hub 的 API 接口，也就是 Docker 守护进程用来实际拉取镜像的地址。
Docker 引擎只需要访问镜像仓库的 API 来拉取镜像，而不是访问网站页面。因此，Docker 配置文件中指定的镜像地址是 API 地址 (https://registry-1.docker.io)，而不是网站的浏览器地址 (https://hub.docker.com/)。
使用:
vim /etc/docker/daemon.json
{ "registry-mirrors": ["https://<your-mirror-url>"]
}`}]},{path:"/content/service/docker/mysql8%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2%E7%AB%AF%E5%8F%A3%E4%BB%8B%E7%BB%8D.html",title:"mysql8容器服务暴露端口介绍",pathLocale:"/",contents:[{header:"",slug:"",content:`mysql8容器服务暴露端口介绍:
33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp
包含了三个部分：
1.33060/tcp:
这是MySQL的X Protocol端口。X Protocol是MySQL 5.7.12及更高版本引入的一个新的协议，用于支持MySQL文档存储等新特性。这个端口默认是暴露的，但没有被映射到主机上。 2.0.0.0.0:3307->3306/tcp:
这是您设置的端口映射。它表示容器内的3306端口（MySQL的默认端口）被映射到主机的3307端口上。0.0.0.0意味着它在主机的所有网络接口上都可以访问。 3.:::3307->3306/tcp:
这与第二项本质上是相同的，但是针对IPv6。:::是IPv6的简写形式，表示所有IPv6接口。 X Protocol端口（33060）主要用于MySQL的新特性和高级功能。以下是X Protocol的一些主要用途：
文档存储：
支持JSON文档的存储和操作，使MySQL能够作为一个文档数据库使用。
CRUD操作：
提供了一种更有效的方式来执行创建、读取、更新和删除操作，尤其是对于复杂的数据结构。
支持多种编程语言：
X Protocol设计用于支持多种编程语言的连接器，如Python、JavaScript、Java等。
异步操作：
支持异步编程模型，可以提高应用程序的性能和可伸缩性。
改进的安全性：
包含了一些安全增强功能，如更好的身份验证机制。
压缩通信：
支持客户端和服务器之间的通信压缩，可以减少网络带宽使用。
会话复用：
允许多个逻辑会话共享同一个网络连接，potentially提高性能。
新的API：
提供了一组新的API，使开发人员能够更灵活地与MySQL交互。 虽然X Protocol提供了这些高级功能，但对于传统的关系型数据库操作，使用标准的MySQL协议（端口3306）通常就足够了。X Protocol主要面向需要利用MySQL新特性或追求更高性能的高级用户和开发者。 关于 mysql x plugin：
https://www.percona.com/blog/understanding-mysql-x-all-flavors/
http://mysql.taobao.org/monthly/2021/02/07/ //很早以前关注过taobao的数据库月报`}]},{path:"/content/service/docker/nginx%E7%9A%84docker%E7%89%88%E6%9C%AC%E4%BB%A3%E7%90%86.html",title:"nginx的docker版本代理",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx的docker版本代理:
最近在使用docker搭建php开发环境的时候，使用到了jwilder/nginx-proxy 镜像，查了看了相关的文档之后，发现这个镜像服务还是很牛逼的
官网: https://hub.docker.com/r/jwilder/nginx-proxy/ Docker 的自动化 Nginx 反向代理:
http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/ 关于使用jwilder/nginx-proxy的一些细节记录:
1.本质上来说jwilder/nginx-proxy是一个nginx代理，可用来代理任何服务，像redis nginx es等
2.配置的时候需要配置一个VIRTUAL_HOST，用来定义该服务的虚拟主机地址
3.示例分析，假如有如下docker-compsoe.yml 的部分配置 mailcatcher: restart: always image: schickling/mailcatcher container_name: "\${APP_NAME}-mailcatcher" environment: VIRTUAL_HOST: "\${MAIL_HOST}" VIRTUAL_PORT: 1080 ports: - "\${MAIL_PORT}:1080" - "\${MAIL_SMTP_PORT}:1025" networks: - network-internal mailcatcher 服务配置说明:
1>. restart: always
容器在停止后会自动重启。
常用于开发环境，确保服务始终运行。 2>. image: schickling/mailcatcher
使用 Docker 镜像 schickling/mailcatcher。
这个镜像提供了一个轻量级的邮件捕获服务，可以通过 Web 界面查看邮件。 3>. container_name: "\${APP_NAME}-mailcatcher"
定义容器名称。
使用环境变量 \${APP_NAME} 动态设置容器的名称，方便区分不同应用。 4>. environment
配置环境变量：
VIRTUAL_HOST：定义该服务的虚拟主机地址，用 \${MAIL_HOST} 动态设置。
VIRTUAL_PORT：定义该服务的虚拟主机端口（HTTP），默认映射到 1080 端口，用于访问 MailCatcher 的 Web 界面。 5>. ports
映射容器内部端口到主机端口：
\${MAIL_PORT}:1080：将 MailCatcher 的 Web 界面端口（1080）映射到主机端口 \${MAIL_PORT}，方便浏览器访问。
\${MAIL_SMTP_PORT}:1025：将 SMTP 端口（1025）映射到主机端口 \${MAIL_SMTP_PORT}，供应用程序发送邮件。 6>. networks
指定使用的 Docker 网络：
network-internal：将 MailCatcher 服务连接到 network-internal 网络，供其他服务（如应用容器）通过内部网络访问。 7>注意事项，如果定义了VIRTUAL_PORT和ports，那么一定要把VIRTUAL_PORT和ports里的对内端口配置一致，比如这里都是1080，如果不一致的话，
ports下的对内端口会覆盖VIRTUAL_PORT的端口，那么导致用过代理访问不生效，但是通过ports访问的生效。
可以只配置VIRTUAL_HOST和VIRTUAL_PORT，而不配置ports，那么只能通过代理访问，反之，如果只配置了ports和VIRTUAL_HOST，那么只能通过VIRTUAL_HOST加port直接访问。 对于网络 network-internal 这个需要和代理服务配置一致，用于代理服务和服务的通信，一般会给代理配置多个network，比如:
networks: network-front: network-internal:
我发现代理默认会使用network-front对外提供访问，实际上对于代理服务和具体的服务可以使用一个network就可以了，比如这里的network-internal，给代理服务取多个的目的，
我想应该是做个区分，一个对外一个对内，其实使用的时候，可以只配置一个。 8>对于里面的环境变量，可以在和docker-compose.yml文件同级目录下定义一个.env,比如:
APP_NAME=myapp
MAIL_HOST=mail.local
MAIL_PORT=1081
MAIL_SMTP_PORT=1026 9>.相关命令
//查看创建的网络
$ docker network ls
NETWORK ID NAME DRIVER SCOPE
c4005c2f14bb bridge bridge local
517c59df10ca docker_network-front bridge local
4223ab92f098 docker_network-internal bridge local 分析:
自动创建网络：
docker_network-front 和 docker_network-internal 都是由 Docker Compose 根据你的 docker-compose.yml 文件自动创建的桥接网络。
它们的命名规则是：<项目名>_<网络名>，这里的项目名是 docker，可能是你运行 docker-compose 时所在目录的名称或通过 -p 参数指定的项目名称。 默认网络作用域：
这些网络的作用域是 local，即它们仅限于当前 Docker 主机中使用。 桥接模式： 这两个网络的驱动是 bridge，表示它们是 Docker 的桥接网络（默认网络类型）。 //删除网络
$ docker network rm docker_network-front docker_network-internal //网络和哪些容器相连
$docker network inspect network-front
$docker network inspect network-internal //查看容器的网络连接
$docker inspect <nginx-proxy-container-name>`}]},{path:"/content/service/docker/php%E4%B9%8Bdocker%E5%AE%B9%E5%99%A8%E5%AE%89%E8%A3%85php%E6%8B%93%E5%B1%95.html",title:"php之docker容器安装php拓展",pathLocale:"/",contents:[{header:"php之docker容器安装php拓展",slug:"php之docker容器安装php拓展",content:`关于 docker-php-ext-install:
docker-php-ext-install 是官方 PHP Docker 镜像自带的工具脚本，专门用于安装 PHP 的内置扩展（bcmath、intl、xsl、gd、pdo_mysql 等等） # build images (will actually only build if images not yet built or if something changed)
echo "Building Docker images..."
docker compose build nginx
docker compose build --no-cache php //不使用缓存， 但是没用
docker compose build solr 直接进入php容器里执行:
docker-php-ext-install bcmath //这也是可以安装成功的，但是不能立即生效，所以需要重启docker,但是之前的安装可能丢失 在容器里查看脚本路径:
root@d7842b65ff32:/var/www# cd /usr/local/bin
root@d7842b65ff32:/usr/local/bin# ls
composer docker-php-ext-configure docker-php-ext-install pear pecl phar.phar php-config wkhtmltoimage
docker-php-entrypoint docker-php-ext-enable docker-php-source peardev phar php phpize wkhtmltopdf`},{header:"能使用 docker-php-ext-install 直接安装的拓展有",slug:"能使用-docker-php-ext-install-直接安装的拓展有",content:`扩展名
说明
常见依赖 bcmath
高精度数学运算
无 bz2
bzip2 压缩支持
libbz2-dev calendar
日历计算函数
无 ctype
字符检测函数
无 curl
cURL 支持
libcurl4-openssl-dev dba
数据库抽象层
取决于后端 dom
DOM XML 支持
libxml2-dev exif
图片 EXIF 元数据
无 fileinfo
文件信息支持
无 ftp
FTP 支持
无 gd
图像处理
libpng-dev、libjpeg-dev、libfreetype6-dev gettext
GNU gettext
libgettextpo-dev gmp
大整数运算
libgmp-dev iconv
字符集转换
无 intl
国际化
libicu-dev json
JSON 处理（PHP7.2+ 内置，通常无需装）
无 ldap
LDAP 访问
libldap2-dev mbstring
多字节字符串
无 mysqli
MySQLi
无 pdo
PDO 基础
无 pdo_mysql
PDO MySQL
无 pdo_pgsql
PDO PostgreSQL
libpq-dev pdo_sqlite
PDO SQLite
无 pgsql
PostgreSQL 扩展
libpq-dev phar
Phar 打包
无 posix
POSIX 支持
无 session
会话管理
无 shmop
共享内存
无 simplexml
SimpleXML
libxml2-dev soap
SOAP 客户端/服务端
libxml2-dev sockets
Socket 支持
无 sysvmsg
System V 消息队列
无 sysvsem
System V 信号量
无 sysvshm
System V 共享内存
无 tokenizer
PHP 代码解析
无 xml
XML 基础
libxml2-dev xmlreader
XML 读取
libxml2-dev xmlwriter
XML 写入
libxml2-dev xsl
XSLT 转换
libxslt1-dev zip
ZIP 压缩
libzip-dev opcache
字节码缓存
无`},{header:"需要使用 pecl install 安装的有",slug:"需要使用-pecl-install-安装的有",content:`扩展名
说明
安装示例 redis
Redis 客户端
pecl install redis && docker-php-ext-enable redis xdebug
PHP 调试工具
pecl install xdebug && docker-php-ext-enable xdebug imagick
ImageMagick 图像处理
需要先装 libmagickwand-dev mongodb
MongoDB 驱动
pecl install mongodb apcu
APC 用户缓存
pecl install apcu yaml
YAML 解析
需要 libyaml-dev memcached
Memcached 客户端
需要 libmemcached-dev amqp
RabbitMQ 客户端
需要 librabbitmq-dev grpc
gRPC 支持
pecl install grpc uv
libuv 事件循环
pecl install uv`},{header:"目前 php 镜像DockerFile配置(部分)",slug:"目前-php-镜像dockerfile配置-部分",content:`RUN sed -i 's|deb.debian.org|archive.debian.org|g' /etc/apt/sources.list \\
&& sed -i '/security.debian.org/d' /etc/apt/sources.list \\
&& apt-get update \\
&& apt-get install -y \\
libxslt1-dev \\
libmagickwand-dev --no-install-recommends \\
libzip-dev \\
&& docker-php-ext-install xsl \\
&& docker-php-ext-install bcmath \\
&& pecl install imagick \\
&& docker-php-ext-enable imagick \\
&& docker-php-ext-install zip \\
&& rm -rf /var/lib/apt/lists/*`},{header:"为什么有的扩展必须用 pecl？",slug:"为什么有的扩展必须用-pecl",content:`PHP 官方源码包（php-src）里并没有这些扩展的源码。
这些扩展是第三方维护的，独立版本更新，不随 PHP 发布绑定。
Docker 镜像的 /usr/src/php/ext 目录里找不到它们。`}]},{path:"/content/service/docker/php%E4%B9%8B%E5%AE%98%E6%96%B9docker%E9%95%9C%E5%83%8F%E4%BB%8B%E7%BB%8D.html",title:"php之官方docker镜像介绍",pathLocale:"/",contents:[{header:"php之官方docker镜像介绍",slug:"php之官方docker镜像介绍",content:""},{header:"1.gitHub 仓库",slug:"_1-github-仓库",content:`官方 Docker 镜像的构建脚本和配置
这里包含用于生成 PHP 官方 Docker 镜像所需的 Dockerfile 模板、版本配置、以及相关的辅助脚本，比如 docker-php-ext-install、docker-php-ext-configure、docker-php-ext-enable 等 (GitHub)。 维护 “official images” 生态的一环
它是 Docker 官方镜像项目（Official Images）的一部分。这个项目由 docker-library/official-images 和 docker-library/docs 等仓库协同工作。docker-library/php 提供 PHP 镜像的源码和构建逻辑，而 official-images 管理镜像标签、架构和生成机制，docs 包含镜像的说明文档 (GitHub)。 提供辅助构建工具
仓库中还包括了构建过程中使用的脚本，如 apply-templates.sh, versions.sh, update.sh 等，确保镜像构建版本一致、支持多架构，并可以自动化生成 Docker Hub 上的 README 和标签 (GitHub)。`},{header:"2.docker 镜像",slug:"_2-docker-镜像",content:`https://hub.docker.com/_/php/ 这是最主要、最可信赖的 PHP 官方镜像库，由 Docker 社区管理维护，包含多种 PHP 版本及构建变体，适用于不同的使用场景，如 CLI、FPM、Apache，或基于不同 Linux 发行版 (Debian、Alpine) 构建的镜像。 官方镜像提供多个标签形式，常见包括： php:8.4, php:8.3, php:8.2 … —— 指定 PHP 主版本。
php:8.4-apache, php:8.4-fpm, php:8.4-cli —— 指定运行模式（如 Apache 模式、FPM 模式、命令行模式）。
php:8.4-apache-bullseye, php:8.4-fpm-buster —— 基于 Debian Bullseye 或 Buster 的镜像；如果省略，如 php:apache，则通常对应当前最新的稳定 Debian 版本。 目前查看官网最新维护的有： alpine3.21 , alpine3.22 , bookworm , trixie 这四个， 之前使用过buster, 但是 buster 已经被archive了, 需要使用特殊的配置才能继续使用， 但是还可以使用 bullseye. 不过后面应该也不能继续直接使用了`},{header:"3.Debian 系列（如 buster、bullseye），Alpine（轻量版） 怎么理解？",slug:"_3-debian-系列-如-buster、bullseye-alpine-轻量版-怎么理解",content:`Debian 系列（buster、bullseye） 和 Alpine（轻量版），其实是指 PHP 官方 Docker 镜像的底层基础操作系统，就像房子下面的地基。
解释一下：`},{header:"1>. Debian 系列（buster、bullseye）",slug:"_1-debian-系列-buster、bullseye",content:`Debian 是一个稳定的 Linux 发行版，很多服务器系统（比如 Ubuntu）都基于它。 buster 和 bullseye 是 Debian 的版本代号： buster → Debian 10（较老）
bullseye → Debian 11（较新，官方目前主推）
（再新的是 bookworm → Debian 12） 特点： 体积中等（比 Alpine 大很多）。
软件包比较全，兼容性好。
更适合安装需要很多系统依赖的 PHP 扩展（比如 gd、intl、imagick）。 例子：
php:8.3-fpm-bullseye # PHP 8.3 + FPM + Debian 11
php:8.3-cli-buster # PHP 8.3 + CLI + Debian 10`},{header:"2>. Alpine（轻量版）",slug:"_2-alpine-轻量版",content:`Alpine Linux 是一个非常小巧的 Linux 发行版。 默认体积非常小（官方 PHP Alpine 镜像通常在 15~30MB 左右）。 特点： 镜像小 → 下载、部署快。
运行时占用低。
但是有时候编译 PHP 扩展会比较麻烦，因为 Alpine 使用的是 musl 而不是 glibc，一些扩展可能需要额外 patch 或依赖。 例子：
php:8.3-fpm-alpine # PHP 8.3 + FPM + Alpine
php:8.3-cli-alpine3.18 # 指定 Alpine 版本`},{header:"3>. 对比总结",slug:"_3-对比总结",content:`特性
Debian 系列（buster/bullseye）
Alpine（轻量版） 镜像大小
大（80~150MB）
小（15~30MB） 安装依赖
简单，APT 包全
有时复杂，需要 APK 或编译 性能
稳定
内存占用更少，但编译有坑 适用场景
功能齐全、依赖多
极简环境、追求体积 选择建议： 初学/大多数业务场景 → 用 Debian（bullseye），省心。 极致轻量或熟悉 Alpine 生态 → 用 Alpine（适合云函数、小镜像部署）。`},{header:"4.PHP 官方 Docker 镜像目前底层主要就支持这两种系统系",slug:"_4-php-官方-docker-镜像目前底层主要就支持这两种系统系",content:`Debian 系列（不同版本代号：buster、bullseye、bookworm）
Alpine 系列（不同版本号：alpine3.18、alpine3.19 等）`},{header:"📌 原因",slug:"📌-原因",content:`官方维护成本
PHP 官方镜像是 Docker 官方库（docker-library/php）维护的，如果同时支持很多底层发行版（比如 Ubuntu、CentOS、Fedora），维护、构建、测试成本会非常高。 兼容性 Debian 系列稳定性高、依赖齐全，适合大多数业务。
Alpine 轻量、启动快，适合追求极致镜像体积的场景。
这两种基本覆盖了常见需求。 技术路线
Debian + Alpine 已经能覆盖： 全功能 + 高兼容性（Debian）
轻量化部署（Alpine）`},{header:"当前可见的变体",slug:"当前可见的变体",content:`（以 PHP 8.3 为例） 标签
底层系统 php:8.3, php:8.3-bullseye, php:8.3-fpm, php:8.3-apache
Debian 11 (bullseye) php:8.3-buster, php:8.3-fpm-buster
Debian 10 (buster) php:8.3-bookworm, php:8.3-fpm-bookworm
Debian 12 (bookworm) php:8.3-alpine, php:8.3-fpm-alpine3.18
Alpine 3.18 / 3.19 💡 换句话说： 要稳定、依赖好装 → 用 Debian 变体（bullseye / bookworm）
要极致轻量 → 用 Alpine 变体（alpine3.x）`},{header:"查看PHP 容器的操作系统类型（以及版本）",slug:"查看php-容器的操作系统类型-以及版本",content:`进入php 容器实行:
# cat /etc/os-release 我的:
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/" 分析:
这个PHP 容器底层操作系统是 Debian 12（Bookworm）。
从提供的信息可以看出： 字段
值
含义 PRETTY_NAME
Debian GNU/Linux 12 (bookworm)
人类可读的完整系统名称 NAME
Debian GNU/Linux
系统名称 VERSION_ID
12
版本号 VERSION
12 (bookworm)
版本信息 VERSION_CODENAME
bookworm
Debian 代号 ID
debian
系统 ID，用于脚本识别 HOME_URL / SUPPORT_URL / BUG_REPORT_URL
官方网站和支持链接
官方资源链接 💡 总结： PHP 镜像基于 Debian Bookworm。
这是当前 Debian stable（稳定版），官方镜像推荐在生产环境中使用。
相比 Alpine 镜像，Bookworm 镜像更大，但兼容性和稳定性更好。
如果安装 PHP 扩展，可以直接使用 docker-php-ext-install、docker-php-ext-configure 等工具，无需额外处理源码目录（非 Alpine 镜像通常自带 /usr/src/php/ext）。`},{header:"Debian vs Alpine PHP 官方镜像对比表",slug:"debian-vs-alpine-php-官方镜像对比表",content:`🐘 PHP 官方镜像底层对比：Debian vs Alpine 特性
Debian 系列（buster/bullseye/bookworm）
Alpine 系列 镜像体积
中等，约 80~150MB
极小，约 15~30MB 包管理
APT (apt-get)
APK (apk) 默认 libc
glibc
musl 扩展安装
大部分扩展开箱即用，兼容性高
某些扩展可能需要额外依赖和 patch 稳定性
高，适合生产环境
较高，但部分扩展可能遇到兼容问题 启动速度
中等
快（轻量） 适用场景
- 稳定生产服务- 需要完整依赖支持的项目- 容器大小不是首要考虑
- 极致轻量化部署- CI/CD 快速拉取镜像- 云函数 / 微服务环境 默认 PHP 官方镜像
php:8.3-fpm-bullseyephp:8.3-cli-bullseye
php:8.3-fpm-alpine3.18php:8.3-cli-alpine3.18 维护便利性
高，文档和社区案例多
中，需要熟悉 Alpine 生态 💡 选择建议 优先稳定和兼容性 → Debian 系列
追求最小镜像体积 / 快速部署 → Alpine 系列
新项目建议： 不在乎镜像体积 → Debian bullseye 或 bookworm
极致轻量 → Alpine 3.x 使用版本格式 alpine:
php:<php_version>-<sapi>-<alpine_version> php:8.3-fpm-alpine3.17 # 基于 Alpine 3.17
php:8.3-fpm-alpine3.18 # 基于 Alpine 3.18
php:8.3-fpm-alpine3.19 # 基于 Alpine 3.19 debian:
php:<php_version>-<sapi>-<debian_codename> php:8.3-fpm-bullseye → PHP 8.3 + FPM + Debian 11 (bullseye)
php:8.3-fpm-buster → PHP 8.3 + FPM + Debian 10 (buster)
php:8.3-fpm-bookworm → PHP 8.3 + FPM + Debian 12 (bookworm)`},{header:"关于镜像的SAPI",slug:"关于镜像的sapi",content:"在 PHP 官方镜像里，CLI 和 FPM 是两种不同的 SAPI（Server API）："},{header:"1>. SAPI 的概念",slug:"_1-sapi-的概念",content:`SAPI = Server API，表示 PHP 与外部环境交互的方式。
不同 SAPI 决定了 PHP 的运行模式和用途。`},{header:"2>. 常见 SAPI 类型",slug:"_2-常见-sapi-类型",content:`PHP 官方镜像 SAPI 对照图，把 CLI、FPM、Apache 的关系、用途和特点一目了然地展示出来：
+----------------------+---------------------+-------------------------+
| SAPI 类型 | 官方镜像标签 | 用途 / 特点 |
+----------------------+---------------------+-------------------------+
| CLI (Command Line) | php:<version>-cli | - 命令行脚本运行 |
| | | - Cron / CI / 工具 |
| | | - 无 Web 服务 |
+----------------------+---------------------+-------------------------+
| FPM (FastCGI) | php:<version>-fpm | - 配合 Nginx / Apache |
| | | - 高并发 Web 请求处理 |
| | | - 多进程并发 |
+----------------------+---------------------+-------------------------+
| Apache Module | php:<version>-apache| - PHP 内嵌 Apache |
| | | - 内置 Web 服务器 |
| | | - 开发/小型部署 |
+----------------------+---------------------+-------------------------+ 说明： SAPI（Server API） 决定了 PHP 与外部环境交互的方式，不同 SAPI 影响运行模式和用途。
CLI → 只做脚本，不处理 Web 请求。
FPM → 专为 Web 服务设计，配合反向代理服务器（Nginx/Apache）使用，支持高并发。
Apache Module → PHP 直接嵌入 Apache，适合开发或小型部署，性能和扩展性略低于 FPM + Nginx。 总结： PHP 官方镜像里 CLI 和 FPM 就是 两种不同 SAPI。
选择哪个 SAPI，取决于你是做 脚本/工具 还是 Web 服务。`}]},{path:"/content/service/docker/ubuntu22%E4%B8%8B%E4%BD%BF%E7%94%A8docker.html",title:"ubuntu22下使用docker",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22下使用docker:
1>端口映射关系，也适用于直接docker run -p host_port:container_port https://juejin.cn/s/docker-compose.yml%20%E7%AB%AF%E5%8F%A3 2>docker 命名卷
默认情况下,命名卷在大多数 Linux 发行版中存储在主机文件系统的 /var/lib/docker/volumes 目录下
比如:
volumes: - volume-mysql-duoxiaozhan:/var/lib/mysql //声明 命名卷，然后挂载到 /var/lib/mysql，用来存储mysql数据，这样即使容器销毁数据还在
在 Linux 上: /var/lib/docker/volumes/volume-mysql-duoxiaozhan/_data 3>为docker-compose 配置环境变量
https://docs.docker.com/compose/environment-variables/set-environment-variables/ 4>关于jwilder/nginx-proxy
http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/ 5>现在可以直接使用 docker compose build , 过去需要使用 docker-compose build
对于新版 Docker(19.03+),只需安装 Docker Engine 即可使用 docker compose 命令
对于旧版 Docker,需要先安装 Docker Engine,再单独安装 docker-compose 还有一点很重要:
过去在当前 docker-compose.yml目录下执行 docker-compose up，如果镜像不存在，会自动执行 docker-compose build [可以加单独镜像名称，比如nginx]命令
现在必须要先执行 docker compose build [可以加单独镜像名称，比如nginx], 然后单独执行 docker compose up [-d参数]， 使用 -d 标志启动容器,表示以"分离(detached)"模式运行。
分离模式意味着容器将在后台运行,而不会将它们的输出流(标准输出和标准错误)连接到您的终端。 6>执行 docker image ls，报下面的错误
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Head ...... 原因是:
这是因为你当前的用户没有这个权限。默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。即我们当前的用户不是root用户。 解决办法：把我们当前的用户添加到docker组中就可以了，这样他们就是一家人了。 第一步：sudo gpasswd -a username docker #将普通用户username加入到docker组中，username这个字段也可以直接换成$USER。
第二步：newgrp docker #更新docker组
第三步：再执行你报错的命令，此时就不会报错了。 7>docker 容器内执行vim
root@b8c739f8b2b3:/app# apt-get update
root@b8c739f8b2b3:/app# apt-get install -y vim https://blog.csdn.net/hkl_Forever/article/details/125466251 8>docker容器内导入数据
root@bf42367264b4:/dumps# mysql -u duoxiaozhan -p duoxiaozhanpub_dev < /dumps/duoxiaozhanpub.sql
Enter password: ERROR 1118 (42000) at line 1739814: Row size too large (> 8126). Changing some columns to TEXT or BLOB or using ROW_FORMAT=DYNAMIC or ROW_FORMAT=COMPRESSED may help. In current row format, BLOB prefix of 768 bytes is stored inline. 解决方式: 找到对应表DML，把 ROW_FORMAT=COMPACT 改为 ROW_FORMAT=DYNAMIC:
DROP TABLE IF EXISTS \`users\`;
CREATE TABLE \`users\` ( \`id\` int unsigned NOT NULL AUTO_INCREMENT, \`editor_id\` int unsigned DEFAULT NULL, \`email\` char(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL, \`password\` char(80) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL,
) ENGINE=InnoDB AUTO_INCREMENT=2184475 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC; 至于网上的 各种设置都没用，其实就上面的提示就是解决方法 然后执行:
root@bf42367264b4:/dumps# ls
duoxiaozhanpub.sql tables
root@bf42367264b4:/dumps# mysql -u root -p duoxiaozhanpub_dev < /dumps/duoxiaozhanpub.sql
Enter password: root@bf42367264b4:/dumps# 导入完成 补充:
https://blog.csdn.net/guo_zhen_qian/article/details/132254406 //命令行安装(简单)
https://docs.docker.com/desktop/install/linux-install/ //安装desk版本
https://docs.docker.com/engine/install/ubuntu/ //安装engine版本 // docker-compose 安装, 新版本的docker 可以不用单独安装这个，可以直接使用，见上面的命令操作
sudo curl -L https://github.com/docker/compose/releases/download/v2.26.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
$ sudo chmod +x ./docker-compose //记得赋权限`}]},{path:"/content/service/docker/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAgitlab-runner%E5%8F%8A%E4%BD%BF%E7%94%A8.html",title:"使用docker搭建gitlab-runner及使用",pathLocale:"/",contents:[{header:"",slug:"",content:`使用docker搭建gitlab-runner及使用:
1>拉取镜像
guoshipeng@tianyi510s:~$ docker pull docker.1ms.run/gitlab/gitlab-runner:latest
latest: Pulling from gitlab/gitlab-runner
86e5016c2693: Pull complete 5194af8da5c7: Pull complete fdb3ce38ee35: Pull complete 7225e83a9762: Pull complete Digest: sha256:5e6a430ca17726c0fa67d4bde6faeb32e1eeb7f3a53284b2fb2952ccf2f12f35
Status: Downloaded newer image for docker.1ms.run/gitlab/gitlab-runner:latest
docker.1ms.run/gitlab/gitlab-runner:latest
guoshipeng@tianyi510s:~$ docker image tag docker.1ms.run/gitlab/gitlab-runner:latest gitlab/gitlab-runner:latest
guoshipeng@tianyi510s:~$ docker rmi docker.1ms.run/gitlab/gitlab-runner:latest 2>安装命令
docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest 3>查看运行状态
docker ps | grep gitlab-runner 4>注册runner(和gitlab关联), 官方镜像一直提示放弃使用registration-token，而使用AUTHENTICATION_TOKEN，但是一直没有找到AUTHENTICATION_TOKEN在呢里配置的 docker exec -it gitlab-runner gitlab-runner register \\ --url "YOUR_GITLAB_SERVER" \\ --token "YOUR_AUTHENTICATION_TOKEN" \\ --executor "docker" \\ --docker-image "alpine:latest" --url：你的 GitLab 地址（改成你自己的）
--token：在 GitLab 界面复制的 Authentication Token
--executor：GitLab Runner 的执行模式（如 docker、shell）
--docker-image：指定使用的 Docker 镜像（这里用 alpine:latest，你可以换成 ubuntu:latest 或其他） 关于token:
https://docs.gitlab.com/ee/security/tokens/index.html#runner-authentication-tokens-also-called-runner-tokens 只能尝试还是使用registration-token：
guoshipeng@tianyi510s:~$ docker exec -it gitlab-runner gitlab-runner register \\ --url "http://gitlab.example.com:9080/" \\ --registration-token a_RVyNwT6bNN9DvH2bvm \\ --executor "docker" \\ --docker-image "alpine:latest"
Runtime platform arch=amd64 os=linux pid=24 revision=690ce25c version=17.8.3
Running in system-mode. Enter the GitLab instance URL (for example, https://gitlab.com/):
[http://gitlab.example.com:9080/]: Enter the registration token:
[a_RVyNwT6bNN9DvH2bvm]: Enter a description for the runner:
[8446a748968a]: a runner for local gitlab
Enter tags for the runner (comma-separated):
tag1
Enter optional maintenance note for the runner: WARNING: Support for registration tokens and runner parameters in the 'register' command has been deprecated in GitLab Runner 15.6 and will be replaced with support for authentication tokens. For more information, see https://docs.gitlab.com/ee/ci/runners/new_creation_workflow ERROR: Registering runner... failed runner=a_RVyNwT status=couldn't execute POST against http://gitlab.example.com:9080/api/v4/runners: Post "http://gitlab.example.com:9080/api/v4/runners": dial tcp: lookup gitlab.example.com on 192.168.5.1:53: no such host
PANIC: Failed to register the runner. 这里尝试把url改为gitlab的容器地址:
$ docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' gitlab
172.17.0.4 $ docker exec -it gitlab-runner gitlab-runner register \\ --url "http://172.20.0.4:9080/" \\ --registration-token a_RVyNwT6bNN9DvH2bvm \\ --executor "docker" \\ --docker-image "alpine:latest" 还是有问题，查看docker网络
$ docker network ls
NETWORK ID NAME DRIVER SCOPE
fb9d0551c552 bridge bridge local
5319aeb64a2e host host local
7cbb16a986d6 laravel-dev-v2-external bridge local
fab0b27bf071 laravel-dev-v2_network-laravel-internal bridge local
e6742f9d2eb1 meta-dev-v2_network-meta-internal bridge local
331156baf737 minikube bridge local
62128f5c9c7c none null local 分别查看gitlab和gitlab-runner的网络，发现都是bridge,但是就是不能互相通信
$ docker inspect gitlab | grep -A 5 "Networks" "Networks": { "bridge": { "IPAMConfig": null, "Links": null, "Aliases": [ "8a4f7a01b396", $ docker inspect gitlab-runner | grep -A 5 "Networks" "Networks": { "bridge": { "IPAMConfig": null, "Links": null, "Aliases": [ "8446a748968a" $ docker network inspect bridge
[ { "Name": "bridge", "Id": "fb9d0551c552356cfa4995b2ef3b08ab9ed0a047ccb3718bc5cc86c741e827b7", "Created": "2025-02-09T21:16:38.148797896+08:00", "Scope": "local", "Driver": "bridge", "EnableIPv6": false, "IPAM": { "Driver": "default", "Options": null, "Config": [ { "Subnet": "172.17.0.0/16", "Gateway": "172.17.0.1" } ] }, "Internal": false, "Attachable": false, "Ingress": false, "ConfigFrom": { "Network": "" }, "ConfigOnly": false, "Containers": { "710c1256ac29156deb5c550f20ab450bce5ac64eb15524ea8f7d08964b058ada": { "Name": "alist", "EndpointID": "9761e9b19ef6ba76934e4c31f02b2baca1e2bd006fba5d22a4b923337e028897", "MacAddress": "02:42:ac:11:00:02", "IPv4Address": "172.17.0.2/16", "IPv6Address": "" }, "8446a748968a0deecb2fc212192716c4c6e184ef480fac02c421b09de9a2c79d": { "Name": "gitlab-runner", "EndpointID": "bf49157aeddc10d1527b18f02fb0456a55202fa0a217d3b6b22cd83f3f1af1a6", "MacAddress": "02:42:ac:11:00:04", "IPv4Address": "172.17.0.3/16", "IPv6Address": "" }, "8a4f7a01b396f322bafa16d67702eda8b71094bc814aa961b4544ba64a90b105": { "Name": "gitlab", "EndpointID": "e193a83211c18a7e2ee65b2b55f889f9266a2b3bbdea969ea6344c78984f5ad6", "MacAddress": "02:42:ac:11:00:03", "IPv4Address": "172.17.0.4/16", "IPv6Address": "" } }, "Options": { "com.docker.network.bridge.default_bridge": "true", "com.docker.network.bridge.enable_icc": "true", "com.docker.network.bridge.enable_ip_masquerade": "true", "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0", "com.docker.network.bridge.name": "docker0", "com.docker.network.driver.mtu": "1500" }, "Labels": {} }
] 5>网络问题分析
后来查询得知，在linux下,，需要把url配置为宿主机在局域网下的ip地址，通过如下命令可以获取本机的所有 IP 地址（IPv4 和 IPv6），但 不包括回环地址（如 127.0.0.1）。
$ hostname -I
192.168.5.17 192.168.49.1 172.17.0.1 172.18.0.1 172.20.0.1 172.19.0.1 通过 ip a 命令可以查看，这些 ip 对应的网卡:
$ ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever
2: enp3s0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc fq_codel state DOWN group default qlen 1000 link/ether f4:6b:8c:89:58:f6 brd ff:ff:ff:ff:ff:ff
3: wlp2s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether e0:0a:f6:78:3b:1d brd ff:ff:ff:ff:ff:ff inet 192.168.5.17/24 brd 192.168.5.255 scope global dynamic noprefixroute wlp2s0 valid_lft 77836sec preferred_lft 77836sec inet6 fe80::76cf:e344:df5b:cd7d/64 scope link noprefixroute valid_lft forever preferred_lft forever
4: br-331156baf737: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:39:32:14:79 brd ff:ff:ff:ff:ff:ff inet 192.168.49.1/24 brd 192.168.49.255 scope global br-331156baf737 valid_lft forever preferred_lft forever
...
...
...
可以确定:
wlp2s0（无线网卡）:
192.168.5.17 是当前设备在 局域网 (Wi-Fi) 中的 IP 地址。
这个地址是 动态分配的（dynamic），说明可能是从 DHCP 服务器（如你的路由器）获取的。
你可以使用 ping 192.168.5.17 从其他设备（同一局域网内）测试它是否可达。 br-331156baf737（Docker 网络桥）:
192.168.49.1 是 Docker 创建的网桥 (bridge network)，用于容器之间的通信。
可以用 docker network ls 确认它属于哪个 Docker 网络：
$ docker network ls | grep 331156baf737
331156baf737 minikube bridge local
可以看到
192.168.49.1 IP 地址是 Minikube 创建的 Docker 桥接网络 (bridge network)，通常用于 Minikube 虚拟机与本机的通信。
运行:
$ docker network inspect minikube
[ { "Name": "minikube", "Id": "331156baf737418aef246012c7ae1d0cbd10e92e005873b8b0054651e679656b", "Created": "2024-12-10T22:25:56.520372769+08:00", "Scope": "local", "Driver": "bridge", "EnableIPv6": false, "IPAM": { "Driver": "default", "Options": {}, "Config": [ { "Subnet": "192.168.49.0/24", "Gateway": "192.168.49.1" } ] }, "Internal": false, "Attachable": false, "Ingress": false, "ConfigFrom": { "Network": "" }, "ConfigOnly": false, "Containers": {}, "Options": { "--icc": "", "--ip-masq": "", "com.docker.network.driver.mtu": "1500" }, "Labels": { "created_by.minikube.sigs.k8s.io": "true", "name.minikube.sigs.k8s.io": "minikube" } }
]
会发现 "Gateway": "192.168.49.1"， 说明这个是minikube和宿主机通信的地址，关于上面的配置分析如下:
192.168.49.1 作为 Minikube 内部网络的网关，主要用于 Minikube 虚拟机（或容器）与宿主机之间的通信。 通信原理
Minikube 在 192.168.49.0/24 子网内创建一个网络： 网关地址：192.168.49.1
Minikube 虚拟机的 IP（通常是 192.168.49.2）
运行在 Minikube 内部的 Pod 可能分配到 192.168.49.x 其他地址
宿主机如何访问 Minikube 内部？ Ubuntu 主机 可以通过 192.168.49.1 访问 Minikube 虚拟机，前提是 Minikube 正在运行。
总结:
192.168.49.1 是 Minikube 内部网络的网关，Minikube 及其 Pod 通过它访问宿主机。
宿主机可以访问 Minikube 虚拟机的 minikube ip，Minikube 内部可以通过 192.168.49.1 访问宿主机。 6>使用下面的命令试一试
docker exec -it gitlab-runner gitlab-runner register \\ --url "http://192.168.5.17:9080/" \\ --registration-token a_RVyNwT6bNN9DvH2bvm \\ --executor "docker" \\ --docker-image "alpine:latest" 执行:
$ docker exec -it gitlab-runner gitlab-runner register \\ --url "http://192.168.5.17:9080/" \\ --registration-token a_RVyNwT6bNN9DvH2bvm \\ --executor "docker" \\ --docker-image "alpine:latest"
Runtime platform arch=amd64 os=linux pid=91 revision=690ce25c version=17.8.3
Running in system-mode. Enter the GitLab instance URL (for example, https://gitlab.com/):
[http://192.168.5.17:9080/]: Enter the registration token:
[a_RVyNwT6bNN9DvH2bvm]: Enter a description for the runner:
[8446a748968a]: a runner for local gitlab
Enter tags for the runner (comma-separated):
tag1
Enter optional maintenance note for the runner: WARNING: Support for registration tokens and runner parameters in the 'register' command has been deprecated in GitLab Runner 15.6 and will be replaced with support for authentication tokens. For more information, see https://docs.gitlab.com/ee/ci/runners/new_creation_workflow Registering runner... succeeded runner=a_RVyNwT
Enter an executor: kubernetes, instance, custom, shell, docker, docker-windows, docker+machine, ssh, parallels, virtualbox, docker-autoscaler:
[docker]: Enter the default Docker image (for example, ruby:2.7):
[alpine:latest]: Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! Configuration (with the authentication token) was saved in "/etc/gitlab-runner/config.toml" $ docker exec -it gitlab-runner gitlab-runner verify
Runtime platform arch=amd64 os=linux pid=114 revision=690ce25c version=17.8.3
Running in system-mode. Verifying runner... is alive runner=t1_UNMMA 上面的配置说明 gitlab-runner 已经注册成功，我直接打开gitlab CI/CD runners的时候，发现拉取runners失败，重启调脑，就可以了，说明要重启一个gitlab才行，下次注意
也可能是，我之前直接在gitlab CI/CD runners 下创建了一个runner(其实这个runner只是有一个初始信息，并没有和gitlab-runner关联，没什么实际意义，唯一的可能是，可以直接在gitlab-runner上关联这个命名好的runner吧，但是没有测试过。其实可以直接在启动的gitlab-runner上通过命令注册的，如下面所说), 后来又通过gitlab-runner注册的，通过gitlab-runner注册的,也可以填写一些关于runner的信息，我感觉这两种方式有冲突，导致的问题. 7>由于实际项目中，使用shell作为executor，所以这里要修改
# docker exec -it gitlab-runner /bin/bash
# apt update && apt install -y vim //已经是root用户，不需要sudo
# vim /etc/gitlab-runner/config.toml
concurrent = 1
check_interval = 0
shutdown_timeout = 0 [session_server] session_timeout = 1800 [[runners]] name = "a runner for local gitlab" url = "http://192.168.5.17:9080/" id = 4 token = "t1_UNMMAbUzz1k-_5zyzyQa" token_obtained_at = 2025-02-09T14:42:54Z token_expires_at = 0001-01-01T00:00:00Z executor = "docker" [runners.custom_build_dir] [runners.cache] MaxUploadedArchiveSize = 0 [runners.cache.s3] [runners.cache.gcs] [runners.cache.azure] [runners.docker] tls_verify = false image = "alpine:latest" privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = ["/cache"] shm_size = 0 network_mtu = 0 修改后为:
[[runners]] name = "your-runner-name" url = "http://your-gitlab-url" token = "your-registration-token" executor = "shell" # 更改为 shell 同时把runners.docker 相关的删除 保存,重启gitlab-runner:
docker restart gitlab-runner 8>实际使用过程中，gitlab的pipelines的job一直报
Running with gitlab-runner 17.8.3 (690ce25c) on a runner for local gitlab t1_UNMMA, system ID: r_iTJKxTxte9W9
Preparing the "shell" executor
00:00
Using Shell (bash) executor...
Preparing environment
00:00
Running on 8446a748968a...
Getting source from Git repository
00:00
Fetching changes with git depth set to 20...
Reinitialized existing Git repository in /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/.git/
fatal: unable to access 'http://gitlab.example.com/front/laravel-15.git/': Could not resolve host: gitlab.example.com
Cleaning up project directory and file based variables
00:00
ERROR: Job failed: exit status 1 设个问题说明tilab-runner在拉取gitlab的代码的时候，出了问题，重新进入到gitlab-runner容器，修改config.toml配置
# vim /etc/gitlab-runner/config.toml
concurrent = 1
check_interval = 0
shutdown_timeout = 0 [session_server] session_timeout = 1800 [[runners]] name = "a runner for local gitlab" url = "http://192.168.5.17:9080/" id = 4 token = "t1_UNMMAbUzz1k-_5zyzyQa" token_obtained_at = 2025-02-09T14:42:54Z token_expires_at = 0001-01-01T00:00:00Z executor = "shell" clone_url = "http://192.168.5.17:9080/" # 确保拉取代码时使用正确的 URL，加了这个确实可以了 [runners.custom_build_dir] [runners.cache] MaxUploadedArchiveSize = 0 [runners.cache.s3] [runners.cache.gcs] [runners.cache.azure] 现在pipelines中的job运行成功:
//默认的main分支
Running with gitlab-runner 17.8.3 (690ce25c) on a runner for local gitlab t1_UNMMA, system ID: r_iTJKxTxte9W9
Preparing the "shell" executor
00:00
Using Shell (bash) executor...
Preparing environment
00:00
Running on 8446a748968a...
Getting source from Git repository
00:04
Fetching changes with git depth set to 20...
Reinitialized existing Git repository in /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/.git/
Checking out 24a2c686 as detached HEAD (ref is main)...
Skipping Git submodules setup
Executing "step_script" stage of the job script
00:10
$ echo "Linting code... This will take about 10 seconds."
Linting code... This will take about 10 seconds.
$ sleep 10
$ echo "No lint issues found."
No lint issues found.
Cleaning up project directory and file based variables
00:00
Job succeeded //新增一个 feat/1001_get-user 分支
Running with gitlab-runner 17.8.3 (690ce25c) on a runner for local gitlab t1_UNMMA, system ID: r_iTJKxTxte9W9
Preparing the "shell" executor
00:00
Using Shell (bash) executor...
Preparing environment
00:00
Running on 8446a748968a...
Getting source from Git repository
00:01
Fetching changes with git depth set to 20...
Reinitialized existing Git repository in /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/.git/
Checking out c1367898 as detached HEAD (ref is feat/1001_get-user)...
Skipping Git submodules setup
Executing "step_script" stage of the job script
00:00
$ echo "Compiling the code..."
Compiling the code...
$ echo "Compile complete."
Compile complete.
Cleaning up project directory and file based variables
00:00
Job succeeded 至此，gitlab-runner成功运行起来，这是是一个基本的使用，还有关于网络部分的配置分析，我想重新来一个篇幅，还有配合=自定义的docker registory 使用的`}]},{path:"/content/service/docker/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAgitlab%E5%8F%8A%E4%BD%BF%E7%94%A8.html",title:"使用docker搭建gitlab及使用",pathLocale:"/",contents:[{header:"使用docker搭建gitlab-ce:",slug:"使用docker搭建gitlab-ce",content:""},{header:"三大步骤:",slug:"三大步骤",content:`1>配置镜像
$ docker pull docker.1ms.run/gitlab/gitlab-ce:latest
$ docker image tag docker.1ms.run/gitlab/gitlab-ce:latest gitlab/gitlab-ce:latest
$ docker rmi docker.1ms.run/gitlab/gitlab-ce:latest 2>安装
然后:
docker run --detach \\
--hostname gitlab.example.com \\
--publish 9080:80 --publish 9443:443 --publish 9022:22 \\
--name gitlab \\
--restart always \\
--volume /srv/gitlab/config:/etc/gitlab \\
--volume /srv/gitlab/logs:/var/log/gitlab \\
--volume /srv/gitlab/data:/var/opt/gitlab \\
gitlab/gitlab-ce:latest 先进入到容器:
docker exec -it gitlab bash
修改配置:
root@gitlab:/# vi /etc/gitlab/gitlab.rb
找到 external_url 'http://gitlab.example.com'
改为 external_url 'http://gitlab.example.com:9080' //注意如果使用https, external_url 'https://gitlab.example.com:9443' 然后执行:
root@gitlab:/# gitlab-ctl reconfigure 看到如下信息，代表配置完成
...
...
Running handlers:
[2025-02-06T16:14:56+00:00] INFO: Running report handlers
Running handlers complete
[2025-02-06T16:14:56+00:00] INFO: Report handlers complete
Infra Phase complete, 34/868 resources updated in 42 seconds Deprecations:
* git_data_dirs has been deprecated since 17.8 and will be removed in 18.0. See https://docs.gitlab.com/omnibus/settings/configuration.html#migrating-from-git_data_dirs for migration instructions. Update the configuration in your gitlab.rb file or GITLAB_OMNIBUS_CONFIG environment. gitlab Reconfigured!
root@gitlab:/#
root@gitlab:/# exit 3>宿主机配置
宿主机上，添加hosts文件:
127.0.0.1 gitlab.example.com 访问:
http://gitlab.example.com:9080 首次登录，使用 root 账户，密码存储在：
docker exec -it gitlab cat /etc/gitlab/initial_root_password $ docker exec -it gitlab cat /etc/gitlab/initial_root_password
# WARNING: This value is valid only in the following conditions
# 1. If provided manually (either via \`GITLAB_ROOT_PASSWORD\` environment variable or via \`gitlab_rails['initial_root_password']\` setting in \`gitlab.rb\`, it was provided before database was seeded for the first time (usually, the first reconfigure run).
# 2. Password hasn't been changed manually, either via UI or via command line.
#
# If the password shown here doesn't work, you must reset the admin password following https://docs.gitlab.com/ee/security/reset_user_password.html#reset-your-root-password. Password: kICRKydbHX69mkbeqgeA7fPbWDPdaLHl/5GnPRLSKks= 然后就登进去了... http://gitlab.example.com:9080/admin //可以查看管理面板 维护 GitLab
操作	命令
查看容器状态	docker ps -a
启动 GitLab	docker start gitlab
停止 GitLab	docker stop gitlab
重新启动 GitLab	docker restart gitlab
删除 GitLab 容器	docker rm -f gitlab 4>使用这个gitlab-ce
$ git clone git@gitlab.example.com:root/laravel-14.git
Cloning into 'laravel-14'...
ssh: connect to host gitlab.example.com port 22: Connection refused
fatal: Could not read from remote repository. Please make sure you have the correct access rights
and the repository exists. $ docker ps | grep gitlab
8a4f7a01b396 gitlab/gitlab-ce:latest "/assets/wrapper" 23 hours ago Up 40 minutes (healthy) 0.0.0.0:9022->22/tcp, :::9022->22/tcp, 0.0.0.0:9080->80/tcp, :::9080->80/tcp, 0.0.0.0:9443->443/tcp, :::9443->443/tcp gitlab # gitlab_rails['gitlab_shell_ssh_port'] = 22
打开默认注释,配置为:
gitlab_rails['gitlab_shell_ssh_port'] = 9022 root@gitlab:/# gitlab-ctl reconfigure
...
...
Running handlers:
[2025-02-07T15:30:13+00:00] INFO: Running report handlers
Running handlers complete
[2025-02-07T15:30:13+00:00] INFO: Report handlers complete
Infra Phase complete, 6/818 resources updated in 38 seconds Deprecations:
* git_data_dirs has been deprecated since 17.8 and will be removed in 18.0. See https://docs.gitlab.com/omnibus/settings/configuration.html#migrating-from-git_data_dirs for migration instructions. Update the configuration in your gitlab.rb file or GITLAB_OMNIBUS_CONFIG environment. gitlab Reconfigured! root@gitlab:/# gitlab-ctl restart
ok: run: alertmanager: (pid 3572) 1s
ok: run: gitaly: (pid 3590) 0s
ok: run: gitlab-exporter: (pid 3618) 0s
ok: run: gitlab-kas: (pid 3630) 0s
ok: run: gitlab-workhorse: (pid 3640) 0s
ok: run: logrotate: (pid 3665) 0s
ok: run: nginx: (pid 3672) 0s
ok: run: postgres-exporter: (pid 3696) 1s
ok: run: postgresql: (pid 3705) 0s
ok: run: prometheus: (pid 3716) 0s
ok: run: puma: (pid 3725) 0s
ok: run: redis: (pid 3738) 0s
ok: run: redis-exporter: (pid 3747) 0s
ok: run: registry: (pid 3754) 0s
ok: run: sidekiq: (pid 3781) 0s
ok: run: sshd: (pid 3791) 0s 退出gitlab容器 在宿主机 ~/.ssh/config 新增配置:
Host gitlab.example.com
HostName gitlab.example.com
User git
Port 9022
IdentityFile ~/.ssh/id_rsa 虽然之前已经添加了github的，仍然可以在后面继续添加 测试一下:
$ ssh -T git@gitlab.example.com
The authenticity of host '[gitlab.example.com]:9022 ([127.0.0.1]:9022)' can't be established.
ED25519 key fingerprint is SHA256:79UEk9sTgEkSKjTbJ5qdzc2iYRyYHMYr1z13GSngLIo.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '[gitlab.example.com]:9022' (ED25519) to the list of known hosts.
Welcome to GitLab, @root! 然后就就可以clone代码了:
$ git clone git@gitlab.example.com:root/laravel-14.git
Cloning into 'laravel-14'...
remote: Enumerating objects: 3, done.
remote: Counting objects: 100% (3/3), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (3/3), done. 其实也可以直接这样，不用在~/.ssh/config下添加配置，适合临时执行的:
GIT_SSH_COMMAND="ssh -p 9022" git clone git@gitlab.example.com:root/laravel-14.git 对于已经存在的项目，想使用新的remote 连接，可以改为:
git remote set-url origin ssh://git@gitlab.example.com:9022/root/laravel-14.git 用户邮箱注册流程:
1>到登陆页面注册
guoshipengdss@gmail.com
rx7UJjznL@W57iU 2>注册完成后还不能登陆，需要管理员统一
http://gitlab.example.com:9080/admin 下的users目录下的Pending approval可以看到等待通过的用户 3>点击edit之后，选择Approval即可通过新注册的用户 为gitlab设置新的Group
1>管理员登陆
http://gitlab.example.com:9080/admin 下的Groups目录下可以选择创建新的group，比如 dev， 那么就会有
http://gitlab.example.com:9080/dev`}]},{path:"/content/service/docker/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAregistry%E4%BB%93%E5%BA%93.html",title:"使用docker搭建registry仓库",pathLocale:"/",contents:[{header:"使用docker搭建registry仓库:",slug:"使用docker搭建registry仓库",content:`1>
$ docker pull docker.1ms.run/registry:2
$ docker image tag docker.1ms.run/registry:2 registry:2
$ docker rmi docker.1ms.run/registry:2 2>
docker run -d \\
--name registry \\
-p 5000:5000 \\
--restart=always \\
-v /opt/registry/data:/var/lib/registry \\
registry:2 解释:
-d：后台运行容器
--name registry：容器名称
-p 5000:5000：映射本地 5000 端口到容器的 5000 端口
--restart=always：开机自启
-v /opt/registry/data:/var/lib/registry：挂载本地目录到容器内 $ docker ps 和 $ docker container ls 效果一样, docker ps -a 查看所有容器，包括被停止的 3>
验证:
浏览器访问 http://localhost:5000/v2/ 或者curl 访问 http://localhost:5000/v2/ 返回 {} 表示成功 4>推送和拉取
4.1 先将官网的拉下来，再重新push到本地仓库
docker pull busybox
docker tag busybox localhost:5000/busybox
docker push localhost:5000/busybox 4.2删掉本地的镜像
$ docker rmi localhost:5000/busybox 4.3再从本地仓库拉取
$ docker pull localhost:5000/busybox 结论，可以拉取到本地仓库的镜像 5.配置远程访问
默认情况下，Docker 只允许使用 https 连接到私有仓库。如果你只想在局域网内使用，可以通过配置 Docker 允许 http 访问。 编辑 /etc/docker/daemon.json（如果文件不存在，就创建）：
{
"insecure-registries": ["localhost:5000"]
} 然后重启docker:
sudo systemctl restart docker 如果是远程机器访问，将 localhost 替换为你的服务器 IP，例如 192.168.1.100:5000 实际上本地访问不加"insecure-registries": ["localhost:5000"] 也可以，原因如下:
如果你在 本地（localhost） 搭建 Docker Registry，并且 Docker 默认支持推送到 localhost:5000 的 HTTP 端口，那么你可以不配置 "insecure-registries" 也能正常 docker push。`},{header:"原因分析",slug:"原因分析",content:`Docker 允许 localhost 作为特殊情况 localhost 被 Docker 认为是本地地址，因此不会强制 HTTPS 连接。
只要 registry 在 localhost:5000 运行，Docker 允许 http://localhost:5000 进行推送和拉取操作。 "insecure-registries" 主要用于远程访问 如果你在其他机器（如 192.168.1.100:5000）上运行 Registry，默认情况下 Docker 需要 HTTPS 连接。
你必须在 /etc/docker/daemon.json 配置 "insecure-registries": ["192.168.1.100:5000"]，否则 docker push 会失败。`},{header:"什么时候需要 insecure-registries？",slug:"什么时候需要-insecure-registries",content:`本机（localhost） 访问 localhost:5000 → 不需要
局域网（如 192.168.1.100:5000） 访问 → 需要
公网 IP 或域名（如 registry.example.com:5000） 访问 → 需要`},{header:"如何验证",slug:"如何验证",content:`如果你尝试推送到非 localhost 地址：
docker tag busybox 192.168.1.100:5000/busybox
docker push 192.168.1.100:5000/busybox 你可能会遇到类似的错误：
http: server gave HTTP response to HTTPS client 这表明 Docker 默认需要 HTTPS，你需要在 daemon.json 添加：
{ "insecure-registries": ["192.168.1.100:5000"]
} 然后重启 Docker：
sudo systemctl restart docker`},{header:"结论",slug:"结论",content:`本地 localhost:5000 访问 registry:2，Docker 默认允许 HTTP，无需额外配置。
远程访问 192.168.1.100:5000 需要 "insecure-registries"，否则必须使用 HTTPS。 如果要使用 HTTPS，需要：
申请或自签证书
配置 Docker Registry 使用 HTTPS
在 Docker 客户端信任该证书
需要在 /etc/docker/daemon.json 中配置 registry-mirrors 和 insecure-registries，或者使用反向代理（如 Nginx）加 HTTPS。`},{header:"要查看Docker Registry（私有仓库）中有哪些镜像，可以使用以下几种方法：",slug:"要查看docker-registry-私有仓库-中有哪些镜像-可以使用以下几种方法",content:""},{header:"方法 1：使用 curl 直接查询",slug:"方法-1-使用-curl-直接查询",content:`Docker Registry 提供了一个 REST API，可以用 curl 查询已存储的镜像列表：
curl -X GET http://localhost:5000/v2/_catalog //对应可以直接浏览器访问: http://localhost:5000/v2/_catalog 示例返回：
{ "repositories": ["busybox", "nginx", "my-app"]
} 这表示你的私有仓库里存储了 busybox、nginx 和 my-app 这三个镜像。
如果你的 Registry 运行在远程服务器（例如 192.168.1.100），可以这样查询：
curl -X GET http://192.168.1.100:5000/v2/_catalog`},{header:"方法 2：查看某个镜像的所有标签",slug:"方法-2-查看某个镜像的所有标签",content:`如果你想查看某个镜像有哪些标签（版本），可以使用：
curl -X GET http://localhost:5000/v2/busybox/tags/list 示例返回：
{ "name": "busybox", "tags": ["latest", "1.35", "1.36"]
} 这表示 busybox 镜像在你的私有仓库中有 latest、1.35 和 1.36 三个版本。`},{header:"方法 3：使用 Docker CLI",slug:"方法-3-使用-docker-cli",content:`Docker CLI 没有直接的 docker registry ls 命令，但你可以这样做：
docker pull registry:2
docker run --rm registry:2 bin/registry garbage-collect /etc/docker/registry/config.yml （不推荐，通常 curl 方法更简单）`},{header:"方法 4：通过 UI 浏览（可选）",slug:"方法-4-通过-ui-浏览-可选",content:`如果你希望用 Web 界面来管理 Registry，可以使用 portus 或 docker-registry-ui：
docker run -d -p 8080:80 --name registry-ui \\ -e REGISTRY_URL=http://localhost:5000 \\ -e DELETE_IMAGES=true \\ joxit/docker-registry-ui:latest 然后在浏览器访问：
http://localhost:8080 它会列出所有镜像，并提供管理功能。`},{header:"总结",slug:"总结",content:`最简单的方法：用 curl http://localhost:5000/v2/_catalog
查看具体镜像的版本：curl http://localhost:5000/v2/busybox/tags/list
想用 UI 管理：用 docker-registry-ui 或 portus`},{header:"为docker私有仓库配置账号和密码:",slug:"为docker私有仓库配置账号和密码",content:`1>生成用户名和密码(使用 htpasswd 命令创建认证文件)
$ sudo apt install apache2-utils -y # 安装 htpasswd（如果未安装）
$ sudo mkdir -p /opt/registry/auth # 存放认证文件
$ sudo htpasswd -B -c /opt/registry/auth/htpasswd myuser
New password:
Re-type new password:
Adding password for user myuser 这会创建 /opt/registry/auth/htpasswd 文件，其中 myuser 是用户名，你可以换成自己的用户名。 2>停止和删除容器，可以先通过 docker ps -a 查看所有容器(包括运行的和停止的)
$ docker stop registry
$ docker rm registry 3>然后重新运行 Registry，增加 -e 环境变量指定认证文件：
docker run -d \\
--restart=always \\
--name registry \\
-p 5000:5000 \\
-v /opt/registry/data:/var/lib/registry \\
-v /opt/registry/auth:/auth \\
-e "REGISTRY_AUTH=htpasswd" \\
-e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \\
-e "REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd" \\
registry:2 4>验证
再次执行之前的命令，推送到本地仓库:
$ docker push localhost:5000/busybox
Using default tag: latest
The push refers to repository [localhost:5000/busybox]
66140dc7271c: Preparing
no basic auth credentials 会发现没有授权，执行如下命令:
$ docker login localhost:5000
Username: myuser
Password:
WARNING! Your password will be stored unencrypted in /home/guoshipeng/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 再次执行:
$ docker push localhost:5000/busybox
Using default tag: latest
The push refers to repository [localhost:5000/busybox]
66140dc7271c: Layer already exists
latest: digest: sha256:359e81f9b2a9be2b4ae628a146e0fab4d5b8ac8a386f4e8181f099d0f354dfc4 size: 527 再次删除本地已有的镜像:
$ docker rmi localhost:5000/busybox:latest
然后从本地仓库拉取:
$ docker pull localhost:5000/busybox
Using default tag: latest
latest: Pulling from busybox
Digest: sha256:359e81f9b2a9be2b4ae628a146e0fab4d5b8ac8a386f4e8181f099d0f354dfc4
Status: Downloaded newer image for localhost:5000/busybox:latest
localhost:5000/busybox:latest 完美运行! 新增用户:
htpasswd /opt/registry/auth/htpasswd newuser
删除用户:
sed -i '/^olduser/d' /opt/registry/auth/htpasswd
解释:
这条命令的作用是 删除 /opt/registry/auth/htpasswd 文件中以 olduser 开头的行，即 删除 olduser 这个用户的密码记录。`},{header:"命令详解",slug:"命令详解",content:`sed -i '/^olduser/d' /opt/registry/auth/htpasswd 部分
作用 sed
调用 sed 命令（stream editor，流编辑器） -i
直接修改文件（in-place），否则 sed 只会输出修改结果，而不改变原文件 '/^olduser/d'
/^olduser/：匹配以 olduser 开头的行d：删除匹配的行 /opt/registry/auth/htpasswd
要修改的目标文件（存储用户名和密码）`},{header:"示例",slug:"示例",content:`假设 htpasswd 文件内容如下：
olduser:$2y$05$abcde12345...
myuser:$2y$05$xyz98765...
admin:$2y$05$pass45678... 执行：
sed -i '/^olduser/d' /opt/registry/auth/htpasswd 之后 htpasswd 文件变为：
myuser:$2y$05$xyz98765...
admin:$2y$05$pass45678... ✅ olduser 这一行被删除了。`},{header:"删除多个用户",slug:"删除多个用户",content:`如果想删除多个用户（如 olduser1 和 olduser2），可以使用 -e 选项：
sed -i -e '/^olduser1/d' -e '/^olduser2/d' /opt/registry/auth/htpasswd 或者用 |（正则表达式的 OR 运算符）：
sed -i '/^olduser1\\|^olduser2/d' /opt/registry/auth/htpasswd`},{header:"如何验证删除是否成功？",slug:"如何验证删除是否成功",content:`可以用 cat 或 grep 检查：
cat /opt/registry/auth/htpasswd 或者：
grep 'olduser' /opt/registry/auth/htpasswd 如果 grep 没有输出，说明 olduser 已成功删除。`},{header:"总结",slug:"总结-1",content:`删除 htpasswd 文件中 olduser 这一行：sed -i '/^olduser/d' /opt/registry/auth/htpasswd 匹配 htpasswd 文件中多个用户，并删除：sed -i '/^olduser1\\|^olduser2/d' /opt/registry/auth/htpasswd 安全检查，确认用户已删除：grep 'olduser' /opt/registry/auth/htpasswd 这样，你就可以管理 Docker Registry 的用户访问权限了！
加了用户名和密码之后，上面的查看接口，如:
http://localhost:5000/v2/_catalog
访问的时候，就需要输入用户名和秘密`},{header:"在项目中的gitlab-ci.yml测试这个仓库",slug:"在项目中的gitlab-ci-yml测试这个仓库",content:`运行之后报：
Running with gitlab-runner 17.8.3 (690ce25c)
on a runner for local gitlab t1_UNMMA, system ID: r_iTJKxTxte9W9
Preparing the "shell" executor
00:00
Using Shell (bash) executor...
Preparing environment
00:01
Running on 8446a748968a...
Getting source from Git repository
00:02
Fetching changes with git depth set to 20...
Reinitialized existing Git repository in /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/.git/
Checking out 0a2f2a56 as detached HEAD (ref is main)...
Skipping Git submodules setup
Executing "step_script" stage of the job script
00:00
$ echo "Logging into Docker Registry..."
Logging into Docker Registry...
$ docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$REGISTRY"
bash: line 150: docker: command not found
Cleaning up project directory and file based variables
00:00
ERROR: Job failed: exit status 1 但是之前安装docker-runner的时候，已经挂载了宿主机的docker(参考前面的gitlab-runner搭建)，如下可以说明:
# ls -l /var/run/docker.sock
srw-rw---- 1 root gitlab-runner 0 Feb 13 2025 /var/run/docker.sock 这里只是缺少了docker-ci(docker客户端) # docker exec -it gitlab-runner bash
# docker -v
bash: docker: command not found //安装docker-cli
# apt update && apt install -y docker.io
...
... //查看，有了
# docker --version
Docker version 26.1.3, build 26.1.3-0ubuntu1~20.04.1 //继续在gitlab下重试之前的job Search visible log output
Running with gitlab-runner 17.8.3 (690ce25c)
on a runner for local gitlab t1_UNMMA, system ID: r_iTJKxTxte9W9
Preparing the "shell" executor
00:00
Using Shell (bash) executor...
Preparing environment
00:00
Running on 8446a748968a...
Getting source from Git repository
00:01
Fetching changes with git depth set to 20...
Reinitialized existing Git repository in /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/.git/
Checking out 44958810 as detached HEAD (ref is main)...
Skipping Git submodules setup
Executing "step_script" stage of the job script
00:00
$ echo "Logging into Docker Registry..."
Logging into Docker Registry...
$ export PATH="/usr/bin:$PATH"
$ docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$REGISTRY"
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /home/gitlab-runner/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store
Login Succeeded
$ docker build -t "$REGISTRY/$IMAGE_NAME:$CI_COMMIT_REF_NAME" .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
Install the buildx component to build images with BuildKit:
https://docs.docker.com/go/buildx/
unable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /home/gitlab-runner/builds/t1_UNMMA/0/front/laravel-15/Dockerfile: no such file or directory
Cleaning up project directory and file based variables
00:00
ERROR: Job failed: exit status 1 可以知道gitlab-runner下docker已经登陆成功了，现在的问题是项目没有定义Dockerfile.`},{header:"现在在已有的目录下初始化一个nuxt3项目，之前的项目不完整，只是随便写了一些东西，没有Dockerfile这些",slug:"现在在已有的目录下初始化一个nuxt3项目-之前的项目不完整-只是随便写了一些东西-没有dockerfile这些",content:`官方命令:
npx nuxi@latest init <project-name> 由于我的项目已经存在，所以这里直接
npx nuxi@latest init
就可以在当前项目下创建了，会有如下提示:
The directory \`/home/guoshipeng/Documents/code/laravel-15\` already exists. What would you like to do?
直接 override its contents 就可以了，之前的内容还可以保留 在本地的nuxt3项目的Dockerfile下，需要node镜像，使用如下方法下载
$ docker pull docker.1ms.run/node:20.17.0-alpine
$ docker image tag docker.1ms.run/node:20.17.0-alpine node:20.17.0-alpine
$ docker rmi docker.1ms.run/node:20.17.0-alpine 基于docker + gitlab + gitlab-runner + nginx-proxy + nuxt3 部署项目, 总结如下: 使用如下方式搭建gitlab-runner
docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest
现在gitlab-runner容器里的docker 服务和宿主机上docker的服的相同，那么在gitlab-runner 执行gitlab-ci中的脚本的时候，比如执行 docker run 相关的命令的时候，就相当于在宿主机上执行docker相关的命令一样。
原因:
由于在运行 gitlab-runner 容器时挂载了 /var/run/docker.sock，容器内的 Docker CLI 实际上是在直接与宿主机上的 Docker Daemon 交互。这意味着：
任何在 gitlab-runner 容器中执行的 docker 命令（例如 docker run、docker build 等），都会直接作用于宿主机的 Docker，而不是 gitlab-runner 容器本身。
运行的容器是由宿主机的 Docker 管理的，而不是 gitlab-runner 容器内部的独立 Docker 进程。
这也意味着 gitlab-ci.yml 中的 docker 相关命令，都会像在宿主机上执行一样起作用。 这样做的好处是可以让 GitLab Runner 直接管理宿主机的 Docker 资源，而不需要在 gitlab-runner 容器内再运行一个 Docker 进程（即 “Docker in Docker” 方案），避免额外的开销和复杂性。 我发现，在gitlab-runner容器里执行，docker ps, 发现展示的内容和直接在宿主机上执行docker ps 一样。
原因:
由于挂载了宿主机的 Docker 套接字（-v /var/run/docker.sock:/var/run/docker.sock），gitlab-runner 容器内部的 docker CLI 实际上是在直接与 宿主机的 Docker Daemon 交互。因此：
在 gitlab-runner 容器中运行 docker ps，它获取的是 宿主机上运行的所有容器（包括 gitlab-runner 容器本身）。
在宿主机上运行 docker ps，看到的内容和 gitlab-runner 容器内执行 docker ps 的内容完全相同。
这个行为可以验证 gitlab-runner 运行的 CI/CD 任务中 docker 命令 是在宿主机上执行的，而不是在 gitlab-runner 容器的独立环境内执行的。 意味着，可以通过tilab-runner运行gitlab-ci，在宿主机上通过docker部署项目，而不是在gitlab-runner容器里部署项目。
这正是 挂载 /var/run/docker.sock 的关键作用，它使 gitlab-runner 充当一个代理，直接在 宿主机的 Docker 环境 中执行 docker 命令，而不是在 gitlab-runner 容器内部。
这样做的好处：
1.项目部署在宿主机，而不是 gitlab-runner 容器内部 gitlab-runner 只负责触发 CI/CD 任务，不会影响你的部署环境。
可以在 gitlab-ci.yml 里自由使用 docker run、docker compose up 等命令，在宿主机上部署项目。 2.避免 Docker in Docker（DinD）带来的问题 传统的 DinD 方案需要在 gitlab-runner 容器内运行一个独立的 Docker Daemon，可能会导致 权限问题、性能损耗 和 容器网络隔离 的问题。
直接挂载 /var/run/docker.sock，就不需要额外的 Docker Daemon，性能更好，部署更简单。 3.可以管理整个宿主机的 Docker 容器 可以在 GitLab CI 中执行 docker ps、docker stop、docker rm 等命令，直接控制宿主机上的容器。
适用于部署 Web 应用、微服务，或者自动化构建和更新 Docker 容器。 举个例子，假设有如下gitlab-ci.yml:
stages: - deploy deploy: stage: deploy image: docker:latest # 使用 Docker 官方镜像 services: - docker:dind # 这里的 DinD 只是用于 GitLab 兼容性，不会真正运行 script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY - docker pull my-image:latest - docker stop my-container || true - docker rm my-container || true - docker run -d --name my-container -p 8080:8080 my-image:latest 这样 gitlab-runner 只是触发命令，实际的 docker run 操作都是在 宿主机 上执行的，而不是 gitlab-runner 容器内部。`}]},{path:"/content/service/docker/%E5%85%B3%E4%BA%8EDockerfile%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BA.html",title:"关于Dockerfile多阶段构建",pathLocale:"/",contents:[{header:"",slug:"",content:`关于Dockerfile多阶段构建:
示例 Dockerfile
FROM node:hydrogen-alpine AS builder ARG GITLAB_TOKEN # update and install dependency for build stage
RUN apk update && apk upgrade
RUN apk add git # copy source code into image, note .dockerignore
WORKDIR /app
COPY . . # create temp npmrc with npm auth token, install dependencies, prune for production
RUN rm -rf ./node_modules/*
RUN npm cache clean --force
RUN cp /app/.npmrc.local /app/.npmrc
RUN npm ci
RUN npm run postinstall
RUN rm /app/.npmrc
RUN npm run build
RUN npm prune --production FROM node:hydrogen-alpine WORKDIR /app # copy from build stage
COPY --from=builder /app/package.json ./
COPY --from=builder /app/package-lock.json ./
COPY --from=builder /app/ecosystem.config.cjs ./
COPY --from=builder /app/.output ./.output
COPY --from=builder /app/node_modules ./node_modules
# COPY --from=builder /app/ci-scripts/entrypoint.sh ./entrypoint.sh # RUN apk add bash
# RUN chmod +x /app/entrypoint.sh
# ENTRYPOINT ["/bin/bash", "/app/entrypoint.sh"] # install PM2 process manager
RUN npm install pm2 -g
# install git and nginx
# RUN apk add nginx
# COPY --from=builder /app/nginx-template.conf /etc/nginx/templates/nginx-template.conf ENV NITRO_PORT=3000
ENV NITRO_HOST=0.0.0.0 EXPOSE 3000 # start app with PM2 process manager
CMD [ "pm2-runtime", "/app/ecosystem.config.cjs"] 脚本分析:
这个 Dockerfile 使用了多阶段构建(multi-stage build)的方式,这是一个常见的 Docker 构建模式。它包含两个主要阶段: 构建阶段(Builder Stage): 这个阶段用于构建应用程序。它使用 node:hydrogen-alpine 作为基础镜像,执行以下操作: 安装构建所需的依赖项,如 git。
复制源代码到镜像中。
安装 npm 依赖并执行构建命令。
优化最终的依赖项,只保留生产所需的包。 这个阶段的输出是一个优化过的构建结果,包括应用程序代码和生产依赖项。 运行阶段(Runtime Stage): 这个阶段用于运行应用程序。它同样使用 node:hydrogen-alpine 作为基础镜像,但不再包含构建时的工具和依赖项。
它从构建阶段复制所需的文件,如 package.json、package-lock.json、应用程序输出文件和 node_modules 文件夹。
安装 pm2 进程管理器,用于运行应用程序。
设置运行时的环境变量,如 NITRO_PORT 和 NITRO_HOST。
最终,使用 pm2-runtime 命令启动应用程序。 这种多阶段构建的好处是: 优化镜像大小: 构建阶段包含了所有构建依赖项,但在运行阶段,只有应用程序运行所需的文件和依赖项被复制到最终镜像中,减小了镜像体积。
分离构建和运行: 构建和运行阶段被分离,使得每个阶段都能专注于自己的任务,提高了灵活性和可维护性。 总之,这个 Dockerfile 采用了多阶段构建的模式,将构建和运行阶段分离,以优化最终 Docker 镜像的大小和结构。
多阶段构建中 AS builder的作用:
在多阶段构建中使用 AS <name> 语法是可选的,但通常被认为是一种最佳实践。
在这个 Dockerfile 中,使用 AS builder 是为了给第一个构建阶段命名为 "builder"。这样做有以下好处: 可读性: 给每个阶段起名字可以让 Dockerfile 更加清晰易懂。在后续的 COPY --from=builder 语句中,可以清楚地知道它是从哪个阶段复制文件。 复用性: 如果在 Dockerfile 中需要多次引用同一个构建阶段,使用命名可以让引用更加简单直观。 可维护性: 当 Dockerfile 变得复杂时,给构建阶段命名可以让代码更加模块化和可读。这有助于理解 Dockerfile 的结构和工作原理。 所以虽然 AS <name> 语法不是必须的,但它通常被认为是一种良好的实践,可以提高 Dockerfile 的可读性和可维护性。但如果你的 Dockerfile 非常简单,不使用命名也是可以的。
怎么知道是Runtime阶段:
在多阶段构建的 Dockerfile 中,通常最后一个 FROM 语句所定义的阶段就是运行时阶段(Runtime Stage)。
让我们来看看这个 Dockerfile 的结构: 第一个 FROM 语句使用 node:hydrogen-alpine 作为基础镜像,并标记为 AS builder。这是构建阶段(Builder Stage)。
最后一个 FROM 语句同样使用 node:hydrogen-alpine 作为基础镜像。这个没有任何 AS 标记,所以它就是最终的运行时阶段(Runtime Stage)。 通常情况下,多阶段构建的最后一个阶段就是运行时阶段。这个阶段只包含应用程序运行所需的内容,而不包含构建工具和依赖项。
所以在这个 Dockerfile 中,当看到最后一个 FROM 语句使用 node:hydrogen-alpine 作为基础镜像时,我们就可以确定这就是运行时阶段。
总的来说,通过观察 Dockerfile 中 FROM 语句的顺序和是否有 AS 标记,可以很容易地识别出构建阶段和运行时阶段。最后一个 FROM 语句定义的就是最终的运行时阶段。
RUN npm ci的作用:
RUN npm ci 是这个 Dockerfile 中的一个重要命令,它的作用是安装应用程序的依赖项。让我们更详细地解释这条命令: RUN: 这是 Dockerfile 中的一个关键词,它表示在构建镜像过程中需要执行的命令。 npm ci: 这是 npm 命令行工具提供的一个子命令。ci 代表 "clean install"，它与常见的 npm install 命令有一些区别: npm ci 会严格按照 package-lock.json 文件中的版本信息安装依赖项,而不会自动升级依赖的版本。这有助于确保构建的可重复性。
npm ci 会首先删除 node_modules 文件夹,然后从头开始安装依赖项。这确保了一个干净的依赖安装环境。
npm ci 比 npm install 更快,因为它省略了一些额外的检查和处理步骤。 综合起来,在 Dockerfile 的构建阶段使用 RUN npm ci 可以确保应用程序的依赖项被可靠地安装,并且构建过程更加高效和可重复。这有助于确保最终生成的 Docker 镜像的一致性和可靠性。
这个脚本在执行 ci 之前先执行了 RUN rm -rf ./node_modules/*的作用:
在运行 npm ci 命令之前,Dockerfile 中有一行 RUN rm -rf ./node_modules/*。这个命令的作用是: 删除 - rm 命令用于删除文件或目录。
递归删除 - -rf 选项表示递归地删除目录及其内容。
./node_modules/* - 这个路径指的是删除 /app/node_modules 目录下的所有内容。 为什么要在运行 npm ci 之前先删除 node_modules 目录呢?主要有以下几个原因: 清理环境 - 删除旧的 node_modules 文件夹可以确保在安装依赖时从一个干净的环境开始,避免遗留的依赖项干扰新的安装过程。 强制重新安装 - 通过删除 node_modules，强制 npm ci 命令从头开始安装所有依赖项,而不是尝试使用缓存的依赖项。这有助于确保完整和正确的依赖安装。 镜像大小优化 - 在多阶段构建中,删除旧的 node_modules 可以减小最终 Docker 镜像的体积,因为只有新安装的生产依赖项会被复制到运行时镜像中。 总之,这行 RUN rm -rf ./node_modules/* 命令是为了确保在安装依赖项之前,构建环境是干净和一致的,有助于提高构建过程的可靠性和最终镜像的质量。是的,你注意到了这个细节。在运行 npm ci 命令之前,Dockerfile 中有一行 RUN rm -rf ./node_modules/*。这个命令的作用是: 删除 - rm 命令用于删除文件或目录。
递归删除 - -rf 选项表示递归地删除目录及其内容。
./node_modules/* - 这个路径指的是删除 /app/node_modules 目录下的所有内容。 为什么要在运行 npm ci 之前先删除 node_modules 目录呢?主要有以下几个原因: 清理环境 - 删除旧的 node_modules 文件夹可以确保在安装依赖时从一个干净的环境开始,避免遗留的依赖项干扰新的安装过程。 强制重新安装 - 通过删除 node_modules，强制 npm ci 命令从头开始安装所有依赖项,而不是尝试使用缓存的依赖项。这有助于确保完整和正确的依赖安装。 镜像大小优化 - 在多阶段构建中,删除旧的 node_modules 可以减小最终 Docker 镜像的体积,因为只有新安装的生产依赖项会被复制到运行时镜像中。 总之,这行 RUN rm -rf ./node_modules/* 命令是为了确保在安装依赖项之前,构建环境是干净和一致的,有助于提高构建过程的可靠性和最终镜像的质量。`}]},{path:"/content/service/docker/%E5%85%B3%E4%BA%8Edocker%E5%81%9A%E4%B8%80%E4%B8%AA%E6%80%BB%E7%BB%93.html",title:"关于docker做一个总结",pathLocale:"/",contents:[{header:"1.docker是什么",slug:"_1-docker是什么",content:"官方介绍: https://docs.docker.com/get-started/docker-overview/ 当我们通过手动安装docker的时候步骤如下:"},{header:"1. 更新包索引并安装依赖",slug:"_1-更新包索引并安装依赖",content:`sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release`},{header:"2. 添加 Docker 官方 GPG 密钥",slug:"_2-添加-docker-官方-gpg-密钥",content:`sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg`},{header:"3. 设置 Docker 仓库",slug:"_3-设置-docker-仓库",content:`echo \\
"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null`},{header:"4. 安装 Docker Engine",slug:"_4-安装-docker-engine",content:`sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin`},{header:"5. 验证安装",slug:"_5-验证安装",content:"sudo docker run hello-world"},{header:"6. 注意: Docker Compose 作为插件 (docker-compose-plugin) 包含在内，不需要再次单独安装.",slug:"_6-注意-docker-compose-作为插件-docker-compose-plugin-包含在内-不需要再次单独安装",content:`历史背景：
旧版本（V1）： 需要单独安装 docker-compose（Python 编写）
使用命令：docker-compose up（带横杠）
独立的二进制文件 新版本（V2，现在推荐）： 作为 Docker CLI 插件集成
使用命令：docker compose up（空格，无横杠）
用 Go 重写，性能更好`},{header:"2.通过 docker pull/run ... 命令来理解 Docker daemon 和 Docker client 之间的关系:",slug:"_2-通过-docker-pull-run-命令来理解-docker-daemon-和-docker-client-之间的关系",content:""},{header:"当您执行 docker pull/run ... 时：",slug:"当您执行-docker-pull-run-时",content:""},{header:"直接使用的是：Docker Client (CLI)",slug:"直接使用的是-docker-client-cli",content:`就是 docker 这个命令行工具
对应安装包：docker-ce-cli`},{header:"实际工作的是：Docker Daemon",slug:"实际工作的是-docker-daemon",content:`后台运行的服务进程 dockerd
对应安装包：docker-ce（Docker Engine）`},{header:"工作流程：",slug:"工作流程",content:`您输入命令 ↓
Docker Client (docker-ce-cli) ↓
通过 REST API 或 Socket 通信 ↓
Docker Daemon (dockerd, 即 docker-ce) ↓
调用 containerd 实际执行容器操作`},{header:"安装包解释：",slug:"安装包解释",content:"sudo apt-get install \\ docker-ce # Docker Engine (daemon/服务端) docker-ce-cli # Docker Client (命令行工具/客户端) containerd.io # 容器运行时 docker-buildx-plugin # 构建插件 docker-compose-plugin # Compose 插件"},{header:"验证：",slug:"验证",content:`# 查看 Docker Client 版本
docker version | grep "Client:" # 查看 Docker Daemon (Engine) 版本
docker version | grep "Server:" # 查看 daemon 进程
ps aux | grep dockerd`},{header:"所以简单说：",slug:"所以简单说",content:`敲命令 = 使用 Docker Client
实际干活 = Docker Daemon 在后台执行 它们是 客户端-服务器架构，通常装在同一台机器上，通过 Unix socket (/var/run/docker.sock) 通信。`},{header:"可以通过如下命令检查dockerd运行状态",slug:"可以通过如下命令检查dockerd运行状态",content:`$ ps aux | grep dockerd
root 2073 0.3 0.2 4947848 97124 ? Ssl 09:00 0:19 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
root 22625 0.0 0.0 12308 2816 pts/4 S+ 10:44 0:00 grep --color=auto dockerd`},{header:"3.目前docker使用主要有两种",slug:"_3-目前docker使用主要有两种",content:"docker engine https://docs.docker.com/engine/install/ubuntu/ docker desktop https://docs.docker.com/desktop/setup/install/linux/ubuntu/"}]},{path:"/content/service/docker/%E5%85%B3%E4%BA%8Edocker%E6%82%AC%E7%A9%BA%E9%95%9C%E5%83%8F.html",title:"关于docker悬空镜像",pathLocale:"/",contents:[{header:"关于docker悬空镜像",slug:"关于docker悬空镜像",content:`$ docker rmi $(docker images -q --filter "dangling=true")
dangling=true 是 Docker 镜像过滤器的一种选项，用于查找“悬空”（无标签）的镜像。 悬空镜像（Dangling Images）是 没有标签（tag）的镜像，通常出现在：
重新构建镜像时，旧的中间层镜像未被删除
docker build 失败后，留下未使用的临时镜像
docker tag 被更新，导致旧镜像的 tag 失效 如果没有悬空镜像，docker rmi 可能会报错 must specify at least one image
更安全的删除:
$ docker images -q --filter "dangling=true" | xargs -r docker rmi 定期清理悬空镜像，以释放 Docker 存储空间 // 以下是两种场景
$ docker image ls
REPOSITORY TAG IMAGE ID CREATED SIZE
local-nuxt-nginx-my-nginx latest a910ae53e1a8 About an hour ago 192MB
localhost:5000/my-vue-app latest 4a1252aaebb4 4 hours ago 418MB
localhost:5000/my-vue-app main 4a1252aaebb4 4 hours ago 418MB $ docker image ls
REPOSITORY TAG IMAGE ID CREATED SIZE
local-nuxt-nginx-my-nginx latest 165e5bdc91f1 About a minute ago 192MB
<none> <none> a910ae53e1a8 About an hour ago 192MB
localhost:5000/my-vue-app latest 4a1252aaebb4 4 hours ago 418MB
localhost:5000/my-vue-app main 4a1252aaebb4 4 hours ago 418MB
nginx latest 97662d24417b 9 days ago 192MB 如下是一个nginx的启动脚本:
#!/bin/bash
set -u cd "$(dirname "$0")" # the local user's UID & GID are required to build the php Docker container
export USER_ID=$(id -u)
export GROUP_ID=$(id -g) if [[ $(docker images -q --filter "dangling=true") ]]; then echo "Removing untagged Docker images..." docker images -q --filter "dangling=true" | xargs -r docker rmi
fi echo "Building Docker images..."
#docker compose build my-nginx //不需要这个，在 up 的时候加上 --build
docker compose build my-nginx # compose up the stack in detached mode and start to follow the logs output
echo "Starting Docker Compose stack in detached mode..."
#clear
#docker-compose up -d --build
docker-compose up -d 上面有两种启动nginx的方式
1>.
直接 docker-compose up -d --build 2>.
docker compose build my-nginx
docker-compose up -d 这两种方式都会重新构建nginx的镜像，然后nginx服务每次都是最新的，
但是有时候会出现，image tag 为null的情况，就需要在启动之前，通过上面的if条件做个判断。
还有一个启动方式:
docker-compose up,这个会服用之前生成的镜像，即使Dockerfile文件发生了变化，也不会重新build，所以要避免这个情况，一般会单独在前面县buildf一次 通过自定义的Dockerfile build生成的镜像的默认命名规则如下:
<项目名>_<服务名>:<tag> 项目名（Project Name）默认是 docker-compose.yml 所在目录的名称。
服务名（Service Name）来自 docker-compose.yml 里的 services 定义。 如果想 自定义镜像名称，可以在 docker-compose.yml 里添加 image：
services:
my-nginx:
build: .
image: my-nginx:latest # 指定镜像名称，避免默认前缀 如果想 自定义项目名称，可以运行：
docker-compose -p customname up -d --build //通过-p 参数指定项目的名称`}]},{path:"/content/service/docker/%E5%85%B3%E4%BA%8Elinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E7%9A%84%E5%88%86%E6%9E%90.html",title:"关于linux网络配置的分析",pathLocale:"/",contents:[{header:"关于linux网络配置的分析，先从几个命令开始:",slug:"关于linux网络配置的分析-先从几个命令开始",content:""},{header:"查看/管理网卡 IP 地址",slug:"查看-管理网卡-ip-地址",content:`$ ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever
2: enp3s0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc fq_codel state DOWN group default qlen 1000 link/ether f4:6b:8c:89:58:f6 brd ff:ff:ff:ff:ff:ff
3: wlp2s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether e0:0a:f6:78:3b:1d brd ff:ff:ff:ff:ff:ff inet 192.168.5.17/24 brd 192.168.5.255 scope global dynamic noprefixroute wlp2s0 valid_lft 81898sec preferred_lft 81898sec inet6 fe80::76cf:e344:df5b:cd7d/64 scope link noprefixroute valid_lft forever preferred_lft forever
4: br-331156baf737: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:68:b9:16:de brd ff:ff:ff:ff:ff:ff inet 192.168.49.1/24 brd 192.168.49.255 scope global br-331156baf737 valid_lft forever preferred_lft forever
5: br-7cbb16a986d6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:9e:f7:3d:7c brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 brd 172.18.255.255 scope global br-7cbb16a986d6 valid_lft forever preferred_lft forever inet6 fe80::42:9eff:fef7:3d7c/64 scope link valid_lft forever preferred_lft forever
6: br-e6742f9d2eb1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:63:76:d0:bc brd ff:ff:ff:ff:ff:ff inet 172.20.0.1/16 brd 172.20.255.255 scope global br-e6742f9d2eb1 valid_lft forever preferred_lft forever inet6 fe80::42:63ff:fe76:d0bc/64 scope link valid_lft forever preferred_lft forever
7: br-fab0b27bf071: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:62:ab:2b:c9 brd ff:ff:ff:ff:ff:ff inet 172.19.0.1/16 brd 172.19.255.255 scope global br-fab0b27bf071 valid_lft forever preferred_lft forever inet6 fe80::42:62ff:feab:2bc9/64 scope link valid_lft forever preferred_lft forever
8: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:d8:b0:1c:e7 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:d8ff:feb0:1ce7/64 scope link valid_lft forever preferred_lft forever
...
...`},{header:"查看/管理路由表",slug:"查看-管理路由表",content:`$ ip r
default via 192.168.5.1 dev wlp2s0 proto dhcp metric 600 169.254.0.0/16 dev wlp2s0 scope link metric 1000 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 dev br-7cbb16a986d6 proto kernel scope link src 172.18.0.1 172.19.0.0/16 dev br-fab0b27bf071 proto kernel scope link src 172.19.0.1 172.20.0.0/16 dev br-e6742f9d2eb1 proto kernel scope link src 172.20.0.1 192.168.5.0/24 dev wlp2s0 proto kernel scope link src 192.168.5.17 metric 600 192.168.49.0/24 dev br-331156baf737 proto kernel scope link src 192.168.49.1 linkdown`},{header:"查看默认网关",slug:"查看默认网关",content:`$ ip route | grep default
default via 192.168.5.1 dev wlp2s0 proto dhcp metric 600 解析：
默认网关 (default via 192.168.5.1) 这表示所有 非本地子网 的网络流量（即访问外部网络的流量）默认会通过 192.168.5.1 进行转发。
192.168.5.1 通常是你的路由器 IP 地址，宿主机通过这个网关访问外部互联网。
dev wlp2s0 这里的 wlp2s0 是你的 无线网卡接口，表示这个默认网关适用于你的无线网络连接。
如果你使用的是有线网络，可能会看到 eth0 之类的接口名称。
proto dhcp 表示这个默认网关是通过 DHCP（动态主机配置协议）分配的。
metric 600 metric 表示 优先级，数值越低，优先级越高。
这里的 600 说明 这个路由的优先级比更低的 metric（如 100、200）低，但仍然是默认路由。`},{header:"查看宿主机所有的IP",slug:"查看宿主机所有的ip",content:`$ hostname -I
192.168.5.17 192.168.49.1 172.18.0.1 172.20.0.1 172.19.0.1 172.17.0.1 其中192.168.5.17和172.17.0.1比较重要，在docker容器里面可以直接通过这两个IP访问宿主机的服务；同时，在宿主机萨和嗯访问容器服务的时候，是通过172.17.0.1这个docker网关通过NAT实现的。`},{header:"关于子网络掩码计算(时间太久了，忘了不少)",slug:"关于子网络掩码计算-时间太久了-忘了不少",content:`假如我的网络信息如下:
wlp0s20f3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 3c:e9:f7:65:75:d9 brd ff:ff:ff:ff:ff:ff inet 188.188.55.68/23 brd 188.188.55.255 scope global dynamic noprefixroute wlp0s20f3 valid_lft 4311sec preferred_lft 4311sec inet6 fe80::67c5:fbe6:2207:8de/64 scope link noprefixroute valid_lft forever preferred_lft forever 而 $ ip route | grep default
default via 188.188.54.1 dev wlp0s20f3 proto dhcp metric 600
188.188.55.68/23 和188.188.54.1 关系 解析188.188.55.68/23：
inet 188.188.55.68/23 brd 188.188.55.255 scope global dynamic noprefixroute wlp0s20f3 188.188.55.68 是本机 IP 地址（分配给 wlp0s20f3 接口）。
/23 表示子网掩码 255.255.254.0，即 IP 范围是 188.188.54.0 - 188.188.55.255。
brd 188.188.55.255 表示广播地址。 解析默认网关 188.188.54.1:
default via 188.188.54.1 dev wlp0s20f3 proto dhcp metric 600 这条路由规则表示：
默认网关（Internet 出口）是 188.188.54.1。
所有无法直接匹配的流量都会发送到 188.188.54.1 进行转发。
dev wlp0s20f3 说明这个网关通过无线网卡（wlp0s20f3）访问。
proto dhcp 说明这个路由是通过 DHCP 自动分配的。 188.188.55.68/23 和 188.188.54.1 的关系
188.188.55.68 在 188.188.54.0/23 这个子网里，也就是说： 188.188.54.1 和 188.188.55.68 在同一个子网（/23）。
188.188.54.1 作为你的 默认网关，负责将非本地（非 188.188.54.0 - 188.188.55.255）的流量转发出去。 为什么网关是 188.188.54.1 而不是 188.188.55.1？
/23 的子网掩码 255.255.254.0 使得 188.188.54.0 - 188.188.55.255 属于同一个子网。
这个子网的 第一个可用 IP（通常是 .1） 一般作为网关，而 .0 是网络地址，.255 是广播地址。
可能 网络管理员配置了 188.188.54.1 作为这个 /23 网段的网关。 188.188.54.0 - 188.188.55.255 怎么计算来的?
要计算 188.188.54.0 - 188.188.55.255 这个 IP 范围，我们需要根据子网掩码 /23（即 255.255.254.0）来进行计算。这里是具体的步骤：
1. 子网掩码计算
子网掩码 /23 表示： 前 23 位是网络位，后面 9 位是主机位。
255.255.254.0 对应二进制：11111111.11111111.11111110.00000000
这个子网掩码将 IP 地址分为两个部分： 网络部分（前 23 位）
主机部分（后 9 位）
2. 计算网络地址和广播地址
网络地址（Network Address）
IP 地址： 188.188.55.68
子网掩码： 255.255.254.0（即 11111111.11111111.11111110.00000000）
进行按位 与（AND）操作： 188.188.55.68 的二进制表示为：10111100.10111100.00110111.01000100
255.255.254.0 的二进制表示为：11111111.11111111.11111110.00000000
如下:
10111100.10111100.00110111.01000100 (188.188.55.68)
AND
11111111.11111111.11111110.00000000 (255.255.254.0)
-----------------------------------
10111100.10111100.00110110.00000000 (188.188.54.0)
所以，网络地址是 188.188.54.0。 广播地址（Broadcast Address）
广播地址是通过将主机部分的所有位设置为 1 来计算的： 网络部分：188.188.54.0（即 10111100.10111100.00110110.00000000）
主机部分全 1：00000000.00000000.00000001.11111111
如下:
10111100.10111100.00110110.00000000 (188.188.54.0)
OR
00000000.00000000.00000001.11111111 (主机部分全是1)
-----------------------------------
10111100.10111100.00110111.11111111 (188.188.55.255)
所以，广播地址是 188.188.55.255。 IP 地址范围
网络地址： 188.188.54.0（网络起始地址，不可用）
广播地址： 188.188.55.255（广播地址，不可用）
可用的主机地址范围： 188.188.54.1 到 188.188.55.254 总结
网络地址： 188.188.54.0
广播地址： 188.188.55.255
可用主机范围： 188.188.54.1 到 188.188.55.254
所以，188.188.54.0 - 188.188.55.255 这个范围代表了 一个包含 512 个 IP 地址的子网，其中 188.188.54.0 是网络地址，188.188.55.255 是广播地址，中间的 188.188.54.1 到 188.188.55.254 是可用的主机 IP 地址。`}]},{path:"/content/service/docker/%E5%90%8C%E4%B8%80%E4%B8%AA%E9%A1%B9%E7%9B%AE%E9%87%8D%E5%A4%8D%E6%89%A7%E8%A1%8Cdocker_compose_up_d%E7%9A%84%E5%BD%B1%E5%93%8D.html",title:"同一个项目重复执行 docker compose up -d 的影响",pathLocale:"/",contents:[{header:"",slug:"",content:"同一个项目重复执行 docker compose up -d 的影响:\n同一个项目重复执行 `docker compose up -d` 的影响： 重复执行 `docker compose up -d` 对于同一个项目通常是安全的，会产生以下效果： - 对于已经运行的容器： - 如果配置没有变化，Docker Compose 不会对这些容器做任何操作。 - 如果配置有变化（例如环境变量或卷挂载），Docker Compose 会尝试更新这些容器，可能会重新创建它们。 - 对于没有运行的容器： - Docker Compose 会启动这些容器。 - 对于 docker-compose.yml 中定义但当前不存在的服务： - 会创建并启动这些新服务。 - 网络和卷： - 如果需要，会创建新的网络和卷。 - 已存在的网络和卷不会被修改。 - 整体影响： - 这个操作是幂等的，意味着多次执行通常会产生相同的结果。 - 它可以用来确保所有服务都按照最新的配置运行。 重要注意事项：\n. 配置变更： 如果您更改了 docker-compose.yml 文件，重复执行 `up -d` 可能会导致容器重建，这可能会短暂中断服务。 2. 数据持久性： 确保重要数据存储在命名卷或绑定挂载中，以防容器被重新创建。 3. 网络影响： 重复执行通常不会影响现有网络，但要注意网络配置的变更。 4. 资源管理： 频繁执行 `up -d` 不会自动清理不再使用的资源（如旧的容器或卷）。定期使用 `docker compose down` 清理可能是个好习惯。 最佳实践： - 在开发过程中，使用 `docker compose up -d` 来应用配置变更是常见做法。\n- 在生产环境中，应该更加谨慎，可能需要更细粒度的控制和更新策略。\n- 使用版本控制来跟踪 docker-compose.yml 的变更。\n- 考虑使用 CI/CD 流程来管理部署和更新。 总之，重复执行 `docker compose up -d` 对同一项目通常是安全的，但在不同项目间执行时需要格外小心，确保使用正确的项目名和配置。始终使用 `-p` 参数来明确指定项目名，这可以大大减少潜在的问题和混淆。"}]},{path:"/content/service/docker/%E6%9F%A5%E8%AF%A2docker%E9%95%9C%E5%83%8F%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF.html",title:"查询docker镜像的详细信息",pathLocale:"/",contents:[{header:"",slug:"",content:`查询docker镜像的详细信息:
$ docker image inspect jwilder/nginx-proxy:latest
[ { "Id": "sha256:a30f642c4477a306775daa76ec27ce3c04638f1e2e58e0a7e5155a090e7ceb72", "RepoTags": [ "jwilder/nginx-proxy:latest" ], "RepoDigests": [ "jwilder/nginx-proxy@sha256:96103e629e71a549c6003a01adc8ab43810014240776abfb2632e738f83ca8d5" ], "Parent": "", "Comment": "buildkit.dockerfile.v0", "Created": "2024-08-05T00:03:50.935639279Z", "DockerVersion": "", "Author": "", "Config": { "Hostname": "", "Domainname": "", "User": "", "AttachStdin": false, "AttachStdout": false, "AttachStderr": false, "ExposedPorts": { "80/tcp": {} }, "Tty": false, "OpenStdin": false, "StdinOnce": false, "Env": [ "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "NGINX_VERSION=1.27.0", "NJS_VERSION=0.8.4", "NJS_RELEASE=2~bookworm", "PKG_RELEASE=2~bookworm", "NGINX_PROXY_VERSION=1.6.0-17-g83110b2", "DOCKER_GEN_VERSION=", "DOCKER_HOST=unix:///tmp/docker.sock" ], "Cmd": [ "forego", "start", "-r" ], "ArgsEscaped": true, "Image": "", "Volumes": null, "WorkingDir": "/app/", "Entrypoint": [ "/app/docker-entrypoint.sh" ], "OnBuild": null, "Labels": { "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>", "org.opencontainers.image.authors": "Nicolas Duchon <nicolas.duchon@gmail.com> (@buchdag), Jason Wilder", "org.opencontainers.image.created": "2024-08-12T00:03:25.049Z", "org.opencontainers.image.description": "Automated nginx proxy for Docker containers using docker-gen", "org.opencontainers.image.licenses": "MIT", "org.opencontainers.image.revision": "83110b24ef4f453149d464eda7536192c9a2863f", "org.opencontainers.image.source": "https://github.com/nginx-proxy/nginx-proxy", "org.opencontainers.image.title": "nginx-proxy", "org.opencontainers.image.url": "https://github.com/nginx-proxy/nginx-proxy", "org.opencontainers.image.version": "1.6.0-17-g83110b2" }, "StopSignal": "SIGQUIT" }, "Architecture": "amd64", "Os": "linux", "Size": 205251279, "GraphDriver": { "Data": { "LowerDir": "/var/lib/docker/overlay2/a041727d5cbedc52acac058f1746dd02cad0c3216122623b5726c08f4738a4af/diff:/var/lib/docker/overlay2/7c988ab00944c1ccf044c6e7703f15da4f8d897c30d5b9b51b0539f2bb607e8c/diff:/var/lib/docker/overlay2/7d0288ff3d1a3bea286af12b40360c2ad70c7673ba9b5c5fec2a927f84cec232/diff:/var/lib/docker/overlay2/a7f5948d11eb25dd97ca90000dd4a214387d359215116a3547b3482eefbb69a2/diff:/var/lib/docker/overlay2/01174b03fb70176786536b4206aa8ce01138d994906af4d231f401efbde07f14/diff:/var/lib/docker/overlay2/31776373a1356d84a0d8a89931379eb0d981fac7ec44a819de99b48e5d73d3a5/diff:/var/lib/docker/overlay2/795876b2e5ad1b0a622e35a9f6cfc0d80fda6873544efe4c19b63e3b3f9d24f3/diff:/var/lib/docker/overlay2/7b760c31862f4658c93d7bbdc7974502b5694f991e080dd73c340679e22cb5ff/diff:/var/lib/docker/overlay2/564fba017b8a8276cb70e305d29c45104c37553470d04b6579750fcc83fc9eb3/diff:/var/lib/docker/overlay2/cb40640a1096a3349846ecb888f56ded8868510f75101211a9c1dfa2d5ede524/diff:/var/lib/docker/overlay2/675df3a43ee8a26f6902acdae3473ffd06e98c580eab37fbc98d81abc64c975c/diff:/var/lib/docker/overlay2/f08049773b2c5f3401fe64e56b6c155cd88e1583346ae3be654184e4d7b11738/diff", "MergedDir": "/var/lib/docker/overlay2/47ca54da871b0d1e673a4b8c8909413dd68e32301980fe55ddd0e1952516588e/merged", "UpperDir": "/var/lib/docker/overlay2/47ca54da871b0d1e673a4b8c8909413dd68e32301980fe55ddd0e1952516588e/diff", "WorkDir": "/var/lib/docker/overlay2/47ca54da871b0d1e673a4b8c8909413dd68e32301980fe55ddd0e1952516588e/work" }, "Name": "overlay2" }, "RootFS": { "Type": "layers", "Layers": [ "sha256:e0781bc8667fb5ebf954df4ae52997f6f5568ec9f07e21e5db7c9d324ed41e1f", "sha256:fcfa12460e7d6c1aab3b455b464e912f8d6004ac94eab980ccf362978e17bdf7", "sha256:a6355e7844d573a5978b972a7d15f5d64bfc34de68092d65be91409df71420c8", "sha256:a39383416a22a6881d5e4dcbfe414067f8778aa4c5d3afd48e5662f610f05d83", "sha256:09581b9299a2f52daec11dd77870844cb4cbd64bcae125fa93cc49f19b6deb72", "sha256:599e8de62018ddc0638e0f88adff1f2b65e8c5e1bf5a60a2655669f95f353b96", "sha256:60e72fbb314ed5a04c4d3f6ef808f4c142da0d06819aeda0e1790976f076beba", "sha256:4695c0dc00f5a3bfca166ad89d1b348b4fe13a112d2c594d8a119a2878cc296e", "sha256:b383c7787a780ae677c8ff2abd1d653bedc2c15a6927d3d031f7b8e6de1ed8c4", "sha256:ad07f5d19538db489c4f383a684ef4a8738be6d69682418d5e5616fc66d4e754", "sha256:d572154182c540b06bba69b1966cd5fe306e932bf7111310e202e945ebcc91e2", "sha256:9f73e7ece324f39e534d70c1fe53ddbebe3e77cb7f0814c10d692dcb94ce35d2", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef" ] }, "Metadata": { "LastTagTime": "0001-01-01T00:00:00Z" } }
] 或者:
$ docker inspect jwilder/nginx-proxy:latest --format='{{index .RepoDigests 0}}'
jwilder/nginx-proxy@sha256:96103e629e71a549c6003a01adc8ab43810014240776abfb2632e738f83ca8d5 可以在hub.docker下查找jwilder/nginx-proxy，然后找到 INDEX DIGEST 为sha256:96103e629e71a549c6003a01adc8ab43810014240776abfb2632e738f83ca8d5的镜像，不是列表下的 Digest, 那个相当于列表的id, 要点进去，详情里查看. 1.Id 是镜像对象的唯一标识
它是 Docker 引擎内部生成的一个哈希值，用来唯一标识存储在本地的镜像。
作用：
标识镜像的具体内容，包括其所有层和元数据。
Docker 引擎用它来快速查找和管理镜像。
计算依据：
基于镜像的所有层内容和元数据（如环境变量、标签等）计算的 SHA256 哈希值。
一旦镜像的内容发生变化（比如重新构建镜像或修改了元数据），Id 就会改变。
2.RepoDigests 是仓库中镜像的内容标识
它是镜像在远程仓库中的唯一标识，和 Id 不完全相同。
作用：
标识远程仓库中镜像的内容版本。
确保拉取的镜像内容一致性。
区别：
RepoDigests 是 镜像在仓库中的内容地址，而 Id 是本地 Docker 引擎中管理的镜像标识。
RepoDigests 包括镜像的名称（如 jwilder/nginx-proxy）和内容的 digest。
Id 不包含镜像名称。
3.RepoTags 指向镜像的仓库标签，通常为用户设置的可读性好的别名。如: jwilder/nginx-proxy:latest 总结
Id 是镜像的本地标识，用于 Docker 内部管理和操作。
RepoDigests 是镜像在远程仓库中的内容标识，用于确保一致性。
虽然它们都基于镜像内容生成哈希，但作用和适用场景不同：Id 更本地化，而 RepoDigests 更适用于远程一致性验证。`}]},{path:"/content/service/k8s/k8s%E4%B9%8BGatewayAPI.html",title:"k8s之GatewayAPI",pathLocale:"/",contents:[{header:"",slug:"",content:`最近抽时间看了k8s的Gateway Api部分，在这里记录一下:
1.GatewayClass定义了一组共享共同配置和行为的网关。每个GatewayClass将由一个控制器处理，尽管控制器可以处理一个以上的GatewayClass。//所以可以看到每个GatewayClass的spec的controllerName会指定一个ateway-api的实现，比如Kong的(kic) GatewayClass是一个集群范围的资源。必须至少有一个GatewayClass被定义，以便能够有功能性的Gateway。实现Gateway API的控制器通过提供一个相关的GatewayClass资源来实现，用户可以从他们的Gateway（s）中引用。 这与Ingress的IngressClass和PersistentVolumes的StorageClass类似。在Ingress v1beta1中，与GatewayClass最接近的类似物是ingress-class注解，而在IngressV1中，最接近的类似物是IngressClass对象。 2.网关描述了如何将流量转化为集群内的服务。也就是说，它定义了一个请求，要求将流量从不了解Kubernetes的地方转换到了解的地方。例如，由云负载平衡器、集群内代理或外部硬件负载平衡器发送到Kubernetes服务的流量。虽然许多用例都有来自集群 "外部 "的客户端流量，但这并不是一个要求。 它定义了对特定负载平衡器配置的请求，该配置实现了GatewayClass的配置和行为契约。该资源可以由操作员直接创建，也可以由处理GatewayClass的控制器创建。 由于Gateway规范捕获了用户的意图，它可能不包含规范中所有属性的完整规范。例如，用户可以省略诸如地址、TLS设置等字段。这允许管理GatewayClass的控制器为用户提供这些设置，从而产生一个更可移植的规范。这种行为将通过GatewayClass状态对象来明确。 一个Gateway可以被附加到一个或多个路由引用上，这些路由引用的作用是将流量的一个子集导向一个特定的服务 3.路由资源定义了特定的协议规则，用于将请求从网关映射到Kubernetes服务。 从v1alpha2版开始，API中包含了四种路由资源类型。我们鼓励为其他协议定制特定实现的路由类型。未来可能会在API中加入新的路由类型。 HTTPRoute: HTTPRoute用于复用HTTP或终止的HTTPS连接。它的目的是在你想检查HTTP流并使用HTTP请求数据进行路由或修改的情况下使用，例如使用HTTP Headers进行路由，或在飞行中修改它们。
TLSRoute: TLSRoute用于复用TLS连接，通过SNI进行区分。它适用于你想使用SNI作为主要的路由方法，而对HTTP等高级协议的属性不感兴趣的情况。连接的字节流被代理，没有任何检查到后端
TCPRoute and UDPRoute: TCPRoute（和UDPRoute）旨在用于将一个或多个端口映射到一个后端。在这种情况下，没有可以用来选择同一端口的不同后端的判别器，所以每个TCPRoute在监听器上确实需要一个不同的端口（无论如何，一般来说）。你可以终止TLS，在这种情况下，未加密的字节流被传递到后端。你可以选择不终止TLS，在这种情况下，加密的字节流被传递到后端。
GRPCRoute: GRPCRoute是用于习惯性地路由gRPC流量。支持GRPCRoute的网关需要支持HTTP/2，而不需要从HTTP/1进行初始升级，因此保证gRPC流量的正常流动。 对于使用反向代理实现的网关，典型的客户/网关API请求流是： 客户端向 http://foo.example.com 发出请求。
DNS将该名称解析为一个网关地址。//文档中的测试链接:$ curl -s -I -HHost:httpbin.example.com "http://$INGRESS_HOST/get"，先获取 $INGRESS_HOST,这个是一个IP地址，curl 访问这个IP地址，同时通过-H参数指定将要访问的hostName，和直接访问这个hostName效果相同;只不过测试的时候这个hostName还没有配置NDS域名解析。和 curl http://example.com/version --resolve example.com:80:<EXTERNAL-IP> 也是相同的效果 反向代理在监听器上接收请求，并使用主机头来匹配HTTPRoute。
可选的是，反向代理可以根据HTTPRoute的匹配规则执行请求头和/或路径匹配。
可选的是，反向代理可以根据HTTPRoute的过滤规则修改请求，即添加/删除头信息。
最后，反向代理根据HTTPRoute的backendRefs规则，将请求转发给集群中的一个或多个对象，即服务。 https://help.aliyun.com/document_detail/480188.html //利用gateway-api访问服务
https://www.alibabacloud.com/help/zh/alibaba-cloud-service-mesh/latest/use-gateway-api-to-define-a-routing-rule //利用gateway-api定义路由规则，这个里面有获取网关入口的方法 https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1beta1.Hostname //gateway-api各个参数配置，其中有 介绍 Gateway的listeners的address属性，这个如果不配置的话，会自动生成 istio 配置gateway api的网关(https://istio.io/latest/zh/docs/tasks/traffic-management/ingress/ingress-control):
您可以使用类似的命令找到任何网关上的其他端口。 例如在名为 my-gateway 的网关上访问名为 https 的安全 HTTP 端口：
export INGRESS_HOST=$(kubectl get gtw my-gateway -o jsonpath='{.status.addresses[*].value}')
export SECURE_INGRESS_PORT=$(kubectl get gtw my-gateway -o jsonpath='{.spec.listeners[?(@.name=="https")].port}') 执行如下指令，确定您的 Kubernetes 集群是否运行在支持外部负载均衡器的环境中：
$ kubectl get svc "$INGRESS_NAME" -n "$INGRESS_NS"
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
istio-ingressgateway LoadBalancer 172.21.109.129 130.211.10.121 ... 17h 如果 EXTERNAL-IP 值已设置，说明环境正在使用外部负载均衡器，可以用其为 Ingress Gateway 提供服务。 如果 EXTERNAL-IP 值为 <none> （或持续显示 <pending>），说明环境没有为 Ingress Gateway 提供外部负载均衡器，无法使用 Ingress Gateway。 Ingress Gateway 允许定义进入服务网格的流量入口，所有入站流量都通过该入口；Egress Gateway 与之相对，它定义了网格的流量出口。 k8s的Gateway Api 是 Ingress Api的升级版本，目前还在开发中，很多服务商现在开始提供Gateway服务. 参考k8s官网:https://gateway-api.sigs.k8s.io/`}]},{path:"/content/service/k8s/k8s%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html",title:"k8s之基本概念",pathLocale:"/",contents:[{header:"",slug:"",content:`Cluster、Master、Node、 Namespace 介绍 1.Cluster
Cluster（集群） 是计算、存储和网络资源的集合，Kubernetes 利用这些资源运行各种基于容器的应用。
最简单的 Cluster 可以只有一台主机（它既是 Mater 也是 Node） 2.Master
Master 是 Cluster 的大脑，它的主要职责是调度，即决定将应用放在哪里运行。
Master 运行 Linux 操作系统，可以是物理机或者虚拟机。
为了实现高可用，可以运行多个 Master。 3.Node
Node 的职责是运行容器应用。
Node 由 Master 管理，Node 负责监控并汇报容器的状态，并根据 Master 的要求管理容器的生命周期。
Node 运行在 Linux 操作系统，可以是物理机或者是虚拟机。 Namespace 1.在Kubernetes中，命名空间提供了一种机制来隔离单个集群中的资源组。资源的名称在一个命名空间内
需要是唯一的，但在不同的命名空间之间不需要。基于命名空间的范围只适用于命名空间的对象（如部署、服务等），
而不适用于集群范围的对象（如StorageClass、Nodes、PersistentVolumes等） 2.何时使用多个命名空间
命名空间是为了在有许多用户分布在多个团队或项目的环境中使用。对于只有几个到几十个用户的集群，你应该根本不需要创建或考虑命名空间。当你需要命名空间提供的功能时，开始使用命名空间。 命名空间提供了一个名字的范围。资源的名称在一个命名空间内需要是唯一的，但在不同的命名空间之间不需要。命名空间不能相互嵌套，每个Kubernetes资源只能在一个命名空间中。 命名空间是在多个用户之间划分集群资源的一种方式（通过资源配额）。 没有必要使用多个命名空间来分隔略有不同的资源，例如同一软件的不同版本：使用标签来区分同一命名空间内的资源 3.Kubernetes 默认创建了四个 Namespace:
default: 创建资源时如果不指定，将被放到这个 Namespace 中。 kube-node-lease: 这个命名空间持有与每个节点相关的租约对象。节点租赁允许kubelet发送心跳，以便控制平面能够检测到节点故障。 kube-public: 这个命名空间可以被所有的客户（包括那些未经认证的客户）阅读。这个命名空间主要保留给集群使用，因为有些资源应
该在整个集群中公开可见和可读。这个命名空间的公共性只是一个惯例，而不是一个要求。 kube-system: Kubernetes 自己创建的系统资源将放到这个 Namespace 中。 Controller 在 K8s 中，用户通过声明式 API 定义资源的“预期状态”，Controller 则负责监视资源的实际状态，当资源的
实际状态和“预期状态”不一致时，Controller 则对系统进行必要的更改，以确保两者一致，这个过程被称之为调
谐（Reconcile）。 K8s 中有多种类型的 Controller，例如 Deployment Controller、ReplicaSet Controller 和 StatefulSet Controller等。
每个控制器都有不同的工作原理和适用场景，但它们的基本原理都是相同的。我们也可以根据需要编写 Controller 来实现自定义的业
务逻辑。 有时候 Controller 也被叫做 Operator。这两个术语的混用有时让人感到迷惑。Controller 是一个通用的术语，凡是遵循 “Watch K8s 资源并根据资源变化进行调谐” 模式的控制程序都可以叫做 Controller。而 Operator 是一种专用的 Controller，用于在 Kubernetes 中管理一些复杂的，有状态的应用程序。例如在 Kubernetes 中管理 MySQL 数据库的 MySQL Operator。 Service 问题: Deployment 可以部署多个副本，每个 Pod 都有自己的 IP。而 Pod 很可能会被频繁地销毁和重启，它们的 IP 会发生变化，用 IP 来访问 Deployment 副本不太现实。
解决: Service 定义了外界访问一组特定 Pod 的方式。Service 有自己的 IP 和端口，Service 为 Pod 提供了负载均衡。 Pod 介绍 1.Pod 是 Kubernetes 的最小工作单元。
2.每个 Pod 包含一个或多个容器。Pod 中的容器会作为一个整体被 Master 调度到一个 Node 上运行。`}]},{path:"/content/service/k8s/k8s%E5%90%84%E5%AF%B9%E8%B1%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.html",title:"k8s各对象之间的关系",pathLocale:"/",contents:[{header:"",slug:"",content:`关于Pod:
Pod是一个或多个容器的组合，这些容器共享存储、网络和命名空间，以及如何运行的规范。Pod是Kubernetes的最小可部署单元。Pod的中文译词是豌豆荚，docker容器就像是豆子运行在豌豆荚内。 关于ReplicaSet:
这个参数主要是定义Pod运行的副本数 关于Deployment:
Deployment用于管理Pod、ReplicaSet，可实现滚动升级和回滚应用、扩容和缩容。 关于Service:
k8s的Service定义了一个服务的访问入口地址，前端的应用通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，来自外部的访问请求被负载均衡到后端的各个容器应用上。Service与其后端Pod副本集群之间则是通过Label Selector实现关联。 关于Service的type选择，官方文档对type的说明如下[注：直接 运行kubectl explain KindName]：
kubectl explain Service.spec.type
type	<string> type determines how the Service is exposed. Defaults to ClusterIP. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer. "ExternalName" maps to the specified externalName. "ClusterIP" allocates a cluster-internal IP address for load-balancing to endpoints. Endpoints are determined by the selector or if that is not specified, by manual construction of an Endpoints object. If clusterIP is "None", no virtual IP is allocated and the endpoints are published as a set of endpoints rather than a stable IP. "NodePort" builds on ClusterIP and allocates a port on every node which routes to the clusterIP. "LoadBalancer" builds on NodePort and creates an external load-balancer (if supported in the current cloud) which routes to the clusterIP. More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
简单来说：type包括四种类型 ExternalName ClusterIP(默认) NodePort LoadBalancer，其中用的比较多的就是 ClusterIP 和 NodePort，在实际应用中，假如没有用阿里云或者腾讯云，就是自己纯手工配置的话，当选择 ClusterIP
以后可能还需要配合 ingress 才能让外网访问，我就是用了 nginx-ingress(用 istio 没有配置成功,但是 istio 是最好的方案)，但是发现很鸡肋，因为nginx-ingress也会使用NodePort形式暴露端口，而且只能是 30000-32767 之间
的端口。这就有个问题没法使用80/443，所以后来我就没有使用这个方案，选择了 NodePort 方案，这种方案可以通过ip:port访问，如何配置域名访问，那就很简单了，直接通过 nginx 反向代理就可以了，实现80/443端口访问。当然
如果使用阿里云或者腾讯云这都不是问题了，后面我会在腾讯云上跑这个流程。 关于端口: ①port是k8s集群内部访问service的端口，即通过clusterIP: port可以访问到某个service
②nodePort是外部访问k8s集群中service的端口，通过nodeIP: nodePort可以从外部访问到某个service // 注意:如果启用nodePort，那么会在所有node上都会启用这个端口，包括worker节点和master节点
③targetPort是pod的端口，从port和nodePort来的流量经过kube-proxy流入到后端pod的targetPort上，最后进入容器
④containerPort是pod内部容器的端口，targetPort映射到containerPort`}]},{path:"/content/service/k8s/k8s%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E5%88%87%E6%8D%A2.html",title:"kubectl操作多个k8s集群的方法",pathLocale:"/",contents:[{header:"",slug:"",content:`kubectl操作多个k8s集群的方法：
需要合并 kubeconfig，如下操作就可以了，后面只用一个 --flatten即可，不要 --merge，否则，后面的会覆盖之前的config，血泪教训，因为腾讯的 serveless 文档就是这么操作的，非常坑
[root@k8smaster tmp]# cp ~/.kube/config ~/.kube/config.bak //一定要先备份之前的config，方便还原
[root@k8smaster tmp]# KUBECONFIG=~/.kube/config:/usr/local/k8s_tencent_kubeconfig/cls-m3mx4sot-config kubectl config view --flatten > /tmp/config
[root@k8smaster tmp]# mv /tmp/config ~/.kube/config
[root@k8smaster tmp]# export KUBECONFIG=~/.kube/config 查看集群下所有config的内容:
[root@k8smaster tmp]# kubectl config view
apiVersion: v1
clusters:
- cluster: certificate-authority-data: DATA+OMITTED server: https://xx.xx.xx.xx:443/ name: cls-m3mx4sot
- cluster: certificate-authority-data: DATA+OMITTED server: https://xx.xx.xx.xx:6443 name: kubernetes
contexts:
- context: cluster: cls-m3mx4sot user: "100021763219" name: cls-m3mx4sot-100021763219-context-default
- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetes
current-context: cls-m3mx4sot-100021763219-context-default
kind: Config
preferences: {}
users:
- name: "100021763219" user: client-certificate-data: REDACTED client-key-data: REDACTED
- name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED
[root@k8smaster tmp]# 获取多个集群环境：
[root@k8smaster tmp]# kubectl config get-contexts [root@k8smaster tmp]# kubectl config current-context
cls-m3mx4sot-100021763219-context-default
[root@k8smaster tmp]# 切换k8s集群环境:
[root@k8smaster tmp]# kubectl config use-context cls-3jju4zdc-context-default 测试以下默认名称空间下的node:
[root@k8smaster tmp]# kubectl get node 实际应用中其实是这么操作的:
kubectl 使用 --kubeconfig 指定 config 文件地址访问不同的集群
比如下面的操作:
[root@k8smaster ~]# kubectl --kubeconfig ~/.kube/config get nodes // ~/.kube/config 为集群配置文件(config文件路劲可以任意定义，这里只是用了默认的路径)，这里可能是腾讯云上的 A 集群配置，也可以是腾讯云上的 B 集群配置，也可以是其它的
[root@k8smaster ~]# kubectl --kubeconfig ~/.kube/config apply -f service.yaml // 在指定集群下启动服务`}]},{path:"/content/service/k8s/k8s%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B.html",title:"k8s日志查看",pathLocale:"/",contents:[{header:"",slug:"",content:`k8s日志查看，注意指定命名空间：
1.查看指定pod的运行日志
[root@k8smaster k8s-cluster]# kubectl logs -f pods/user-develop-76ff85f7d5-4vm4s -n hello-api-namespace
2022/10/10 04:56:08 server listening at 127.0.0.1:8066
^C
[root@k8smaster k8s-cluster]# kubectl logs -f pods/hello-api-app-75cf6d7bd-22zzk -n hello-api-namespace
2022/10/10 05:44:50 rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 0.0.0.0:8066: connect: connection refused"
2022/10/10 05:44:53 rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 0.0.0.0:8066: connect: connection refused"
2022/10/10 05:45:24 rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial tcp 0.0.0.0:8066: connect: connection refused" 2.查看指定pod的构建日志
[root@k8smaster k8s-cluster]# kubectl describe pods hello-api-app-75cf6d7bd-22zzk -n hello-api-namespace
Name: hello-api-app-75cf6d7bd-22zzk
Namespace: hello-api-namespace
Priority: 0
Node: worker1/124.221.202.241
Start Time: Mon, 10 Oct 2022 13:40:09 +0800
Labels: app.kubernetes.io/name=hello-api-app pod-template-hash=75cf6d7bd
Annotations: <none>
Status: Running
IP: 10.244.1.75
IPs: IP: 10.244.1.75
Controlled By: ReplicaSet/hello-api-app-75cf6d7bd
Containers: hello-api-app: Container ID: docker://ea31cfdeee37f348166766caff00b4c42e492de19887759052fe9e89f4cb25ba Image: chetaixian/k8s-cluster:v1.0.5 Image ID: docker-pullable://chetaixian/k8s-cluster@sha256:b8ae14bb0267db523d4f7a602aadb144e49678877ab39bceab14ea13710beac0 Port: 8082/TCP Host Port: 0/TCP State: Running Started: Mon, 10 Oct 2022 13:40:41 +0800 Ready: True Restart Count: 0 Environment: <none> Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-9t8rf (ro)
Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True
Volumes: default-token-9t8rf: Type: Secret (a volume populated by a Secret) SecretName: default-token-9t8rf Optional: false
QoS Class: BestEffort
Node-Selectors: <none>
Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28m default-scheduler Successfully assigned hello-api-namespace/hello-api-app-75cf6d7bd-22zzk to worker1 Normal Pulling 28m kubelet Pulling image "chetaixian/k8s-cluster:v1.0.5" Normal Pulled 27m kubelet Successfully pulled image "chetaixian/k8s-cluster:v1.0.5" Normal Created 27m kubelet Created container hello-api-app Normal Started 27m kubelet Started container hello-api-app`}]},{path:"/content/service/k8s/k8s%E9%83%A8%E7%BD%B2golang%E9%A1%B9%E7%9B%AE%E4%B9%8B%E8%8E%B7%E5%8F%96%E9%A1%B9%E7%9B%AE%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98.html",title:"k8s部署golang项目之获取项目依赖问题",pathLocale:"/",contents:[{header:"",slug:"",content:`k8s部署golang项目之获取项目依赖问题:
docker build golang项目的时候，需要获取go程序的依赖，可能会有如下的问题:
[root@k8smaster k8s-hello]# docker build -t chetaixian/hello-wolrd:v1.0.3 .
...
...
Step 5/6 : RUN go build -o main . ---> Running in 9ac63e6c09eb
go: downloading github.com/spf13/viper v1.13.0
cmd/config.go:5:2: github.com/spf13/viper@v1.13.0: Get "https://proxy.golang.org/github.com/spf13/viper/@v/v1.13.0.zip": dial tcp 142.251.42.241:443: i/o timeout
The command '/bin/sh -c go build -o main .' returned a non-zero code: 1 在这里如果Dockerfile里面没有配置 go proxy，那么就会从国外站点拉取go项目依赖，一般是拉取不成功的，为了解决这个问题，可以加上 go proxy:
FROM golang:alpine
RUN mkdir /hello-world
COPY . /hello-world
WORKDIR /hello-world
#设置代理
RUN GOPROXY="https://goproxy.cn" GO111MODULE=on go build -o main .
#RUN go build -o main .
CMD ["/hello-world/main", "--config", "/etc/app/config.yaml"] 这样基本就不会有问题 //有时候需要引入私有仓库，通过下面的命令
go env -w GOPRIVATE=gitee.com //假如这个私有仓库是http的，而非https，需要加入insecure里
go env -w GOINSECURE=go.qinhongzs.com //由于配置了私有仓库，那么在 go mod tidy 或者 go get 的时候 需要登录 输入用户名和密码，这个在自动发布项目就会有问题，解决办法就是在 ~/.netrc 文件里记录私
有仓库的登录信息，如下就是记录了 gitee下的账号信息，如果执行 git pull 就不用再输入账号密码信息；go mod tidy 或者 go get 实际上也是调用 git 命令拉取相关的
依赖，也就不用再输入账号密码信息了，这个在做 k8s 的项目自动发布的时候很有用，后面得分项目我会用大
[root@k8smaster ~]# vim ~/.netrc
machine gitee.com
login xxxxx@qq.com
password xxxyyyx=zzz 如果有多个 server 就重复上面的三行， 分别输入对应的服务器、 用户名和密码即可. 也可以把这三行写在同一行：machine gitee.com login xxxxx@qq.com password xxxyyyx=zzz`}]},{path:"/content/service/k8s/k8s%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEHTTPS%E8%AE%BF%E9%97%AE.html",title:"k8s集群配置HTTPS访问",pathLocale:"/",contents:[{header:"",slug:"",content:`k8s集群配置HTTPS访问:
主要是要配置一个Secret的资源，通过yaml文件配置(不想通过命令行)，格式如下：
apiVersion: v1
kind: Secret
metadata: name: k8s-secret-tls namespace: hello-api-namespace
data: tls.crt: 文件内容 tls.key: 文件内容
type: kubernetes.io/tls`}]},{path:"/content/service/k8s/nginx-ingress%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"nginx-ingress的使用",pathLocale:"/",contents:[{header:"",slug:"",content:`nginx-ingress的使用
为什么用到nginx-ingress？，在配置完k8s以后，比如说我通过go开发的api对外提供服务，我可能需要对外提供服务，在这个过程中，需要将IP地址解析到域名，开始我准备使用istio配置的，
但是后来由于版本的问题，一直有问题，我的k8s是1.18.6，后来想到nginx-ingress，这个一定要注意版本的选择，在github 上基本上只列出了k8s1.19+以上的版本的兼容信息，我就选择了
v0.45.0版本，结果没有任何问题
这是我的ingress配置文件
# test-ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata: name: nginx-network-ingress namespace: nginx-ingress-namespace
spec: # 1.18及以后版本需要通过ingressClassName指定使用的controller，或者在ingressClass中设置默认controller，否则ingress不生效 ingressClassName: nginx rules: - host: ingress.xxx.com http: paths: - path: / backend: serviceName: nginx-ingress-app-service servicePort: 8082 tls: - hosts: - ingress.xxx.com secretName: nginx-ingress-app-secret 然后执行：
[root@k8smaster k8s-nginx-ingress]# kubectl apply -f network-ingress.yaml
ingress.networking.k8s.io/nginx-network-ingress created 检查域名映射情况:
[root@k8smaster k8s-nginx-ingress]# kubectl get ingresses -n nginx-ingress-namespace
NAME CLASS HOSTS ADDRESS PORTS AGE
nginx-network-ingress nginx ingress.xxx.com nodeIp 80, 443 2m38s 由于配置了tls，所以这里可以通过https访问，至于怎么配置https我在下一篇会讲到`}]},{path:"/content/service/k8s/pod%E4%B9%8Byaml%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90.html",title:"pod之yaml文件解析",pathLocale:"/",contents:[{header:"",slug:"",content:`pod之yaml文件解析
apiVersion: v1 #必选，版本号，例如v1
kind: Pod #必选，Pod
metadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #必选，Pod所属的命名空间 labels: #自定义标签 - name: string #自定义标签名字 annotations: #自定义注释列表 - name: string
spec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口号名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存清楚，容器启动的初始可用数量 livenessProbe: #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged:false restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork:false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: {} #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string`}]},{path:"/content/service/k8s/%E4%BD%BF%E7%94%A8minikube%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4.html",title:"使用minikube搭建k8s集群",pathLocale:"/",contents:[{header:"",slug:"",content:"使用minikube搭建k8s集群:"},{header:"安装kubectl",slug:"安装kubectl",content:`https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ $ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed
100 138 100 138 0 0 151 0 --:--:-- --:--:-- --:--:-- 151
100 53.7M 100 53.7M 0 0 16190 0 0:58:02 0:58:02 --:--:-- 13459 赋予执行权限:
$ chmod +x ./kubectl
然后:
$ sudo mv ./kubectl /usr/local/bin/ 上面两步也可以直接: sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
解释这个命令：
sudo install： install 命令用于复制文件并设置目标文件的权限和所有者。在这里我们使用 sudo 来以超级用户身份执行这个操作，确保有足够权限将文件安装到 /usr/local/bin。 -o root：指定目标文件的所有者为 root 用户。即 kubectl 文件将归 root 用户所有。 -g root：指定目标文件的用户组为 root。即文件将属于 root 用户组。 -m 0755：设置目标文件的权限为 0755，即文件所有者（root）具有读、写、执行权限，其他用户和用户组具有读、执行权限。这是常见的可执行文件权限设置。 kubectl：这是源文件的路径，即你之前下载的 kubectl 二进制文件。 /usr/local/bin/kubectl：这是目标文件路径，kubectl 将被安装到 /usr/local/bin/ 目录下，这样它就可以全局访问。 #####kubectl常规命令
删除集群
kind delete cluster --name kind 或者 kind delete clusters --all 查看集群的节点:
kubectl get nodes 查看所有 Pod:
kubectl get pods --all-namespaces 查看运行中的部署:
kubectl get deployments 查看日志:
kubectl describe pod -n kube-flannel <POD_NAME> 删除资源
kubectl delete -f kube-flannel.yml 重新运行
kubectl apply -f kube-flannel.yml #####配置docker cli代理
vim ~/.docker/config.json
{ "proxies": { "default": { "httpProxy": "http://127.0.0.1:7890", "httpsProxy": "http://127.0.0.1:7890", "noProxy": "localhost,127.0.0.1" } }
} 这样可以直接docker pull 等操作
最后直接去 docker hub 找到镜像: https://hub.docker.com/r/flannel/flannel-cni-plugin/tags
然后通过 cli 拉取: docker pull flannel/flannel-cni-plugin:v1.6.0-flannel1 #####使用minikube搭建k8s集群
前提需要kubectl安装完毕 1.minikube 安装
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube 2.启动
minikube start
这个命令会创建并启动一个本地的Kubernetes集群。默认情况下，Minikube会使用Docker驱动。默认: minikube start --driver=docker, 可以换其它驱动，如: minikube start --driver=virtualbox。分配资源: minikube start --cpus 4 --memory 8192 注意: Minikube 是一个本地的 Kubernetes 集群管理工具，它可以使用容器（如 Docker）或者虚拟机技术来运行。当你使用 Docker 驱动时，Minikube 本质上是通过在 Docker 容器内运行 Kubernetes 控制平面和工作负载来模拟一个 Kubernetes 集群。所以一定要注意一个问题，宿主机上的docker和通过Minikube创建的容器中的docker是不一样的，前面所有的代理问题都和这个有关系，比如后面想搭建一个redis集群，yaml文件的镜像拉取失败，最后的解决办法是在宿主机上执行: docker pull redis:6.2 (我配置了docker cli 代理,左翼是可以拉取镜像)，然后将镜像加载到 Minikube，通过: minikube image load redis:6.2，最后才可以运行起来. 关于minikube代理配置，参考: https://minikube.sigs.k8s.io/docs/handbook/vpn_and_proxy/ 3.查看集群状态
# 查看集群信息
kubectl cluster-info
正常情况如下提示:
Kubernetes control plane is running at https://192.168.49.2:8443
CoreDNS is running at https://192.168.49.2:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy # 查看节点状态
kubectl get nodes
正常情况如下提示:
NAME STATUS ROLES AGE VERSION
minikube Ready control-plane 6m14s v1.31.0 4.停止集群
minikube stop 5.删除集群
minikube delete 6.查看集群仪表板
minikube dashboard
这将启动 Dashboard，并自动在浏览器中打开一个界面。你不需要手动启动 kubectl proxy，Minikube 会为你处理这一切。与 kubectl 命令一样，Dashboard 也需要适当的权限。如果你正在使用 Minikube，它会使用 Minikube 默认的配置和权限，通常你无需做额外的设置。 7.ssh进入Minikube虚拟机
minikube ssh #####使用minikube搭建的k8s，搭建 redis 集群
分别准备两个yaml文件
guoshipeng@k8s:/usr/local/k8s-local/redis-cluser$ kubectl apply -f redis-service.yaml
service/redis-service created
guoshipeng@k8s:/usr/local/k8s-local/redis-cluser$ kubectl apply -f redis-statefulset.yaml
statefulset.apps/redis created
guoshipeng@k8s:/usr/local/k8s-local/redis-cluser$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
minikube Ready control-plane 130m v1.31.0
guoshipeng@k8s:/usr/local/k8s-local/redis-cluser$ guoshipeng@k8s:/usr/local/k8s-local/redis-cluser$ kubectl get pods
NAME READY STATUS RESTARTS AGE
redis-0 1/1 Running 0 15s
redis-1 1/1 Running 0 11s
redis-2 1/1 Running 0 8s //宿主机直接连接
$ redis-cli -h 192.168.49.2 -p 30079
// 直接 set key 发现报错，突然想起来，我这是一个k8s的redis集群，需要为集群内的节点分配slot
CLUSTERDOWN Hash slot not served 192.168.49.2:30079> cluster nodes
f8c27f635bee637fa579274b11cac1834078eb27 :6379@16379 myself,master - 0 0 0 connected
192.168.49.2:30079> cluster info
cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:0
cluster_current_epoch:0
cluster_my_epoch:0
cluster_stats_messages_sent:0
cluster_stats_messages_received:0
说明集群有问题，没有互通 // 默认k8s集群内的三个节点的互通ip为 10.0.0.1:6379 10.0.0.2:6379 10.0.0.3:6379，如果是在某个worker上执行如下命令，那么只需要meet其它两个就可以了，不再要meet自己，但是我们这里是通过k8s搭建的redis集群，所以需要分别meet这三个
192.168.49.2:30079> cluster meet 10.0.0.1 6379
OK
192.168.49.2:30079> cluster meet 10.0.0.2 6379
OK
192.168.49.2:30079> cluster meet 10.0.0.3 6379
OK 再次设置key，但是还是报(可能出现):
CLUSTERDOWN Hash slot not served 这个问题说明集群存在hash槽异常情况，那么，可以执行以下指令修复下手动修复slot分配问题:
$ redis-cli --cluster fix 192.168.49.2:30079
192.168.49.2:30079 (3f92737a...) -> 0 keys | 0 slots | 0 slaves.
[OK] 0 keys in 1 masters.
0.00 keys per slot on average.
>>> Performing Cluster Check (using node 192.168.49.2:30079)
M: 3f92737a49748ebde447c7c5cba49ce01bc241e9 192.168.49.2:30079 slots: (0 slots) master
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[ERR] Not all 16384 slots are covered by nodes. >>> Fixing slots coverage...
The following uncovered slots have no keys across the cluster:
[0-16383]
Fix these slots by covering with a random node? (type 'yes' to accept): yes
...
...
>>> Covering slot 16282 with 192.168.49.2:30079
>>> Covering slot 1501 with 192.168.49.2:30079
>>> Covering slot 3300 with 192.168.49.2:30079
>>> Covering slot 14876 with 192.168.49.2:30079
>>> Covering slot 13993 with 192.168.49.2:30079
>>> Covering slot 10272 with 192.168.49.2:30079
>>> Covering slot 694 with 192.168.49.2:30079
...
... 再次:
$ redis-cli -h 192.168.49.2 -p 30079 192.168.49.2:30079> cluster nodes
cfdfa8b787ea1fe5bcbb15fb6bf548113a1a5939 10.0.0.2:6379@16379 handshake - 0 0 0 connected
41059609d6a7a9a76642788bac228a08fc1dd01f :6379@16379 myself,master - 0 0 1 connected 0-16383 // 但是不确定这个来自哪里
5c2813c1186543cea74d51a77b5d620b367d65a9 10.0.0.3:6379@16379 handshake - 0 0 0 connected
af2ea4819716fc39def29441bd1bef4cd6142151 10.0.0.1:6379@16379 handshake - 0 0 0 connected 192.168.49.2:30079> cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:3
cluster_size:1
cluster_current_epoch:1
cluster_my_epoch:1
cluster_stats_messages_sent:0
cluster_stats_messages_received:0 现在信息正常了
然后设置key信息 但是后来再执行:
192.168.49.2:30079> cluster nodes
41059609d6a7a9a76642788bac228a08fc1dd01f :6379@16379 myself,master - 0 0 1 connected 0-16383
只有上面一条 192.168.49.2:30079> cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:1
cluster_current_epoch:1
cluster_my_epoch:1
cluster_stats_messages_sent:0
cluster_stats_messages_received:0
还是正常的 我发现退出当前连接：
192.168.49.2:30079> exit
再次进来:
$ redis-cli -h 192.168.49.2 -p 30079
192.168.49.2:30079> cluster info
cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:0
cluster_current_epoch:0
cluster_my_epoch:0
cluster_stats_messages_sent:0
cluster_stats_messages_received:0
192.168.49.2:30079> 192.168.49.2:30079> cluster nodes
f8c27f635bee637fa579274b11cac1834078eb27 :6379@16379 myself,master - 0 0 0 connected
发现redis集群又不能访问了，主要是集群hash又有问题了，需要重新redis-cli --cluster fix 192.168.49.2:30079，反正有问题要么重新hash，要么meet节点 删除redis集群:
$ kubectl delete -f redis-service.yaml
service "redis-service" deleted
$ kubectl delete -f redis-statefulset.yaml
statefulset.apps "redis" deleted redis-service.yaml
apiVersion: v1
kind: Service
metadata: name: redis-service labels: app: redis
spec: type: NodePort ports: - port: 6379 # Redis 服务的端口 targetPort: 6379 # Pod 中 Redis 容器的端口 nodePort: 30079 # 暴露到主机的端口 selector: app: redis redis-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata: name: redis
spec: serviceName: "redis-service" replicas: 3 selector: matchLabels: app: redis template: metadata: labels: app: redis spec: containers: - name: redis image: redis:6.2 ports: - containerPort: 6379 volumeMounts: - name: data mountPath: /data args: - "redis-server" - "--appendonly" - "yes" - "--cluster-enabled" - "yes" - "--cluster-config-file" - "/data/nodes.conf" volumeClaimTemplates: - metadata: name: data spec: accessModes: ["ReadWriteOnce"] resources: requests: storage: 1Gi #####StatefulSet的作用
StatefulSet 是 Kubernetes 中的一种控制器，专门设计用于管理 有状态应用 的部署和扩展。它提供了一种机制来确保应用实例的标识、存储和顺序在扩展或重启时保持一致。 StatefulSet 的特点
1.稳定的网络标识（Stable Network Identity） 每个 Pod 都有一个唯一的名称，以 StatefulSet 名称 + 索引号 的形式命名，例如 redis-0, redis-1, redis-2。
这些 Pod 会通过一个 Headless Service 暴露，并拥有稳定的 DNS 名称（如 redis-0.redis-headless.default.svc.cluster.local），即使 Pod 被删除重建，其 DNS 名称也保持不变。 2.稳定的存储（Stable Storage） 每个 Pod 都可以使用一个独立的 PersistentVolume，这些卷与 Pod 紧密绑定。即使 Pod 被删除，卷中的数据仍然保留，并在 Pod 重建时重新挂载。 3.有序部署和更新（Ordered, Graceful Deployment and Scaling） Pods 的创建、更新和删除按顺序进行。例如： 按索引从小到大逐个创建 Pod。
更新时，会等待前一个 Pod 更新完成并处于 Ready 状态后再更新下一个。
删除 Pods 时，会按索引从大到小逐步删除。 4.支持有状态工作负载 StatefulSet 是为那些需要对每个实例保持唯一状态的工作负载设计的，比如数据库（Redis、MySQL、Cassandra 等）、分布式缓存、消息队列等。 #####StatefulSet 的使用场景
1.分布式数据库 如 Redis 集群、Cassandra、MongoDB 等，它们需要稳定的网络标识和持久化存储。 2.分布式文件系统 如 HDFS、Ceph、GlusterFS。 3.需要顺序依赖的服务 一些服务需要按照特定顺序启动，比如主节点需要先启动，随后是从节点。 4.任何有状态的应用 比如 Kafka、Zookeeper、Elasticsearch。 #####StatefulSet 的行为
扩容：添加一个新 Pod（如 redis-3），并分配新的存储卷。
缩容：删除一个 Pod（如 redis-2），但卷不会自动删除。
重启：重新创建时，Pod 和存储的关系保持一致。 #####StatefulSet vs Deployment
特性 StatefulSet Deployment
Pod的命名 稳定（如 redis-0, redis-1） 动态生成（如 nginx-xyzabc）
存储 持久化，每个 Pod 独立存储 通常为临时存储
网络标识 固定的 DNS 名称 动态分配的 IP 和主机名
应用场景 数据库、分布式系统、缓存等有状态服务 无状态服务，如 Web 应用
更新顺序 按序更新（0 -> N） 无特定顺序 总结:
StatefulSet 是 Kubernetes 中管理有状态应用的核心组件，提供了稳定的标识和存储，适合需要持久化数据和顺序启动的场景。如果你的应用是无状态的（如 Web 服务），Deployment 是更合适的选择；但如果你需要运行数据库或类似的服务，StatefulSet 就是最优解。`}]},{path:"/content/service/k8s/%E4%BD%BF%E7%94%A8minikube%E9%85%8D%E7%BD%AEdashboard.html",title:"使用minikube配置dashboard",pathLocale:"/",contents:[{header:"",slug:"",content:`使用minikube配置dashboard:
//前置条件
清理掉docker cli 代理配置
sudo vim ~/.docker/config.json
{ "proxies": {}
} 恢复 /etc/resolve.conf里的配置 (之前加了dns 8.8.8.8，没用)
sudo vim /etc/resolve.conf
nameserver 127.0.0.53
options edns0 trust-ad
search . 恢复 /etc/hosts下的配置 (修改过本地hostname的解析，没用)
$ hostname
tianyi510s 最后修改了 daemon.json的配置:
sudo vim /etc/docker/daemon.json
{
"registry-mirrors": [
"https://docker.unsee.tech",
"https://dockerpull.org",
"https://dockerhub.icu"
]
} 记得执行: sudo systemctl daemon-reload && sudo systemctl restart docker 这几个镜像加速配置的链接信息(镜像加速查询集合): https://www.cnblogs.com/alex-oos/p/18417200 重点: 其实docker的镜像配置，无论是 daemon 还是cli(虽然cli的可以通过最上面的方式配置)的，直接配置 /etc/docker/daemon.json 对两种方式都生效，根本不需要配置docker.service.d/http-proxy.conf，完全扯蛋的. //正式开始
$ minikube dashboard
🤔 Verifying dashboard health ...
🚀 Launching proxy ...
🤔 Verifying proxy health ... //查看pod状态:
$ kubectl get pods -n kubernetes-dashboard
NAME READY STATUS RESTARTS AGE
dashboard-metrics-scraper-c5db448b4-9wxtf 0/1 ImagePullBackOff 0 117s
kubernetes-dashboard-695b96c756-ftld6 0/1 ErrImagePull 0 117s
kubernetes-dashboard-6b9d555977-rltvk 0/1 ContainerCreating 0 10s //然后就计划拉取镜像到本地，然后load到minikube(主要就是下面这两个镜像)
$ docker pull kubernetesui/dashboard:v2.7.0
v2.7.0: Pulling from kubernetesui/dashboard
Digest: sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93
Status: Downloaded newer image for kubernetesui/dashboard:v2.7.0
docker.io/kubernetesui/dashboard:v2.7.0 $ docker pull kubernetesui/metrics-scraper:v1.0.8
v1.0.8: Pulling from kubernetesui/metrics-scraper
978be80e3ee3: Pull complete 5866d2c04d96: Pull complete Digest: sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c
Status: Downloaded newer image for kubernetesui/metrics-scraper:v1.0.8
docker.io/kubernetesui/metrics-scraper:v1.0.8 //加载镜像到Minikube
minikube image load kubernetesui/dashboard:v2.7.0
minikube image load kubernetesui/metrics-scraper:v1.0.8 //重新启动 Kubernetes Dashboard
kubectl rollout restart deployment kubernetes-dashboard -n kubernetes-dashboard //执行下面命令查看pods状态，还是有问题
$ kubectl get pods -n kubernetes-dashboard
NAME READY STATUS RESTARTS AGE
dashboard-metrics-scraper-c5db448b4-9wxtf 0/1 ImagePullBackOff 0 117s
kubernetes-dashboard-695b96c756-ftld6 0/1 ErrImagePull 0 117s
kubernetes-dashboard-6b9d555977-rltvk 0/1 ContainerCreating 0 10s //然后执行命令查看 kubernetes-dashboard 命名空间下的pod描述信息
$ kubectl describe pod -n kubernetes-dashboard
Name: dashboard-metrics-scraper-c5db448b4-9wxtf
Namespace: kubernetes-dashboard
Priority: 0
Service Account: kubernetes-dashboard
Node: minikube/192.168.49.2
Start Time: Tue, 10 Dec 2024 22:48:35 +0800
Labels: k8s-app=dashboard-metrics-scraper pod-template-hash=c5db448b4
Annotations: seccomp.security.alpha.kubernetes.io/pod: runtime/default
Status: Pending
IP: 10.244.0.4
IPs: IP: 10.244.0.4
Controlled By: ReplicaSet/dashboard-metrics-scraper-c5db448b4
Containers: dashboard-metrics-scraper: Container ID: Image: docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c Image ID: Port: 8000/TCP Host Port: 0/TCP State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Liveness: http-get http://:8000/ delay=30s timeout=30s period=10s #success=1 #failure=3 Environment: <none> Mounts: /tmp from tmp-volume (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6t9pr (ro)
Conditions: Type Status PodReadyToStartContainers True Initialized True Ready False ContainersReady False PodScheduled True Volumes: tmp-volume: Type: EmptyDir (a temporary directory that shares a pod's lifetime) Medium: SizeLimit: <unset> kube-api-access-6t9pr: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true
QoS Class: BestEffort
Node-Selectors: kubernetes.io/os=linux
Tolerations: node-role.kubernetes.io/master:NoSchedule node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 8m15s default-scheduler Successfully assigned kubernetes-dashboard/dashboard-metrics-scraper-c5db448b4-9wxtf to minikube Normal Pulling 5m42s (x4 over 8m12s) kubelet Pulling image "docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c" Warning Failed 5m18s (x4 over 7m42s) kubelet Failed to pull image "docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c": Error response from daemon: Get "https://registry-1.docker.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) Warning Failed 5m18s (x4 over 7m42s) kubelet Error: ErrImagePull Warning Failed 5m8s (x6 over 7m42s) kubelet Error: ImagePullBackOff Normal BackOff 3m5s (x13 over 7m42s) kubelet Back-off pulling image "docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c" Name: kubernetes-dashboard-68df97dbb4-gsfwg
Namespace: kubernetes-dashboard
Priority: 0
Service Account: kubernetes-dashboard
Node: minikube/192.168.49.2
Start Time: Tue, 10 Dec 2024 22:56:05 +0800
Labels: gcp-auth-skip-secret=true k8s-app=kubernetes-dashboard pod-template-hash=68df97dbb4
Annotations: kubectl.kubernetes.io/restartedAt: 2024-12-10T22:56:05+08:00
Status: Pending
IP: 10.244.0.6
IPs: IP: 10.244.0.6
Controlled By: ReplicaSet/kubernetes-dashboard-68df97dbb4
Containers: kubernetes-dashboard: Container ID: Image: docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93 Image ID: Port: 9090/TCP Host Port: 0/TCP Args: --namespace=kubernetes-dashboard --enable-skip-login --disable-settings-authorizer State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Liveness: http-get http://:9090/ delay=30s timeout=30s period=10s #success=1 #failure=3 Environment: <none> Mounts: /tmp from tmp-volume (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-pgfqd (ro)
Conditions: Type Status PodReadyToStartContainers True Initialized True Ready False ContainersReady False PodScheduled True Volumes: tmp-volume: Type: EmptyDir (a temporary directory that shares a pod's lifetime) Medium: SizeLimit: <unset> kube-api-access-pgfqd: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true
QoS Class: BestEffort
Node-Selectors: kubernetes.io/os=linux
Tolerations: node-role.kubernetes.io/master:NoSchedule node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 45s default-scheduler Successfully assigned kubernetes-dashboard/kubernetes-dashboard-68df97dbb4-gsfwg to minikube Warning Failed 20s kubelet Failed to pull image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93": Error response from daemon: Get "https://registry-1.docker.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) Warning Failed 20s kubelet Error: ErrImagePull Normal BackOff 20s kubelet Back-off pulling image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93" Warning Failed 20s kubelet Error: ImagePullBackOff Normal Pulling 6s (x2 over 42s) kubelet Pulling image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93" Name: kubernetes-dashboard-6b9d555977-rltvk
Namespace: kubernetes-dashboard
Priority: 0
Service Account: kubernetes-dashboard
Node: minikube/192.168.49.2
Start Time: Tue, 10 Dec 2024 22:50:22 +0800
Labels: gcp-auth-skip-secret=true k8s-app=kubernetes-dashboard pod-template-hash=6b9d555977
Annotations: kubectl.kubernetes.io/restartedAt: 2024-12-10T22:50:22+08:00
Status: Pending
IP: 10.244.0.5
IPs: IP: 10.244.0.5
Controlled By: ReplicaSet/kubernetes-dashboard-6b9d555977
Containers: kubernetes-dashboard: Container ID: Image: docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93 Image ID: Port: 9090/TCP Host Port: 0/TCP Args: --namespace=kubernetes-dashboard --enable-skip-login --disable-settings-authorizer State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Liveness: http-get http://:9090/ delay=30s timeout=30s period=10s #success=1 #failure=3 Environment: <none> Mounts: /tmp from tmp-volume (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mtg6l (ro)
Conditions: Type Status PodReadyToStartContainers True Initialized True Ready False ContainersReady False PodScheduled True Volumes: tmp-volume: Type: EmptyDir (a temporary directory that shares a pod's lifetime) Medium: SizeLimit: <unset> kube-api-access-mtg6l: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true
QoS Class: BestEffort
Node-Selectors: kubernetes.io/os=linux
Tolerations: node-role.kubernetes.io/master:NoSchedule node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 6m28s default-scheduler Successfully assigned kubernetes-dashboard/kubernetes-dashboard-6b9d555977-rltvk to minikube Normal Pulling 4m2s (x4 over 6m26s) kubelet Pulling image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93" Warning Failed 3m46s (x4 over 6m11s) kubelet Failed to pull image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93": Error response from daemon: Get "https://registry-1.docker.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) Warning Failed 3m46s (x4 over 6m11s) kubelet Error: ErrImagePull Warning Failed 3m36s (x6 over 6m11s) kubelet Error: ImagePullBackOff Normal BackOff 78s (x14 over 6m11s) kubelet Back-off pulling image "docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93" //执行之后和上面一样的结果！！！！！
minikube dashboard //经过上面的操作，原来以为可以了，但是还是不行，最后查看了deployment的资源信息，做了如下操作，就可以了，不明白为什么，其实hash值和我手动拉取的hash值是一样的，我想了一下可能是我在执行 minikube image load 的时候，没有加hash的缘故. //编辑deployment文件(这个文件在我第一次执行minikube dashboard的时候就生成了)
kubectl edit deployment kubernetes-dashboard -n kubernetes-dashboard
然后把 image后的 2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93 hash字符串删掉 //编辑deployment文件(这个文件在我第一次执行minikube dashboard的时候就生成了)
kubectl edit deployment dashboard-metrics-scraper -n kubernetes-dashboard
然后把 image后的 76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c hash字符串删掉 //重新启动 Kubernetes Dashboard:
$ kubectl rollout restart deployment kubernetes-dashboard -n kubernetes-dashboard
deployment.apps/kubernetes-dashboard restarted //检查 Pod 的状态:
$ kubectl get pods -n kubernetes-dashboard
NAME READY STATUS RESTARTS AGE
dashboard-metrics-scraper-59d59485fd-bw2mw 1/1 Running 0 18s
kubernetes-dashboard-548cb8f845-j8f85 1/1 Running 0 7s //确定所有Pod都进入Running状态后，启动Dashboard:
$ minikube dashboard
🤔 Verifying dashboard health ...
🚀 Launching proxy ...
🤔 Verifying proxy health ...
🎉 Opening http://127.0.0.1:40351/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ in your default browser...
Opening in existing browser session. 终于成功了!!!!!!!!!!!!!!!`}]},{path:"/content/service/micro/goKit%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%93%E9%A2%98.html",title:"goKit微服务专题",pathLocale:"/",contents:[{header:"",slug:"",content:`goKit微服务专题:
1>go get 超时问题，主要是用了sudo的问题
https://github.com/goproxy/goproxy.cn/issues/93 2>三大模块: 传输层（Transport layer） 端点层（Endpoint layer） 服务层（Service layer） 3>consul配置
我的计划是单独跑一个服务注册的实例，比如 127.0.0.1:8010, 当有新的后端服务实例启动的时候，比如 这里有个127.0.0.1:8000 启动了，那么就向 127.0.0.1:8010 发一个消息，告诉它有新的服务启动了，需要consul注册这个后端服务实例 127.0.0.1:8010 的主要功能如下: serverIp := 127.0.0.1 // 后端服务ip，通过消息获取
port := 8000 // 后端服务端口，通过消息获取，也可能是8001 8002 8003 等，也可以是不同ip相同端口 err := Tool.RegService("127.0.0.1:8500", "1", "测试", serverIp, port, "5s", "http://192.168.8.176:8000/health", "test") if err != nil { errChan <- err } _ = http.ListenAndServe("0.0.0.0:8000", r) 这样就把服务注册和后端服务提供分开了，总的来说就是下面这些步骤:
具体步骤可以如下： 3-1>部署Consul：在你的生产环境中部署Consul服务器（通常以集群方式运行），并确保其高可用性。Consul服务器将用于存储服务的注册信息和提供服务发现。 3-2>创建服务注册组件：创建一个独立的组件，它负责注册新的后端服务实例到Consul中。这个组件可以监听一个消息队列或接收HTTP请求来获取要注册的服务实例的信息（如IP地址、端口、健康检查URL等），然后使用Consul的API将服务实例信息注册到Consul中。 3-3>后端服务：后端服务提供实际的服务功能，并在启动时通知服务注册组件。服务注册组件会将这些服务实例信息注册到Consul中。 3-4>客户端服务：客户端应用程序使用Consul的API来查询服务注册中心，获取可用的服务实例地址，并将请求发送到这些实例。客户端应用程序不需要了解服务注册的细节，只需使用Consul提供的接口。 这种方式将服务注册和服务提供分开，确保了可维护性和灵活性。服务注册组件可以独立运行，而后端服务只需启动时通知它即可。 总之，你可以使用Consul来管理服务的注册和发现，然后将服务注册的逻辑封装到独立的组件中，以实现你所期望的架构。这种方式可以将服务注册的功能集中在一个地方，提高管理和维护的效率。 将服务注册组件独立运行的好处包括： 高可用性：独立的服务注册组件可以部署为集群，以确保在节点故障时仍能提供服务注册的功能。这提高了整个服务注册和发现系统的可用性。 维护和管理：独立运行的服务注册组件更容易进行维护和管理。你可以为这个组件配置独立的监控、日志记录和警报，而不会影响后端服务。 扩展性：如果你的系统规模增大，你可以轻松地扩展服务注册组件的能力，以应对更多的服务实例注册请求。 隔离风险：将服务注册组件与后端服务分离，降低了彼此之间相互影响的风险。例如，后端服务的故障不会影响服务注册。 总之，在生产环境中，将服务注册组件独立运行是一种常见的做法，以确保整个服务注册和发现系统的稳定性和可扩展性。这使得服务注册的管理变得更加灵活，有助于应对不同规模的系统需求。`}]},{path:"/content/tool/back/frp%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%B7%A5%E5%85%B7.html",title:"frp搭建内网穿透工具",pathLocale:"/",contents:[{header:"frp搭建内网穿透工具",slug:"frp搭建内网穿透工具",content:""},{header:"概念",slug:"概念",content:`帮助您将NAT或防火墙后的本地服务器暴露给互联网的快速反向代理。
A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.`},{header:"工作原理",slug:"工作原理",content:""},{header:"1️⃣ frp 工作原理总结",slug:"_1️⃣-frp-工作原理总结",content:`frp 是一个 内网穿透（NAT/防火墙穿透）工具，通过 反向代理 的方式把内网服务暴露到公网。
它由两部分组成： 组件
作用 frps（服务端）
部署在公网服务器上，接收外部请求并转发到对应的 frpc。 frpc（客户端）
部署在内网主机上，注册自己提供的服务，并通过 frps 转发流量到内网服务。`},{header:"🔹 核心机制",slug:"🔹-核心机制",content:`注册映射 frpc 启动时主动连到 frps，并注册自己负责的域名、端口或服务类型。
frps 内部维护一张映射表：域名/端口 → frpc 通道。 外部访问 浏览器或客户端访问公网服务器（frps）上的域名或端口。
frps 查映射表，找到对应的 frpc。
frps 将请求通过 frp 内部通道转发到 frpc。
frpc 再转发到本地内网服务（如 localhost:8080）。 响应返回 内网服务响应 → frpc → frps → 外部客户端。`},{header:"🔹 流程图（简化）",slug:"🔹-流程图-简化",content:"浏览器 / 外部客户端 | v [frps 公网服务器] | 反向通道 v [frpc 内网主机] | v 内网服务（本地端口）"},{header:"2️⃣ 简单示例（HTTP）",slug:"_2️⃣-简单示例-http",content:`假设： 公网服务器 IP：1.2.3.4
内网电脑服务端口：8080
公网域名：www.example.com 需要DNS解析到 1.2.3.4`},{header:"服务器端 frps.ini",slug:"服务器端-frps-ini",content:`[common]
bind_port = 7000
vhost_http_port = 80
vhost_https_port = 443
dashboard_port = 7500
dashboard_user = admin
dashboard_pwd = 123456`},{header:"内网主机 frpc.ini",slug:"内网主机-frpc-ini",content:`[common]
server_addr = 1.2.3.4
server_port = 7000 [web]
type = http
local_port = 8080
custom_domains = www.example.com`},{header:"外部访问效果",slug:"外部访问效果",content:`http://www.example.com → 自动访问内网 8080 服务
HTTPS 情况可在 frps 上配置 https2http 插件和证书`},{header:"3️⃣ 常用参数说明",slug:"_3️⃣-常用参数说明",content:""},{header:"🔹 frps（服务端）",slug:"🔹-frps-服务端",content:`参数
说明 bind_port
frpc 连接 frps 的控制端口（必须开放） vhost_http_port
用于 HTTP 代理的公网端口（一般 80） vhost_https_port
用于 HTTPS 代理的公网端口（一般 443） dashboard_port
frps 内置监控界面端口 dashboard_user / dashboard_pwd
Dashboard 登录用户名/密码 token
安全认证，必须与 frpc 对应`},{header:"🔹 frpc（客户端）",slug:"🔹-frpc-客户端",content:`参数
说明 server_addr
frps 公网 IP server_port
frps 控制端口（bind_port） type
代理类型：http / tcp / udp / stcp 等 local_port
内网服务端口（本地服务） custom_domains
HTTP 类型使用的自定义域名 subdomain
可用子域名，结合 subdomain_host 使用 remote_port
TCP/UDP 类型的外部访问端口 token
与 frps 对应，认证使用`},{header:"🔹 HTTPS 特殊参数（插件方式）",slug:"🔹-https-特殊参数-插件方式",content:`参数
说明 plugin = https2http
frps 插件，把 HTTPS 转成 HTTP 内部转发 plugin_local_addr
转发解密后的请求到 frpc 通道 plugin_crt_path
TLS 证书路径 plugin_key_path
TLS 私钥路径 总结一句话： frp 的本质是 frps 管理映射表，frpc 注册服务，外部访问 → frps → frpc → 内网服务，
支持 HTTP、HTTPS、TCP/UDP 等多种类型，核心就是 注册和转发。`},{header:"多个不同的本地客户端使用",slug:"多个不同的本地客户端使用",content:"可以解析多个 example.com 的子域名， 比如 a.www.example.com b.www.example.com c.www.example.com, 然后让不同的本地主机使用，这就和 ngrok 使用一样了，不过通过frp可以实现自建服务，很安全"},{header:"站点",slug:"站点",content:"https://github.com/fatedier/frp"}]},{path:"/content/tool/back/gitlab%E4%B9%8Bpipeline%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8.html",title:"gitlab之pipeline配置使用",pathLocale:"/",contents:[{header:"",slug:"",content:`gitlab之pipeline配置使用:
gitlab-->pipelines--->build
Running with gitlab-runner 15.8.0 (12335144) on dev_env KvKW1LHZ, system ID: s_1cf47b3b21f7
Preparing the "shell" executor
00:00
Using Shell executor...
Preparing environment
00:00
Running on dev_env...
Getting source from Git repository
00:06
Fetching changes...
Initialized empty Git repository in /home/gitlab-runner/builds/KvKW1LHZ/0/dev/sciforum-frontend-v2/.git/
Created fresh repository.
Checking out 2b02cbc8 as version_1_0_0...
Skipping Git submodules setup
Executing "step_script" stage of the job script
03:21
$ echo "Running build.sh script with --push option..."
Running build.sh script with --push option...
$ ./build.sh --push
Docker building tag: gitlab-registry.mdpi.com:8081/dev/sciforum-frontend-v2:dev-2b02cbc8 ...
#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 1.03kB done
#1 DONE 0.1s
#2 [internal] load .dockerignore
#2 transferring context: 80B done
#2 DONE 0.3s
#3 [internal] load metadata for docker.io/library/node:hydrogen-alpine
#3 DONE 0.5s
#4 [builder 1/13] FROM docker.io/library/node:hydrogen-alpine@sha256:cf350f8bb497d82471f1f735df5d6d3321138be3b9f7f84ad10a4b86a438bbc3
#4 DONE 0.0s
#5 [builder 2/13] RUN apk update && apk upgrade
#5 CACHED
#6 [builder 3/13] RUN apk add git
#6 CACHED
#7 [builder 4/13] WORKDIR /app
#7 CACHED
#8 [internal] load build context
#8 transferring context: 59.17MB 0.5s done
#8 DONE 0.9s
#9 [builder 5/13] COPY . .
#9 DONE 0.7s
#10 [builder 6/13] RUN rm -rf ./node_modules/*
#10 DONE 2.6s
#11 [builder 7/13] RUN npm cache clean --force
#11 1.095 npm warn using --force Recommended protections disabled.
#11 DONE 1.5s
#12 [builder 8/13] RUN cp /app/.npmrc.local /app/.npmrc
#12 DONE 1.6s
#13 [builder 9/13] RUN npm ci
#13 8.638 npm warn deprecated rimraf@3.0.2: Rimraf versions prior to v4 are no longer supported
#13 9.852 npm warn deprecated npmlog@5.0.1: This package is no longer supported.
#13 10.80 npm warn deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.
#13 11.01 npm warn deprecated glob@8.1.0: Glob versions prior to v9 are no longer supported
#13 11.19 npm warn deprecated gauge@3.0.2: This package is no longer supported.
#13 12.63 npm warn deprecated are-we-there-yet@2.0.0: This package is no longer supported.
#13 17.66 npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
#13 17.68 npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
#13 18.64 npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
#13 38.85 #13 38.85 > postinstall
#13 38.85 > nuxt prepare
#13 38.85 #13 40.81 [nuxt:tailwindcss] ℹ Using Tailwind CSS from ~/assets/scss/main.scss
#13 41.21 ℹ Using yup with vee-validate
#13 41.86 [sidebase-auth] ℹ nuxt-auth setup starting
#13 41.86 [sidebase-auth] ✔ nuxt-auth setup done
#13 43.35 ✔ Router autocompletions generated 🚦
#13 44.03 ✔ Types generated in .nuxt
#13 45.77 #13 45.77 > prepare
#13 45.77 > husky install
#13 45.77 #13 46.08 husky - Git hooks installed
#13 46.11 #13 46.11 added 1320 packages, and audited 1322 packages in 45s
#13 46.11 #13 46.11 266 packages are looking for funding
#13 46.11 run \`npm fund\` for details
#13 46.14 #13 46.14 3 vulnerabilities (2 moderate, 1 high)
#13 46.14 #13 46.14 To address issues that do not require attention, run:
#13 46.14 npm audit fix
#13 46.14 #13 46.14 To address all issues (including breaking changes), run:
#13 46.14 npm audit fix --force
#13 46.14 #13 46.14 Run \`npm audit\` for details.
#13 DONE 46.5s
#14 [builder 10/13] RUN npm run postinstall
#14 6.633 #14 6.633 > postinstall
#14 6.633 > nuxt prepare
#14 6.633 #14 8.403 [nuxt:tailwindcss] ℹ Using Tailwind CSS from ~/assets/scss/main.scss
#14 8.789 ℹ Using yup with vee-validate
#14 9.436 [sidebase-auth] ℹ nuxt-auth setup starting
#14 9.436 [sidebase-auth] ✔ nuxt-auth setup done
#14 10.97 ✔ Router autocompletions generated 🚦
#14 11.62 ✔ Types generated in .nuxt
#14 DONE 13.6s
#15 [builder 11/13] RUN rm /app/.npmrc
#15 DONE 6.1s
#16 [builder 12/13] RUN npm run build
#16 5.967 #16 5.967 > build
#16 5.967 > npm run build:ts:definitions && nuxt build
#16 5.967 #16 6.163 #16 6.163 > build:ts:definitions
#16 6.163 > vue-tsc --noEmit
#16 6.163 #16 20.12 Nuxt 3.11.2 with Nitro 2.9.6
#16 21.59 [nuxt:tailwindcss] ℹ Using Tailwind CSS from ~/assets/scss/main.scss
#16 21.97 ℹ Using yup with vee-validate
#16 22.69 [sidebase-auth] ℹ nuxt-auth setup starting
#16 22.69 [sidebase-auth] ✔ nuxt-auth setup done
#16 24.29 ✔ Router autocompletions generated 🚦
#16 25.40 ℹ Building client...
#16 25.42 ℹ vite v5.2.12 building for production...
#16 25.46 ℹ transforming...
#16 35.55 ℹ ✓ 697 modules transformed.
#16 35.95 Inspect report generated at /app/.nuxt/analyze/.vite-inspect
#16 36.00 Generated an empty chunk: "swiper-vue".
#16 36.42 ℹ rendering chunks...
...
... gitlab-->pipelines--->sonar_inspect
Running with gitlab-runner 15.8.0 (12335144) on dev_env KvKW1LHZ, system ID: s_1cf47b3b21f7
Preparing the "shell" executor
00:00
Using Shell executor...
Preparing environment
00:00
Running on dev_env...
Getting source from Git repository
00:06
Fetching changes...
Initialized empty Git repository in /home/gitlab-runner/builds/KvKW1LHZ/0/dev/sciforum-frontend-v2/.git/
Created fresh repository.
Checking out 2b02cbc8 as version_1_0_0...
Skipping Git submodules setup
Restoring cache
00:00
Checking cache for sonar_inspect-protected...
Runtime platform arch=amd64 os=linux pid=4006789 revision=12335144 version=15.8.0
No URL provided, cache will not be downloaded from shared cache server. Instead a local version of cache will be extracted. Successfully extracted cache
Executing "step_script" stage of the job script
00:48
$ docker pull sonarsource/sonar-scanner-cli:latest
latest: Pulling from sonarsource/sonar-scanner-cli
Digest: sha256:0bc49076468d2955948867620b2d98d67f0d59c0fd4a5ef1f0afc55cf86f2079
Status: Image is up to date for sonarsource/sonar-scanner-cli:latest
docker.io/sonarsource/sonar-scanner-cli:latest
$ mkdir -p ./.sonar
$ docker run \\ # collapsed multi-line command
INFO: Scanner configuration file: /opt/sonar-scanner/conf/sonar-scanner.properties
INFO: Project root configuration file: /usr/src/sonar-project.properties
INFO: SonarScanner 5.0.1.3006
INFO: Java 17.0.10 Alpine (64-bit)
INFO: Linux 5.15.0-91-generic amd64
INFO: User cache: /opt/sonar-scanner/.sonar/cache
INFO: Analyzing on SonarQube server 9.9.3.79811
INFO: Default locale: "en_US", source code encoding: "UTF-8"
INFO: Load global settings
INFO: Load global settings (done) | time=135ms
INFO: Server id: 92D88F0A-AYwfUX2SG7dI3mmP5Tlr
INFO: User cache: /opt/sonar-scanner/.sonar/cache
INFO: Load/download plugins
INFO: Load plugins index
INFO: Load plugins index (done) | time=63ms
INFO: Plugin [l10nzh] defines 'l10nen' as base plugin. This metadata can be removed from manifest of l10n plugins since version 5.2.
INFO: Load/download plugins (done) | time=1976ms
INFO: Process project properties
INFO: Process project properties (done) | time=0ms
INFO: Execute project builders
INFO: Execute project builders (done) | time=2ms
INFO: Project key: dev_sciforum-frontend-v2_AY-DNwJcrV2YXbScBCHQ
INFO: Base dir: /usr/src
INFO: Working dir: /usr/src/.scannerwork
INFO: Load project settings for component key: 'dev_sciforum-frontend-v2_AY-DNwJcrV2YXbScBCHQ'
INFO: Load project settings for component key: 'dev_sciforum-frontend-v2_AY-DNwJcrV2YXbScBCHQ' (done) | time=25ms
INFO: Load quality profiles
INFO: Load quality profiles (done) | time=55ms
INFO: Load active rules
INFO: Load active rules (done) | time=1387ms
INFO: Load analysis cache
INFO: Load analysis cache | time=28ms
INFO: Load project repositories
INFO: Load project repositories (done) | time=28ms
INFO: Indexing files...
INFO: Project configuration:
INFO: Excluded sources: **/node_modules/**, **/dist/**, **/coverage/**, **/public/**, **/build
INFO: 221 files indexed
INFO: 4 files ignored because of inclusion/exclusion patterns
INFO: 0 files ignored because of scm ignore settings
INFO: Quality profile for css: MDPI way
INFO: Quality profile for js: Sonar way
INFO: Quality profile for json: Sonar way
INFO: Quality profile for ts: Sonar way
INFO: ------------- Run sensors on module dev_sciforum-frontend-v2_AY-DNwJcrV2YXbScBCHQ
INFO: Load metrics repository
INFO: Load metrics repository (done) | time=22ms
INFO: Sensor JaCoCo XML Report Importer [jacoco]
INFO: 'sonar.coverage.jacoco.xmlReportPaths' is not defined. Using default locations: target/site/jacoco/jacoco.xml,target/site/jacoco-it/jacoco.xml,build/reports/jacoco/test/jacocoTestReport.xml
INFO: No report imported, no coverage information will be imported by JaCoCo XML Report Importer
INFO: Sensor JaCoCo XML Report Importer [jacoco] (done) | time=2ms
INFO: Sensor IaC CloudFormation Sensor [iac]
INFO: 0 source files to be analyzed
INFO: 0/0 source files have been analyzed
INFO: Sensor IaC CloudFormation Sensor [iac] (done) | time=216ms
INFO: Sensor IaC Kubernetes Sensor [iac]
INFO: 0 source files to be analyzed
INFO: 0/0 source files have been analyzed
INFO: Sensor IaC Kubernetes Sensor [iac] (done) | time=137ms
INFO: Sensor JavaScript analysis [javascript]
INFO: 6 source files to be analyzed
INFO: 6/6 source files have been analyzed
INFO: Hit the cache for 0 out of 6
INFO: Miss the cache for 6 out of 6: ANALYSIS_MODE_INELIGIBLE [6/6]
INFO: Sensor JavaScript analysis [javascript] (done) | time=6212ms
INFO: Sensor TypeScript analysis [javascript]
INFO: Resolving TSConfig files using 'tsconfig.sonar.json' from property sonar.typescript.tsconfigPaths
INFO: Found 1 TSConfig file(s): [/usr/src/tsconfig.sonar.json]
INFO: Analyzing 193 files using tsconfig: /usr/src/tsconfig.sonar.json
INFO: 193 source files to be analyzed
INFO: 82/193 files analyzed, current file: /usr/src/server/api/auth/login.post.ts
INFO: 193/193 source files have been analyzed
INFO: Hit the cache for 0 out of 193
INFO: Miss the cache for 193 out of 193: ANALYSIS_MODE_INELIGIBLE [193/193]
INFO: Sensor TypeScript analysis [javascript] (done) | time=18969ms
INFO: Sensor CSS Rules [javascript]
INFO: 103 source files to be analyzed
INFO: 103/103 source files have been analyzed
INFO: Hit the cache for 0 out of 0
INFO: Miss the cache for 0 out of 0
INFO: Sensor CSS Rules [javascript] (done) | time=1098ms
INFO: Sensor CSS Metrics [javascript]
INFO: Sensor CSS Metrics [javascript] (done) | time=49ms
INFO: Sensor C# Project Type Information [csharp]
INFO: Sensor C# Project Type Information [csharp] (done) | time=2ms
INFO: Sensor C# Analysis Log [csharp]
INFO: Sensor C# Analysis Log [csharp] (done) | time=21ms
INFO: Sensor C# Properties [csharp]
INFO: Sensor C# Properties [csharp] (done) | time=0ms
INFO: Sensor HTML [web]
INFO: Sensor HTML [web] (done) | time=105ms
INFO: Sensor TextAndSecretsSensor [text]
INFO: 211 source files to be analyzed
INFO: 211/211 source files have been analyzed
INFO: Sensor TextAndSecretsSensor [text] (done) | time=315ms
INFO: Sensor VB.NET Project Type Information [vbnet]
INFO: Sensor VB.NET Project Type Information [vbnet] (done) | time=1ms
INFO: Sensor VB.NET Analysis Log [vbnet]
INFO: Sensor VB.NET Analysis Log [vbnet] (done) | time=11ms
INFO: Sensor VB.NET Properties [vbnet]
INFO: Sensor VB.NET Properties [vbnet] (done) | time=0ms
INFO: Sensor IaC Docker Sensor [iac]
INFO: 1 source file to be analyzed
INFO: 1/1 source file has been analyzed
INFO: Sensor IaC Docker Sensor [iac] (done) | time=88ms
INFO: ------------- Run sensors on project
INFO: Sensor Analysis Warnings import [csharp]
INFO: Sensor Analysis Warnings import [csharp] (done) | time=0ms
INFO: Sensor Zero Coverage Sensor
INFO: Sensor Zero Coverage Sensor (done) | time=22ms
INFO: SCM Publisher SCM provider for this project is: git
INFO: SCM Publisher 33 source files to be analyzed
INFO: SCM Publisher 33/33 source files have been analyzed (done) | time=256ms
INFO: CPD Executor 91 files had no CPD blocks
INFO: CPD Executor Calculating CPD for 108 files
INFO: CPD Executor CPD calculation finished (done) | time=71ms
INFO: Analysis report generated in 93ms, dir size=781.7 kB
INFO: Analysis report compressed in 343ms, zip size=579.2 kB
INFO: Analysis report uploaded in 68ms
INFO: ------------- Check Quality Gate status
INFO: Waiting for the analysis report to be processed (max 300s)
INFO: ------------------------------------------------------------------------
INFO: EXECUTION FAILURE
INFO: ------------------------------------------------------------------------
INFO: Total time: 42.510s
INFO: Final Memory: 35M/224M
INFO: ------------------------------------------------------------------------
ERROR: Error during SonarScanner execution
ERROR: QUALITY GATE STATUS: FAILED - View details on https://sonarq.mdpi.dev/dashboard?id=dev_sciforum-frontend-v2_AY-DNwJcrV2YXbScBCHQ
ERROR: ERROR: Re-run SonarScanner using the -X switch to enable full debug logging.`}]},{path:"/content/tool/back/ubuntu22%E5%AE%89%E8%A3%85wkhtmltopdf.html",title:"ubuntu22安装wkhtmltopdf",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22安装wkhtmltopdf:
1>选择系统合适版本 https://wkhtmltopdf.org/downloads.html 2>安装
$ sudo dpkg -i ~/Downloads/wkhtmltox_0.12.6.1-2.jammy_amd64.deb
报:
dpkg: dependency problems prevent configuration of wkhtmltox: wkhtmltox depends on xfonts-75dpi; however: Package xfonts-75dpi is not installed
解决:
$ sudo apt-get install xfonts-75dpi 版本:
$ wkhtmltopdf --version
wkhtmltopdf 0.12.6.1 (with patched qt) $ /usr/local/bin/wkhtmltopdf --version //默认安装位置在/usr/local/bin下
wkhtmltopdf 0.12.6.1 (with patched qt) php下使用: exec("{$this->wkhtmltopdf} --image-quality 100 --margin-left 17.5mm --margin-right 17.5mm --margin-top 17.5mm $htmlFile $pdfFile");
unlink($htmlFile); 使用参考:https://segmentfault.com/a/1190000018988358`}]},{path:"/content/tool/back/ubuntu22%E6%88%AA%E5%9B%BE%E5%B7%A5%E5%85%B7.html",title:"ubuntu22截图工具",pathLocale:"/",contents:[{header:"",slug:"",content:`ubuntu22截图工具:
ksnip`}]},{path:"/content/tool/back/vpn%E6%90%AD%E5%BB%BA.html",title:"vpn搭建",pathLocale:"/",contents:[{header:"vpn搭建",slug:"vpn搭建",content:"技术栈：V2ray: vless+tcp+xtls"},{header:"1. V2Ray",slug:"_1-v2ray",content:"V2Ray 是一个多协议、可扩展的网络代理工具，主要用于科学上网、穿透防火墙或做内网穿透。它支持多种协议（VMess、VLESS、Trojan 等）和多种传输方式（TCP、WebSocket、QUIC 等）。"},{header:"2. VLESS",slug:"_2-vless",content:`全称：V2Ray Lightweight Encryption Secure Socket 相比 VMess： 轻量：VLESS 本身没有加密负载（加密由传输层完成），减少开销。
性能更高，尤其在高并发场景下。
更适合和 XTLS 结合使用。 典型用途：用作 V2Ray 的客户端-服务端通信协议。`},{header:"3. TCP",slug:"_3-tcp",content:`传输层协议。 特点： 稳定可靠，保证数据顺序和完整性。
支持流量伪装（比如 HTTP/2 伪装）。 缺点： 延迟相对高于 UDP 或 QUIC。`},{header:"4. XTLS",slug:"_4-xtls",content:`全称：X Transport Layer Security 功能： 替代传统 TLS，优化了 TLS 握手效率。
支持 direct mode，服务端可以在 TLS 握手阶段直接获取 VLESS 的流量信息，提高性能。
对于高并发、短链接场景（比如移动端）更友好。 优点： 减少 CPU 占用。
增加吞吐量。
支持 流量混淆，更难被识别。`},{header:"🔹 总结",slug:"🔹-总结",content:`组合 VLESS + TCP + XTLS 是一种高性能且相对安全的 V2Ray 配置： VLESS：轻量协议。
TCP：稳定可靠传输。
XTLS：提升 TLS 性能，减少 CPU 开销。 这种组合适合： 追求低延迟和高吞吐量的场景。
服务器资源有限的情况。
移动端或高并发用户的访问。`}]},{path:"/content/tool/back/%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E8%A7%86%E9%A2%91%E7%82%B9%E6%92%AD%E5%8E%9F%E7%90%86.html",title:"实现本地视频点播原理",pathLocale:"/",contents:[{header:"实现本地视频点播原理",slug:"实现本地视频点播原理",content:`主要命令:
ffmpeg -i input.mp4 \\ -hls_time 10 \\ -hls_key_info_file keyinfo.txt \\ -hls_playlist_type vod \\ output.m3u8 仔细分析一下这条 ffmpeg 命令，每个参数的作用都说明清楚：
ffmpeg -i input.mp4 \\ -hls_time 10 \\ -hls_key_info_file keyinfo.txt \\ -hls_playlist_type vod \\ output.m3u8`},{header:"1️⃣ ffmpeg",slug:"_1️⃣-ffmpeg",content:`调用 ffmpeg 工具进行音视频处理和转码
可以处理 MP4、MKV、MOV 等各种视频格式`},{header:"2️⃣ -i input.mp4",slug:"_2️⃣-i-input-mp4",content:`指定输入文件 input.mp4
这是你要转 HLS 的原始视频`},{header:"3️⃣ -hls_time 10",slug:"_3️⃣-hls-time-10",content:`每个 HLS 片段的时长，单位是秒
上例中设置为 10 秒 → 视频会被切成 10 秒一段的 .ts 文件
切片太短：请求次数多，CPU/带宽压力大
切片太长：快进响应慢`},{header:"4️⃣ -hls_key_info_file keyinfo.txt",slug:"_4️⃣-hls-key-info-file-keyinfo-txt",content:`AES-128 加密的 key 信息
keyinfo.txt 文件内容格式： /absolute/path/to/local.key # 生成的 AES-128 key 文件在本地路径
http://your-server.com/key.key # 播放器请求 key 的 URL
iv=00000000000000000000000000000001 # 可选 IV（初始化向量） ffmpeg 会用这个 key 对生成的 .ts 片段进行 AES-128 加密
播放器在播放 .m3u8 时会通过 key URI 下载 key 解密`},{header:"5️⃣ -hls_playlist_type vod",slug:"_5️⃣-hls-playlist-type-vod",content:`设置 HLS 播放列表类型为 点播（VOD）
生成完整 .m3u8 列表，适合点播视频
如果是直播可以使用 -hls_playlist_type event 或不指定`},{header:"6️⃣ output.m3u8",slug:"_6️⃣-output-m3u8",content:`输出播放列表文件（m3u8）
里面包含所有切片的路径信息（ts 文件）和加密 key URI
浏览器 / HLS 播放器会读取 m3u8，然后按顺序请求 ts 片段播放`},{header:"🔹 输出文件示例",slug:"🔹-输出文件示例",content:`假设输入视频 30 秒，-hls_time 10，生成：
output.m3u8
segment0.ts
segment1.ts
segment2.ts output.m3u8 内容类似：
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:10
#EXT-X-KEY:METHOD=AES-128,URI="http://your-server.com/key.key"
#EXTINF:10.0,
segment0.ts
#EXTINF:10.0,
segment1.ts
#EXTINF:10.0,
segment2.ts
#EXT-X-ENDLIST #EXT-X-KEY：指定加密方式和 key URI
#EXTINF：每个 ts 片段的时长
播放器自动按顺序请求 ts 并解密播放`}]},{path:"/content/tool/front/css%E6%A0%B7%E5%BC%8F%E6%95%88%E6%9E%9C%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0.html",title:"css样式效果在线运行平台",pathLocale:"/",contents:[{header:"",slug:"",content:`css样式效果在线运行平台:
https://developer.mozilla.org/zh-CN/play`}]},{path:"/content/tool/front/husky%E4%BD%BF%E7%94%A8.html",title:"husky使用",pathLocale:"/",contents:[{header:"",slug:"",content:`使用husky统一管理git-hooks,实现git commit之前校验eslint，通过才能commit成功: 1.安装husky npm install husky --save-dev 2.初始化husky npm run prepare 执行完上述安装命令后，将会发生如下几个变化：
在.git同级目录生成.husky文件夹，文件夹下有一个可以编辑的示例pre-commit钩子
在package.json中的scripts中添加了"prepare": "husky install"
更改.git文件下面的config文件，配置项 core.hooksPath 为 .husky 3.创建一个hook 要添加另一个钩子，请使用husky add
如： npx husky add .husky/commit-msg 'npx --no-install commitlint --edit "$1"' 4.更新hooks脚本 修改.husky文件夹下的hooks脚本即可 5.卸载并还原husky npm uninstall husky
// 删除.husky文件夹，并且重置core.hooksPath
rm -rf .husky && git config --unset core.hooksPath 6.实战 项目中commit的时候，校验eslint, 警告和错误都不可以commit 1>安装好 husky 之后，编辑.husky/pre-commit，添加如下内容，而pre-push不用处理，就用默认内容 npx lint-staged 2>安装lint-staged，lint-stated就是针对Git暂存区的文件做校验的一个工具。由于在commit之前，我们要提交的文件是在暂存区的，我们可以利用这个工具来校验我们即将commit的文件，而不会校验其它的文件 npm install lint-staged --save-dev 3>配置lint-staged // package.json { "lint-staged": { "*.{js,ts,vue}": [ "prettier --write", "eslint --cache --fix" // 也可以添加这个参数 eslint --max-warnings 0 ], "*.{scss, md}": [ "prettier --write" ] } } 4>提交 commit 的时候，触发了 pre-commit的gitHook, 就执行了里面的脚本 lint-staged, 然后执行了 eslint --max-warnings 0, 最终eslint 0 警告 0 错误就可以commit成功，反之不行`}]},{path:"/content/tool/front/math%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8Fts%E5%8C%85.html",title:"math数学公式ts包",pathLocale:"/",contents:[{header:"",slug:"",content:`math数学公式ts包:
https://katex.org/`}]},{path:"/content/tool/front/npm%E5%8C%85%E5%90%8D%E5%89%8D%E5%B8%A6@%E5%92%8C%E4%B8%8D%E5%B8%A6@%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"npm包名前带@和不带@的区别",pathLocale:"/",contents:[{header:"npm包名前带@和不带@的区别",slug:"npm包名前带-和不带-的区别",content:"在 npm 中，包名前带 @ 和不带 @ 的区别如下："},{header:"✅ 1. 带 @ 符号的包（作用域包 Scoped Package）",slug:"✅-1-带-符号的包-作用域包-scoped-package",content:`格式：@scope/package-name
例如：
@vue/compiler-sfc
@nestjs/core`},{header:"意义：",slug:"意义",content:`@scope 是一个命名空间（通常是组织或用户）。
用于将包组织在一起，便于管理和发布。
私有包 和 大组织内部的包 常用这种形式。
可以发布到 npm 或私有 npm registry。`},{header:"示例：",slug:"示例",content:"npm install @vue/compiler-sfc"},{header:"✅ 2. 不带 @ 的包（普通包）",slug:"✅-2-不带-的包-普通包",content:`格式：package-name
例如：
axios
lodash
vue
express`},{header:"意义：",slug:"意义-1",content:`这是 npm 的传统命名方式。
所有开发者都可以发布这样的包，只要名字不冲突。`},{header:"示例：",slug:"示例-1",content:"npm install axios"},{header:"🚩 补充说明",slug:"🚩-补充说明",content:`形式
举例
是否必须公开
是否支持私有 package-name
axios, vue
是
否（要私有需加作用域） @scope/name
@vue/compiler-sfc
否
✅ 是（可私有）`},{header:"📦 私有包示例（@your-org/internal-lib）：",slug:"📦-私有包示例-your-org-internal-lib",content:`{ "name": "@your-org/internal-lib", "version": "1.0.0", "private": true
} 如你公司内部有多个团队，可以这样划分作用域： @company/frontend-utils
@company/backend-core
@company/shared-config`}]},{path:"/content/tool/front/npm%E5%92%8Cnpx%E7%9A%84%E5%8C%BA%E5%88%AB.html",title:"npm和npx的区别",pathLocale:"/",contents:[{header:"",slug:"",content:`npm和npx的区别:
npm 和 npx 是 Node.js 生态系统中的两个不同的工具，它们有一些区别：
npm (Node Package Manager):
npm 是 Node.js 包管理器，用于安装、卸载和管理 Node.js 模块。
它提供了一种在项目中安装和管理依赖项的方式，并允许你将这些依赖项记录在项目的 package.json 文件中。
npm 还允许你运行项目中的脚本，这些脚本通常在 package.json 文件中的 "scripts" 部分定义。 npx:
npx 是 Node.js 5.2.0 版本引入的一个工具，用于运行包安装时的可执行文件。
它的主要目的是为了解决全局安装的包中的可执行文件在不同项目中版本冲突的问题。
npx 允许你在不全局安装包的情况下执行特定包的命令。它会在本地的 node_modules/.bin 目录中查找可执行文件，从而避免了全局安装可能带来的问题。
除了运行本地的可执行文件，npx 还可以用于运行远程存储库中的脚本，无需提前安装它们。这对于在不同项目中共享脚本很有用。
总的来说，npm 是用于包管理的工具，而 npx 是一个用于执行包中的可执行文件或运行远程脚本的工具。使用 npx 可以帮助你在不同项目中更灵活地运行命令，而不必担心全局安装的包可能导致的问题。`}]},{path:"/content/tool/front/npm%E8%AE%BE%E7%BD%AEtaoao%E6%BA%90%E4%BB%A5%E5%8F%8A%E6%81%A2%E5%A4%8D.html",title:"npm设置taoao源以及恢复",pathLocale:"/",contents:[{header:"",slug:"",content:`npm设置taoao源以及恢复:
NPM默认的源在某些国内主机（如阿里云）的某些时间段访问会非常的慢，大家在使用NPM源时常常会使用国内的淘宝镜像源：
npm config set registry http://registry.npm.taobao.org/ 但是这个淘宝源亲测不是总是最新的，如我今天使用NPM时遇到了这个情况：
“No matching version found for nodebb-theme-persona@9.1.36”
百思不得其解，最后想起可能是之前使用了淘宝源，包不是最新的有关。 切换回默认的源：
npm config set registry https://registry.npmjs.org 使用下面的语句检查你的当前NPM源：
npm config get registry`}]},{path:"/content/tool/front/nvm(Node%20Version%20Manager)%E4%BD%BF%E7%94%A8.html",title:"nvm(Node Version Manager)使用",pathLocale:"/",contents:[{header:"",slug:"",content:`nvm(Node Version Manager)使用:
1>官方介绍
https://github.com/nvm-sh/nvm
2>ubuntu22 安装nvm
//The script clones the nvm repository to ~/.nvm， 我这里指定的版本是v0.39.7,可以根据实际配置
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash 默认上面的脚本执行完以后，会在 ~/.bashrc 里追加下面的内容 export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \\. "$NVM_DIR/nvm.sh" # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \\. "$NVM_DIR/bash_completion" # This loads nvm bash_completion 然后执行:
source ~/.bashrc 查看是否安装成功:
nvm --version
0.39.7
或者运行 command -v nvm
nvm
表示安装完成
参考：
https://blog.csdn.net/lxyoucan/article/details/130288356
https://github.com/nvm-sh/nvm //官网 3>使用，下面安装一个v18.xxx的版本，这里是 v18.19.0
nvm install lts/hydrogen (这里 hydrogen 只是v18版本的一个名称，这样会下载最新的v18版本)或者直接 nvm install 18.19.0，注意可能会有权限问题 nvm use 18.19.0 再切换会之前安装的 nvm use system 使用的过程中我发现，使用nvm use，只能临时有效。重新打开新的终端版本又变回原来的了
如果让设置永久生效呢? nvm alias default xx.xx.x nvm alias default 18.19.0，当然切换回之前的版本也是 nvm alias default system 4>查看本地node安装的版本
nvm list -> system
iojs -> N/A (default)
node -> stable (-> N/A) (default)
unstable -> N/A (default)
lts/* -> lts/iron (-> N/A)
lts/argon -> v4.9.1 (-> N/A)
lts/boron -> v6.17.1 (-> N/A)
lts/carbon -> v8.17.0 (-> N/A)
lts/dubnium -> v10.24.1 (-> N/A)
lts/erbium -> v12.22.12 (-> N/A)
lts/fermium -> v14.21.3 (-> N/A)
lts/gallium -> v16.20.2 (-> N/A)
lts/hydrogen -> v18.19.0 (-> N/A)
lts/iron -> v20.10.0 (-> N/A) 注意上面展示了，通过nvm安装和自定义安装的node, 比如上面的 system, 其实就是我之前手动安装的 v19.3.0 版本 4>配合 .nvmrc 使用
我这直接在这个文件里面配置 lts/hydrogen // v18.xx版本 5>权限问题解决方案
在自行 nvm install 18.19.0的时候可能会报类似下面的错误
Downloading and installing node v19.4.0...
Downloading https://nodejs.org/dist/v19.4.0/node-v19.4.0-linux-x64.tar.xz...
Warning: Failed to open the file Warning: /home/wang/.nvm/.cache/bin/node-v19.4.0-linux-x64/node-v19.4.0-linux-x
Warning: 64.tar.xz: Permission denied
curl: (23) Failure writing output to destination Binary download from https://nodejs.org/dist/v19.4.0/node-v19.4.0-linux-x64.tar.xz failed, trying source.
grep: /home/wang/.nvm/.cache/bin/node-v19.4.0-linux-x64/node-v19.4.0-linux-x64.tar.xz: 没有那个文件或目录
Provided file to checksum does not exist.
Binary download failed, trying source.
Downloading https://nodejs.org/dist/v19.4.0/node-v19.4.0.tar.xz...
Warning: Failed to open the file Warning: /home/wang/.nvm/.cache/src/node-v19.4.0/node-v19.4.0.tar.xz: Warning: Permission denied
curl: (23) Failure writing output to destination Binary download from https://nodejs.org/dist/v19.4.0/node-v19.4.0.tar.xz failed, trying source.
grep: /home/wang/.nvm/.cache/src/node-v19.4.0/node-v19.4.0.tar.xz: 没有那个文件或目录
Provided file to checksum does not exist. 解决思路:
观察报错信息，发现下载安装包时就报错了，错误信息为 curl: (23) Failure writing output to destination
出现这个错误，首先想到我的 curl 是通过 snap 安装的，那么卸载使用apt重装试试，因为官方文档里有人一直在说这个snap,可以去看看，我开始也不知道为什么. 解决方案:
确认一下你的curl是不是用snap安装的:
sudo snap list | grep curl 有输出，则为snap安装，则卸载:
sudo snap remove curl 然后用apt重新安装:
sudo apt install curl 最后重新运行安装命令:
nvm install 18.19.0 执行完install 以后默认会自动把这个安装的版本设置为默认版本 https://blog.csdn.net/m0_63969219/article/details/128712231`}]},{path:"/content/tool/front/pm2%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD%E5%91%BD%E4%BB%A4.html",title:"pm2重新加载命令",pathLocale:"/",contents:[{header:"",slug:"",content:`pm2重新加载命令:
pm2 delete ecosystem.config.js
当你运行 pm2 delete ecosystem.config.js 时，PM2 会查找指定配置文件中定义的所有进程，并将其停止并从进程列表中删除。这个命令对于清理不再需要运行的应用程序或者重新启动应用程序时非常有用。
pm2 start ecosystem.config.js //执行完上面的命令再执行这个就可以重新加载配置了 pm2 reload ecosystem.config.js
如果修改了 PM2 的配置文件（比如 ecosystem.config.js），然后想要让新的配置生效，可能需要重新加载配置或者重启 PM2 进程管理器。直接使用 pm2 stop 然后 pm2 start 并不会重新加载配置文件，因此新的配置不会生效。
一种更简单的方法是使用 pm2 reload 命令，它会重新加载配置文件而不需要先停止再启动进程。 pm2 restart ecosystem.config.js，这个和 pm2 stop 然后 pm2 start效果一样，都不会重新加载配置文件 如何使用pm2管理多个应用程序的ecosystem.config.js文件？
分析如下ecosystem.config.js.js文件
module.exports = { apps: [{ name: 'app1', 脚本'./app1/index.js', watch: true, ignore_watch：['node_modules'], env: { NODE_ENV: 'production', port： 3001 } }]
} 要想实现管理多个应用就需要为每个应用不同的命名
然后在管理应用的时候加上 --name参数，比如这里的启动指定应用 pm2 start ecosystem.config.js --name="app1"`}]},{path:"/content/tool/front/semantic-release%E7%9A%84%E4%BD%BF%E7%94%A8.html",title:"semantic-release的使用",pathLocale:"/",contents:[{header:"semantic-release的使用",slug:"semantic-release的使用",content:`1.安装
npm install semantic-release
根据需要还需要单独安装
"@semantic-release/changelog",
"@semantic-release/npm",
"@semantic-release/git",
"@semantic-release/github" 下面这两个，semantic-release 会间接依赖，然后安装
"@semantic-release/commit-analyzer",
"@semantic-release/release-notes-generator", 2.配置文件 .releaserc.json
类似下面的结构(根据实际情况调整)
"release": { "branches": ["main", "next"], "plugins": [ "@semantic-release/commit-analyzer", "@semantic-release/release-notes-generator", "@semantic-release/changelog", "@semantic-release/npm", "@semantic-release/git", "@semantic-release/github" ]
} 目前我项目配置:
{ "branches": ["master"], "plugins": [ "@semantic-release/commit-analyzer", "@semantic-release/release-notes-generator", [ "@semantic-release/changelog", { "changelogFile": "docs/CHANGELOG.md" } ], [ "@semantic-release/gitlab", { "gitlabUrl": "https://gitlab.duoxiaozhan.com:8081", "gitlabApiPathPrefix": "/api/v4/", "verifyConditions": [], "failComment": false, "failTitle": false, "assets": [ { "path": "dist/*", "label": "Built assets" }, { "path": "docs/CHANGELOG.md", "label": "Changelog" }, { "path": "package.json", "label": "package.json" } ] } ], "@semantic-release/npm", [ "@semantic-release/git", { "assets": ["package.json", "docs/CHANGELOG.md", "dist/*"], "message": "chore(release): \${nextRelease.version} [skip ci]\\n\\n\${nextRelease.notes}" } ] ]
} 重点说下
@semantic-release/npm 会在发布 npm 包时 自动调用 npm 命令（如 npm publish 或 npm pack）来上传包。
它会在当前环境（CI 或本地）寻找 .npmrc 文件，使用其中的配置和认证信息 对于 .npmrc: 可以配置私有仓库的地址以及token信息 3.执行
"scripts": { "semantic-release": "semantic-release"
} npm run semantic-release`},{header:"在git提交的使用分析",slug:"在git提交的使用分析",content:`这条 Git 提交记录：
chore(release): 3.10.0 [skip ci] 遵循了 Conventional Commits 规范，并具有以下含义：`},{header:"✅ 各部分含义解析：",slug:"✅-各部分含义解析",content:""},{header:"1. chore",slug:"_1-chore",content:`这是 提交类型（type），表示“杂项/构建任务”，不影响代码逻辑，例如构建、依赖升级、脚本更新等。
常见类型包括： feat：新增功能
fix：修复 bug
docs：文档更新
style：代码格式修改（不影响功能）
refactor：重构
test：测试代码变更
chore：其他不属于以上类型的杂项`},{header:"2. (release)",slug:"_2-release",content:"这是 可选的作用域（scope），指此次提交影响的是“发布流程”相关的内容。"},{header:"3. 3.10.0",slug:"_3-3-10-0",content:`这是 提交说明（description），说明这是一次版本发布，发布的是 v3.10.0。
通常，这类提交是由自动化工具（如 semantic-release 或 standard-version）在发布版本时生成的。`},{header:"4. [skip ci]",slug:"_4-skip-ci",content:"这是一个特殊的标记，用于告诉 CI 工具（如 GitLab CI、GitHub Actions、CircleCI 等）跳过此次提交的 CI/CD 流程，因为这个提交只是用于发布，不需要运行构建或测试。"},{header:"🚀 总结这条提交做了什么：",slug:"🚀-总结这条提交做了什么",content:`这条提交说明： 类型是 chore，代表杂项；
作用是 release，说明它是版本发布相关的更改；
发布的版本是 3.10.0；
[skip ci] 表示这次提交不需要运行 CI；
极可能是自动工具生成的，不是手动写的。`},{header:"✅ 这类提交的常见用途：",slug:"✅-这类提交的常见用途",content:`自动发布版本并打 Tag；
自动更新 CHANGELOG.md；
和语义版本工具搭配使用（如 semantic-release, standard-version）；
保持 changelog、tag 和 package.json 版本号一致。 如果使用了 semantic-release 或类似工具来做自动版本管理，那么这种提交会自动出现在每次发布流程中。`}]},{path:"/content/tool/front/ts%E6%96%87%E4%BB%B6%E7%BC%96%E8%AF%91%E9%81%8D%E5%8E%86%E5%A4%AA%E5%A4%9A%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"ts文件编译遍历太多的问题",pathLocale:"/",contents:[{header:"ts文件编译遍历太多的问题",slug:"ts文件编译遍历太多的问题",content:`目前问题是，nuxt3项目下，运行tsc --noEmit 之后，定义的server下的$fetch会报如下问题:
Type instantiation is excessively deep and possibly infinite. 检查发现是 typescript 里的一个参数是硬编码为5e6，解决办法是修改这个配置
sed -i.bak 's/5e6/9e6/g' ./node_modules/typescript/lib/tsc.js 官方也有人提过能不能将上面的参数做成一个配置参数，但是被微软拒绝了，如下:
https://github.com/microsoft/TypeScript/issues/34933
https://github.com/microsoft/TypeScript/pull/44997 调试问题:
可以在tsconfig.json 下加:
"traceResolution": true,
"extendedDiagnostics": true 如下:
{ // https://nuxt.com/docs/guide/concepts/typescript "extends": "./.nuxt/tsconfig.json", "compilerOptions": { "incremental": true, "types": [], "traceResolution": true, "extendedDiagnostics": true }
} 在terminal一下运行:
tsc --noEmit > ts-trace.log 得到如下结果:
../stores/ui/registration/registration-ticket.ts(645,5): error TS1343: The 'import.meta' meta-property is only allowed when the '--module' option is 'es2020', 'es2022', 'esnext', 'system', 'node16', or 'nodenext'.
../stores/ui/registration/registration-ticket.ts(646,3): error TS1343: The 'import.meta' meta-property is only allowed when the '--module' option is 'es2020', 'es2022', 'esnext', 'system', 'node16', or 'nodenext'.
../stores/ui/registration/registration-ticket.ts(647,49): error TS1343: The 'import.meta' meta-property is only allowed when the '--module' option is 'es2020', 'es2022', 'esnext', 'system', 'node16', or 'nodenext'.
Files: 2387
Lines of Library: 49568
Lines of Definitions: 261448
Lines of TypeScript: 20852
Lines of JavaScript: 74930
Lines of JSON: 0
Lines of Other: 0
Identifiers: 446642
Symbols: 536003
Types: 183451
Instantiations: 13455940 //但是这个数值并不是报错中的Instantiations
Memory used: 700197K
Assignability cache size: 102819
Identity cache size: 2603
Subtype cache size: 1044
Strict subtype cache size: 3269
I/O Read time: 0.17s
Parse time: 1.97s
ResolveModule time: 1.00s
ResolveTypeReference time: 0.03s
ResolveLibrary time: 0.02s
Program time: 3.65s
Bind time: 1.11s
Check time: 19.58s
I/O Write time: 0.00s
printTime time: 0.06s
Emit time: 0.07s
Total time: 24.40s`}]},{path:"/content/tool/front/typescript%E6%96%87%E6%A1%A3%E4%BB%A5%E5%8F%8A%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83.html",title:"typescript文档以及运行环境",pathLocale:"/",contents:[{header:"",slug:"",content:`typescript使用
1. 官网
https://www.typescriptlang.org/ 2.在线运行环境
https://www.typescriptlang.org/play 3.官方文档
https://gibbok.github.io/typescript-book/zh-cn/book/typescript-introduction/ 4.国产文档
https://wangdoc.com/typescript/ 5.使用
1>安装
tsc 是一个 npm 模块，使用下面的命令安装（必须先安装 npm）。
$ sudo npm install -g typescript 2>查看版本
$ tsc -v
Version 5.3.2 3>使用
TypeScript 允许将tsc的编译参数，写在配置文件tsconfig.json。只要当前目录有这个文件，tsc就会自动读取，所以运行时可以不写参数。 $ tsc file1.ts file2.ts --outFile dist/app.js 上面这个命令写成tsconfig.json，就是下面这样：
{ "files": ["file1.ts", "file2.ts"], "compilerOptions": { "outFile": "dist/app.js" }
} 有了这个配置文件，编译时直接调用tsc命令就可以了：
$ tsc 4>vue-tsc --noEmit的使用
vue-tsc：Vue 官方提供的命令，用于执行 TS 的类型检查。它在执行时会根据项目中的 tsconfig.json 文件配置进行类型检查
--noEmit：TS 编译器的选项，使用 --noEmit 选项后，编译器仅执行类型检查，而不会生成任何实际的编译输出 一般配置在package.json的scripts下:
"build": "vue-tsc --noEmit && nuxt build",`}]},{path:"/content/tool/front/vue3%E4%B8%8Beslint%E8%87%AA%E5%8A%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E9%97%AE%E9%A2%98.html",title:"vue3下eslint自动修复的问题",pathLocale:"/",contents:[{header:"vue3下eslint自动修复的问题",slug:"vue3下eslint自动修复的问题",content:`vue3有如下代码:
watch(eventInSeries.value, (value) => { if (value?.value) { const isExist = selectedItems.value.some( (item) => item.value === value.value, ); if (!isExist) { selectedItems.value.push(value); } }
}); 通过如下命令:
npx eslint path/to/file.vue --fix $ npx eslint ./components/UserForm.vue --fix 会自动把上面的
if (value?.value) {}
修改为
if (value.value) {} 导致git提交一直报:
⚠ lint-staged prevented an empty git commit. Use the --allow-empty option to continue, or check your task configuration
husky - pre-commit script failed (code 1) 但是实际上我们需要判断value是否为null，否则value.value会报错 解决办法:
watch(eventInSeries.value, (value) => { // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition if (value?.value) { const isExist = selectedItems.value.some( (item) => item.value === value.value, ); if (!isExist) { selectedItems.value.push(value); } }
}); 局部加上
// eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
说明就可以了 全局配置:
在eslint.config.mjs里( ESLint 的 Flat Config 模式（即新版配置方式），不是传统的 .eslintrc.js。)
rules: { '@typescript-eslint/no-unnecessary-condition': 'off', // ✅ 关闭它！本来设置的是 '@typescript-eslint/no-unnecessary-condition': 'error', },`}]},{path:"/content/tool/front/vue3%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0.html",title:"vue3在线运行平台",pathLocale:"/",contents:[{header:"",slug:"",content:`vue3在线运行平台:
https://play.vuejs.org/ 在线前端项目运行平台，类似sanbox
https://stackblitz.com/`}]},{path:"/content/tool/front/webstorm_watch_limit%E8%BE%BE%E5%88%B0%E4%B8%8A%E9%99%90%E4%B9%8B%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html",title:"webstorm_watch_limit达到上限之解决办法",pathLocale:"/",contents:[{header:"",slug:"",content:`webstorm_watch_limit达到上限之解决办法:
To prevent this situation it is recommended to increase the watches limit (to, say, 512K): 1>.Add the following line to a new *.conf file (e.g. idea.conf) under /etc/sysctl.d/ directory:
fs.inotify.max_user_watches = 524288 2>.Then run this command to apply the change:
sudo sysctl -p --system 3>.And don't forget to restart your IDE. Note: the watch limit is per-account setting. If there are other programs running under the same account that also use inotify, the limit should be raised high enough to suit the needs of all of them. https://intellij-support.jetbrains.com/hc/en-us/articles/15268113529362-Inotify-Watches-Limit-Linux`}]},{path:"/content/tool/front/web%E7%AB%AF%E5%AE%9E%E6%97%B6%E8%BE%93%E5%87%BA%E6%89%A7%E8%A1%8Clog.html",title:"web端实时输出执行log",pathLocale:"/",contents:[{header:"web端实时输出执行log",slug:"web端实时输出执行log",content:"一般使用这个工具 xterm ，就可以输出执行的log信息，尤其是在自动化输出 build 日志的时候，或者 composer install 信息的时候 官网: https://xtermjs.org/ 安装: npm install @xterm/xterm"}]},{path:"/content/tool/front/%E4%BD%BF%E7%94%A8editorconfig%E4%BF%9D%E6%8C%81%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E4%B8%80%E8%87%B4.html",title:"使用editorconfig保持开发环境一致",pathLocale:"/",contents:[{header:"",slug:"",content:`使用editorconfig保持开发环境一致:
1.在webstorm中的使用
打开webStrome > File > settings > Plugins；
在Marketplace中搜索EditorConfig（此时会发现已经默认安装）
若没有安装点击安装 2.只要创建了文件并且IDE也安装并使用了对应的插件，此配置将会强制自动生效
1>创建 .editorconfig 文件
2>配置信息，更多配置可查阅官网 # http://editorconfig.org root = true [*] # 表示所有文件适用
charset = utf-8 # 设置文件字符集为 utf-8
indent_style = space # 缩进风格（tab | space）
indent_size = 4 # 缩进大小
end_of_line = lf # 控制换行类型(lf | cr | crlf)
trim_trailing_whitespace = true # 去除行尾的任意空白字符
insert_final_newline = true # 始终在文件末尾插入一个新行 [*.md] # 表示仅 md 文件适用以下规则
max_line_length = off
trim_trailing_whitespace = false`}]},{path:"/content/tool/front/%E5%89%8D%E7%AB%AF%E4%BD%BF%E7%94%A8strapi%E8%B0%83%E7%94%A8%E6%8E%A5%E5%8F%A3.html",title:"前端使用strapi调用接口",pathLocale:"/",contents:[{header:"",slug:"",content:`前端使用 strapi 调用接口:
https://strapi.nuxtjs.org/setup`}]},{path:"/content/tool/front/%E5%89%8D%E7%AB%AF%E5%8C%85%E5%8F%91%E5%B8%83%E5%92%8C%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86.html",title:"前端包发布和版本管理",pathLocale:"/",contents:[{header:"前端包发布和版本管理工具",slug:"前端包发布和版本管理工具",content:"https://github.com/semantic-release/semantic-release"}]},{path:"/content/tool/front/%E5%89%8D%E7%AB%AF%E6%97%B6%E9%97%B4%E6%97%B6%E5%8C%BA%E8%8E%B7%E5%8F%96%E5%8C%85.html",title:"前端时间时区获取包",pathLocale:"/",contents:[{header:"前端时间时区获取包",slug:"前端时间时区获取包",content:`https://momentjs.com/
https://momentjs.com/timezone/`}]},{path:"/content/tool/front/%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7.html",title:"前端项目代码类型检测工具",pathLocale:"/",contents:[{header:"",slug:"",content:"前端项目代码类型检测工具:\noxlint使用: https://oxc.rs/docs/guide/usage/linter\n注意: We recommend running oxlint before ESLint in your lint-staged or CI setup for a quicker feedback loop, considering it only takes a few seconds to run on large codebases. 同时使用eslint和oxlint: https://github.com/oxc-project/eslint-plugin-oxlint 使用lint相关工具，需要lintstage配置文件:\n有了 `.lintstagedrc.js` 文件后，你就不需要在 `package.json` 中单独配置 `lint-staged` 了。`lint-staged` 会优先读取 `.lintstagedrc.js` 文件中的配置，因此你可以将所有与 lint-staged 相关的配置集中在这个文件中，保持代码的整洁性和可维护性。 如果你已经在 `.lintstagedrc.js` 中定义了需要执行的命令，确保 `package.json` 中的 `lint-staged` 部分没有重复的配置即可。如果 `package.json` 中还有与 `lint-staged` 相关的配置，建议将其删除，以避免混淆或不必要的重复定义。这样做的好处包括： 1. 集中管理：所有 lint-staged 配置集中在一个文件中，易于查看和修改。\n2. 简化 `package.json`：`package.json` 文件更加简洁，不会被冗长的配置占用。\n3. 可扩展性：如果将来需要添加更多 lint-staged 配置，只需在 `.lintstagedrc.js` 中进行，而无需触碰 `package.json`。 总之，使用 `.lintstagedrc.js` 可以使你的项目结构更加清晰。 eslint官网:\nhttps://eslint.org/\n关于new-cap规则:\nhttps://eslint.org/docs/latest/rules/new-cap\n在线平台:\nhttps://eslint.org/play/\n部分规则依赖关系:\n@nuxt/eslint ----->@nuxt/eslint-config----->eslint-plugin-unicorn\n所以 packege.json下配置了 @nuxt/eslint ,那么也会安装后面这两个"}]},{path:"/content/tool/front/%E5%9F%BA%E4%BA%8ENode%E5%AE%9E%E7%8E%B0%E7%9A%84%E8%B7%A8%E5%B9%B3%E5%8F%B0web%E8%B0%83%E8%AF%95%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7.html",title:"基于Node实现的跨平台web调试代理工具",pathLocale:"/",contents:[{header:"",slug:"",content:`基于Node实现的跨平台web调试代理工具:
whistle代理工具:
https://wproxy.org/whistle/`}]},{path:"/content/tool/front/%E5%9F%BA%E4%BA%8Eeslint%E5%92%8Cprettier%E7%9A%84%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96.html",title:"基于eslint和prettier的代码格式化",pathLocale:"/",contents:[{header:"",slug:"",content:`基于eslint和prettier的代码格式化: 在线文档以及在线平台 https://prettier.io/docs/en/
https://prettier.io/playground/ 下面是一个.eslintrc.json文件:
{ "env": { "browser": true, "node": true }, "root": true, "parser": "vue-eslint-parser", "extends": [ "@nuxtjs/eslint-config-typescript", "plugin:prettier/recommended" ], "plugins": ["prettier"], "rules": { // ignore for page names "vue/multi-word-component-names": [ "error", { "ignores": [ "index", "[slug]", "[...slug]", "[id]", "default", "boilerplate", "custom", "error" ] } ], "vue/block-lang": [ "error", { "script": { "lang": "ts" } } ], "vue/block-order": [ "error", { "order": ["template", "script", "style"] }] }
} 但是实际可以简化一点,删除这个 "plugins": ["prettier"]:
{ "env": { "browser": true, "node": true }, "root": true, "parser": "vue-eslint-parser", //这个地方用了 vue-eslint-parser 解析器,该解析器允许我们对 .vue 文件的 <template> 进行检查。如果我们在模板中使用复杂的指令和表达式，就很容易在 <template> 上犯错。这个解析器和 eslint-plugin-vue 的规则可以发现其中的一些错误。 "extends": [ "@nuxt/eslint-config", //这个才是NUXT3的版本 "plugin:prettier/recommended" ], "rules": { // ignore for page names，下面这些，都是 eslint-plugin-vue 的规则的使用，具体可以参考:https://eslint.vuejs.org/rules/block-order.html,这里面定义了很多规则，本来要使用下面的 eslint-plugin-vue,需要先在plugins下引入vue的，即 plugins: ["vue"], 但是由于在配置中使用了 parser: "vue-eslint-parser"，ESLint 会自动查找并使用与所选 parser 相关的插件规则，包括 eslint-plugin-vue。因此，虽然你没有在 plugins 中引入 eslint-plugin-vue，但由于使用了 parser: "vue-eslint-parser"，相关的 Vue.js 规则仍然会生效。这是一种在 Vue.js 项目中使用 ESLint 的常见方式。 "vue/multi-word-component-names": [ "error", { "ignores": [ "index", "[slug]", "[...slug]", "[id]", "default", "boilerplate", "custom", "error" ] } ], "vue/block-lang": [//限制vue页面使用的script，必须定义lang="ts" "error", { "script": { "lang": "ts" } } ], "vue/block-order": [//限制vue页面 ["template", "script", "style"] 三者的顺序 "error", { "order": ["template", "script", "style"] }] }
} 参考:
https://juejin.cn/post/6924568874700505102
https://zhuanlan.zhihu.com/p/68026905
https://github.com/prettier/eslint-plugin-prettier // 这个markdown文档里面有介绍 plugin:prettier/recommended 可以同时设置 eslint-plugin-prettier 和 eslint-config-prettier
https://github.com/nuxt/eslint-config // 在nuxt下使用的话，需要看这个，不同版本的nuxt，安装的不一样，之前的模板项目里面的配置，就有问题，我修改了
https://typescript-eslint.io/getting-started // 这个链接下，是关于 @typescript-eslint/parser 和 @typescript-eslint/eslint-plugin 这两个包的使用，之前模板项目里面配置了，但是我发现没有用到，我就去掉了
https://github.com/nuxt/eslint-plugin-nuxt //这个目前也没用，我也去掉了，但是markdown下有一个配置的两种用法间接的解释了extends和plugins写关系 总结:
①其实大部分最后都会将 prettier 作为主要的格式化样式，但是 prettier 和 其它eslint插件不同的是，它必须包括 eslint-plugin-prettier 和 eslint-config-prettier 两个文件，而 其它的只需要一个就可以了
②extends 、plugins 和 rules 三者之间的关系
在我实际使用看来， extends = plugins + rules plugins:
eslint本身有些规则，但肯定无法包含所有语法，因此eslint支持自定义规则，而针对特殊语法自定义的那些规则我们称之为eslint插件，常见的有： eslint-plugin-import、eslint-plugin-promise、eslint-plugin-react。这些插件都是
单独的package，安装这些插件后，若要是项目支持这些规则，必须将其配置在eslint字段中，比如针对如上三个示例插件的配置：plugins: ["import", 'promise', 'react']。 extends:
plugins的配置仅仅代表在项目中引入了哪些规则，并没有指明该规则是警告、报错、忽略，extends要做的就是引入eslint推荐的规则设置。按照eslint插件的开发规范，每个插件的入口文件都会导出一个对象，其中就有一个configs字段，该字段
是个对象，他可以把该插件已有的规则分成不同的风格，比如：x eslint插件共定义了a、b、c三个规则，这三个规则我可以配置多种风格，比如：
module.exports = { configs: { recommended: { plugins: ["x"], env: ["browser"], rules: { a: 1, b: 0, a: 2, } }, node: { plugins: ["x"], env: ["node"], rules: { a: 0, b: 2, a: 1, } } }
}; 假设我们要选择recommended风格，在extends字段中填写 ["plugin:x/recommended"]。至此，项目便可以基于X语法的recommended风格做代码检测. rules:
当eslint插件没有指定风格时，我们可以基于rules完全自定义一套风格，当某个风格的单个规则不满足需求，在rules中重新设置便可覆盖.`}]},{path:"/project/symfony/part3/part1.html",title:"",pathLocale:"/",contents:[{header:"由于本项目是一个前后端分离项目，所以使用JWT认证",slug:"由于本项目是一个前后端分离项目-所以使用jwt认证",content:""},{header:"1.使用到的 composer 包",slug:"_1-使用到的-composer-包",content:`"doctrine/dbal": "^3",
"doctrine/doctrine-bundle": "^2.14",
"doctrine/doctrine-migrations-bundle": "^3.4",
"doctrine/orm": "^3.3",
"doctrine/persistence": "^3.0", "gesdinet/jwt-refresh-token-bundle": "^1.3",
"lexik/jwt-authentication-bundle": "^3.1",`},{header:"2.doctrine相关的包用于数据库操作",slug:"_2-doctrine相关的包用于数据库操作",content:""},{header:"3.lexik/jwt-authentication-bundle 包用于jwt token的认证",slug:"_3-lexik-jwt-authentication-bundle-包用于jwt-token的认证",content:`执行完: composer require "lexik/jwt-authentication-bundle" 再次执行:
# php bin/console lexik:jwt:generate-keypair
Available options:
--skip-if-exists will silently do nothing if keys already exist.
--overwrite will overwrite your keys if they already exist. 这会在 ~/config/jwt下生成一对 private.pem 和 public.pem 在 .env 下生成:
###> lexik/jwt-authentication-bundle ###
JWT_SECRET_KEY=%kernel.project_dir%/config/jwt/private.pem
JWT_PUBLIC_KEY=%kernel.project_dir%/config/jwt/public.pem
JWT_PASSPHRASE=e6ff1a4be458abe9da450aeac31b23768f400369529878c9758f93303de5750d
###< lexik/jwt-authentication-bundle ### 将上面的配置复制到 .env.local下 详细配置参考官网:
https://symfony.com/bundles/LexikJWTAuthenticationBundle/current/index.html`},{header:"4.lexik/jwt-authentication-bundle 包用于刷新access_token",slug:"_4-lexik-jwt-authentication-bundle-包用于刷新access-token",content:`执行: composer require gesdinet/jwt-refresh-token-bundle
这个默认会装^0.1版本，太底了，和上面的 lexik/jwt-authentication-bundle" 冲突，需要手动指定版本，如下 composer require gesdinet/jwt-refresh-token-bundle "^1.3"
然而还是会报其它错误:
Problem 1 - Root composer.json requires gesdinet/jwt-refresh-token-bundle ^1.3 -> satisfiable by gesdinet/jwt-refresh-token-bundle[v1.3.0, v1.4.0]. - gesdinet/jwt-refresh-token-bundle[v1.3.0, ..., v1.4.0] require doctrine/persistence ^1.3.3|^2.0|^3.0 -> found doctrine/persistence[1.3.3, ..., 1.3.8, 2.0.0, ..., 2.5.7, 3.0.0, ..., 3.4.0] but the package is fixed to 4.0.0 (lock file version) by a partial update and that version does not match. Make sure you list it as an argument for the update command. 执行: composer require "doctrine/persistence": "^3.0" 然后再次执行： composer require gesdinet/jwt-refresh-token-bundle "^1.3" 详细配置参考官网: https://packagist.org/packages/gesdinet/jwt-refresh-token-bundle 配置即可`}]},{path:"/project/symfony/part3/part2.html",title:"",pathLocale:"/",contents:[{header:"由于使用了composer包，基本上不需要单独写认证的逻辑, 主要是一些配置",slug:"由于使用了composer包-基本上不需要单独写认证的逻辑-主要是一些配置",content:""},{header:"1.相关包的配置",slug:"_1-相关包的配置",content:`my_project/
├── bin/
├── config/
│ ├── packages/
│ └── lexik_jwt_authentication.yaml
│ └── gesdinet_jwt_refresh_token.yaml`},{header:"2.lexik_jwt_authentication 配置如下",slug:"_2-lexik-jwt-authentication-配置如下",content:`具体内容:
lexik_jwt_authentication: secret_key: '%kernel.project_dir%/config/jwt/private.pem' public_key: '%kernel.project_dir%/config/jwt/public.pem' pass_phrase: '%env(JWT_PASSPHRASE)%' token_ttl: 3600`},{header:"3.gesdinet_jwt_refresh_token 配置如下",slug:"_3-gesdinet-jwt-refresh-token-配置如下",content:`具体内容:
gesdinet_jwt_refresh_token: refresh_token_class: App\\Entity\\RefreshToken #指定用哪个实体来保存 refresh token（自定义的） ttl: 86400 #默认这个refresh_token有效期是一个月，这里配置为1天 ttl_update: true #每次使用 refresh token 成功刷新后，自动延长它的过期时间, 顺便说一下 ttl_update: true 的效果 当客户端用 refresh token 请求 /api/token/refresh 时，如果刷新成功，会自动把这个 refresh token 的 valid 时间 续期，也就是重新+1小时（或+1天，看你的 ttl 配置）。如果 ttl_update: false，那么 refresh token 用一次就快过期了（不续命）。`},{header:"3.路由配置",slug:"_3-路由配置",content:`在~/config/routes.yaml下添加如下配置: api_login_check: path: /api/login_check
api_refresh_token: path: /api/token/refresh`},{header:"4.firewalls 配置",slug:"_4-firewalls-配置",content:"在~/config/packages/security.yaml下添加如下配置: providers: app_user_provider: entity: class: App\\Entity\\User # 这里定义了 property: email, 那么整个登陆过程就不会调用 User Entity 下的 getUserIdentifier， 实际上是 UserRepository 下的 loadUserByIdentifier, 而是直接使用 email 作为用户登陆的唯一标识 # 根据实际开发需求，需要在 loadUserByIdentifier 下，自定义用户登录库的验证逻辑(拦截验证) # 这个配置告诉 Symfony 应该用哪个字段来查找用户， 两种方式 1.通过直接定义字段的凡是，比如这里的 email，2. 通过 loadUserByIdentifier # property: email firewalls: login: pattern: ^/api/(login|token/refresh) stateless: true json_login: check_path: /api/login_check success_handler: lexik_jwt_authentication.handler.authentication_success failure_handler: lexik_jwt_authentication.handler.authentication_failure refresh_jwt: check_path: /api/token/refresh provider: app_user_provider api: pattern: ^/api stateless: true jwt: ~ dev: pattern: ^/(_(profiler|wdt)|css|images|js)/ security: false # Easy way to control access for large sections of your site # Note: Only the *first* access control that matches will be used access_control: - { path: ^/api/(login|token/refresh), roles: PUBLIC_ACCESS } - { path: ^/api, roles: IS_AUTHENTICATED_FULLY }"}]},{path:"/project/symfony/part3/part3.html",title:"",pathLocale:"/",contents:[{header:"整个登陆模块主要涉及两个表 users 和 refresh_tokens",slug:"整个登陆模块主要涉及两个表-users-和-refresh-tokens",content:""},{header:"1.users表",slug:"_1-users表",content:`1.在~/Entity/下定义User.php <?php namespace App\\Entity; use App\\Repository\\UserRepository;
use Symfony\\Component\\Security\\Core\\User\\PasswordAuthenticatedUserInterface;
use Symfony\\Component\\Security\\Core\\User\\UserInterface;
use Doctrine\\ORM\\Mapping as ORM; #[ORm\\Entity(repositoryClass: UserRepository::class)]
#[ORM\\Table("users")]
class User implements UserInterface, PasswordAuthenticatedUserInterface
{ #[ORM\\Id] #[ORM\\GeneratedValue] #[ORM\\Column] private int $id; #[ORM\\Column(length: 180, unique: true)] private string $email; #[ORM\\Column] private array $roles = []; #[ORM\\Column] private string $password; public function getId(): int { return $this->id; } public function getEmail(): string { return $this->email; } public function setEmail(string $email): self { $this->email = $email; return $this; } /** * A visual identifier that represents this user. */ public function getUserIdentifier(): string { return $this->email; } public function getRoles(): array { $roles = $this->roles; // 保证每个用户至少有 ROLE_USER $roles[] = 'ROLE_USER'; return array_unique($roles); } public function setRoles(array $roles): self { $this->roles = $roles; return $this; } public function getPassword(): string { return $this->password; } public function setPassword(string $password): self { $this->password = $password; return $this; } public function eraseCredentials(): void { // 如果你存储了任何临时敏感数据，请在这里清除 }
} 2.根据这个Entity生成迁移文件 <?php declare(strict_types=1); namespace DoctrineMigrations; use Doctrine\\DBAL\\Schema\\Schema;
use Doctrine\\Migrations\\AbstractMigration; /** * Auto-generated Migration: Please modify to your needs! */
final class Version20250423152250 extends AbstractMigration
{ public function getDescription(): string { return ''; } public function up(Schema $schema): void { // this up() migration is auto-generated, please modify it to your needs // 为什么现在生成的是 <<<'SQL' 而不是普通字符串？ //这是因为： //nowdoc 更安全、更清晰地表示“纯文本” //不会解析其中的变量、特殊字符、换行 //非常适合写多行 SQL，避免用字符串拼接或者转义引号 $this->addSql(<<<'SQL' CREATE TABLE users (id INT AUTO_INCREMENT NOT NULL, email VARCHAR(180) NOT NULL, roles JSON NOT NULL, password VARCHAR(255) NOT NULL, UNIQUE INDEX UNIQ_1483A5E9E7927C74 (email), PRIMARY KEY(id)) DEFAULT CHARACTER SET utf8mb4 COLLATE \`utf8mb4_unicode_ci\` ENGINE = InnoDB SQL); } public function down(Schema $schema): void { // this down() migration is auto-generated, please modify it to your needs $this->addSql(<<<'SQL' DROP TABLE users SQL); }
}`},{header:"2.refresh_tokens 表",slug:"_2-refresh-tokens-表",content:`1.在~/Entity/下定义RefreshToken.php <?php namespace App\\Entity; use Doctrine\\ORM\\Mapping as ORM;
use Gesdinet\\JWTRefreshTokenBundle\\Entity\\RefreshToken as BaseRefreshToken; #[ORM\\Entity(repositoryClass: "Gesdinet\\JWTRefreshTokenBundle\\Entity\\RefreshTokenRepository")]
#[ORM\\Table(name: "refresh_tokens")]
class RefreshToken extends BaseRefreshToken
{
// 注意！这里不需要再声明id字段了，父类 BaseRefreshToken 已经有了， 也就是说
//你自己的 App\\Entity\\RefreshToken，只要 extends 它，就天然有了这4个字段，不需要再手动去定义。如下: //字段 | 类型 | 说明
//id | int | 主键，自增
//refreshToken | string | 生成的 refresh token 值
//username | string | 用户名或者用户的标识
//valid | DateTimeImmutable | refresh token 过期时间
} 2.根据这个Entity生成迁移文件 <?php declare(strict_types=1); namespace DoctrineMigrations; use Doctrine\\DBAL\\Schema\\Schema;
use Doctrine\\Migrations\\AbstractMigration; /** * Auto-generated Migration: Please modify to your needs! */
final class Version20250426154026 extends AbstractMigration
{ public function getDescription(): string { return ''; } public function up(Schema $schema): void { // this up() migration is auto-generated, please modify it to your needs $this->addSql(<<<'SQL' CREATE TABLE refresh_tokens (id INT AUTO_INCREMENT NOT NULL, refresh_token VARCHAR(128) NOT NULL, username VARCHAR(255) NOT NULL, valid DATETIME NOT NULL, UNIQUE INDEX UNIQ_9BACE7E1C74F2195 (refresh_token), PRIMARY KEY(id)) DEFAULT CHARACTER SET utf8mb4 COLLATE \`utf8mb4_unicode_ci\` ENGINE = InnoDB SQL); } public function down(Schema $schema): void { // this down() migration is auto-generated, please modify it to your needs $this->addSql(<<<'SQL' DROP TABLE refresh_tokens SQL); }
}`},{header:"3.执行迁移命令生成对应的表到数据库(相关的命令在文章部分查阅)",slug:"_3-执行迁移命令生成对应的表到数据库-相关的命令在文章部分查阅",content:""},{header:"4.UserRepository 仓库层",slug:"_4-userrepository-仓库层",content:`<?php namespace App\\Repository; use App\\Entity;
use Doctrine\\Bundle\\DoctrineBundle\\Repository\\ServiceEntityRepository;
use Symfony\\Bridge\\Doctrine\\Security\\User\\UserLoaderInterface;
use Symfony\\Component\\Security\\Core\\User\\UserInterface;
use Doctrine\\Persistence\\ManagerRegistry; /** * @extends ServiceEntityRepository<Entity\\User> */
class UserRepository extends ServiceEntityRepository implements UserLoaderInterface
{ public function __construct(ManagerRegistry $registry) { parent::__construct($registry, Entity\\User::class); } public function loadUserByIdentifier(string $identifier): ?UserInterface { //TODO:: 自定义用户认证 }
}`}]},{path:"/project/symfony/part3/part4.html",title:"",pathLocale:"/",contents:[{header:"测试登陆功能",slug:"测试登陆功能",content:""},{header:"1.通过命令生成测试用户",slug:"_1-通过命令生成测试用户",content:`邮箱可以自定义，这里定义为：
gspgsp@gmail.com 密码可以通过如下命令生成：
php bin/console security:hash-password`},{header:"2.postman测试",slug:"_2-postman测试",content:`请求地址:
http://symfony.api.local/api/login_check 参数:
{ "username": "gspgsp@gmail.com", "password": "123qwe"
} 响应:
{ "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpYXQiOjE3NDY2MjkzOTMsImV4cCI6MTc0NjYzMjk5Mywicm9sZXMiOlsiUk9MRV9VU0VSIl0sInVzZXJuYW1lIjoiMjI0OTg3NTk4MEBxcS5jb20ifQ.JkvLwXl77DEUr5TUYQN2Zq5CuMJDk7gnPCsdtukQdiOEjaH5v4jJNIkHJJuEYPE-lkdcIqNVOhbIB_DCqdW2GniOuQYPRdDF02FpGy92h3WCMmrCfJYMfvWZiG-OG1BeM0R-R9Feusar4AlqAFN8fI_YIsslJgJlyaG6Fx4ZrcVX6wD7TkWLBetTzSmoaC8fuNpTACUdtyLxYYZqodpcYHsbxgZITRWgn0xps28GqijnBlo0DVUPdSBoygkdJEDUOXyBCAknz6EbSbyWITaRYs62VjwwwyXxijKi5HltMvbwvVk8ffutHqtrElbBFF11glalK8ISYiXW9tgrOvpG8w", "refresh_token": "rt_cc72bbbde650e9c5b365e2c1a397c0c0a7d4d23811288af3d8528a88bc7bba4d86f564a7feda1c43"
} 证明请求成功`}]},{path:"/project/symfony/part3/part5.html",title:"",pathLocale:"/",contents:[{header:"自定义handler, 主要是自定义json_login的success_handler 和 failure_handler",slug:"自定义handler-主要是自定义json-login的success-handler-和-failure-handler",content:""},{header:"1.修改security.yaml配置",slug:"_1-修改security-yaml配置",content:`providers:
# users_in_memory: { memory: null } app_user_provider: entity: class: App\\Entity\\User firewalls: login: pattern: ^/api/(login|token/refresh) stateless: true json_login: check_path: /api/login_check success_handler: App\\Security\\CustomAuthenticationSuccessHandler failure_handler: App\\Security\\CustomAuthenticationFailureHandler refresh_jwt: check_path: /api/token/refresh provider: app_user_provider api: pattern: ^/api stateless: true jwt: provider: app_user_provider authenticator: app.custom_jwt_authenticator dev: pattern: ^/(_(profiler|wdt)|css|images|js)/ security: false # Easy way to control access for large sections of your site # Note: Only the *first* access control that matches will be used access_control: - { path: ^/api/login_check, roles: PUBLIC_ACCESS } - { path: ^/api/(login|token/refresh), roles: PUBLIC_ACCESS } - { path: ^/api, roles: IS_AUTHENTICATED_FULLY } 主要修改内容为:
修改了默认的 success_handler 和 failure_handler
对于 api 防火墙，添加了自定义的jwt认证`},{header:"2.定义 CustomAuthenticationSuccessHandler 和 CustomAuthenticationFailureHandler",slug:"_2-定义-customauthenticationsuccesshandler-和-customauthenticationfailurehandler",content:`//CustomAuthenticationSuccessHandler
<?php namespace App\\Security; use Gesdinet\\JWTRefreshTokenBundle\\Model\\RefreshTokenManagerInterface;
use Gesdinet\\JWTRefreshTokenBundle\\Entity\\RefreshToken;
use Lexik\\Bundle\\JWTAuthenticationBundle\\Services\\JWTTokenManagerInterface;
use Symfony\\Component\\HttpFoundation\\JsonResponse;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;
use Symfony\\Component\\Security\\Http\\Authentication\\AuthenticationSuccessHandlerInterface;
use Symfony\\Component\\DependencyInjection\\ParameterBag\\ParameterBagInterface; class CustomAuthenticationSuccessHandler implements AuthenticationSuccessHandlerInterface
{ public function __construct( private JWTTokenManagerInterface $jwtManager, private RefreshTokenManagerInterface $refreshTokenManager, private ParameterBagInterface $params, ) {} public function onAuthenticationSuccess(Request $request, TokenInterface $token): JsonResponse { $user = $token->getUser(); $jwt = $this->jwtManager->create($user); // 读取配置的 ttl $ttl = $this->params->get('gesdinet_jwt_refresh_token.ttl'); $validUntil = (new \\DateTimeImmutable())->modify("+$ttl seconds"); $refreshTokenString = $this->generateSecureRefreshToken(); $refreshToken = new RefreshToken(); $refreshToken ->setRefreshToken($refreshTokenString) ->setUsername($user->getUserIdentifier()) ->setValid($validUntil); $this->refreshTokenManager->save($refreshToken); return new JsonResponse([ 'access_token' => $jwt, 'refresh_token' => $refreshTokenString, ]); } private function generateSecureRefreshToken(): string { try { return 'rt_' . bin2hex(random_bytes(40)); // 40 bytes = 80 hex chars } catch (\\Exception $e) { throw new \\RuntimeException('can not generate a security refresh token', 0, $e); } }
} //CustomAuthenticationFailureHandler
<?php namespace App\\Security; use Symfony\\Component\\HttpFoundation\\JsonResponse;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\Security\\Core\\Exception\\AuthenticationException;
use Symfony\\Component\\Security\\Http\\Authentication\\AuthenticationFailureHandlerInterface;
use Symfony\\Component\\Security\\Core\\Exception\\BadCredentialsException;
use Symfony\\Component\\Security\\Core\\Exception\\CustomUserMessageAuthenticationException; class CustomAuthenticationFailureHandler implements AuthenticationFailureHandlerInterface
{ public function onAuthenticationFailure(Request $request, AuthenticationException $exception): JsonResponse { $message = 'Authentication failed.'; if ($exception instanceof BadCredentialsException) { $message = 'Invalid username or password.'; } elseif ($exception instanceof CustomUserMessageAuthenticationException) { $message = $exception->getMessage(); } return new JsonResponse(['status' => 401, 'message' => $message], JsonResponse::HTTP_UNAUTHORIZED); }
}`},{header:"3.自定义 authenticator: app.custom_jwt_authenticator",slug:"_3-自定义-authenticator-app-custom-jwt-authenticator",content:`//CustomJwtAuthenticator
<?php namespace App\\Security; use Lexik\\Bundle\\JWTAuthenticationBundle\\Security\\Authenticator\\JWTAuthenticator;
use Lexik\\Bundle\\JWTAuthenticationBundle\\Services\\JWTTokenManagerInterface;
use Lexik\\Bundle\\JWTAuthenticationBundle\\TokenExtractor\\TokenExtractorInterface;
use Symfony\\Component\\HttpFoundation\\Request;
use Symfony\\Component\\Security\\Core\\Exception\\AuthenticationException as SymfonyAuthenticationException;
use Symfony\\Component\\Security\\Core\\Exception\\CustomUserMessageAuthenticationException;
use Symfony\\Component\\Security\\Core\\User\\UserProviderInterface;
use Symfony\\Component\\Security\\Http\\Authenticator\\Passport\\Passport;
use Symfony\\Contracts\\EventDispatcher\\EventDispatcherInterface;
use Symfony\\Contracts\\Translation\\TranslatorInterface; class CustomJwtAuthenticator extends JWTAuthenticator
{ public function __construct( JWTTokenManagerInterface $jwtManager, EventDispatcherInterface $eventDispatcher, TokenExtractorInterface $tokenExtractor, UserProviderInterface $userProvider, ?TranslatorInterface $translator = null, ) { parent::__construct($jwtManager, $eventDispatcher, $tokenExtractor, $userProvider, $translator); } public function supports(Request $request): ?bool { return str_starts_with($request->getPathInfo(), '/api/'); } public function authenticate(Request $request): Passport { try { $passport = parent::authenticate($request); } catch (\\LogicException $exception) { throw new CustomUserMessageAuthenticationException("User not logged in. Please authenticate to proceed.:".$exception->getMessage()); } catch (SymfonyAuthenticationException $exception) { throw new CustomUserMessageAuthenticationException("Login failed.:".$exception->getMessage()); } return $passport; }
} 然后在services.yaml下配置 app.custom_jwt_authenticator: class: App\\Security\\CustomJwtAuthenticator parent: lexik_jwt_authentication.security.jwt_authenticator`},{header:"4.再次登陆测试，依然可以登陆成功",slug:"_4-再次登陆测试-依然可以登陆成功",content:""},{header:"5.使用access_token访问指定的路由",slug:"_5-使用access-token访问指定的路由",content:`请求地址:
http://symfony.api.local/api/lucky/number 参数:
header 参数
Authorization:Bearer {{access_token}} 响应:
{ "code": 401, "message": "Login failed.:"
}
发现是使用的是错误的token 使用最新的access_token:
<html> <body> Lucky number: 44 </body>
</html> 请求成功`}]},{path:"/title/database/mongodb/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/mysql/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/mysql/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/mysql/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/mysql/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/postgressql/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/database/redis/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base7.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/html/base8.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base10.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base11.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base12.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base13.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base14.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base15.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base16.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base17.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base7.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base8.html",title:"",pathLocale:"/",contents:[]},{path:"/title/front/js/base9.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/base/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/base/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/base/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/base/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/base/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/go/gin/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/interview/golang/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/java/base/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/java/spring/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/linux/command/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/linux/command/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/linux/command/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/linux/nginx/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/linux/nginx/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/llm/ai/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/git/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/other/spread/base7.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/base/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/laravel/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/laravel/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base10.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base5.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base6.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base7.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base8.html",title:"",pathLocale:"/",contents:[]},{path:"/title/php/symfony/base9.html",title:"",pathLocale:"/",contents:[]},{path:"/title/search/solr/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/deploy/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/docker/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/docker/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/docker/base3.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/docker/base4.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/k8s/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/service/micro/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/tool/back/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/tool/front/base1.html",title:"",pathLocale:"/",contents:[]},{path:"/title/tool/front/base2.html",title:"",pathLocale:"/",contents:[]},{path:"/404.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:"404 Not Found"}]}],H="update-vuepress-search-plugin-index";var _=E(U),q=k(()=>{const e=new Map;for(const t of _.value)e.set(t.path,t);return e});import.meta.webpackHot&&(__VUE_HMR_RUNTIME__[H]=e=>{_.value=e});function j(e){const t=E([]);let r=null;return D(e,()=>{r&&clearTimeout(r),r=setTimeout(s,100)}),t;function s(){const c=e.value.toLowerCase().trim();if(!c){t.value=[];return}const a=new Map,n=new Set;for(const o of _.value)for(const i of G(o,c)){n.add(i.parentPageTitle);let l=a.get(i.parentPageTitle);l||(l=[],a.set(i.parentPageTitle,l)),l.push(i)}const p=[...n].sort((o,i)=>{const l=a.get(o);return a.get(i).length-l.length});t.value=[...a].flatMap(([,o])=>o).sort((o,i)=>o.parentPagePriority-i.parentPagePriority||p.indexOf(o.parentPageTitle)-p.indexOf(i.parentPageTitle)||o.priority-i.priority)}}function*G(e,t){const r=w(e.title,t);if(r){yield{path:e.path,parentPageTitle:A(e),title:e.title,display:r,page:e,content:null,parentPagePriority:1,priority:1};return}for(const s of e.contents){const c=w(s.header,t);if(c){yield{path:e.path+(s.slug?`#${s.slug}`:""),parentPageTitle:A(e),title:e.title,display:c,page:e,content:null,parentPagePriority:10,priority:2};continue}const a=w(s.content,t);a&&(yield{path:e.path+(s.slug?`#${s.slug}`:""),parentPageTitle:A(e),title:e.title,display:[{type:"header",str:`${s.header}
`},...a],page:e,content:null,parentPagePriority:10,priority:10})}}function A(e){const t=e.path.split("/");let r="/";return t[1]&&(r=`/${t[1]}/`),(q.value.get(r)||e).title}function w(e,t){const r=[];let s=0;const c=e.toLowerCase().replace(/\s/gu," ");let a=0,n=c.indexOf(t,a);if(n<0)return null;for(;n>=0;){const o=n+t.length;if(p(e.slice(a,n),"normal"),p(e.slice(n,o),"highlight"),a=o,n=c.indexOf(t,a),s>100)break}return p(e.slice(a),"normal"),r.filter(o=>o.str);function p(o,i){let l=o;i==="normal"&&l.length>100&&s===0&&(l=`… ${l.slice(-10)}`);let h=!1;if(s+l.length>100){if(r.some(g=>g.type==="ellipsis"))return;l=l.slice(0,Math.max(100-s,1)),h=!0}r.push({type:i,str:l}),s+=l.length,h&&(r.push({type:"ellipsis",str:" …"}),s+=2)}}var V={"/":{placeholder:"Search"},"/zh/":{placeholder:"搜索"}};const W=V,z=R({name:"SearchBox",props:{locales:{type:Object,required:!1,default:()=>W}},setup(e){const{locales:t}=I(e),r=E(""),s=E(!1),c=E(-1),a=j(r),n=k(()=>r.value&&s.value&&a.value.length),p=L(),o=$(),i=k(()=>t.value[o.value]??{});function l(){if(!n.value)return;let d=c.value-1;d<0&&(d=a.value.length-1),g(d)}function h(){if(!n.value)return;let d=c.value+1;d>=a.value.length&&(d=0),g(d)}function g(d){c.value=d}function P(){c.value=-1}function T(d){if(!n.value)return;const S=a.value[d];S&&p.push(S.path)}return{query:r,focused:s,focusIndex:c,suggestions:a,activeSuggestion:n,onUp:l,onDown:h,focus:g,unfocus:P,go:T,locale:i}}}),Y={class:"search-box",role:"search"},J=["placeholder"],Q=["onMousedown","onMouseenter"],K=["href"],X={key:0,class:"parent-page-title"},Z={class:"suggestion-row"},ee={class:"page-title"},te={class:"suggestion-content"};function ne(e,t,r,s,c,a){return u(),m("div",Y,[M(f("input",{ref:"input","onUpdate:modelValue":t[0]||(t[0]=n=>e.query=n),"aria-label":"Search",class:b({focused:e.focused}),placeholder:e.locale.placeholder??"Search",autocomplete:"off",spellcheck:"false",onFocus:t[1]||(t[1]=()=>e.focused=!0),onBlur:t[2]||(t[2]=()=>e.focused=!1),onKeyup:[t[3]||(t[3]=y(n=>e.go(e.focusIndex),["enter"])),t[4]||(t[4]=y((...n)=>e.onUp&&e.onUp(...n),["up"])),t[5]||(t[5]=y((...n)=>e.onDown&&e.onDown(...n),["down"]))]},null,42,J),[[O,e.query]]),e.activeSuggestion?(u(),m("ul",{key:0,class:"suggestions",onMouseleave:t[7]||(t[7]=(...n)=>e.unfocus&&e.unfocus(...n))},[(u(!0),m(B,null,x(e.suggestions,(n,p)=>(u(),m("li",{key:p,class:b(["suggestion",{focused:p===e.focusIndex}]),onMousedown:o=>e.go(p),onMouseenter:o=>e.focus(p)},[f("a",{href:n.path,onClick:t[6]||(t[6]=F(()=>{},["prevent"]))},[n.parentPageTitle&&(!e.suggestions[p-1]||e.suggestions[p-1].parentPageTitle!==n.parentPageTitle)?(u(),m("div",X,v(n.parentPageTitle),1)):C("",!0),f("div",Z,[f("div",ee,v(n.title||n.path),1),f("div",te,[(u(!0),m(B,null,x(n.display,(o,i)=>(u(),m("span",{key:i,class:b(o.type)},v(o.str),3))),128))])])],8,K)],42,Q))),128))],32)):C("",!0)])}const se=N(z,[["render",ne],["__scopeId","data-v-73dbe2ba"],["__file","SearchBox.vue"]]);export{se as default};
